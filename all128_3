[ 
  {
    "released_date": "20160511", 
    "overall_handling_caveats": [], 
    "id": "20160511|fromsiginttohuminttosigint(throughhumint)part1", 
    "document_date": "2005-03-10 00:00:00", 
    "codewords": [], 
    "agency": [
      "NSA"
    ], 
    "sub_paragraphs_classifications": [
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": null, 
        "paragraph_text": "dynamic page -- highest possible classification is ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret // si / tk // rel to usa aus can gbr nzl ", 
        "paragraph_relto": [
          "United Kingdom", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "Canada"
        ]
      }, 
      {
        "paragraph_handling_caveats": [
          "fouo"
        ], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "(u//fouo) from sigint to humint to sigint (through humint) -- part 1 from: eric fair intelligence analysis intern run date: 03/10/2005 ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "how a sigint'er became an interrogator in iraq, and what he learned as a result. (s) ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s) in december of 2003, just weeks into my first tour at the nsa and against the advice of a number of people, i resigned my position as an intelligence analyst and took a job as a contractor in iraq. having watched my old unit, the 101st, take casualties in mosul, i found myself unable to resist the urge to be more closely involved in the conflict. my years as a police officer, combined with my security clearance and some formal humint training in the army, opened the door for me to be hired on as one of the first few civilians assigned to abu ghraib prison as an interrogator. though my only goal at the time was to get to iraq, it turned out to be an incredible introduction to the discipline of humint that in turn would become a great tool for me in my career with sigint. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s) though much has been written and spoken about the dreadful conditions at abu ghraib, what became readily apparent to me as i looked out at the huge collection of iraqi prisoners was the vast goldmine of intelligence available to be gathered. it was an exciting realization for me that the faceless voices i had listened to as a linguist in the army were now standing in front of me in the flesh. it was a once in a lifetime opportunity for anyone in the intelligence field. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s) i had always been limited to gathering only the information a target would reveal in a conversation, searching for small clues and hints, never having the ability to pry deeper when a target seemed to have vital information. now i would have the opportunity to get to know these targets, ask them questions about their personal lives, gain a better understanding of who they were, and actually design and tailor specific approaches for each individual. it was an opportunity never afforded to me in sigint and i was excited to get started. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s) the overwhelming number of detainees provided us an endless supply of interrogations to conduct. my interrogations lasted anywhere from 2 minutes to 2 hours and i conducted as many as i could in a day. the harder i worked, the quicker the days went by and the closer i got to home. though mortar, rocket and small arms attacks remained constant, the insurgency hadn't yet gathered full steam and the hope was to cut it off before it got worse. it was apparent however that we were bringing in more prisoners than we could process, and as the numbers grew, so too did the ominous feeling that things were going downhill. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s) in early march of 2004, in an attempt to sort through the detainees more efficiently and prevent abu ghraib from becoming overcrowded, i began traveling between abu ghraib and camp st. mere in fallujah in order to set up a division level interrogation facility with the 82nd airborne (abn). because the numbers at the facility in fallujah were more manageable, i was able to spend more time with fewer detainees. i focused on building relationships and found that i would get favorable reactions when i attempted to use my rusty arabic skills. detainees found themselves laughing at my terrible accent and limited iraqi vocabulary and it became a great tool for me to break the tension and open doors. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s) gathering actual intelligence in the interrogations was not easy, and there were far more failure than success stories. most detainees were scared and apprehensive, and it was all i could do to get them talking about basic biographical information let alone their knowledge of the insurgency. when the success stories would come, it was often because the detainee was tired and worn out from his ordeal and hoped to gain something by providing information. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s) my most successful interrogation was with a man who sat down in my interrogation booth, asked for a cigarette and something sweet, and without provocation spent the next 3 days with me naming names, locating weapon caches, cataloging groups involved in attacks, and providing specific information about future operations. i began to realize that the collection of humint could be just as frustrating as the collection of sigint. as with sigint, there were a variety of approaches i could use and a number of tools at my disposal, but if the target chose not to cooperate, there was only so much i could accomplish. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s) as my arabic and interviewing skills improved, and as more and more contractors resigned their positions and headed home, a number of doors opened up for me in iraq. after surviving the uprising in fallujah in april, and the increasing number of ied* attacks on the road between camp st. mere and abu ghraib, i was transferred back to baghdad to work the front gates of camp victory. my job there was less about interrogations and more about getting to know all the workers who lined up outside every day to come on base and work for the coalition. i looked to make friends by handing out cigarettes and chocolate and in return got help identifying strangers in the community who warranted closer attention. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s) i spent my final two months in iraq getting to know iraqis. i learned about their lives under saddam, their experiences in the iran-iraq war, their views of sunni, shia, christian, kurd and jew, their lives now with and without electricity, and their cautious hope for the changeover and election that was to come. i learned the difference between the privilege and the hardship that membership in the baath party offered, the lure of a few dollars to risk working with americans, the variety of sermons in the thousands of mosques, and the motivation behind placing a bomb on the street for a few hundred american dollars. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s) the countless hours i spent outside the gates talking with iraqis from a variety of backgrounds became the most valuable experience of my life. but as the number of close calls continued to rise, and as i found myself missing my wife more and more, i decided in june of 2004 that six months in iraq had been enough and it was time to come home. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "(u) read the conclusion of this article tomorrow! ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "(u) note: ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "(u) ied = improvised explosive device ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [
          "fouo"
        ], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "\"(u//fouo) sidtoday articles may not be republished or reposted outside nsanet without the consent of s0121 (dl sid comms).\" dynamic page -- highest possible classification is ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret // si / tk // rel to usa aus can gbr nzl derived from: nsa/cssm 1-52, dated 08 jan 2007 declassify on: 20320108 ", 
        "paragraph_relto": [
          "United Kingdom", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "Canada"
        ]
      }
    ], 
    "pdf_paths": [
      "2005-03-10-SIDToday-From-SIGINT-to-HUMINT-to.pdf"
    ], 
    "overall_classification": null, 
    "description": "This SIDToday article from 10 March 2005 details the experiences of Eric Fair, a US interrogator in Iraq who went on to work for the NSA. In his memoirs, published in 2016, Fair admits self-censoring in order not to disclose his moral qualms to colleagues: see the Intercept article The Secret NSA Diary of an [\u2026]", 
    "plain_text": "\ufeffDYNAMIC PAGE -- HIGHEST POSSIBLE CLASSIFICATION IS\r\n\r\nTOP SECRET // SI / TK // REL TO USA AUS CAN GBR NZL\r\n\r\n(U//FOUO) From SIGINT to HUMINT to SIGINT (through HUMINT) --\r\npart 1\r\n\r\nFROM: Eric Fair\r\nIntelligence Analysis Intern\r\nRun Date: 03/10/2005\r\n\r\nHow a SIGINT'er became an interrogator in Iraq, and what he learned as a result. (S)\r\n\r\n(S) In December of 2003, just weeks into my first tour at the NSA and against the advice of a\r\nnumber of people, I resigned my position as an Intelligence Analyst and took a job as a\r\ncontractor in Iraq. Having watched my old unit, the 101st, take casualties in Mosul, I found\r\nmyself unable to resist the urge to be more closely involved in the conflict. My years as a police\r\nofficer, combined with my security clearance and some formal HUMINT training in the Army,\r\nopened the door for me to be hired on as one of the first few civilians assigned to Abu Ghraib\r\nprison as an interrogator. Though my only goal at the time was to get to Iraq, it turned out to\r\nbe an incredible introduction to the discipline of HUMINT that in turn would become a great tool\r\nfor me in my career with SIGINT.\r\n\r\n(S) Though much has been written and spoken about the dreadful conditions at Abu Ghraib,\r\nwhat became readily apparent to me as I looked out at the huge collection of Iraqi prisoners was\r\nthe vast goldmine of intelligence available to be gathered. It was an exciting realization for me\r\nthat the faceless voices I had listened to as a linguist in the Army were now standing in front of\r\nme in the flesh. It was a once in a lifetime opportunity for anyone in the intelligence field.\r\n\r\n(S) I had always been limited to gathering only the information a target would reveal in a\r\nconversation, searching for small clues and hints, never having the ability to pry deeper when a\r\ntarget seemed to have vital information. Now I would have the opportunity to get to know these\r\ntargets, ask them questions about their personal lives, gain a better understanding of who they\r\nwere, and actually design and tailor specific approaches for each individual. It was an\r\nopportunity never afforded to me in SIGINT and I was excited to get started.\r\n\r\n(S) The overwhelming number of detainees provided us an endless supply of interrogations to\r\nconduct. My interrogations lasted anywhere from 2 minutes to 2 hours and I conducted as many\r\nas I could in a day. The harder I worked, the quicker the days went by and the closer I got to\r\nhome. Though mortar, rocket and small arms attacks remained constant, the insurgency hadn't\r\nyet gathered full steam and the hope was to cut it off before it got worse. It was apparent\r\nhowever that we were bringing in more prisoners than we could process, and as the numbers\r\ngrew, so too did the ominous feeling that things were going downhill.\r\n\r\n(S) In early March of 2004, in an attempt to sort through the detainees more efficiently and\r\nprevent Abu Ghraib from becoming overcrowded, I began traveling between Abu Ghraib and\r\nCamp St. Mere in Fallujah in order to set up a Division level interrogation facility with the 82nd\r\nAirborne (ABN). Because the numbers at the facility in Fallujah were more manageable, I was\r\nable to spend more time with fewer detainees. I focused on building relationships and found that\r\nI would get favorable reactions when I attempted to use my rusty Arabic skills. Detainees found\r\nthemselves laughing at my terrible accent and limited Iraqi vocabulary and it became a great\r\ntool for me to break the tension and open doors.\r\n\r\n(S) Gathering actual intelligence in the interrogations was not easy, and there were far more\r\nfailure than success stories. Most detainees were scared and apprehensive, and it was all I could\r\ndo to get them talking about basic biographical information let alone their knowledge of the\r\ninsurgency. When the success stories would come, it was often because the detainee was tired\r\nand worn out from his ordeal and hoped to gain something by providing information.\r\n\r\n(S) My most successful interrogation was with a man who sat down in my interrogation booth,\r\nasked for a cigarette and something sweet, and without provocation spent the next 3 days with\r\n\r\nme naming names, locating weapon caches, cataloging groups involved in attacks, and providing\r\nspecific information about future operations. I began to realize that the collection of HUMINT\r\ncould be just as frustrating as the collection of SIGINT. As with SIGINT, there were a variety of\r\napproaches I could use and a number of tools at my disposal, but if the target chose not to\r\ncooperate, there was only so much I could accomplish.\r\n\r\n(S) As my Arabic and interviewing skills improved, and as more and more contractors resigned\r\ntheir positions and headed home, a number of doors opened up for me in Iraq. After surviving\r\nthe uprising in Fallujah in April, and the increasing number of IED* attacks on the road between\r\nCamp St. Mere and Abu Ghraib, I was transferred back to Baghdad to work the front gates of\r\nCamp Victory. My job there was less about interrogations and more about getting to know all the\r\nworkers who lined up outside every day to come on base and work for the coalition. I looked to\r\nmake friends by handing out cigarettes and chocolate and in return got help identifying\r\nstrangers in the community who warranted closer attention.\r\n\r\n(S) I spent my final two months in Iraq getting to know Iraqis. I learned about their lives under\r\nSaddam, their experiences in the Iran-Iraq war, their views of Sunni, Shia, Christian, Kurd and\r\nJew, their lives now with and without electricity, and their cautious hope for the changeover and\r\nelection that was to come. I learned the difference between the privilege and the hardship that\r\nmembership in the Baath party offered, the lure of a few dollars to risk working with Americans,\r\nthe variety of sermons in the thousands of mosques, and the motivation behind placing a bomb\r\non the street for a few hundred American dollars.\r\n\r\n(S) The countless hours I spent outside the gates talking with Iraqis from a variety of\r\nbackgrounds became the most valuable experience of my life. But as the number of close calls\r\ncontinued to rise, and as I found myself missing my wife more and more, I decided in June of\r\n2004 that six months in Iraq had been enough and it was time to come home.\r\n\r\n(U) Read the conclusion of this article tomorrow!\r\n\r\n(U) Note:\r\n\r\n(u) IED = Improvised explosive device\r\n\r\n\"(U//FOUO) SIDtoday articles may not be republished or reposted outside NSANet\r\nwithout the consent of S0121 (DL sid comms).\"\r\n\r\nDYNAMIC PAGE -- HIGHEST POSSIBLE CLASSIFICATION IS\r\nTOP SECRET // SI / TK // REL TO USA AUS CAN GBR NZL\r\nDERIVED FROM: NSA/CSSM 1-52, DATED 08 JAN 2007 DECLASSIFY ON: 20320108", 
    "sigads": [], 
    "overall_relto": [], 
    "countries_mentioned": [
      "Iran (IRN/IR)", 
      "Iraq (IRQ/IQ)", 
      "United States (USA/US)"
    ], 
    "link": "https://edwardsnowden.com/2016/05/15/from-sigint-to-humint-to-sigint-through-humint-part-1/", 
    "document_topic": [
      "SIDtoday"
    ], 
    "pub_date": "Sun, 15 May 2016 19:38:12 +0000", 
    "article_links": [
      "https://theintercept.com/2016/05/11/the-secret-nsa-diary-of-an-abu-ghraib-interrogator/"
    ], 
    "categories": [
      "Revealed documents", 
      "101st", 
      "abu ghraib", 
      "arabic", 
      "camp st mere", 
      "camp victory", 
      "eric fair", 
      "fallujah", 
      "ied", 
      "intelligence analysis intern", 
      "interrogation", 
      "interrogator", 
      "iraq", 
      "mosul", 
      "nsa_orig", 
      "sidtoday"
    ], 
    "title": "From SIGINT to HUMINT to SIGINT (through HUMINT) \u2013 part 1", 
    "doc_text": "\ufeffDYNAMIC PAGE -- HIGHEST POSSIBLE CLASSIFICATION IS\r\n\r\nTOP SECRET // SI / TK // REL TO USA AUS CAN GBR NZL\r\n\r\n(U//FOUO) From SIGINT to HUMINT to SIGINT (through HUMINT) --\r\npart 1\r\n\r\nFROM: Eric Fair\r\nIntelligence Analysis Intern\r\nRun Date: 03/10/2005\r\n\r\nHow a SIGINT'er became an interrogator in Iraq, and what he learned as a result. (S)\r\n\r\n(S) In December of 2003, just weeks into my first tour at the NSA and against the advice of a\r\nnumber of people, I resigned my position as an Intelligence Analyst and took a job as a\r\ncontractor in Iraq. Having watched my old unit, the 101st, take casualties in Mosul, I found\r\nmyself unable to resist the urge to be more closely involved in the conflict. My years as a police\r\nofficer, combined with my security clearance and some formal HUMINT training in the Army,\r\nopened the door for me to be hired on as one of the first few civilians assigned to Abu Ghraib\r\nprison as an interrogator. Though my only goal at the time was to get to Iraq, it turned out to\r\nbe an incredible introduction to the discipline of HUMINT that in turn would become a great tool\r\nfor me in my career with SIGINT.\r\n\r\n(S) Though much has been written and spoken about the dreadful conditions at Abu Ghraib,\r\nwhat became readily apparent to me as I looked out at the huge collection of Iraqi prisoners was\r\nthe vast goldmine of intelligence available to be gathered. It was an exciting realization for me\r\nthat the faceless voices I had listened to as a linguist in the Army were now standing in front of\r\nme in the flesh. It was a once in a lifetime opportunity for anyone in the intelligence field.\r\n\r\n(S) I had always been limited to gathering only the information a target would reveal in a\r\nconversation, searching for small clues and hints, never having the ability to pry deeper when a\r\ntarget seemed to have vital information. Now I would have the opportunity to get to know these\r\ntargets, ask them questions about their personal lives, gain a better understanding of who they\r\nwere, and actually design and tailor specific approaches for each individual. It was an\r\nopportunity never afforded to me in SIGINT and I was excited to get started.\r\n\r\n(S) The overwhelming number of detainees provided us an endless supply of interrogations to\r\nconduct. My interrogations lasted anywhere from 2 minutes to 2 hours and I conducted as many\r\nas I could in a day. The harder I worked, the quicker the days went by and the closer I got to\r\nhome. Though mortar, rocket and small arms attacks remained constant, the insurgency hadn't\r\nyet gathered full steam and the hope was to cut it off before it got worse. It was apparent\r\nhowever that we were bringing in more prisoners than we could process, and as the numbers\r\ngrew, so too did the ominous feeling that things were going downhill.\r\n\r\n(S) In early March of 2004, in an attempt to sort through the detainees more efficiently and\r\nprevent Abu Ghraib from becoming overcrowded, I began traveling between Abu Ghraib and\r\nCamp St. Mere in Fallujah in order to set up a Division level interrogation facility with the 82nd\r\nAirborne (ABN). Because the numbers at the facility in Fallujah were more manageable, I was\r\nable to spend more time with fewer detainees. I focused on building relationships and found that\r\nI would get favorable reactions when I attempted to use my rusty Arabic skills. Detainees found\r\nthemselves laughing at my terrible accent and limited Iraqi vocabulary and it became a great\r\ntool for me to break the tension and open doors.\r\n\r\n(S) Gathering actual intelligence in the interrogations was not easy, and there were far more\r\nfailure than success stories. Most detainees were scared and apprehensive, and it was all I could\r\ndo to get them talking about basic biographical information let alone their knowledge of the\r\ninsurgency. When the success stories would come, it was often because the detainee was tired\r\nand worn out from his ordeal and hoped to gain something by providing information.\r\n\r\n(S) My most successful interrogation was with a man who sat down in my interrogation booth,\r\nasked for a cigarette and something sweet, and without provocation spent the next 3 days with\r\n\r\nme naming names, locating weapon caches, cataloging groups involved in attacks, and providing\r\nspecific information about future operations. I began to realize that the collection of HUMINT\r\ncould be just as frustrating as the collection of SIGINT. As with SIGINT, there were a variety of\r\napproaches I could use and a number of tools at my disposal, but if the target chose not to\r\ncooperate, there was only so much I could accomplish.\r\n\r\n(S) As my Arabic and interviewing skills improved, and as more and more contractors resigned\r\ntheir positions and headed home, a number of doors opened up for me in Iraq. After surviving\r\nthe uprising in Fallujah in April, and the increasing number of IED* attacks on the road between\r\nCamp St. Mere and Abu Ghraib, I was transferred back to Baghdad to work the front gates of\r\nCamp Victory. My job there was less about interrogations and more about getting to know all the\r\nworkers who lined up outside every day to come on base and work for the coalition. I looked to\r\nmake friends by handing out cigarettes and chocolate and in return got help identifying\r\nstrangers in the community who warranted closer attention.\r\n\r\n(S) I spent my final two months in Iraq getting to know Iraqis. I learned about their lives under\r\nSaddam, their experiences in the Iran-Iraq war, their views of Sunni, Shia, Christian, Kurd and\r\nJew, their lives now with and without electricity, and their cautious hope for the changeover and\r\nelection that was to come. I learned the difference between the privilege and the hardship that\r\nmembership in the Baath party offered, the lure of a few dollars to risk working with Americans,\r\nthe variety of sermons in the thousands of mosques, and the motivation behind placing a bomb\r\non the street for a few hundred American dollars.\r\n\r\n(S) The countless hours I spent outside the gates talking with Iraqis from a variety of\r\nbackgrounds became the most valuable experience of my life. But as the number of close calls\r\ncontinued to rise, and as I found myself missing my wife more and more, I decided in June of\r\n2004 that six months in Iraq had been enough and it was time to come home.\r\n\r\n(U) Read the conclusion of this article tomorrow!\r\n\r\n(U) Note:\r\n\r\n(u) IED = Improvised explosive device\r\n\r\n\"(U//FOUO) SIDtoday articles may not be republished or reposted outside NSANet\r\nwithout the consent of S0121 (DL sid comms).\"\r\n\r\nDYNAMIC PAGE -- HIGHEST POSSIBLE CLASSIFICATION IS\r\nTOP SECRET // SI / TK // REL TO USA AUS CAN GBR NZL\r\nDERIVED FROM: NSA/CSSM 1-52, DATED 08 JAN 2007 DECLASSIFY ON: 20320108", 
    "pdf": [
      "https://edwardsnowden.com/wp-content/uploads/2016/05/2005-03-10-SIDToday-From-SIGINT-to-HUMINT-to.pdf"
    ]
  }, 
  {
    "released_date": "20130621", 
    "overall_handling_caveats": [], 
    "id": "20130621|accesstothefuture", 
    "document_date": "0000-00-00 00:00:00", 
    "codewords": [
      "TEMPORA"
    ], 
    "agency": [
      "GCHQ"
    ], 
    "sub_paragraphs_classifications": [
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": null, 
        "paragraph_text": "conclusion ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 you are in a privileged position  repay that trust, o you have ready access to a lot of sensitive data, o understand your legal obligations  dont become a case study in a future legalities training presentation, o if you have legal or ethical concerns, speak to someone: they will be taken seriously. 9 you are in an enviable position  have fun and make the most of it. ", 
        "paragraph_relto": []
      }
    ], 
    "pdf_paths": [
      "Access-to-the-future-2-006.jpg"
    ], 
    "overall_classification": null, 
    "description": "This concluding slide from an undated GCHQ presentation on Tempora reminds analysts that they are in a \u201cenviable\u201d and \u201cprivileged\u201d position \u2013 \u201cyou have access to a lot of sensitive data\u2026 have fun and make the most of it\u201d: see the Guardian article Mastering the internet: how GCHQ set out to spy on the world [\u2026]", 
    "plain_text": "\ufeffConclusion\r\n\r\nTOP SECRET STRAP1\r\n\r\n\u00ae You are in a privileged position \u2014 repay that trust,\r\no You have ready access to a lot of sensitive data,\r\no Understand your legal obligations \u2014 don\u2019t become a case\r\nstudy in a future legalities training presentation,\r\no If you have legal or ethical concerns, speak to someone: they\r\nwill be taken seriously.\r\n\r\n9 You are in an enviable position \u2014 have fun and make the\r\nmost of it.", 
    "sigads": [], 
    "overall_relto": [], 
    "countries_mentioned": [], 
    "link": "https://edwardsnowden.com/2016/05/01/access-to-the-future/", 
    "document_topic": [
      "Internet Metadata", 
      "Internet Content"
    ], 
    "pub_date": "Sun, 01 May 2016 15:26:06 +0000", 
    "article_links": [
      "http://www.theguardian.com/uk/2013/jun/21/gchq-mastering-the-internet"
    ], 
    "categories": [
      "Revealed documents", 
      "gchq_orig", 
      "internet_content", 
      "internet_metadata", 
      "mastering the internet", 
      "mti", 
      "tempora"
    ], 
    "title": "Access to the future", 
    "doc_text": "\ufeffConclusion\r\n\r\nTOP SECRET STRAP1\r\n\r\n\u00ae You are in a privileged position \u2014 repay that trust,\r\no You have ready access to a lot of sensitive data,\r\no Understand your legal obligations \u2014 don\u2019t become a case\r\nstudy in a future legalities training presentation,\r\no If you have legal or ethical concerns, speak to someone: they\r\nwill be taken seriously.\r\n\r\n9 You are in an enviable position \u2014 have fun and make the\r\nmost of it.", 
    "pdf": [
      "https://edwardsnowden.com/wp-content/uploads/2013/10/Access-to-the-future-2-006.jpg"
    ]
  }, 
  {
    "released_date": "20160202", 
    "overall_handling_caveats": [], 
    "id": "20160202|himrdataminingresearchproblembook", 
    "document_date": "2011-09-20 00:00:00", 
    "codewords": [
      "DISTILLERY", 
      "MIRANDA", 
      "SWAMP", 
      "FISH", 
      "LECKWITH", 
      "PRESTON", 
      "TERRAIN"
    ], 
    "agency": [
      "GCHQ"
    ], 
    "sub_paragraphs_classifications": [
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only reference:\topc-m/tech.a/455 (v1.0, r206) date:\t20 september 2011 copy no: himr data mining research problem book opc-mcr, gchq summary in this problem book we set out areas for long-term data mining research at the heilbronn institute for mathematical research starting in october 2011 and continuing for at least three years. the four areas are beyond supervised learning, information flow in graphs, streaming exploratory data analysis and streaming expiring graphs. copy\tdistribution 1\tnsa r1 2 3 4 i 6 7 8 9 10 ii 12 13 14 15 16 17 18 nsa r4 nsa r6 llnl csec cri dsd gcsb ictr ictr-cisa ictr-dmr ictr-mca ndist iact ptd i himr (circ.) opc-mcr (circ.) opc-m/tech.a/455 (v1.0, r206) [96 pages] this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) this page is intentionally left blank 2 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) himr data mining research problem book 20 september 2011 contents 1\tintroduction\t7 2\ta brief introduction\tto sigint\t9 2.1\tpassive sigint..................................................... 9 2.1.1\tcollection................................................... 9 2.1.2\tprocessing.................................................. 10 2.1.3\tanalysis, reporting and target development.................. 11 2.2\tcomputer network operations and the cyber mission................. 12 2.2.1\tcyber....................................................... 12 2.2.2\tattack, exploit, defend, counter............................ 13 2.2.3\tdata mining for cyber discovery ............................ 14 3\tbeyond supervised learning\t16 3.1\tintroduction...................................................... 16 3.1.1\tsupervised learning prior work.............................. 17 3.1.2\tsemi-supervised learning prior work......................... 18 3.2\tsemi-supervised learning.......................................... 18 3.2.1\thow useful is semi-supervised learning?..................... 18 3.2.2\tpositive-only learning...................................... 19 3.2.3\tactive learning............................................. 19 3.2.4\tnew algorithms and implementations ......................... 20 3.3\tunreliable marking of data ....................................... 20 3.3.1\tweak labels................................................. 20 3.3.2\tfusion of scores............................................ 21 3.4\trelevant data..................................................... 22 3.4.1\ttruthed datasets............................................ 22 3.4.2\tfusion of scores data....................................... 23 3.5\tcollaboration points.............................................. 23 4\tinformation flow in\tgraphs\t25 4.1\tintroduction...................................................... 25 4.2\tpast work......................................................... 26 4.2.1\tgraphical methods........................................... 26 4.2.2\ttemporal correlation........................................ 28 4.3\twhat we care about now ........................................... 29 3 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) 4.3.1\tdefinition and discovery...................................... 30 4.3.2\tmissing data and noise........................................ 30 4.4\tpotential future interests.......................................... 31 4.4.1\tperforming inference on flows................................. 31 4.4.2\tinformation flow for graph generation......................... 32 4.5\trelevant data....................................................... 32 4.6\tcollaboration points................................................ 32 5\teda on streams\t34 5.1\tintroduction........................................................ 34 5.1.1\teda .......................................................... 34 5.1.2\tstreams....................................................... 34 5.1.3\tthe problems ................................................. 35 5.2\tgraph problems with no sub-sampling................................. 35 5.2.1\tthe framework of graphs and hypergraphs....................... 35 5.2.2\tcliques and other motifs...................................... 36 5.2.3\ttrusses ...................................................... 37 5.2.4\tother approaches.............................................. 37 5.3\tvisualization....................................................... 38 5.3.1\tvisualization in general...................................... 38 5.3.2\tstreaming plots .............................................. 38 5.4\tmodelling and outlier detection..................................... 39 5.4.1\tidentifying outlier activity.................................. 39 5.4.2\tbackground distributions for significance tests............... 39 5.4.3\twindow sizing................................................. 39 5.5\tprofiling and correlation........................................... 40 5.5.1\tcorrelations.................................................. 40 5.5.2\tfinding behaviour that matches a model........................ 40 5.6\teasy entry problems................................................. 41 5.7\trelevant data....................................................... 41 5.8\tcollaboration points................................................ 42 5.8.1\tinternal...................................................... 42 5.8.2\texternal...................................................... 42 6\tstreaming\texpiring graphs\t44 6.1\tintroduction........................................................ 44 6.1.1\tthe problems.................................................. 44 6.2\tproperties to find and track........................................ 45 6.2.1\tcomponent structure........................................... 45 6.2.2\tgraph distance................................................ 45 6.2.3\tcliques and other motifs...................................... 45 6.2.4\tcentrality measures........................................... 46 6.3\tquestions relevant to all properties................................ 47 6.3.1\tapproximation................................................. 47 6.3.2\tcomputational cost ........................................... 47 4 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) 6.3.3\texpiry policy...................................................... 48 6.4\tfurther questions ....................................................... 48 6.4.1\tparallel and distributed processing................................ 48 6.4.2\tbootstrapping ..................................................... 48 6.4.3\tanomaly detection.................................................. 48 6.4.4\tresilience......................................................... 49 6.4.5\tqueries on graphs with attributes ................................. 49 6.5\trelevant data............................................................ 49 6.6\tcollaboration points..................................................... 49 a ways of working\t51 a.1\tfive-eyes collaboration.................................................. 51 a.2\tknowledge sharing........................................................ 51 a.\t3\tacademic engagement ..................................................... 52 b distillery\t54 b.\t1\twhen would i use infosphere\tstreams? .................................... 54 b.2\tdocumentation and training............................................... 55 b.3\tlogging on and getting started........................................... 55 b.4\tdata..................................................................... 56 b.5\tconventions ............................................................. 58 b.5.1 use threaded ports on\tshared data................................... 58 b.\t5.2 operator toolkits and\tnamespaces.................................. 58 b.\t6\tfurther help and resources............................................... 59 c hadoop\t60 c.\t1\twhen would i use hadoop?................................................. 60 c.2\tdocumentation and training............................................... 61 c.3\tlogging on and getting started........................................... 61 c.4\tdata..................................................................... 62 c.5\tconventions and restrictions............................................. 62 c.\t5.1 scheduler......................................................... 62 c.5.2 hdfs /user/yoursid space ........................................... 63 c.6\trunning hadoop on the lid\t.............................................. 63 c.7\tfurther help and resources............................................... 65 d other computing resources\t66 e legalities\t67 e.1\toverview ................................................................ 67 e.2\tprocedures .............................................................. 67 5 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) f\tdata\t69 f.1 sigint\tevents............................................................... 69 f.1.1\tsalamanca............................................................... 69 f.1.2\tfive alive.............................................................. 70 f.1.3\thrmap................................................................... 71 f.1.4\tskb..................................................................... 71 f.1.5\tarrival processes....................................................... 72 f.1.6\tsolid ink and fluid ink................................................. 73 f.1.7\tsqueal hits ............................................................ 74 f.2 open-source graphs and events.................................................. 74 f.2.1\tenron................................................................... 74 f.2.2\tus flights data......................................................... 75 f.2.3\twikipedia graph......................................................... 75 f.3 sigint\treference data....................................................... 77 f.3.1\twebsites of interest ................................................... 77 f.3.2\ttarget selectors........................................................ 77 f.3.3\tcovert infrastructure................................................... 78 f.3.4\tconficker botnet........................................................ 78 f.3.5\tpayphones............................................................... 78 f.4 sigint\ttruthed data ........................................................ 79 f.4.1\tlogo recognition........................................................ 79 f.4.2\tspam detection.......................................................... 80 f.4.3\tprotocol classification................................................. 80 f.4.4\tsteganography detection................................................. 81 f.4.5\tgenre classification.................................................... 81 f.4.6\twebsite classification.................................................. 82 f.5 fusion\tof scores data ....................................................... 82 references\t85 6 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) 1\tintroduction the government office for science reviewed gchq technology research in 2010 and identified that we could lengthen our technology research horizon. the heilbronn institute for mathemat- ical research (himr) had shown its mettle during a one-off graph mining workshop [i60, w42] and thus the idea to more permanently expand himr research beyond pure maths and into data mining was born. this also fits into gchqs overall research and innovation strategy for the next few years [i75], where engagement with academia via himr is a key plank. like many organisations, gchq is having to approach the big data problem. after reviewing our current research we identified four broad areas for long-term research in math- ematics and algorithms at himr. all of the four problem areas are about improving our understanding of large datasets: beyond supervised learning: can we use semi-supervised learning and related techniques to improve the use of machine learning techniques? information flow in graphs: can we identify information flowing across a communications graph, typically from timing patterns alone? streaming exploratory data analysis: can we develop new techniques for understanding and visualising streaming data? streaming expiring graphs: can we efficiently maintain current situational awareness of a streaming expiring graph? himr researchers are free to devote their effort amongst these problems as they see fit during their classified time. these problems have been chosen due to their sigint relevance and sigint data is provided for all these problems. however we also recognise that these problems have overlaps with current academic research areas. thus, conditional on security considerations, himr ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "researchers should be able to generalise from classified research to unclassified research and ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "publications during their unclassified time. data is made available to himr researchers in the following forms: streams: gchq are prototyping the use of the distillery streaming architecture (see appendix b for details). many data analysis problems can be efficiently approached in the stream [e39] and processing in the stream brings the advantages of live situational awareness and the potential to reduce follow-on storage and processing costs. mapreduce: gchq store recent communications meta-data as distributed text files in ha- doop clusters which can then be processed with mapreduce [e10] (see appendix c for details). this environment will allow researchers to use large datasets typically spanning the last six months of collection. reference: we also provide some smaller datasets (e.g. reference data or data that has already been processed or truthed) as text files. 7 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) the development of techniques in hadoop or distillery is recommended as that will enable easy technology transfer from himr into gchq. the himr deputy director, the authors of this problem book and members of gchqs information and communications technology research (ictr) business unit should be seen as the primary points-of-contact for this research. however we will also identify various other areas for classified collaboration both in gchq and abroad. gchq imagines that the most useful outcomes of this research will come in one of the following forms: ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "classified or unclassified research papers describing new techniques (or in limited cases a literature review of existing techniques). classified research papers describing new or existing techniques applied to sigint data. new analytics (typically in hadoop or distillery) and documentation. in this problem book we adopt two conventions: we distinguish between references to internal literature, external literature and websites. citations are prefixed i, e and w respectively. where possible literature is made ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "available in discover (see appendix d). we have deliberately aimed to be more com- prehensive in citing internal literature than external literature; external references should be easier to find from citation paths and review papers. we highlight problems with a  in the right-hand margin. in the interests of brevity, this problem book does not give full definitions for all terms in use in gchq and the use of gcwiki [w15] is a good place to find out more. we would like to thank the many people across the 5-eyes community who have helped us with the problem book, both in formal contributions and in informal discussions at various conferences and visits over the last year. within gchq we have had plenty of support from members of ictr (in particular\tand\tand ptd (in particular ). we start the problem book with an overview of relevant sigint background before describ- ing the problems in detail. in appendices we suggest some ways of working, describe gchqs implementations of hadoop and distillery and describe the datasets available. 8 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) 2\ta brief introduction to sigint this is a very brief, high-level overview for people unfamiliar with the sigint system, focused on what data miners need to know about the data available to them and how data mining can be applied to problems in target discovery and cyber. researchers are encouraged to find out more by browsing gcwiki and asking questions that arise. sigint is intelligence derived from intercepted signals. although this encompasses a huge variety of emanations, we are principally concerned with comint: intercepted communica- tions. parliaments joint intelligence committee (jic) formulates a set of priorities and require- ments for intelligence on various topics, which gchq tries to meet by producing end product reports (epr) based on intercepted communications. gchq has the legal authority to inter- cept communications for the specific purposes of safeguarding the uks national security and economic well-being, and to prevent and detect serious crime. gchq always acts in accordance with uk law. all researchers who have access to sigint data will be given legalities training, and there is also some information in appendix e on how data should be handled. 2.1\tpassive sigint this section looks at some of the main stages in the intelligence cycle: how data gets collected, processed and analysed to produce reports for gchqs customers. 2.1.1\tcollection there are many ways of communicating, and consequently there are many sources of sigint data. traditionally, we collect signals using a variety of masts and dishes to pick up radio or satellite signals. increasingly, we are interested in network communications (phone calls or internet traffic), and in this case to intercept the communication we usually need an access point in the network. (sometimes network data passes over a satellite link where we can pick it up comsat collectionbut more often it doesnt.) collection of this network communication data is called special source collection, the details of which are covered by ecis. access to raw data collected from special source is protected by a coi called chordal. some information about what the underlying sensitivities are, and the processes we have in place to protect them, is provided in the chordal briefing. one final twist is that a uk service provider can be compelled by a warrant signed by the ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "home secretary or the foreign secretary to provide us with the communications data for a specific line or account for a specified time. this goes by several names: lawful intercept (li), warranted collection, and preston. we refer to a single internet link as a bearer. we collect data from a bearer using a probe, and our current technology can collect from a 10g bearer (i.e. a 10 gigabit-per-second link). when a bearer is connected to a probe and associated processing equipment we describe the bearer as being on cover. we have been building up our sustained collection of 10g bearers since about 2008, and we now have approximately 200 bearers on sustained cover, spread across cheltenham, bude and leckwith. we refer to these three sites as processing centres ; they are abbreviated to cpc, rpc-1 and opc-1 respectively. 9 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) we have access to many more bearers than we can have on cover at any one time, and the set we have on cover is changed to meet operational needs.1 as well as the fact that bearers get taken on and off, it is not unusual for technical problems to interrupt processing from a bearer, both for short and prolonged periods. this means that one must be careful about making assumptions about how traffic volumes from a given end-point vary over time: see [i10] for a detailed discussion of the problem and one way to deal with it. 2.1.2\tprocessing a 10g bearer produces a phenomenal amount of data: far too much to store, or even to process in any complicated way. our way of dealing with this is a multi-component system called mvr (massive volume reduction). to make things manageable, the first step is to discard the vast majority of the packets we see. this is accomplished by the packet processing framework (ppf), a software framework allowing a very limited set of matching operations to be run on specialized hardware; packets that hit on these matches are then passed back to the software layer, where more complicated processing (including sessionization, done by a platform called terrain) can be performed on the selected subset of the data. collected data falls into two categories: metadata and content. roughly, metadata comes from the part of the signal needed to set up the communication, and content is everything else. for telephony, this is simple: the originating and destination phone numbers are the metadata, and the voice cut is the content. internet communications are more complicated, and we lean on legal and policy interpretations that are not always intuitive. for example, in an http request, the destination server name is metadata (because it, or rather its ip address, is needed to transmit the packet), whereas the path-name part of the destination uri is considered content, as it is included inside the packet payload (usually after the string get or post). for an email, the to, from, cc and bcc headers are metadata (all used to address the communication), but other headers (in particular, the subject line) are content; of course, the body of the email is also content. there are extremely stringent legal and policy constraints on what we can do with content, but we are much freer in how we can store and use metadata. moreover, there is obviously a much higher volume of content than metadata. for these reasons, metadata feeds will usually be unselectedwe pull everything we see; on the other hand, we generally only process content that we have a good reason to target.2 gchqs targeting database is called broad oak, and it provides selectors that the front-end processing systems can look for to decide when to process content. examples of selectors might be telephone numbers, email addresses or ip ranges. a selector whose communications are currently being targeted is said to be on cover. metadata generally gives us information that we think of as events (a communicated with b at time t), and this terminology filters through into the name for the corporate processing and storage system for 10g bearers: next generation events (nge). xin order to make decisions about which bearers to place on cover, we carry out a cyclic survey of all bearers. each bearer is connected to a probe for 15 minutes and data collected about the traffic seen during that time. this is stored in the flexible-survey knowledge base or fkb. 2we do collect some unselected content for survey and research purposes, but the requirements that our activities be necessary and proportionate strictly limit what we can do with full-take content and who can have access to it: in particular, analysts are not usually allowed to write reports based on it. 10 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) once packets (or files or sessions created by assembling multiple packets) have been selected and they emerge from mvr, they go to several different places. content databases. traditional relational databases are still the ultimate point of rest for corporate content data. there are also some legacy events database stores; soon, all of gchqs events processing and storage will move to the systems described in the next three bullets. qfds. query-focused datasets (qfds) pick out data and store it in a way that makes it easy to answer particular questions. for example, five alive is a dataset with a record for each ip event seen, consisting of the 5-tuple (timestamp, source ip, source port, destination ip, destination port) plus some information on session length and size. this lets us answer questions about the network activity of a specific ip address.3 distillery. a stream processing platform enabling near real time processing of data. see appendix b. the cloud. a scalable distributed filesystem along with a mapreduce processing frame- work. see appendix c. it is important to emphasize that even after mvr, the data volumes in the qfds, cloud and distillery are still vast, and we dont want to ship everything back to cheltenham. everything is distributed across the processing centres, with limited amounts of information being sent between them: queries to the stored data are all federated to the separate processing centres, with only the results being sent back to cheltenham and the analysts desktop. 2.1.3\tanalysis, reporting and target development traditionally, an analyst would be given a particular target set to look at, and his or her aim would be to use the communications of these targets to write reports answering questions of interest to policymakers. for example, the target might be the ruritanian ministry of foreign affairs (mfa), and the aim to understand their posture in forthcoming negotiations with the uk; or it might be kawastans air force, and the aim to understand their general intentions and specific movements in a region where uk forces are currently deployed. the point is that the target set is generally well understood, and while looking at the contacts of a known senior figure in the mfa might reveal other government ministers or officials worth targeting, the problem essentially involves analysing communications carefully selected to be likely to bear on the questions under consideration. counter-terrorism, and to a lesser extent increased work on serious crime, has changed this landscape dramatically. the failure of the security services to prevent the 9/11 and 7/7 attacks has been widely dissected, both in the press and in government inquiries here and in the us. targets are no longer neatly identified by their affiliation to a foreign mfa, military, or intelligence organization: finding the targets in the first place is now one of the most important problems facing analysts, before they can even begin to assess their plans and intentions. 3see appendix f.1.2 for more information on this qfd. 11 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) contact chaining is the single most common method used for target discovery. starting from a seed selector (perhaps obtained from humint), by looking at the people whom the seed communicates with, and the people they in turn communicate with (the 2-out neighbourhood from the seed), the analyst begins a painstaking process of assembling information about a terrorist cell or network. but what about those who simply are not on our radar at all, like the 7/7 bombers? the main driver in target discovery has been to look for known modus operandi (mos): if we have seen a group of targets behave in a deliberate and unusual way, we might want to look for other people doing the same thing. for this reason, a whole tranche of problems in this book looks at ways of picking out behaviour matching a specific mo in a large dataset. specific mos should be treated as particularly sensitive; knowledge of mos can give sigint the edge over our targets who wish to remain undiscovered. for example, sometimes targets will buy separate mobile phones and only use them to speak to each other, believing this to be good opsec. in fact, this is unusual behavior that makes them stand out. analysts call these closed loops; to a mathematician looking at a telephony graph, they are small components disconnected from the giant component that always forms in communications graphs. another example is the use of payphones (commonly called telephone kiosks or tks), which are an obvious way to communicate anonymously. looking for calling patterns between tks, or between a tk in the uk and a number in (let us say) pakistan, has provided valuable intelligence leads. many of the problems in this book invite you to find new ways to use the data we have to discover things that analysts either could never find by themselves, or would never have the time to find in practice. it is important to point out that tolerance for false positives is very low: if an analyst is presented with three leads to look at, one of which is probably of interest, then they might have the time to follow that up. if they get a list of three hundred, five of which are probably of interest, then that is not much use to them. once we have targets, clustering or community detection algorithms give us a way to expand them into cells without laborious work by analysts. doing this reliably and at scale is another fundamental challenge presented in this problem book. it is also worth saying that techniques developed for counter-terrorism analysis can also feed back into traditional diplomatic and military analysis. for example, dynamicgraph (see section 6) is a way to visualize communication events around a seed set. many of the ap- plications have been to counter-terrorism operations, but it was first developed to look at the communications of foreign government officials visiting london for a g20 summit in 2009 [w18]. 2.2\tcomputer network operations and the cyber mission 2.2.1\tcyber traditional diplomatic and military theories imagine nation states engaging in various physical domains: land, sea, air and space. the cyber domain is an increasingly important new site for interactions between states, and will only become more so as time goes on. the uk government has recognized the critical importance of cyber to our strategic position: in the comprehensive spending review of 2010, it allocated a significant amount of new money to cyber, at a time when almost everything else was cut. much of this investment will be entrusted to gchq, and 12 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) in return it is imperative for us to use that money for the uks advantage. some of the problems in this book look at ways of leveraging gchqs passive sigint capabilities to give us a cyber edge, but researchers should always be on the look-out for opportunities to advance the cyber agenda. this section briefly discusses how sophisticated state actors (including ourselves and our five-eyes partners) currently conduct themselves in cyberspace. it is important to bear in mind that other states, in particular russia and china, are not bound by the same legal framework and ideas of necessity and proportionality that we impose on ourselves. moreover, there are many other malicious actors in cyberspace, including criminals and hackers (sometimes motiv- ated by ideology, sometimes just doing it for fun, and sometimes tied more or less closely to a nation state). we certainly cannot ignore these non-state actors. 2.2.2\tattack, exploit, defend, counter ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Confidential", 
        "paragraph_text": "there are four basic postures an actor can take in computer network operations (cno).4 attack. this is obviously the most directly aggressive approach. it is commonly referred ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Confidential", 
        "paragraph_text": "to as computer network attack (cna); at gchq, one also hears it called effects. the actor accesses an adversarys network and deletes his files, destroys his network connectivity, or causes other damage or inconvenience. there has been a lot of discussion, both internally and externally, about the possibility of a cyber-based attack that could cause physical damage beyond the network, for example by shutting down a power station. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Confidential", 
        "paragraph_text": "exploit. gchqs first cne (computer network exploitation) operation was carried out in the early nineties, and since then cne has grown to the scale of a small industry in gchq. a typical operation involves establishing a long-term covert presence (an im- plant ) on a target computer, which sends back (exfiltrates) useful information over an extended time period. you will know from press reports and public statements by the head of security service that uk networks and those of our alliesboth government and commercial networksare in turn routinely targeted by other countries. defend. cesg is responsible for protecting uk networks (primarily government net- works, but the security of banks or other companies operating in the uk is also important for economic well-being) from hostile cna or cne activitythe acronym for this is cnd, or computer network defence. it is important to be able to prevent attacks by rejecting malicious packets at sensors or firewalls, and to understand who is attacking us (the attribution problem), why, and what they are looking for. counter. this is a relatively new approach for gchq, which might better be called active defence. as we come to understand the cne infrastructure of a hostile actor, we can target that infrastructure and attack it, disrupt its activities, or make use of the data that someone else has exfiltrated from a network that is also of intelligence interest to us (fourth party collection). this is sometimes called c-cne (counter-cne), not to be confused with ccne, which was the name of ptd for a few years. 4this area is rich in jargon: see [w8] for a comprehensive list, along with links to further details on the subjects mentioned here. 13 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) figure 1: the cyber wheel. 2.2.3\tdata mining for cyber discovery cne and cna activity will leave traces in passive sigint. one of gchqs key contentions in discussions on spending for cyber has been that understanding the internet through sigint is the best foundation on which to build any cyber capability, whether offensive or defensive. this is the very first stage in the cyber wheel (figure 1), which is meant to be a visual representation of all the aspects of cyber, with sigint at the centre. nsa produced a simpler and earlier visualization [w43] of the same idea in 2007 (figure 2). during the initial exploitation of a target box, malicious data needs to be delivered to the target. we (as well as commercial anti-virus and security companies) try to produce signatures for these infection vectors, which packets can be matched against. once machines have been implanted, they will usually perform certain characteristic activ- ities on the network. two major functions of an implant are beaconing, which involves sending short periodic messages back to the implants controller confirming that the implant is alive and available for tasking; and exfiltration, i.e. pulling back data from the target box. the fact that these activities are visible in passive sigint presents an opsec risk to us [w7], but also an opportunity for data mining to discover hostile cne activity. the core of a particular actors infrastructure might be quite small, and discovering it can open up a whole chunk of their activity to be defended against or countered. botnets are large collections of implanted machines under the control of a single bot-herder. they are usually associated with organized criminals rather than intelligence agencies. again 14 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) figure 2: another view of the relationship between cno and digital network intelligence (dni), i.e. passive network sigint. there are stereotyped behaviour patterns associated with botnets: command and control ex- changes (also called c&c or c2), which are analogous to beaconing for implants; and coordin- ated activity in a short time windowfor example many machines in the botnet simultaneously trying to access a website being targeted in a distributed denial of service (ddos) attack. data mining offers the possibility of finding suspicious activity by detecting anomalies or outliers in bulk data. temporal analysis and behavioural pattern-matching can be used to detect hostile network activity from cne and botnets, but at present there is very little being done in this direction on our streaming data feeds. several of the problem areas in the rest of this document touch on applications to these important cyber problems. 15 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) 3\tbeyond supervised learning 3.1\tintroduction supervised learning is the machine learning task of inferring a function from training data. the training data is a set of training examples. each example is a pair consisting of a feature vector and a desired output value (also called truthed data or labelled data). a training algorithm analyses this data and produces an inferred function, which is called a classifier (if the output is discrete) or a regression function (if the output is continuous). the inferred function should predict the correct output value for any valid input object. this requires the learning algorithm to generalise from the training data to unseen situations in a reasonable way.5 there are a vast number of supervised machine learning algorithms which can often produce functions with high accuracies on real-world data sets. however, these techniques have had surprisingly little impact in gchq. there are various reasons why this has been the case but the principal reason has been the difficulty in creating training sets. in particular, the difficulty comes from knowing the desired output value for many training examples, either due to the required human effort and/or uncertainty in the desired output value. this difficulty is unlikely to be a one-off issue for an operational application. the nature of communications and our data changes with time and leads to concept drift; any algorithm must be periodically retrained. the aim of this research area is to improve the adoption of machine learning techniques. we suggest three ways forward on this area: 1.\tsemi-supervised learning alters the setup of supervised learning by only knowing the true value for a subset of training examples. 2.\ta special case of semi-supervised learning is active learning: in this case the training algorithm decides which examples it wants to be truthed. the aim is to make these the most informative examples rather than waste human effort on randomly chosen cases. this point-of-view also naturally works in a streaming context as a way of dealing with concept drift. 3.\tallow ourselves to work with inaccurate truth data or weak labels. such an approach would allow more automated labelling or reduce the human effort required. we provide some small example datasets that have come from supervised learning problems. all examples in these datasets typically come with a label and a truth value. the scale of these datasets should not limit your imagination and larger untruthed datasets should often be obtainable either from the cloud or from a research area in gchq. if a very large number of unlabelled examples is found to be of value then streaming or mapreduce techniques will probably be needed. it is important to note that the aim of this research is not necessarily to maximise the accuracy of prediction on these datasets. in the main, these datasets are fully-truthed and thus we expect that existing research on supervised learning will be competitive. also these data sets are fixed and are thus not tracking customer interests or concept drift. we also include the problem of fusion of scores that may be approachable by a natural extension of the weak labels research area. 5paragraph adapted from [w41]. 16 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) 3.1.1\tsupervised learning prior work supervised learning has had many applications in the research community but few applications have been deployed operationally. some research examples over the last ten years (along with the classifier type used) are: steganography detection (random forest) [i74], website classification (decision tree) [i36], protocol classification (random forest and neural network) [w1], spam detection (random forest) [i44], payphone detection (random forest) [i3] and drug smuggler detection (logistic regression) [i77]. random forests a common theme in many sigint applications is the use of random forest classifiers [e6]6. random forests are an ensemble learning technique [w13]. the base learners are unpruned decision trees [w10] which then vote to reach decision. randomness is inserted into each tree by two means. firstly, each tree is built on a bootstrap sample of the training data. secondly, the trees are built in a top-down manner by choosing the best feature at each node from a random subset of the features. one reason for the use of random forests may be because they typically produce high accuracies with little tuning. however our feature spaces may also naturally lend themselves to random forests. properties of our feature spaces include: features are typically based on categorical and count data. random forests can handle a mixture of ordered and categorical feature types. our data do not often show simple clusters. some features (e.g. port numbers in the protocol classification example) behave a bit like ordered features and a bit like categorical features (nearby ports are sometimes associated but not always). our features also show special values. a particular example could be a zero in a count could derive from missing data due to limited sigint visibility rather than saying any- thing relevant about the property of interest. one adaptation to random forests considered in-house to improve accuracy and help un- derstand the tuning of random forests is weighting of individual trees [i68]. interpretability a problem with the use of random forests is that their decisions can not be simply and intu- itively explained to an analyst. this black box nature can lower analyst trust in a prediction. (nsa r1) has been leading an effort to make random forests more interpretable [i18]. it would be good if semi-supervised models could have a broad-brush interpretability even if there are some complex exceptions that break these simple interpretations. 6the nsa were very early adopters of random forests through direct contact with\tvia the nsa statistical advisory group (nsasag) [w31]. the nsasag remain a useful conduit to statisticians at us universities [w28]. 17 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) scale the community has also considered scaling training of random forests to large datasets for the rare cases where one has computer-based truthing. the most trivial scaling is naive parallelisation per tree. to do this one duplicates the data on multiple hosts, grows trees on each host independently and then combines the trees together into a final forest. the author of [i74] found this approach helpful in building classifiers for steganography detection. nsa have looked at ways to implement random forests in hadoop [i8, i4]. in gchq we have looked at streaming approaches with random decision trees [i61] and very fast decision trees [i7]. 3.1.2\tsemi-supervised learning prior work semi-supervised learning is an area of active research in academia (see [e7] for a text-book reference and [e46, e36] for literature reviews). given our interest with random forests, the recent paper on semi-supervised random forests may be of interest [e24]. however semi-supervised learning is less well developed in the intelligence community. llnl have been considering active learning approaches for finding cyber attacks [i13]. fran- cois theberge at cri has looked at transductive learning (a special case of semi-supervised learning where a predictive function is not learnt at anywhere other than pre-chosen values) ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "[i80]. the gchq maths summer student programme (ssp) in 2011 have been asked to look at transductive learning in the context of determining the relationship between entities [w32]. 3.2\tsemi-supervised learning semi-supervised learning algorithms typically [use] a small amount of labeled data with a large amount of unlabeled data. [w38] this viewpoint is very desirable to gchq: like many organisations we have large datasets of which only a tiny subset can be truthed by hand. we have more metadata than content. for truthing we may require content but policy or data volumes means that content is only available for a small fraction of the data covered by metadata. therefore classifiers that run on metadata but are truthed based on limited (and not randomly selected) content are desirable. traditionally we have approached these problems with supervised learning and ignored all the unlabelled data. the overarching question of this research area is can we use semi-supervised learning to our advantage? what shape must the problem have for there to be significant benefit? 3.2.1\thow useful is semi-supervised learning? there do not seem to be strong theoretical results in academia to explain the benefits of semi- supervised learning as opposed to supervised learning. can we develop an applicable theoretical understanding of semi-supervised learning? 18 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) even if a theoretical understanding eludes us can we develop useful empirical rules of thumb on the value of semi-supervised learning? a simple starting point might be to measure gains in accuracy based on different approaches for the example sigint datasets. there are a range of known semi-supervised techniques; two major classes are: generative models and low-density separation [e7]. can we tell what type of algorithm one might want to use on a particular dataset? what is the nature of a good feature space for semi-supervised learning? are there feature transformations that could be applied to help this? if our truthing comes from an automated process then we may have untruthed examples that have failed automated classification. alternatively if we truth a meta-data classifier based on content then our truthing will only exist where we have content. in both these examples, in contrast to the traditional viewpoint of semi-supervised learning, the truthed examples are likely not to be independently distributed of the features or classes. in the missing value imputation literature such truthing would be called missing not at random (mnar). a potential approach to handle such truthing is described in [e33]. can we build valid models when the truthing is not independent of the feature space or classes? in the above, we have assumed that each training example can be treated independently. many sigint datasets have relationships between examples which can be represented as a graph. progress is being made externally on graph-based semi-supervised learning (see [e17] and references therein) - can these external techniques be usefully applied to sigint problems? 3.2.2\tpositive-only learning a special case of semi-supervised learning is when we only have labels for some members of one class and want to learn a binary classifier. an example is payphone classification where we have lists of some payphones and no labels for other phone numbers. in the outside literature^^^ [e13] presented a bayesian approach to positive-only learning but internally\t[i50] pointed out an error in their approach. however, in the world of statistical testing\thas pointed out that one can still identify the most powerful test by considering the quasi-power [i49]. this approach was successfully used in a positive-only learning scenario for botnet detection [i71]. asks, can we find or develop a theorem of the form: a binary classifier can be trained if and only if .... can positive-only learning be shown to work with no other constraints? this type of theorem would also be relevant to the rest of the beyond supervised learning problem area. can we design a new classifier for positive-only learning? 3.2.3\tactive learning many approaches to semi-supervised learning present a random subset of the data for truthing. this approach means that human effort is probably wasted classifying examples that have little impact on the learnt function. active learning instead sets up the truthing process as a sequential process where the algorithm sequentially chooses examples for truthing based on all the information so far at its disposal. a useful review of external research in active learning is [e37]. 19 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) the benefits of active learning are uncertain as an algorithm can focus on minor refinements to the current model and deliberately ignore examples that if truthed would lead to major changes to the current model. do active learning algorithms quickly converge to a good model when allowed to choose which truthed items to use from the example datasets? a risk with active learning is that after many truthing examples one decides that the chosen algorithm is not suitable for the data set. it may not be practical to ask for more truthing with a different algorithm. what happens if you take the partially truthed dataset from one active learning run and use that dataset with a different semi-supervised learning algorithm? active learning is a process where the algorithm and human are closely coupled and thus human factors are important.\tsuggests looking at active learning scenarios where the human is asked to rank two or three items rather then give a score or label. this may be easier from a human factors point of view. can we design algorithms for active learning based on ranking pairs? how does the number of example pairs required compare to the number of truthed examples in traditional active learning? see [e35] for an example supervised approach. 3.2.4\tnew algorithms and implementations the asymptotic complexity of many semi-supervised learning algorithms is not good (e.g. o(n3), where n is the number of examples, or worse) [e46]. such complexities are likely to be prohibitive on large datasets. ideally we would like algorithms to run in o(n log n) or better. wed be interested in new accurate and fast semi-supervised learning techniques. the requirement to scale to large datasets will hopefully lead to streaming and/or mapreduce implementations. the sigint datasets provided may also inspire new techniques to enhance classification accuracies. (nsa r6) suggests that we may often be in the scenario that we have our truthed data as a small data set on which one can do a large amount of in-memory computation but our untruthed data as a large dataset in hadoop. can a learning algorithm be developed that iterates between complex in-memory analysis of the truthed data and single table scans of the untruthed data? 3.3\tunreliable marking of data an alternative approach to improve the applicability of machine learning techniques is to allow inaccurate truthing of data, so called weak labels. we think of this case as related to semi- supervised learning; in traditional semi-supervised learning you have perfect knowledge of some cases and no knowledge of other cases - in the case of weak labels this knowledge is diffused across the entire dataset. 3.3.1\tweak labels scenarios where weak labels could occur are: 20 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) semi-synthetic data: if suitable training data can not be found we may want to modify data to have the properties we want. an example of this is steganography detection [i74]. we take a large number of images from sigint and add steganography into some the images to make our truthed data. errors will occur as some of these images may have steganography before we start. automated labelling: we might base our labels on content based-signatures that may not be accurate (e.g. for protocol classification [i70]). natural error: even experts make mistakes when labelling. externally the field of weak labels has been rejuvenated by the use of the internet for truthing by amateurs, e.g. using amazons mechanical turk where one may have multiple labels per item [e31]. however, the field dates back many years; for example [e27] showed the impact of weak labels on nearest-neighbour classifiers and ^-consistent estimators. another recent approach has been miforests [e23] which shows an approach to adapt random forests to binary classifiers based on sets of inaccurately marked data. as mentioned in section 3.2.2 by looking at quasi-power [i49] we can work directly with weakly labelled items (with some constraints on the labelling) to identify a most powerful test. can we understand the influence of labelling errors on different techniques? do some traditional supervised learning techniques work out-of-the-box with weak labels? can we develop algorithms that understand and compensate for the errors? 3.3.2\tfusion of scores a problem which might be a natural extension of this work is fusion of scores. for example, we have multiple techniques to try to infer a relationship between entities (e.g. from contacts, timing behaviour and geo behaviour). these techniques produce scores that are typically real numbers between 0 (no relationship) and 1 (a relationship exists). if these were (proportional to) independent likelihoods then these scores could simply be multiplied. however, these scores will not be independent and will not be likelihoods. how can we combine such scores in general? can we combine such scores to posterior probabilities? how large a deviation from independent likelihoods can we cope with? this problem is exactly the problem of weak labels if we treat one score as being a weak label and the rest of the scores as features. we have the added power that we can choose any feature as the weak label. internally we have considered score fusion in two main contexts: relationship scoring: chart breaker [i31] research initially looked at handling the multiple scores derived from the email communication hypergraph but is currently being extended to handle multiple communication mediums as part of first contact. geo-reference data: we have multiple sources of data giving us information on the geoloca- tion of an ip address. the geofusion project [i53] and radonsharpen-b [i59] have looked at combining country labels and confidences from multiple sources to come up with a decision for an ip addresss country. 21 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) dataset\tref\t# truthed\t#features\toutput\tnoisy\t+ve only logo recognition\tf.4.1\t530\t64\t109 classes\tn\tn spam detection\tf.4.2\t1809\t143\t11 classes\tn\tn protocol classification\tf.4.3\t799,541\t51\t15 or 39 classes\tn\tn steganography detection\tf.4.4\t1,550,000\t661\t(0,1) range\ty\tn genre classification\tf.4.5\t~16,000\t108\t2-17 classes\tn\tn website classification\tf.4.6\t6,705\t200\t4 classes\tn\tn payphone detection\tf.3.5\t97,993\tn/a\tbinary\tn\ty arrival process correlation\tf.1.5\t763,392\tn/a\tbinary\ty\tn table 1: truthed data sets. further details about these datasets can be found in appendix f as referenced in the second column. if were dealing with labels rather than scores then theres a line of literature in medical statistics looking at estimating the accuracy of diagnostic tests. these are based on the hui- walter method of independent tests [e19, e32, e21]. extensions have now looked at correlated tests [e11]. [e38] makes the link between these approaches and latent class models and thus this problem can be seen to be related to that being considered\tat llnl for learning with network data [i58]. [e31] shows an extension to real valued functions. nsa have also looked at this problem in the context of log-likelihoods that may not be independent [i45] (their approach has been reviewed by gchq [i26]). 3.4\trelevant data 3.4.1\ttruthed datasets we provide various sigint truthed datasets as summarised in table 1. most of these data sets consist of features and truthed output for all examples. there are a few exceptions: the protocol classification set has some null labels for which automated signature- based classification failed. this dataset can be seen as an example of a semi-supervised set where the truthed examples are not randomly chosen. the payphone data set comes with no features. we do not have feature extraction in hadoop. implementation of the features in [i3] should not be too large a task and implementing a complete system would aid deployment. the arrival process correlation data set has no features extracted. also the truthing comes as two sets where one set is richer in true cases than the other. this data is included as it is an active area of statistical research and overlaps with the information flow in graphs problem. if features are required for this set then the clasp scores [i49] could be useful features but new approaches would also be welcome. for the fully-truthed data sets in table 1 it is imagined that semi-supervised or weak label experiments can be conducted by hiding truth labels or perturbing truth labels. 22 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) the steganography detection dataset may also be a good dataset if we want to look at cost-sensitive feature extraction within the context of semi-supervised learning. the features are computed in classes, each with a cost. we can give some metrics on these costs if required. it should be remembered that the aim of this problem area is not to maximise the accuracy of classification on these datasets. these datasets should be used to support improvements in understanding and algorithms. a flaw with these datasets is that they are mostly small (having derived from experiments with supervised learning). the ability of algorithms to scale to larger sizes should be considered. the payphone data may be the most promising one to look at at scale. 3.4.2\tfusion of scores data we provide fusion of scores data from geofusion. scores in geofusion are typically ordered confidence labels (low to very high) rather than real numbers. we provide the country and confidence from four sigint systems as well as the akamai edgescape commercial geolocation dataset. see appendix f.5 for more details on this data. we hope that data for fusion of identifier relationship scores will be available soon. al- ternatively researchers could use existing software to compute scores from telephony or c2c data on the cloud themselves - please consult the authors for more guidance on this route if required. 3.5\tcollaboration points there are several areas where one might find useful collaboration in this problem area: ictr-mca: the media content analysis team are looking to automatically determine the relationship between entities based on communication content and think that semi- supervised techniques are likely to be needed;\tis leading on this work. and\talso think that their work on speaker identification may lead to a semi-supervised problems with weak labels.\tis also plan- ning to revisit the problem of finding ied triggers in audio content and which may lead to a dataset with features derived from roughly continuous data (as opposed to many of the provided sets being based on discrete data), see [w44] for more details. ictr-dmr:\tis leading a major research package on fusion of scores. would also be interested in any developments based on the payphone detection dataset. us national labs: at\tand are working on active learning for finding anomalies in c2c data. at llnl and\tteam at sandia national labs have been working on large-scale machine learning algorithms.\tat llnl was interested in latent class models (potentially linked to fusion of scores) but has now been posted to australia. nsa r6: is interested in large scale semi-supervised learning algorithms. 23 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) nsa r1: ^^^^g is always interested in anything that can advance the arrival process correlation score. also\tis interested in techniques that may improve the interpretability of random forests (he particularly mentions the treebeard technique [i18]\tas having further research possibilities). cri:\tis working on transductive learning which is closely related to semi- supervised learning. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "ibm research:\tsuggests that unclassified engagement may be possible with (ibm research) on active learning. ^^g also works with^^^^^^f ^^jfrom yahoo research who has also been working on fast online learning algorithms, exemplified by vowpal wabbit. 24 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) 4\tinformation flow in graphs 4.1\tintroduction this section of the problem book concerns information flow in graphs. by this we mean the study and discovery of related information or messages being relayed over multiple edges in a communications graph. for this problem we will initially consider working on a static graph, although you should feel free to consider the streaming case if you desire. we get to observe a set of transactions taking place on the edges of the graph. given these transactions we would like to be able to infer something about likely information flows across multiple edges. in most cases we will know nothing of the content of the transactions. we therefore wish to focus mainly on techniques which do not require any content knowledge. data with content should therefore mainly be seen as truthed data for exploration and familiarisation with existing techniques. we will now provide two motivating examples for our interest in information flow in graphs. these are chosen to reflect intelligence interests over the last decade or so. the first example is a target-centric communications network. consider the graph formed by telephone calls around a certain target set. each call, or transaction, serves the purpose of conveying information between participants. if significant flows could be extracted then this would provide information on the structure of the target setperhaps identifying commanders, middlemen and operatives. now, if one of the commanders was no longer part of the network we could again examine how the flows have changed and therefore gain insight on any reorgan- isation that has taken place. further, it may even be possible to identify a significant change in flows on the graph and identify a change in structure purely from transactional data. the second example is the detection of botnet command and control infrastructure. for a botnet to be effective it needs to be able to convey commands from its controller to all infected nodes. one can imagine that with some knowledge of infected nodes it may be possible to use information flows to trace out the infrastructure, discover further infections, or even track back to find the botnets owner. this type of capability would be of enormous interest due to the current emphasis on cyber defence. we now define a cascade and discuss how we will use them to summarise the significant information flows. figure 3: examples of cascades. a downwards pointing triangle is a source and an upwards one a sink. a diamond means the node is both the source and a sink. 25 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) definition 1. a cascade is defined to be a directed connected subgraph with a single source and one or more sinks, consisting only of directed paths from the source to every sink. being a source or sink is considered an attribute rather than necessarily having no in or out edges respectively. figure 3 shows some example cascades. subfigure 3(b) demonstrates a cascade where the source is also a sinkthere is nothing in the definition which prohibits this. further, we can imagine situations with an information flow like this. for instance consider a friend to ask their friend for a favour and then having the response relayed back. cascades can be used to represent significant, repeated information flows on the graph. each directed edge in the cascade, starting from the source, should occur no earlier in time than its predecessors. algorithms developed should probably output such representative cascades. we are interested in techniques which do not depend upon having the content of transactions as this limits their applicability. this is because much metadata is of the form a communicated with b at time t, with few or no clues to what the content of that communication was. because our data is in this form we place a particular emphasis on temporal correlation when surveying past work. this section of the problem book has a relatively small number of wide problems. this is because the main problem of information flow definition and discovery is meant to be open ended with plenty of scope for exploration and experimentation7. 4.2\tpast work we will now describe past work in related areas of research, with a particular emphasis on internal research. we will introduce key areas of work, give a sketch of their workings and provide references for further reading. external work discussed should be seen as a sample rather than a definitive list. this subsection will first discuss methods on graphs, starting with explicitly temporal ones and then moving on to static ones. we will then discuss the extensive research that has been conducted on temporal correlation of stochastic processes. we expect that research on information flow in graphs may want to draw on all areas, perhaps applying our knowledge on temporal correlation in a graphical setting. 4.2.1\tgraphical methods there have been several approaches used to exploit timing information present in transactions on graphs. if two vertices participate in timing patterns then it is likely that they are closely related. further if one of these vertices is a target then the other may be worth investigating more closely. the first temporal graph algorithm in gchq was remit, developed under contract by detica for ictr-dmr [i78]. a large amount of subsequent research can be seen to have been directly triggered by the chains analytic within remit. chains is about the simplest approach possible to finding information flow in graphs. one simply defines a maximum time allowed 7the problem find and score related stochastic processes has already had many man-years of research effort expended across dozens of approaches. 26 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) between transactions on adjacent edges and a minimum flow length. the chains algorithm will then find all flows satisfying these conditions. despite this simplicity trials showed that it could produce useful intelligence when applied to a target-centric telephony graph [i41]. unsurprisingly, given its fixed time window, chains had issues with flows spuriously going through vertices with a high activity rate. this motivated the next stage of research in temporal graph methods. prime time [i42] was the next approach created. prime time introduced a statistical model to compensate for varying vertex activity levels. specifically an exponential distribution is fitted to a vertex based upon its mean time between transactions. this exponential is used to calculate a p-value on waiting times for transactions on pairs of adjacent edges. if the p-value is less than some critical value then the transactions will be considered related. furthermore the p-values are collected for future scoring of long and/or repeated flows. however the methods of combination used are ad-hoc and not statistically motivated. the original prime time paper talks of chains of related edges, although in practice only length 2 were computed. even so this suggests the beginning of the study of information flow in graphs. currently a streaming version of prime time is being developed by detica for the stream- ing analysis team in ictr [i63]. hidden otter is an ictr-ne prototype that similarly tries to find temporal chains in communications data [i62]. in particular they are interested in finding things such as back- haul networks, tor networks and botnet structures. it has the simple approach of finding temporally ordered chains of transactions on edges starting from a specified set of seed nodes. hidden otter is essentially a reinvention of the remit chains algorithm, but in hadoop. bakers dozen is a technique for finding batches of near-sequential phone numbers that display causal behaviour [i11]. given population-level telephony data it generates a list of pairs of telephone numbers that are near-sequential. for each of these pairs it conducts tests to discover if they are causally related. one of these tests is temporally correlated communications with the same third party. this third party condition is important at population level as otherwise there are too many random coincidences due to identifiers merely being active at the same time. clasp8 was rejected for having little statistical power due to exactly this reason. the bakers dozen test measures the proportion of events which involve a common third party and occur within t minutes of each other. a beta distributed prior and most powerful value for t were learnt from the data. the causal threshold was learnt by evaluating the statistic for 20 million random pairs and then choosing the value which led to a p-value of 10-6. this statistic proved to be powerful in the sense of promoting many pairs above the causal threshold. there has been a large amount of research on information diffusion and cascades in the external literature e.g. [e44, e18, e25, e29]. however the focus has tended to be on datasets where one can directly observe the pieces of information flowing through the network. examples could be hashtags through twitter or the spread of disease through a contact network. r66 at nsa have developed a mapreduce algorithm based on [e18] to track the passing of files between implanted machines [i35]. the reading rack for this problem (on [w24]) contains a number of citations of external papers considering information cascades and diffusion. those papers should provide a good starting point in the literature, but is nowhere near exhaustive. internally there has been some research on block modelling [i28, i29, i30]. block modelling 8covered in subsection 4.2.2. 27 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (vl.o, r206) time ---------------- 0.2  i  1 i i\t0.3  l\t,  1  1\t\t\t0.4  l\t,  1  1 l  l  i  i figure 4: an example of the non-homogeneous poisson process used in [149, 164, 152]. here we are testing the hypothesis that rs events are triggered by as. we therefore project ts events onto a's timeline: the first falls 0.2 of the way between two a events, the second 0.3 and the third 0.4. this figure is adapted from [164] assumes that vertices in a graph each belong to different classes. the communication between vertices is then determined entirely by their classes. the job of a block modelling algorithm is therefore to assign vertices to classes and describe how the classes interact with each other. although this has not so far considered information flows there is the possibility that they could be useful for block modelling. further the outputs of certain block models may be interpretable in a similar manner to potential applications of information flows. for instance both may be able to distinguish directors, middle managers and workers in a company hierarchy. is it possible to use block modelling to inform the discovery of information flows? 4.2.2\ttemporal correlation internally there has been much research undertaken in understanding temporal correlation between stochastic processes. this work should be a great aid in tackling the information flow in graphs problem area, especially when the information cannot be directly observed flowing over the graph. if we are interested in comparing adjacent edges then this work is directly applicable by restricting the scored processes to those with a common vertex. this research started in 2005, motivated by a desire to find cross-media temporal correla- tions. an example of a cross-media correlation would be a calling b to arrange for b to initiate an instant messenger conversation with him. [149] found that modelling the stochastic processes as non-homogeneous poisson processes (nhpp) gave the best performance of the approaches attempted. this contrasts to prime time which models activity as a homogeneous pois- son process. assuming that one can model the rate function of the nhpp correctly then the events of unrelated processes should fall uniformly with respect to each other. figure 4 shows an example of this mapping. all tests seek to find deviations from this null hypothesis. the original paper proposed 14 tests for non-uniformity, some of which place particular emphasis on the start of the interval. ongoing research on this strand of temporal correlation can be seen to fall into two areas: 28 this information is exempt under the freedom of information ac^oo^foia^nariay b^xemp^mdei^theiak information legislation. refer any foia queries to gcfiq on\tor ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) testing for non-uniformity and improving rate function estimation. the current best test for non-uniformity is the pcg statistic [i64]. this uses the fact that if there are k points uniformly distributed on (0,1) then the first of these is distributed according to a beta(1,k) distribution. one can then calculate a left-tail p-value for each interval and combine them using fishers method. this simple method beats more complicated approaches [i6, i39, i23, i65] on the standard datasets. the current best technique for rate function estimation is described in [i52]. this is a two stage process. firstly one clusters the set of stochastic processes. secondly one counts time not in seconds but in the number of events that have occurred within a process cluster. it is worth contemplating why this works. consider the phones belonging to gchq employees - these cannot be brought into the building and so are very quiet between 9 and 5. if an employee turns their phone on at the end of the day and responds to a voicemail left earlier in the day then this activity has been triggered despite the multi-hour gap. by performing this transformation we turn this from a gap of many hours to one of a few events and we are better able to spot the causality. the slide deck [i47] contain details of much of the research conducted before october 2010. this does not however include the cluster-based rate estimation from [i52]. research into a streaming implementation of the pcg algorithm has been conducted in r1 at nsa [i51]. the work focuses mainly on data structures and approximations to allow the algorithm to remain within main memory. however given the large size of some of the datasets for this problem the techniques outlined may be useful should scaling prove to be a problem. r1 have started to investigate using inference on a parametric model for how causal time series are generated [i24]. this proposes a mixture model where bs events happen either according to an underlying poisson process or because of a causal a event. they demonstrate that this is a continous markov process and formulate tests on whether given pairs of stochastic processes are likely to be correlated. when the model assumptions are correct their likelihood ratio statistic is tens of times more powerful than the best general methods known at small sizes for some generating parameters. many of these techniques are included in the clasp software package, with new methods added once demonstrated as useful.\tmaintains clasp. it is available on the lid at /data/cryptomath_research/windata/infoproc/software/clasp/ saga is a technique which extends a measure of item similarity to set similarity [i48]. it has provably desirable properties and has case studies that have demonstrated its utility. in particular it has been used as a method for performing temporal correlations. if one treats a stochastic process as a set of times and defines a similarity measure between times then saga may be applied to measure the similarity of pairs of stochastic processes. this approach is radically different to anything else attempted and can perform surprisingly well on the standard clasp datasets. 4.3\twhat we care about now this subsection will set out the problems that are of interest regarding information flow in graphs. 29 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) 4.3.1\tdefinition and discovery the first and most fundamental problem is the definition and discovery of information flows in the graphs. this document deliberately declines to provide a mathematical definition of an information flow. there is not an immediately obvious definition and therefore it seems best to leave this as part of the problem. it was suggested by\tof r1 that it may be a good idea to start from how you would define it given perfect information and then work backwards. however hopefully the examples given in the introduction sufficiently illustrate the type of things we hope to find. further thinking about cascades as previously defined may help with a definition. of r1 suggested an approach for defining repeated information flows. one could phrase it as learning a distribution over when/which edge will have a transaction next given previous (and possibly future) activity on adjacent edges and further information, such as time of day. repeated information flows could then be seen as high likelihood paths through this dis- tribution. can such a probability distribution be written down in a form where (approximately) evaluating it is tractable? the enron and skb datasets are atypical of sigint data in that there is information on the content available. however this should be very useful for formulating definitions of information flow as it will be easier to see the flows occurring. in the skb the flows correspond to various media being passed around the internet. the circulation of extremist media is of particular intelligence interest. it is suggested that these datasets be seen as truthed data and for gaining familiarity with techniques suggested in the literature. we are less interested in developing new techniques which depend upon having the content of transactions as this limits their applicability. we are therefore probably restricted to extracting flows which repeat rather than occur singly. what do the skb and enron datasets tell us about how well we can extract information flows without content? can we perform exploratory data analysis on the skb to inform the definition and discovery of flows? can we spot typical transfer patterns? research on improving clasp has been aided by the availability of two standard datasets. these each consist of two subsetsa random sample of processes for which there is no reason to believe any relationship exists, and a sample of pairs for which there is some external reason to believe a relationship may exists. this allows roc curves [w34] to be compared between techniques and an objective comparison to take place. can similar datasets and comparison mechanisms can be created for this problem and therefore help drive research collaboration? there have been many different approaches to temporal correlation, both explicitly graph- based and not, as demonstrated in the previous subsection. can we find a theory that unifies these approaches? one possible direction is to consider having placed a prior distribution on the probability of a significant temporal correlation being present. for example clasp can be seen as putting a uniform prior over all pairs of edges, while prime time is uniform only over edges sharing a common vertex. 4.3.2\tmissing data and noise sigint data is almost always incomplete. in terms of this problem certain edges may not have been observed or some transactions on edges may be missing. in experiments carried out on billing records and sigint during the 2008 graph mining swamp at himr there was 30 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) shown be a huge disparity between our view of the world and ground truth [i73]. csec have perform similar analyses with similar conclusions [w4]. it is therefore important to be resilient to missing data, especially where a flow may be cut in two. an internal example of coping with missing edges is salty otter [w37]. it uses clasp to find likely cross-media triggering patterns, for example telephone conversations typically causing instant messenger chats. the tool is essentially coping with the missing edge and allowing the information flow to carry on regardless. there has been some external work on how sampling or missingness affects the appearance of information diffusion and cascades. [e9] evaluates how different sampling strategies affect the view of hashtag diffusion in twitter. clearly we do not generally get to choose how our data is sampled, but this work may help the understanding of how well/poorly we are likely to do. [e34] goes further in proposing a method to correct for missing data in information cascades. their method assumes that cascades are k-trees, each vertex in the graph is sampled with uniform probability and the graph structure is known for sampled vertices. given these, they claim to be successful in reconstructing properties of the original cascades. these external approaches assume that we have the content of a transactionis there anything we can do when we do not? the obvious approach to this problem is to remove edges/transactions from a dataset to simulate poor collection. we can then evaluate different coping strategies by seeing how our performance is impacted. here the enron dataset is probably a good place to start, as we have ground truth and can uniquely guarantee that it is the complete dataset. however any technique developed must behave sensibly on sigint data. the data that we do have has further problems beyond missingness. in particular the quality of the timing information is not as good as we might hope for. this presents at least two concrete problems. firstly, our data tends to have second timestamps, which may be too coarse a measure for many applications. does the granularity of the timestamps affect our chances of finding causal flows? secondly the clocks on our probes are not synchronised. this means that there is likely to be a constant offset between events happening on different bearers. any technique to correct for this offset will both aid this problem area and be of general interest to the internal data mining and information processing community. can we correct for the clock offset between probes? possible solutions may involve examining the same connection being intercepted on different bearers. 4.4\tpotential future interests there are further problems in this area that may become tractable as the subject knowledge grows. 4.4.1\tperforming inference on flows assuming that information flows can successfully be identified and extracted we should then be able to perform inference on/with them. the obvious first area to investigate would be anomaly and change detection. the interest in this was hinted at in the introduction in investigating how a target network changes after the removal of a commander. given that this document does not even define a flow then it is not reasonable to scope this future problem any more 31 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) tightly. should you reach a point where you can tackle this problem you should have a good idea of what anomalies and changes mean within the framework you have developed. 4.4.2\tinformation flow for graph generation there are many existing models for graph generation. examples include the forest fire al- gorithm [e26] and bollobas-janson-riordan family of graphs [e5]. however, these approaches, although sequential, do not describe how graphs are truly generated. that is, they do not accurately correspond to how a graph, and the transactions on it, are generated in reality. if the definition and discovery of information flows is successful then it may be possible to use the descriptive models for graph generation. this feels far closer to how graphs are really gener- ated. each transaction is undertaken to convey information. therefore adequately modelling the flows leads to the observations.\tof\tmay well be interested in such ideas as he has stated dissatisfaction with the existing approaches. there is probably limited sigint interest in this problem unless a convincing argument can be made otherwise. we know of no internal work on any subject which has used any graph generation algorithm. 4.5\trelevant data we have several relevant datasets with truthed data, of which some have already been men- tioned in the main body of this section. the enron (appendix f.2.1) and skb (appendix f.1.4) datasets are atypical as most sigint data does not have any content associated with it. they can be treated as truthed datasets for the evaluation of algorithms for extracting significant information flows. we also have a large dump of five alive (appendix f.1.2) that summarises all ip con- nections on research bearers. there is no content associated with this data. we do have some truthing on flows that may exist in the data. specifically, we have data on covert infrastructure (appendix f.3.3) used for exfiltrating data from cne implants. these suspected flows can be used for both eda and evaluation purposes. further, we have lists of ips that we suspect to be infected with the conficker botnet (appendix f.3.4), either due to signatures collected or behavioural analysis. again, we suspect that there are some information flows involving these ip addresses. we also provide two standard datasets used for evaluating temporal correlation algorithms (appendix f.1.5). if you have any insights on how to perform temporal correlation due to your work on this problem you may wish to use these for evaluation purposes. 4.6\tcollaboration points there are several collaboration opportunities available for information flow in graphs. nsa r1\tcoordinates the research into temporal correlation and is always happy to hear of new ideas and approaches. he also indicated an interest in this new research area. 32 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) ictr-dmr the temporal analysis tools prime time and salty otter were developed in ictr-dmr. although they currently are not working in this area they would certainly be interested in any results.\tshould be your first contact in ictr-dmr. ictr-ne ictr-ne are interested in using information flows to find tor routes, identify backhaul routes and map botnets. they currently have a hadoop prototype called hid- den otter which performs simple temporal chaining. they would be very interested in any work you produce and may wish to collaborate. hidden otter was produced by\tand| ictr-cisa the streaming analysis team have had a streaming prime time developed by detica. they are always interested in streaming algorithms and deploying them as research prototypes. if your research takes you in a streaming direction then you should contact the streaming analysis team led by ccs bowie\tof georgia institute of technology is a leading academic figure in large graph analysis. he is cleared and has previously worked as a consultant in nsa r1. he is now in the process of joining ccs bowie in a similar role. he is interested in ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "this problem area and may be a possible collaborator on both classified and unclassified work. us national labs at sandia national laboratory research on large graph processing for defensive analysis. and are leading 33 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) 5\teda on streams 5.1\tintroduction 5.1.1\teda exploratory data analysis (eda) is all about trying to find interesting features of data without necessarily having pre-formed hypotheses to test. one of the pioneers of eda was j. tukey [e41, e42], who argued for the value of eda over the traditional statistical approach, which he called confirmatory data analysis, where one starts with an hypothesis and collects data in order to test it. in eda, the data comes first, and what counts is understanding the data as it is. for the data analyst, this is an open-ended problem that is not tightly defined, but for the mathematical researcher developing algorithms, things are much more concrete. the aim is to use ones intuition, guided by domain-specific knowledge from the analysts, to develop precise algorithms that provide human insight on the data. we usually think of eda as being concerned with pulling out global properties of data; broad-brush visualizations of data. the second is really a variant of the first: we can reduce the data to more discrete values than a human could take in in a list or table, as long as there is a way to visualize them. (compare summarizing pairs by a correlation coefficient, or in a scatter-plot.) 5.1.2\tstreams in a stream we do not have enough memory to store everything we see, and we only get to see each piece of data once. many problems admit simple approximate solutions in the static setting by subsampling. in the stream, this option is not always available. the problems become much harder and controlling error estimates in approximate solutions is very difficult. on the other hand, streaming analysis gives us the opportunity to get situational awareness and real-time tipping from our data, as well as letting us process bigger datasets than we can afford to store. these are key benefits that we strongly want to capitalize on. for hands-on work, we are thinking of distillery, as opposed to hadoop (see appen- dices b and c). one way to think about the problem is in terms of data structures. there are only a few structures that we typically use to keep track of data when we write programs: lists, trees, heaps, hash tables and so on. what carries through to the streaming setting? which structures can we update in a stream? if we can tolerate some loss, can we maintain approximations to familiar data structures in the stream? if so, can we quantify and bound the errors? these streaming data structures are then the building blocks for streaming algorithms. given a particular data stream, what is an appropriate data structure that will capture what we need to know about the data in order to answer the sigint questions we have? a short survey summarizing various approaches to streaming data can be found in [e39]. the 2009 information processing scamp at la jolla also produced relevant material [i12]. 34 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) note on terminology when we speak of streaming graph algorithms at gchq, we are usually referring to what the external literature calls the semi-streaming paradigm. if the graph has n vertices, then we can typically store a small amount of information for each vertex, but we are not able to store all the edges or do any significant processing as each edge arrives. in other words, we assume we have o(n log n) storage, and can do o(1) work per event. (usually this can be o(1) amortized work, as long as this does not cause undue back pressure: see section b.5.1.) 5.1.3\tthe problems the problem areas on this topic overlap at the edges, and also tend to merge into the streaming expiring graphs problems, but to give some order to this section we loosely cluster them into four areas: graph problems with no sub-sampling allowed; visualization; modelling and outlier detection; profiling and correlation. 5.2\tgraph problems with no sub-sampling 5.2.1\tthe framework of graphs and hypergraphs events data frequently has a natural representation as a graph, or more generally a hypergraph. often, an event will be a communication between two entities, which we think of as an edge between two vertices, one vertex for each entity. there will normally be a notion of the originator and recipient of the communication, which makes the graph into a directed graph. sometimes, a communication can involve more than two nodes, in which case we can think of it as a hyperedge, and the overall structure a hypergraph9. we also look at graphs other than communications graphs: for example, colocation graphs, where vertices are joined by an edge if they were geolocated to the same place at the same time; network graphs, whose edges are physical links; or even semantic graphs, where nodes are concepts and edges relations between them. frequently, our data will come with additional information beyond the simple fact that a communication took place. for example, each vertex will have a boolean attribute, is this entity a target in broad oak? similarly, edges might have attributes like duration of communication. a common metaphor is to think of discrete attributes as colours and continuous attributes as weights. although we often need to do algorithmic computations on the underlying graph or digraph, taking account of the available attributes can enrich the sigint value of any analysis we do. 9some people prefer to think of simple hypergraphs as bipartite graphs, where the vertices and hyperedges are the two parts, and edges represent inclusion. 35 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) we are interested in finding global properties of graphs in a streamexactly if possible, but we expect that approximate solutions will often be the best we can hope for. this is obviously closely related to the streaming expiring graphs topic, but in our case we are not worried about expiring edges, and we focus more on counting rather than identifying and extracting graph structures. probabilistic counting in general (not specifically in a graph context) has been an area of active research both internally [i72, i40, i5] and externally [e16, e8] in recent years. 5.2.2\tcliques and other motifs an n-clique is a subgraph isomorphic to a complete graph kn. in a communication graph, this corresponds to an intuitive idea of a strong, close community, where everyone communicates with everyone else. for eda purposes, we would like to understand the clique structure of a streaming graph. what are the cliques? if a target node belongs to a k-clique, how surprising is that? one way to answer the second question is to get a good random graph model for the communication graph, and do monte carlo simulations to find out how likely k-cliques are to occur in the model graphs. there has been a lot of work on this, for example [i1, i57], but it has proved very difficult to find models that capture all the relevant properties of sigint graphs, or even to understand exactly what relevant properties we want to capture. an alternative approach is to just work empirically with the graph we see, and try to estimate how many k-cliques it has: this gives us some measure of how surprised we should be if target nodes belong to such a clique. this leads us to consider probabilistic counting. we might want to count not just cliques, but other subgraphs too: perhaps a clique with one edge missing. a motif in a graph is a subgraph isomorphic to a particular pattern graph: for example, when the pattern graph is a kn, the motifs matching it are the n-cliques. there are probabilistic algorithms for counting the cardinality of a set: for example, flajolet et al.s hyperloglog sketches [e16], proposed on the outside and extended internally by\t[i72]. there are also a variety of algorithms for counting triangles, i.e. 3-cliques. one example is [e40];\t[e8] has produced a good survey. is there a probabilistic counting algorithm for cliques or other motifs in a streaming graph? what can we say about error bounds? besides counting, we might also be interested in motif collection. if we have two fixed target nodes then motifs containing both nodes will give information about their common neighbours. for example, how many distinct v-shapes or squares contain them both? some csec work [i21] from a few years ago may be relevant. can we collect specified motifs containing a target node or nodes? removing pizza nodes (i.e. very high-degree nodes) is likely to be an essential prior com- ponent to get useful results. intuitively, a pizza node is likely to be a large impersonal entity like a pizza parlour or an electricity supplier: the fact that two people both communicate with the pizza node gives us no reason to think that they are linked socially. 36 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) 5.2.3\ttrusses let k > 3. a k-truss is a connected graph with > 2 vertices such that every edge of the graph is reinforced by at least k  2 pairs of edges that make a triangle with that edge. this concept was developed\tat nsa: the idea is to weaken the definition of a clique (any k-clique is certainly a k-truss) to allow for a few missing edges, but still capture the notion of a cohesive community, and at the same time produce something that is computationally tractable. people in the sigint community have looked quite a bit at trusses, following on from the foundational theoretical work\t[i15, i14] on properties of trusses, their relationship to cores and cliques, and streaming algorithms to find them. in particular, there has been some experimental work [i76] looking at trusses in communication graphs. the findings were surprising: there turned out to be huge k-trusses for quite large values of k, like k = 17. this was true even after splitting trusses at cut-points. a number of variants and generalizations have also been proposed (for example [i16, i17]). we would like to understand why these form. is there a better definition of truss that captures something like a closed-loop intuition (see section 2.1.3) without pulling in huge mon- strosities? in particular, as we have mentioned, a truss can have cut-points, i.e. single vertices whose removal disconnects the graph. on the other hand, trusses have high edge connectivity: one has to remove at least k  1 edges from a k-truss to make it disconnected. can we define truss- like structures with a different balance of vertex and edge connectivity? do giant structures still form? can we use a partial order derived from truss or core structures to perform hierarchical clustering? if so, can we avoid forming giant clusters? can we understand when community detection or clustering algorithms produce giant clusters? are there ways to prove (given some probabilistic model for the graph) that with high probability an algorithm will not produce large clusters? one specific suggestion by ^ is to look at clique percolation [e4] where there are multiple labels per node. what is the background distribution of sizes of k-trusses? is there a probabilistic solution (cf. the previous section)? 5.2.4\tother approaches there are also more open-ended questions about streaming algorithms for graphs. what graph invariants are both useful and can be found or approximated in a stream? in the academic world, there is a whole cottage industry devoted to coming up with new clustering algorithms. many will not have much use beyond allowing someone to publish a paper. is there a hidden gem in the open literature that the sigint community has missed? this problem obviously has the potential to lead one off down rabbit holes. as a concrete thing to look at, the first author has identified birch [w3] as an algorithm that may deserve a hearing. can we compute any measurements of centrality or betweenness in a stream? (we are more interested in centrality measures in subgraphs around targets: chart breaker [w6] vertex scores do something like this.) how stable are they as the graph evolves? is there concept drift? 37 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) can we approximate the graph distance distribution, and see how it varies with the pizza threshold? this has a bearing on what hop distance we should choose for contact chaining. conven- tionally, analysts focus on a 2-hop neighbourhood of their targets, but some work comparing billing records with sigint [i73] found that one needed to chain much, much further through sigint to reach a 2-hop neighbourhood from billing data. can we use the sigint to billing mapping (solid ink to fluid inksee appendix f.1.6) to help decide what the right thing to measure on a telephony graph is? csec have also done some work [w4] on comparing sigint and billing records. billing data is unlikely to be shareable, but for comparing results on different datasets, h4a would be a natural point of collaboration. 5.3 visualization 5.3.1\tvisualization in general for most people, visualization is a crucial ingredient in the sense-making loop when given a large amount of data to analyse. gchq is actively developing tools for visual analytics. a large team in ictr, split between mca and dmr, works on semantic graphs and visualization research [w14], and a visual analytics tool called mamba [w27] is currently being developed in partnership with detica. for graph visualization, nsas renoir application [w33] is also under active development. as himr researchers explore data for themselves, they will naturally develop their own visualizations to help them understand it. we encourage them to record what they come up with: perhaps some of these ad hoc visualizations could be useful to analysts too. himrs expertise is obviously in algorithms, not developing sophisticated visual analytics platforms. nonetheless, what dynamic or interactive visual tools would be helpful to explore sigint data sets, if someone else could be enlisted to create them? grinning roach [w17] and pirate carebear [w30] are existing tools for visual- izing sigint events, developed by dmr: they both produce plots for pattern-of-life analysis. dashboarding is well-established for electronic attack events, both internally and by anti- virus and security companies. can similar methods be applied to provide useful visualizations for traditional sigint analysis? there is some work in progress at gchq [w5] on dashboarding for the 2012 olympics, but it is fair to say that the approaches so far are not mathematically sophisticated. 5.3.2\tstreaming plots there has been some work in r1 on binning streaming data for histograms [i37]. what interesting plots can be produced in a stream? suggests starting with qq-plots; this is closely related to the problem of computing approximate quantiles of streaming data. cisa have also done some work [i55] on time series modelling in a stream, including bund- ling up r for use in distillery: this may be a good foundation to build on. if any algorithms of the sort discussed in section 5.2.4 that calculate summary statistics are 38 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) produced, could they be refined to produce plots (from which those statistics could be read off)? 5.4\tmodelling and outlier detection 5.4.1\tidentifying outlier activity outliers (e.g. low-volume telephone numbers, small connected components) are often exactly what sigint is interested in. they are also exactly what gets lost in subsampling. how can we find rare events with limited memory? can we take beyond supervised learning to the limit, and find a way to classify normal and abnormal behaviour from the data itself, without needing to train a classifier? a simple idea would be to choose an n in advance, classify the first n items in the stream as normal, then use a positive-only learning algorithm to build a classifier to apply to the remainder of the stream. can we do anything more sophisticated to bootstrap a classifier out of the data itself? work from\tat llnl is relevant to this. he is learning a gaussian mixture model on cyber data with particle filters and asking about newness by looking at probability density. can we ask about tail area instead? this question has also been posed to the 2011 nsasag [w28]. can we track new small connected components? this might be a group of targets who have dumped their old sim cards and replaced them. 5.4.2\tbackground distributions for significance tests we have already touched on the idea that we want a measure of surprise when we find outliers (section 5.2.2), and for this we want to know the background distribution: what does normal look like, and how can we quantify that? this section gives some specific examples of outlying behaviour that we look for, and for which we therefore want to find an empirical background distribution. any information along these lines could also feed into tests in dynamic graph. what is the distribution of the number of common neighbours of two nodes in a graph as a function of their degree? this is one way to try to measure the strength of association of two entities. what is the distribution of component sizes? terrorist cells and other target groups have been found because they form small components (or closed loops, to use the analysts term) isolated from the giant component. how surprising is it to see a node in a component of a given size? likewise for other measures of connectivity. what significance do various chart breaker [w6] relationship scores have? this involves looking at an email hypergraph, rather than just a simple graph. 5.4.3\twindow sizing we often want to pull off a finite chunk from a stream, either for offline analysis or for change detection metrics. how should we choose the window size? is there a happy medium between a narrow window 39 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) (little data, so large variance) and a large window (concept drift, so large variance) that leads to small sample variance? can we do something akin to anova analysis to look at the effect on sample variance of sample size versus concept drift across different window sizes? 5.5\tprofiling and correlation we are often interested in finding nodes that behave like a target node: they might be following the same modus operandi, or be another selector for a known target. 5.5.1\tcorrelations with millions of entities, there is no hope of storing useful information on all pairs. is there a sparse approximation to a correlation matrix? auto assoc [w2] scores may provide a relevant example of a large correlation matrix. these are similarity scores for pairs of target detection identifiers or tdis, which are unique, persistent identifiers associated to particular users or machines that indicate their presence on the network: the aim of auto assoc is to find out when multiple tdis belong to the same user or machine. see section 3.3.2 for further discussion of association scores. can we keep an approximate list of the top n nodes most closely correlated with a given target node? there is also the underlying question of how to score association. this is not strictly about eda on streams, but looking at how existing scores perform on streaming data might suggest ways of improving them. how can we score the association between two nodes? chart breaker [w6] gives a significance score between pairs of nodes based on emails exchanged. there is an ad hoc balancing between the value of an email where one side is sole recipient, ccd or bccd (cf. assigning weights to golds, silvers and bronzes in medal tables). is there a method with a better theoretical justification behind it? can we correlate the busyness profiles of nodes, for example to provide situational aware- ness of a ddos attack? 5.5.2\tfinding behaviour that matches a model frequently we have a modus operandi known to be used by particular targets, and we want to search for events matching that model in streaming data. recent work by\ton low-rank approximations [e1] may be useful: she has a general framework called cpd analysis that uses tensor decompositions to model multi-variable data and extract meaningful factors as rank 1 tensors. reducing dimension should make it easier to match up features. (this also has applications to link prediction, which is pertinent in sigint applications where we expect to have a lot of missing data.) if a target disposes of his phone and buys a new one, can we rediscover it in data? can we find ip addresses fitting the profile of, for example, a box engaged in a denial-of- service attack, or an implanted box beaconing to a c2 server? 40 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) mathematically, this may come down to something like solving an approximate subgraph isomorphism problem. csecs 2010 sawuneh did some exploratory work on data mining for cyber defence [i82], which gives some concrete examples of malicious behaviour to look for in events data. there is also existing work along these lines for botnet detection in crouching squirrel [i27, i71], and it may be interesting to compare with external work on streaming botnet detection by adaptive sampling [e45]. 5.6\teasy entry problems this section has some ideas for problems that do not have high entry requirements in terms of reading up on existing literature or doing lots of preliminary data manipulation: they might be a good place to start for people who like to get into things quickly. maths route: motif finding properties of trusses and their generalizations finding outliers data route: visualization streaming qq plots 5.7\trelevant data this problem set has the advantage that eda is needed for any and all of the streaming communication datasets we have available: the telephony, email, hrmap and cyber datasets all readily map to graphs (or hypergraphs), and present challenges for all four areas: streaming graph analytics, visualization, outlier detection and correlation. there is also a graph of the links between wikipedia articles (appendix f.2.3) in case researchers want a static graph of links to compare with the dynamic graph of clicks provided by hrmap. appendices f.1.3, f.1.1, f.1.2 and f.1.6 describe some particularly appropriate datasets, but most of the datasets in appendix f could usefully be explored. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "since eda is such a general requirement, it is equally possible to work with unclassified data sets. appendix f.2.2 describes a dataset being analysed by the ukvac (see section 5.8.2): besides being another source of events data that is somewhat different in nature to commu- nication data, it would also be useful to work with this data should any collaboration develop with ukvac participants. 41 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) 5.8\tcollaboration points 5.8.1\tinternal ictr-dmr.\thas the best knowledge of how analysts work and what will be useful to them. he also champions research on payphone activity.\tdeveloped some of the fundamental algorithms currently used at gchq for contact chaining and scoring strength of association.\tleads on eda, though not specifically focused on streams. for visualization,\tand\tare involved with the mamba project. ictr-cisa.\tis a distillery guru, and\ttracks research on streaming algorithms across the community.\tis also a good source of in- formation on distillery and streaming implementations in general. nsa/r1: information processing group. there are already good contacts with r1 from himrs crypt work, and it would be good to build on that: for example, is a frequent visitor to himr and is always interested in questions about probability, ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Confidential", 
        "paragraph_text": "random hypergraphs and stochastic processes.\t(currently sitting in lts) has published on eda on streams, and is planning to write a book on the subject. kachina. sandia national lab in the usa has a multi-year project called kachina to look at large graph processing for defence analysis. a good point of contact is (nsa/r4). pod 58: cyber exploration. in particular in the past. (nsa/r1), who has visited himr 5.8.2\texternal ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "ukvac (uk visual analytics consortium). one of the two challenge problems for phase 2 (approximately 18 months from may 2011, subject to funding) asks for visual analysis of 120m events (several years worth of flight arrivals and departures in the ussee section f.2.2). the brief they have been given is very closely aligned with the streaming events model described in this section, and there is as much of an overlap with ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "the problems here as is possible at unclassified. if anyone in the sigint community is going to collaborate directly with ukvac, it will probably be himr. there are five fairly independent groups working as part of the ukvac. imperial ) and oxforddo substantive mathematics. middlesex and\tdo substantive non-mathematics. bangor seem most engaged with this dataset so far. the best thing is probably to spot promising activity that emerges, get in touch with the people doing it, contribute suggestions and hope that this leads to collaboration. in the fairly likely event that it is difficult to track what is happening and who is doing what,\t(middlesex) has high betweenness-centrality in the graph of ukvac participants, and would be a good first point of contact. 42 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) instinct. the ukvac is sponsored by instinct, a uk government project to use data mining for counter-terrorism, led out of the home office. they organize other activities too, most recently a public competition on ways of fusing data streams [e20]. some of their projects will be more relevant than others, but it may be worth keeping an eye on what they are doing. upcoming projects usually get mentioned on blogs on gcweb; will also be able to suggest contacts if required. (at&t). an expert in probabilistic counting; has been keen to engage ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "with gchq at the unclassified level. ibm safer planet. this is a big corporate project covering some of the same ground as this problem book.\tis in touch with the organizers, and is keen to look for opportunities to get gchq and himr involved. 43 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) 6\tstreaming expiring graphs 6.1\tintroduction streams of transactional events often arise in sigint problems. a classic example would be telephony events where we have a directed event from one telephone number to another when we detect a phone call. in this case we would typically have a relatively small number of target numbers we are interested in and would collect the events around these - we call this a seeded graph. an event or transaction is a (normally timestamped) observation of an edge, and so for each edge in the graph we may see multiple events. in some recent problems, for example electronic attack events, we have been interested in looking for structure in the entire graph. a denial of service attack might be visible for example as a vertex which suddenly has many incoming edges. we have techniques for handling the seeded case in a streaming way, expiring old edges and maintaining a current view of a graph, for example gchq dynamic graph [w12] and associated simulations completed by nsa [i2]. this research area is about investigating the second case where we are interested in tracking the full graph as it varies over time. we imagine that we want to expire old events or edges somehow. this might be by maintaining a buffer of the most recent n events, maintaining the n most recently seen edges, or by decaying edge weights over time and expiring those with the lowest weights. other decay strategies might also be appropriate. for some problems we may not need to store the full window, and can instead find an analytic that produces equivalent results. any algorithm should ideally parallelise so that we arent restricted to the memory or network bandwidth available on a single computer. in a dynamic graph problem the typical aim is to maintain a data structure for answering queries whilst also receiving updates to the graph. the aim is to maintain information that can be updated efficiently given the stream of changes to the graph, and to avoid total re- computation for each query. we say a graph problem is fully dynamic if the updates include both insertions and deletions of edges. a problem permitting only one type of update (insertion or deletion) is sometimes described as partially dynamic. some literature uses the term evolving graph instead. an old but good overview of some dynamic graph algorithms is given in [e14]. an expiring graph can be thought of as being a dynamic graph where we allow arbitrary edge insertion, but edge deletion is restricted to one of a small subset of the edges, for example the oldest or lowest weight edges. as in the eda on streams problem (section 5), we expect solutions to run in a streaming fashion on the distillery platform. we are also interested in how we might bootstrap such an algorithm using a map-reduce job on a hadoop cluster where that makes sense, however this is not the main focus. 6.1.1\tthe problems in section 6.2 we list graph properties which we would like to be able to find and track as the graph evolves. we allow some freedom in how the graph evolves. edges may decay over time with low weight edges being expired. we might maintain the most recently observed edges, or we might retain a window of the most recent events, either chosen to be a fixed size or over a fixed time period. we expect different problems to be possible with different expiry 44 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) mechanisms so the choice should be considered separately for each problem. for each property we list, we are interested in answers to the questions posed in section 6.3. we list some further extensions in section 6.4. 6.2\tproperties to find and track in this section we assume a graph g(v, e) with n vertices in vertex set v and with edge set e. we use dv to mean the degree of vertex v. 6.2.1\tcomponent structure in most sigint graphs we empirically expect to find a giant component containing most of the vertices (see for example [i34] and [i33]). it has been shown in the past that examining the remaining components can yield valuable intelligence [i32]. for example a humint agent and their handler might use specific phones to speak to each other and never use these phones otherwise. terrorist cells might have separate phones for calling each other; again these would never contact numbers in the giant component of the graph. we are therefore interested in finding these small components (note that this interest is very sensitive). component tracking has been studied for dynamic graphs for example [e2]. can we identify small components in an expiring graph? the query could include a time since which edges should be considered, or such a time might be implicit in the expiry strategy. can we track the component structure of an expiring graph to be able to answer a query such as is there a path between a and b with all edges having been observed since time t? given an approximate solution to these problems, can we provide an error estimate, for example upper and lower bounds? these might for example take the form of the maximum proportion of queries for which we provide the wrong answer. 6.2.2\tgraph distance the distance between two nodes in a graph can be an indicator of how related they are, for example in contact-chaining analysts will often look at the two-hop contact network of a target. for some graphs we might like to be able to answer queries of the form what is the distance from a to b with all edges having been observed since time t?. we can think of the graph as being either directed or undirected, and weighted or unweighted. we would typically remove high degree vertices before asking such a question. external work in the area includes [e15]. give an approximate answer for the distance between any two vertices for edges observed since time t, including error bounds. a related problem is to provide alerts when the graph distance between two sets of vertices goes below some threshold, for example if two groups of targets are seen to communicate. can we track the distance between two (possibly dynamic) sets of vertices. can we efficiently identify when two sets of vertices have a length d path between them? 6.2.3\tcliques and other motifs in section 5.2.2 we describe the problem of counting cliques and other motifs. network analysis suggests that some structure may be important for example in target identification or malware 45 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only a a ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) detection. where we expect a structure to be rare, the appearance of such structures may be an anomaly we wish to investigate. in telephony data, cliques or near cliques with few connections to the remainder of the graph is a known mo of certain target groups. the members are in frequent contact with each other, but rarely call others. in the case where they never call other numbers we describe it as a closed loop (see section 6.2.1 on the preceding page). can we find and track cliques or near-cliques which are persistent in the graph over time? if a new number enters a clique (or near clique) at the same time as another member ceases communication we might infer that a user has changed phone number. can we identify such occurrences? bounds here are likely to be based around the size of the clique found, for example given there exists a k-clique in the graph what size sub-clique does the algorithm guarantee to find? our graph also has a time element - edges are observed repeatedly. given a timestamp, can we extract all cliques or near-cliques of some size where all edges have been observed since that timestamp? can we do this for other motifs? 6.2.4\tcentrality measures the centrality of a vertex in a graph measures the relative importance of that vertex. for example it might show how important a person is within a social network, or how important a website is in terms of reachability of other sites. common centrality measures include the degree, betweenness, and eigenvector centrality. the simplest is the degree centrality, defined for each vertex as the number of incident links, scaled by the possible number, that is cd (v) dv n  1 tracking the (approximate) degree centrality in o(n) space is relatively easy without expiry of edges, but can we track it for each vertex in the case of an expiring graph, for both the weighted and unweighted cases. the vertex betweenness centrality of vertex v is (informally) the proportion of all shortest paths in the graph which pass through vertex v. if aab is the number of shortest paths between a and b, and aab(v) is the number of shortest paths between a and b passing through v then cb (v) e a=v=bv vab(v) ab we are not particularly interested in the global betweenness centrality, but would be inter- ested in ways to track it for specific subgraphs, for example the 2-hop graph around some set of seed vertices. is it possible to maintain an approximation to the betweenness centrality for a set of vertices as the graph (and the vertex set) evolves? some internal work in this field is described in [i46]. the eigenvector centrality scores nodes in such a way that high scoring nodes contribute more score to their neighbours than low scoring nodes. a variant is the google pagerank algorithm [e30]. in the basic case, the eigenvector centrality of vertex v is the corresponding entry in the eigenvector of the adjacency matrix of g corresponding to the largest eigenvalue. 46 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) again we arent directly interested in the global eigenvector centrality measures, but would be interested to track local variants, for example personalized pagerank or the internally developed kl-relative pagerank [w45]. can we track any personalized variants of the eigenvector centrality for some (possibly changing) set of vertices in an expiring graph? there has been internal work on updating eigenvectors and eigenvalues as more edges are observed at the information processing scamp in 2009, see [i81], along with a report on its possible implementation [i56]. 6.3 questions relevant to all properties 6.3.1\tapproximation typically it is not necessary to know the exact values of the properties listed above, and we can make do with an approximation. for an approximation to be useful it should include some form of error bounds, although the form these take will depend on the specific problem. they could include e-6 bounds, strict upper and lower bounds, errors with a known statistical distribution, etc. are there approximate solutions to any of the problems listed? where an exact solution exists, how does the computational cost (time and memory) compare? 6.3.2\tcomputational cost for each of the problems listed in section 6.2 we would like to know the cost of evaluating the properties in this way. for our purposes cost is cpu time and memory usage as a function of the data size (asymptotics are important but we also care about the constants as derived from experiments). we typically work under the semi-streaming graph model where we allow ourselves o(n log(n)) space. for example, we might imagine storing a component id for each vertex. for most problems it would be possible to collect a window of data from the stream and re- compute the required statistics at the desired query interval. whether this is practical depends on the window size, the frequency of updates to the graph, and the frequency (and latency) with which an answer to the query must be returned. the trade-offs should be considered - incremental updates might take more compute overall, but in situations where we can take some automated action based on the results then we might be willing to accept the cost to gain the low latency. in most settings it is unnecessary to know the answer to a question for every edge addition or deletion, and it is instead sufficient to be able to compute the answer after each batch update, so long as those updates are sufficiently fast. furthermore, the online process may track and store data to allow efficient updates, but to get the desired answer may then require us to further process the data we have stored. we might then choose to run this further processing less often, for instance at the request of an analyst. this is a perfectly valid approach, and could be particularly valuable if the data structure lends itself to answering multiple types of query. concrete questions include: what is the (mean) cost of an update? what is the worst-case cost? 47 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) at what query frequency does the total computational cost of incremental updates become lower than the cost of total re-computation on each query? how does this depend on batch size? how does the computational cost vary depending on features of the graph, for example diameter or average distance. how does the cost vary depending on the window size or the decay rate? 6.3.3\texpiry policy as well as affecting the speed and computational cost of an algorithm, the choice of expiry mechanism will affect the accuracy of the results. for windowed data, how should we choose the window size to ensure we get realistic results at a reasonable speed? is it possible to dynamically change the window size? for decaying data, how should we chose our decay rate to maintain realistic results? can we change the decay rate without restarting the algorithm? 6.4\tfurther questions 6.4.1\tparallel and distributed processing for high rate data feeds it may be necessary to process the data on multiple nodes of a cluster. the data feed would be split between nodes and these streams cannot be combined until their rate is sufficiently reduced. which of the graph properties can be computed in a parallel way? some sigint data sources are split between multiple geographical sites, with limited band- width between them. is it possible to solve any of these problems for the (virtual) stream of joined data? in this case we would expect to process each feed at the collection site and send a much smaller set of data between sites, either periodically or in order to answer a query. 6.4.2\tbootstrapping for some properties it may be possible to get an initial approximation to the correct values by running a map-reduce query on an events hadoop cluster. can we make use of bootstrapping to improve the efficiency of our processing? this might be particularly relevant when we process the stream in parallel and wish to split the vertices over multiple nodes of a cluster with each node being responsible for some proportion of the vertices. 6.4.3\tanomaly detection for many of the properties we wish to compute, we would also like to be able to produce an alert for anomalies in the data. for example, in the web graph, if a vertex is suddenly connected to a large number of other vertices this may indicate a denial of service attack. alerts may be used to trigger additional processing, for example capture and storage of relevant data or additional processing to categorise the event. some internal research in this area can be found in [i20]. can we detect significant changes in the properties we are tracking? how soon are we able 48 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) to detect the change after it initially occurs? 6.4.4\tresilience over time our collection posture changes. bearers are tasked and de-tasked, and systems can fail. this can have a significant effect, especially when monitoring for how are the algorithms affected by variations in data volumes? if we identify that a change is due to a processing failure, can we account for generating future alerts once the processing resumes? see for example [i10]. 6.4.5\tqueries on graphs with attributes many sigint graphs have some form of attributes associated with vertices and edges, for example the location of a phone. it can be useful to answer queries where we restrict ourselves to vertices with a particular value for some attribute. is it possible to modify your algorithm to enable queries on vertices with particular attributes? 6.5\trelevant data any streaming graphical data is suitable for these problems, giving a variety of options. ex- amples include hrmap, telephony, email, squeal alerts and ip flow metadata. all provide a stream of events with some notion of a source and destination vertex, along with the timestamp of the event. in addition we have various reference datasets. for example section f.3.1 describes a database of websites of interest to counter terrorism and broad oak lists known target phone numbers and email addresses (see section f.3.2). these could be used to identify if an extracted graph structure has a higher density of targets than would be expected. the idea of wanting to process a stream of edges is not specific to the intelligence community, and so external collaboration should be possible given a suitable dataset. 6.6\tcollaboration points there are the following potential collaboration opportunities both within and outside the in- telligence community. kachina: sandia national lab in the usa has a multi-year effort called kachina which includes the questa project to look at large graph processing for defence analysis. they hold security clearances, and would be an obvious group to collaborate with. points of contact are^^^^^^^^| (nsa employee deployed to sandia) and^^^^^j is engaged both in external research at georgia tech and as a researcher in r1 at nsa. his external research in the field includes [e3, e12, e28]. collaboration ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "should be possible on both classified and unclassified problems. pod58  cyber exploration:\tthe pod runs until the end of january 2012, and aims to use analysis frameworks including distillery to support analysis of cyber data. s the r1 research lead in the pod. 49 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only processing anomalies. that when ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) nsa/r: various people around the research division at nsa would be good people with whom to collaborate. specific names include\tand\twho normally attend the various five-eyes conferences.\tis a gchq integree at nsa working on data mining problems including the integration of streaming analysis and mapreduce based analysis. ictr-cisa: this team is responsible for streaming analysis research at gchq. much of their work revolves around the platform (distillery) however they are also active in developing algorithms.\tis the team lead. ibm research: as part of the infosphere streams (distillery) platform, ibm are devel- oping a graph analytics toolkit. this is in its early phases and there is potential to ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "collaborate on this (at an unclassified level), and potentially have any algorithms developed incorporated into the toolkit. initial contact can be made through in ictr. 50 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) a ways of working this section gives a few thoughts on ways of working. the aim is to build on the positive culture already established in the institutes crypt work. himr researchers are given considerable freedom to work in whatever way suits them best, but we hope these ideas will provide a good starting-point. a.1 five-eyes collaboration as on the crypt side, we hope that ukusa collaboration will be a foundation-stone of the data mining effort at himr. this problem book is full of links to related research being carried out by our five-eyes partners, and researchers are very strongly urged to pursue collaborative angles wherever possibleabove all, to get to know the people working on the same problems and build direct relationships. researchers are encouraged to attend and present at community- wide conferences (principally sanar and ace), as funding and opportunity allows. we hope that informal short visits to and from himr will also be a normal part of data mining life. himr has a tradition of holding short workshops to focus intensively on particular topics, where possible with participation from experts across the five eyes community. fre- quently these are held during university vacations, to allow our cleared academic consultants to take part. each summer, himr hosts a swamp: a two-month long extended workshop on (traditionally) two topics of high importance, similar to the scamps organized by ida. we hope that himr researchers will feel inspired to suggest possible data mining sub-topics for future swamps. a.2 knowledge sharing inevitably, there is a formal side to reporting results: technical papers, conference talks, code handed over to corporate processing, and so on. but informal dissemination of ideas, results, progress, set-backs and mistakes is also extremely valuable. this is especially true at himr, for several reasons. there is a high turnover of people, and it is important that a researchers ideas (even the half-baked ones) dont leave with him or her. academic consultants form an important part of the research effort: they may only have access to classified spaces a few times a year for a few days at a time, so being able to catch up quickly with whats happened since their last visit is crucial to help them make the most of their time working with us. himr is physically detached from the rest of gchq, and its important to have as many channels of communication as possiblepreferably bidirectional!so that this detach- ment doesnt become isolation. the same goes even more so for second party partners as well. in himrs meteor shower work, knowledge sharing is now primarily accomplished through two compartmented wikis hosted by ccr princeton. for data mining, there should be more flexibility, since almost none of the methods and results produced will be eci, and 51 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) in fact they will usually be strap1 or lower. paradoxically, however, the fact that work can be more widely shared can mean that there is less of a feeling of a community of interest with whom one particularly aims to share it: witness the fact that there is no shining model of data mining knowledge sharing elsewhere in the community for himr to copy! we suggest that as far as possible, data miners at himr build up a set of pages on gcwiki (which can then be read and edited by all five-eyes partners) in a similar way to how crypt research is recorded on the ccr wikis. they can then encourage contacts at gchq and elsewhere to watch, edit and comment on relevant pages. in particular, the practice of holding regular bull sessions10 and taking live wiki notes during them is highly recommended. if any researchers feel so inclined, gcblog and the other collaborative tools on gcweb are available, and quite suitable for all strap1 work. for informal communications with people from mcr and ictr, there is a chat-room called himr_dm: anyone involved in the himr data mining effort can keep this open in the background day by day. there is also a distillery room that is sadly under-used: in principle, it discusses spl and the corporate distillery installations. for any strap2 work that comes along, there are currently no good collaborative options: creating an email distribution list would be one possibility. a.3 academic engagement the first test for himrs classified work must be its applicability and usefulness for sigint, but given that constraint, gchq is keen to encourage himr researchers to build relationships and collaborate with academic data miners, and publish their results in the open literature. of course, security and policy will impose some red lines on what exactly is possible, but the basic principle is that when it comes to data mining, sigint data is sensitive, but generally- applicable techniques used to analyse that data often are not. just about everyone nowadays, whether they are in academia, industry or government, has to deal with big data, and by and large they all want to do the same things to it: count it, classify it and cluster it. if researchers develop a new technique that can be published in an open journal once references to sigint are excised, and after doing a small amount of extra work to collect results from applying it to an open source dataset too, then this should be a win-win situation: the researcher adds to his or her publication tally, and himr builds a reputation for data mining excellence. of course, there may be occasions when publication is not appropriate, for example where ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "a problem comes from a very specific sigint situation with no plausible unclassified analogy. day-to-day contact with the deputy director at himr should flag up cases like this early on. there are also cases where we feel we have an algorithmic advantage over the outside that is worth trying to maintain, and this can be further complicated if equity from other partners is involved, or if a technique brings in ideas from areas like crypt where strict secrecy is the norm. the deputy director should be consulted before discussing anything that might be classified in a non-secure setting: he or she can further refer the question to ops policy if necessary. over 10informal meetings at blackboards where people briefly describe work they have been doing and problems they have encountered, with accompanying discussion from others in the room. the rules: people who wish to speak bid the number of minutes they need (including time for questions). talks are ordered from low to high bid, with ties broken arbitrarily. you can ask questions at any time. you can leave at any time. if you manage to take the chalk from the speaker, you can give the talk. 52 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) time, researchers will build up a good idea of what is sensitive and what is not, but in the first instance, erring on the side of caution is a sound starting point where classified information is involved. similarly, if there are grey areas about when work should count as part of a researchers ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "classified or unclassified effort, this can be settled by an informal conversation with the himr director or deputy director. 53 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) b distillery distillery is a project to deliver a platform for near-real-time streaming analytics. it is a research partnership between nsa and ibm research, with gchq also having been involved for a number of years. distillery was released by ibm as a commercial product in 2010 as ibm infosphere streams, often shortened to just streams. we use the three terms synonymously. for more on the distillery platform, and links to plenty of other useful pages see [w11]. central to the distillery platform is the stream processing paradigm. we use the terminology of the streams documentation. a streams application is made up of one or more composite operators. a composite operator contains one or more operators, each of which has zero or more input ports and zero or more output ports. data takes the form of tuples conforming to a schema, where the schema defines the names and types of the entries which make up a tuple. streams of tuples flow along the edges of the flow graph between the operator ports and the operators carry out some kind of transformation on these streams. when built and launched into the streams platform, operators are placed in a series of processing elements or pes connected according to the application flow graph. each pe contains one or more operators (by default exactly one, but we can combine multiple operators into a single pe for efficiency). crucially, we can process data as it arrives. if we know in advance what questions we would like to ask of the data then we may never need to store the data. instead, we build a processing flow to answer the question on the stream of data. our output is a stream of answers. as well as saving storage, processing data provides other advantages. an obvious one is near-real-time tipping. given some event of interest, we can alert an analyst as soon as we observe that event. we can typically provide a tip-off within a second of the event occurring, although the latency of the analyst is somewhat higher. however we do not restrict ourselves to tipping a human. observing an event might cause us to take some other action, for example collecting more detailed data for identifiers that appear in the initial event. streams applications are written in spl, the streams processing language [w40], and are run on infosphere streams version 2. older applications were written in spade and run on infosphere streams version 1. we are currently converting our applications from spade to spl, and we plan for most new applications to be written in spl. b.1 when would i use infosphere streams? stream based processing is useful any time where you want to produce results as soon as possible after the relevant events occur or when we cannot reasonably store all the data required for a problem. in these situations we can use streams to handle the plumbing between our operators. it provides parallelism over multiple hosts in a cluster whilst also providing some resiliency against system failures. through the use of import and export operators an application can be developed and deployed in stages, and data streams can be shared with other users. import operators will also allow you to take advantage of the data streams already available on the cluster. in this case, someone else will already have arranged for the feed to be delivered from our front-end collection systems, and your application need not be concerned with format changes. 54 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) b.2 documentation and training documentation is linked from and\tfurther documentation can be found on a streams cluster at the spl documentation consists of: spl introductory tutorial: start here after following the instructions on getting started below. spl language specification: describes the language itself. spl standard toolkit reference: describes the operators provided in streams. spl standard toolkit types and function: describes the built in functions. spl config reference: covers additional configuration options which allow you to alter the behaviour of operators or the runtime platform. spl compiler usage reference: describes the many compiler options in detail. spl operator model reference: the information you need to write a new operator. spl streams debugger reference: describes how to use the debugger. studio installation and users guide: describes the eclipse development tools available to help you write spl. installation and administration guide: covers how to install streams and to configure a streams instance. training may be available from ibm uk organised through qa - contact or details of upcoming courses. ibm, nsa and gchq have published a paper on design principles which may be useful [e43]. b.3 logging on and getting started access to a distillery cluster is via ssh, and you will initially use the bhdist ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "cluster (see below). use one of once you log on for the first time you should go through the steps listed on the getting started gcwiki page [w16], although the following steps should be sufficient to get you started. configure key based ssh access (accept the defaults presented by ssh-keygen): ssh-keygen -t dsa cd ~/.ssh cat id_dsa.pub > authorized_keys chmod 600 * 55 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [
          "startjobs"
        ], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) you should then be able to type ssh localhost and it wont ask for a password. this is essential as distillery uses ssh to launch commands and processes on all nodes (even when running only on localhost). add the following to your .bashrc file: # source global definitions if [ -f /etc/bashrc ]; then . /etc/bashrc fi umask 0027 export java_home=/opt/ibm/java-x86_64-60/ export eclipse_home=/opt/eclipse-spl export path=$java_home/bin:opt/eclipse-spl:$path export streams_splpath=/opt/distillery/toolkits source / configure a streams public/private keypair (to avoid needing a password to stop/start jobs) with: streamtool genkey set up a hostfile to tell streams which hosts to use. the hosts file is in e and for now should contain a single line with the host youre using but in the blackhole.net domain as this uses a faster network switch, e.g. you should now be able to follow the spl introductory tutorial linked from for using the eclipse tools, including the ability to view your jobs in a flow graph, then use eclipse with\tthis should be in your path if you followed the instructions above. figure 5 shows an example of multiple jobs connected together in a shared distillery instance, as seen through the streams live graph view in eclipse. many people choose to run a vnc session on the cluster to provide a desktop environment. for instructions see the distillery pages on gcwiki. the two main clusters used for research work are listed in table 2. to get an account on either contact b.4 data data typically arrives into a distillery cluster via either a udp or tcp socket from our front-end processing systems. udp is used where we need to avoid delays in our processing causing delays earlier in the processing chain - instead we just drop the extra data. we are moving to using tcp and then using a threaded port on the next operator so we can measure our data losses (see section b.5.1 on page 58). your home directory is shared over the cluster, as is\t. applications need to be run from a shared location so all nodes can access them. results should be saved to rather than your home directory as the filesystem is local to the cluster. 56 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) figure 5: streams live graph view: interlinked jobs in the ahs explore distillery cluster. node names\tnumber of nodes\taccount  management\tpurpose 10\tictr\tdevelopment and operational prototypes. data from ictr re- search probes. 3\tahs\tdevelopment and explore prototypes. data from mvr and mailorder. table 2: distillery clusters available for use. 57 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) b.5 conventions the distillery clusters contain operational prototypes as well as development code, so it is important to consider the impact on others when running jobs. when running jobs on the live data feeds, try to do initial processing and data reduction on the same host as the data import to avoid unnecessary network use. avoid causing back pressure to the live feeds - see section b.5.1. ideally you should test your code on a small sample before connecting to the live data feeds, although this may not always be possible. b.5.1 use threaded ports on shared data if the incoming data rate is faster than you can process then by default you will cause the incoming data to slow down, causing back pressure. if you are reading from a shared data stream then this affects everyone reading from that stream - all processing will be slowed down. this may cause data to be lost further up the chain, for example at the point where it is received from the front-end probes. to avoid causing this problem, you should normally configure the first operator of a job to drop tuples if it has too many already waiting to be processed. typically this would be an import() operator, which is configured as follows: stream i1 = importo { param subscription : datafeed == \"somedata\"; } stream i2 = functor(il) { config threadedport : queue(i1, sys.droplast); } the queue function has an optional third parameter which specifies the buffer size (in tuples), and the second option can be replaced by sys.dropfirst. when reading from a file then you should not set such a buffering configuration, since you want to read the data as fast as you can process it but without discarding any tuples. b.5.2 operator toolkits and namespaces spl (distillery) code is stored in toolkits. these split into two broad types - tookits of operators and toolkits containing applications. the five eyes repositories of toolkits are held in madforge and are described at . when we wish to share our operators (typically once they are tried and tested) then we will add them to madforge. before that we store the code in a git repository on http://github.ar.gchq, with the repository name matching the toolkit name but prefixed with spl-. instructions for creating a new repository can be found at most of the repositories get built at least once a week and deployed to the cluster. to add a repository to the build list contact\tor\tto have new versions of your toolkit be automatically deployed you must ensure that you increment the toolkit version number. toolkits are installed to /opt/distillery/toolkits and can then be 58 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) used in your applications. rather than hard-code this path we put it into the streams_splpath environment variable. toolkits containing operators are placed in the gchq.* namespace, for example gchq.ingest contains the tcplinereader operator for multi-threaded reading of sigint data. application toolkits are in the gchq.app.* namespace to differentiate them. these are not in- stalled into /opt/distillery/toolkits but are instead checkout out into /streams/apps if you want to run them. one particularly important toolkit is\t. despite the name, this is in fact installed into\tand contains the schemas for the data available in the cluster. this is needed when importing data into your application. as an example, hrmap data matches the hrmaprecord schema. details for all the datasets described in section f can be found in b.6 further help and resources the distillery team in ictr-cisa are the best points of contact for questions. is the team lead and can cover most types of issue.\tis the best contact for infrastructure issues. in opc-mcr the best contact for distillery questions is there is a distillery room on the instant messaging server (accessed using pidgin, see appendix d). this can be used to ask questions on spade, spl, and the infrastructure. although the ictr team do not make much use of it at present, there is normally someone there who can help. all relevant resources, are linked from 59 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) c hadoop hadoop is a software framework that supports static data-intensive distributed applications. its design is heavily based on that of googles infrastructure as disclosed in [e10]. it is designed to be scalable rather than fast and efficient. this means that for any given task there is likely to exist a more efficient solution. however the ease of parallelism more than counteracts this in most cases. in this model of parallelism the computation is shipped to the data, rather than data to computation, therefore saving large amounts of network traffic. typically hadoop is installed across a cluster of computers, which are often referred to as clouds. indeed the only reason to install it on a single computer is for testing purposes. hadoop consists of two main components, the hadoop distributed file system (hdfs) and mapreduce. as a user it should not be necessary to worry about how the file system is implemented. instead one can consider it to act just like a very large filesystem. however should one wish to use hadoop to process data then knowledge of mapreduce is required. fortunately the key concepts of mapreduce are simple and easily understood. as the name suggests there are two stages to any mapreduce joba map and a reduce. in the map stage one receives successive input records. for each input one produces zero, one or many output records in the form of key-value pairs. these output records then go into a shuffle phase, in which all records are sorted so that the reduce stage receives all records with a common key together. this reduce group is then processed together and again zero, one or many output records may be produced. as the entire output of the mapper is being sorted it is possible to perform a secondary sort to provide data to the reducer in an advantageous order. this is done by specifying that grouping should only consider part of the key, whereas ordering should consider all of it. a common use of this is to provide time ordered data in a reducer for a particular identifier. the hadoop framework is written in java. java is therefore a popular choice for writing hadoop mapreduce applications. using java one has access to the full functionality of hadoop and is recommended for sustainable code. however it is not necessary to know any java to get mapreduce jobs running on hadoop using the streaming package. streaming is invoked from the command line on a hadoop node. any script or program that accepts data on stdin and outputs it to stdout can be specified as a mapper or reducer. this significantly lowers the entry barrier and is ideal for quickly trying out ideas where the full java treatment seems like overkill. c.1 when would i use hadoop? the short answer is whenever you want to batch process a large amount of static data. there is not really any other option for such computations within gchq. a slightly longer answer is that hadoop clusters are where gchq has chosen to keep its bulk events data. this is due to the large amount of data processing power hadoop offers. with hundreds of hard disks working simultaneously multiple gigabytes can be read per second. this allows the processing of the multi-terabyte datasets we intercept. by having the data in its raw state it is possible to ask a huge number of different questions of it. this can be contrasted with the qfds which also store very large amounts of data, but are databases optimised for a specific type of analyst queries. the qfds therefore do not offer a sensible data mining 60 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) platform. hadoop generally excels when your algorithm can be expressed in a small number of mapre- duce steps. it is less efficient when implementing iterative algorithms. this is because between iterations all state must be written down to disk and then read back in again. this extra i/o cost can easily end up swamping the time taken to perform the computations. sometimes there may be no other way of performing an algorithm given the size of the data and the only solution is patience11. c.2 documentation and training the standard hadoop documentation is available linked from this consists of: a mapreduce tutorial that shows you how to write mapreduce applications in java. an introduction to hadoop streaming. although not a full tutorial all the information you need to run streaming jobs is there. an overview of the hadoop command line arguments. the java documentation of the hadoop api. if writing hadoop in java this is extremely useful. the hadoop page on gcwiki [w20] has many resources, including: 6 lectures and 2 exercises from cloudera, a hadoop consultancy company. an overview of hadoop by ibms jimeng sun. tom whites book hadoop: the definitive guide is probably the best book currently available on hadoop. it is also available on nsas safari book library [w35]. classroom based training should also be available. tdb have organised internal training led by gchq employees. some people have also attended a multi-day training course offered by cloudera. c.3 logging on and getting started access to hadoop clusters is via ssh. you will ssh to an edge node. these are not part of the compute cluster but do allow you to submit jobs and interact with hdfs. instructions for accessing sun storm, the largest cluster, are available at the other clusters are detailed in table 3. some useful aliases for your .bashrc are given below. adding these will save you a huge amount of typing and make interacting with hdfs feel more like using a regular filesystem. 11ictr-dmr are currently developing bagel an implementation of googles pregel distributed graph mining solution. while still in its early stages bagel keeps its state in memory and therefore avoids this extra i/o cost between steps. 61 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) cluster name\tnum nodes\tpurpose sun storm\t897\tcheltenham events cluster gold mine\t125\tcyber/content cluster hager awel\t800\tbude events cluster woody\t133\tictr research cluster buzz\t42\tictr research cluster table 3: gchqs hadoop clusters export hadoop_home=/opt/hadoop/current alias hadoop=${hadoop_home}/bin/hadoop alias hstream=hadoop jar $hadoop_home/contrib/streaming/hadoop-streaming-0.20.10.jar alias hl=hadoop fs -ls alias hjobl=hadoop job -list alias hjobk=hadoop job -kill alias hjob=hadoop job alias hjar=hadoop jar alias hc=hadoop fs -count alias hput=hadoop fs -put alias hget=hadoop fs -get alias hf=hadoop fs alias hcat=hadoop fs -cat alias hdu=hadoop fs -du export tmout=36000000 c.4 data there are a large number of datasets available on the corporate clusters. these typically each occupy a subdirectory under data. the datasets on sunstorm are listed at has equivalent datasets containing data processed at bude rather than cheltenham. c.5 conventions and restrictions the three corporate clusters are all configured similarly. this subsection refers to their configurationsfor the research clusters all bets are off and ictr-dmr should advise you of any restrictions should you gain access. c.5.1 scheduler the clusters all have the fair scheduler installed [w19]. this replaces the vanilla fifo that hadoop has installed by default. fair scheduling is a method of assigning resources to jobs such that all jobs get, on average, an equal share of resources over time. when there is a single job running, that job uses the entire cluster. when other jobs are submitted, task slots that free up are assigned to the new jobs, so that each job gets roughly the same amount of cpu time. 62 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) each user (and special processing users) are assigned their own pool. the scheduler tries to give each pool an equal amount of time on the cluster. processing users also have a minimum number of map and reduce slots below which they will not drop if they request them. further each user is restricted to having a single concurrent running job. c.5.2 hdfs /user/yoursid space on logging into a corporate cluster you will have a hdfs home directory created at /user/yoursid. this is where the results of your hadoop jobs will end up by default. that is, if you dont specify an absolute path,it will be taken relative to your home directory. your home directory has a size limit on it (believed to be 2tb). if you need more space than this then you should contact the cluster administrators to find a solution. c.6 running hadoop on the lid it is discouraged to use either sun storm or hager awel for developing code as they are both somewhat production systems. it is therefore a good idea to iron out bugs elsewhere if possible to ensure your code will not bring the cluster down. the easiest way to do this is probably on a pseudo-distributed hadoop installation, following the instructions given in the standard hadoop documentation. if you wish to do this on the lid then you need to do slightly more to get around issues with localhost not always being the same depending which box you are on. following these instructions should give you working hadoop instance. if the standard ports are already in use then more configuration properties need to be added. at this point its probably best to either try another machine or ask for some advice. 1.\tmake sure you can execute a passwordless ssh to your machine. this must be done using the machines hostname, not localhost. this is because there are multiple different lid servers, each with a different idea of what localhost is. by adding one machines localhost to the known_hosts file you will cause yourself problems. if passwordless ssh does not work execute the following commands. ssh-keygen -t rsa -p  -f ~/.ssh/id_rsa cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys 2.\tchoose a directory in which to install hadoop. this should be somewhere visible from all lid machines. following shell scripting we will refer to this as $hadoop_home. in fact you might want to put the following into your .userprofile along with the other aliases given previously. export hadoop_home=/path/to/hadoop/dir/ 3.\tuntar the hadoop tarball into $hadoop_home. 4.\tin $hadoop_home/conf/hadoop-env.sh add the line export java_home=/usr/lib/jvm/java-1.6.0/ 63 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) 5.\tmake the directories $hadoop_home/data and $hadoop_home/name 6.\tin $hadoop_home/conf/hdfs-site.xml add the entries dfs.replication 1 dfs.data.dir hadoop_home/data dfs.name.dir hadoop_home/name where hadoophome is replaced with the hadoop home directory. using shell vari- ables wont work here as the configuration files are read verbatim. 7. in $hadoop_home/conf/mapred-site.xml add the entries mapred.job.tracker hostname:9001 where hostname is replaced with the hostname of the machine you are on. 8. in $hadoop_home/conf/core-site.xml add the entries fs.default.name hostname:9000 where hostname is replaced with the hostname of the machine you are on. 9. in $hadoop_home/conf/masters and $hadoop_home/conf/slaves replace localhost with the hostname of the machine you are on. 10.\trun $hadoop_home/bin/hadoop namenode -format to format the namenode. 11.\trun $hadoop_home/bin/start-all.sh to start the hadoop daemons. 64 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) 12.\tto check this has worked ok go to http://hostname:50070/ to check on the status of the namenode and http://hostname:50030/ for the jobtracker. 13.\tnow you can try to run a toy hadoop job. copy the input files into the distrib- uted filesystem: $hadoop_home/bin/hadoop fs -put conf input. now run some of the examples provided: $hadoop_home/bin/hadoop jar hadoop-*-examples.jar grep input output dfs[a-z.] + . when you log out of this lid session the hadoop daemons will be killed by the logoff script. you will therefore need to restart them in your next lid session. however each time you log into the lid you cannot guarantee which machine you will be allocated. if you are allocated a different machine to that where you installed hadoop you will not be able to directly restart it. instead you will need to do so over ssh: ssh hostname hadoop_home/bin/start-all.sh again hostname is the machine on which you originally installed hadoop. you can then submit jobs and interact with hdfs from any lid machine, i.e. including the one you currently have a session on. hadoop will then carry on running until the end of the next session you are assigned on the machine on which you installed it. c.7 further help and resources in opc-mcr^^^^^^^^^^| is the best contact for hadoop questions,\tcan also offer advice, particularly on streaming. outside of mcr there is a large community of hadoop users and administrators. the best way to contact this community is probably through the rough_diamond chatroom on the jabber server. there are a large number of resources available on gcwiki. some highlights, in no partic- ular order: _(work_package): the main page for silver lining, the work package within tdb that provides hadoop clusters. it links to many places and may stay more up to date than this document. _-_user_guide: an initial user guide for the sun storm cluster. however many of the tips hold in general across all hadoop clusters. _-_streaming_interface: a short guide to user hadoop streaming with code examples to run on data on sun storm. : silver library is a library of ha- doop parsers, writables and other utility classes to simplify development of mapreduce analytics in java. this pages describes at least some of it. links to utilities and search are on the right hand side. the library is strongly recommded for java mapreduce on the corporate clusters as it has built in parsers that save users having to understand how the events are structured. 65 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) d other computing resources there are various computing options available to himr researchers beyond the bulk data sources of hadoop and distillery. there is expertise in these environments at himr so we only briefly document these options here. further information can be found at [w22, w21]. firstly researchers have access to the microsoft windows environment of valhalla. valhalla is the standard desktop and provides email, microsoft office, web browsing, in- stant messaging and a gateway to other systems. the /data/himr_dm/ filesystem should be accessible in windows with valhalla (at the time of writing the windows mount location is not known). instant messaging is accessible via the pidgin application. many employees of gchq can be found online both for direct messaging and in chat rooms. the following chat rooms are of particular note: himr_dm (himr data mining research), distillery (distillery users), ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Confidential", 
        "paragraph_text": "rough_diamond (hadoop users), hecsupport (compute clusters queries) and lid_support (lid support). instructions for getting going on pidgin can be found at [w29]. from valhalla researchers can access discover. this is gchqs document repos- itory. literature for this research task has been filed at discover 10499535. other sources of information that are of particular note are the the collaborative gcwiki [w15], which con- tains information about many gchq activities, and the safari online bookshelf [w35], which provides electronic versions of many technical books. the primary interactive data analysis environment will be the linux interactive desktop (lid). the lid provides a remote desktop onto a redhat linux box. various mathematical tools such as r, matlab, mathematica, maple, sage and magma are available. scripting languages are available: perl is the most commonly used scripting language in gchq but python is starting to gain traction. compilers are also available for c, c++ and fortran. it is worth noting that gchq have imported the general repository for r packages, cran, at [w9] and implementations of many machine learning techniques can be found there. there are two linux compute clusters available. mount mckinley is probably the machine of choice and has 652 compute nodes each with 8 cores, giving a total of 5216 cores. the cores are clocked at 2.4ghz. each node has 32gb of ram and there is a fast interconnect between nodes. mount mckinley can be accessed from valhalla. the catch with mount mckinley is there are few user tools available and hence it should primarily be seen as a place to run compiled code (perl and python scripting is also available). mount mckinley is also used for operational processing so researchers will need to abide by conventions around himrs use. an older compute cluster called sepang is also available but is expected to be decommissioned shortly. sepang is firewalled from the rest of the gchq network and does not have easy access to any of the data sources described; however it does have a wide range of user tools installed and is reserved for himrs sole use. both the lid and mount mckinley user nodes mount\tif you want to analyse data from hadoop or distillery on lid or mount mckinley then you will need to transfer the data with scp. 66 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) e legalities this appendix is intended as a brief guide to the legal information of most relevance to your work at himr. however [w25] and your legalities training should be treated as the definitive references. e.1 overview gchq always complies with uk law12. in particular we are bound by the regulation of investigatory powers act (ripa) and intelligence services act (isa). ripa requires gchq to have arrangements in place to minimise its retention and dissemination of intercepted material. ripa also applies specific protection to the communications of people in the uk. isa requires gchq to have arrangements in place to ensure that it obtains or discloses information only in the proper discharge of its functions or for the purpose of any criminal proceedings. the complete and official compliance guide can be found in [w25]. in general we must be able to demonstrate that our actions are both necessary and proportionate. we show that our actions are necessary and proportionate by producing an accountable record for oversight and audit. this typically takes the form of an hra (human rights act) justification. the human rights acts defines the basic rights everyone must have respected. in particular there is a right to privacy which can only be violated in the interests of national security, public safety or the economic well-being of the country, for the prevention of disorder or crime, for the protection of health and morals, or for the protection of the rights and freedoms of others. for gchq this means we must justify our activities as being in the interests of national security, the economic well-being of the uk, or in support of the prevention or detection of serious crime. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "you should bear in mind that you have signed and are bound by the official secrets act (osa). in particular you should take care in discussing or releasing potentially classified data and techniques. if you are unsure on an items classification then you should seek guidance from the data owner. our data and information is also exempt from the freedom of information act (foia). all documents should carry the same caveat as this document. as accessing the content of an individuals communications is regarded as more invasive than examining its metadata there are tighter restrictions imposed on such data. content need not necessarily be an email or phone call. for example, the content of a uri beyond the first slash is considered content, as are the specifics of someones online mapping activity. e.2 procedures we now highlight some specific procedures that should be followed when working with bulk metadata. detailed policy guidance for corporate hadoop clusters can be found at [w26]. we give the most relevant information here. if you are extracting a dataset or performing analyses in a way which is not expected to target an individual then there is no need to do anything. however if the criteria specify individuals, or behaviours which are sufficiently precise that they apply to only a few individuals, then you will need to complete a manual hra log [w23]. you do not need to complete this every time that you perform the same extraction, or perform follow-on 12the bulk of our work is also compliant with the policies and laws of five-eyes partners. 67 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) analysis using similar techniques and for a similar purpose, so long as you write your first log in a way that is just general enough to cover your current work. further if your analyses specify five-eyes individuals or organisations, or if the query includes data that is designated as content then you will need sensitive targeting approval in addition to completing a manual hra log. when completing a manual hra log the application name should be silver_lining if working on a hadoop cluster. the reason should be ns (national security), a jic pri- ority of 1 and miranda number of 20135 (intelligence in support of gchq research work intended to maintain and develop general purpose capabilities in the field of target com- munications in order to be able to meet such intelligence requirements as may be specified now and in the future). if you are developing new techniques then the query type should be qfd-development, or if selecting data that focuses down to a few individuals then bulkextract. queries in distillery should also be logged using the manual hra logging service and most of the guidance above applies. until distillery is added to the list of applications, please use black_hole. the data source should be the source most closely matching the feeds you are using, otherwise use ad_hoc_external_data. in order to complete the number of results returned field you will need to submit the log after you have run the query - there is currently no way for you to update a manual hra log. 68 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) f data in this appendix we summarise the datasets made available at the outset of this research. researchers are encouraged to work with gchq staff to find other datasets if required. f.1 sigint events firstly we describe datasets of raw sigint events: typically these are available as live datasets in hadoop or distillery. f.1.1 salamanca ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "the contents of this dataset are classified top secret strap2 chordal. gchq collects telephone call record events from a wide variety of sources, and these are stored in a database called salamanca [w36]. this data is also fed to the sun storm cloud and the bhdist distillery cluster (and other distillery clusters). this data is a relatively low rate feed of user events, around 5000 events per second, and can be viewed as either a directed or undirected graph. it could be used for the streaming eda and streaming expiring graphs topics as well as feature extraction for payphones for the beyond supervised learning topic. in general we have better collection of calls where the two sides are in different countries, although for some countries we also have good collection of in-country calls. this means the graph can have some unusual features and it is worth bearing these in mind when examining features of the graph. some properties of sigint collected telephony graphs are discussed in [i33, i34]. a comparison between sigint collected call records and billing records is given in [i73].\t_________________ on sun storm the data can be found under\tin folders named by date. the full format is as described in the interface control document [i79] but with an additional field at the end which uniquely identifies the event within sun storm. in distillery the data is forwarded into the shared spl instance on the bhdist cluster by running a vltcpsource in client mode. the resulting stream can be subscribed to using the subscription datafeed==\"salamanca\" && eventtype==\"fullcallrecord\". the full data contains many attributes, but the relevant ones are the timestamp and calllength along with identifiers. records will typically have some of diallednumber, di- allednumbernorm, callerid and calleridnorm, where the norm versions may have been normalised, for example by adding the country code. the normalised versions are in e.164 format and give the fully qualified number as opposed to the digits actually dialled which could include just the local number. some identifiers are specific to mobile telephony, including the imsi (which is an id for a sim card), the imei (which is an id for a mobile phone handset), and the msisdn (which should match one of diallednumbernorm and calleridnorm). to know which side of the call these attributes refer to you must also read the calldirection attribute which is either mo for mobile originated (i.e. the imsi and imei relate to the callerid) or mt for mobile terminated (i.e. the imsi and imei relate to the diallednumber). 69 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) may 01\tmay 06\tmay 11\tmay 16\tmay 21 time figure 6: plot of events counts per hour in our snapshot of five alive data. the period from may 6-11 is clearly the best quality. f.1.2 five alive five alive is an ictr prototype query focused dataset (qfd) providing access to bulk ip-ip connection events, giving a unique unselected view of all activity on sigint bearers. each record in five alive summarises a flow between two ip addresses. this summary consists of: the start of flow time, unfortunately at second granularity in the static dataset, but microsecond granularity in distillery. the source and destination ips and ports and the protocoltogether these are known as the 5-tuple, hence the name five alive. optionally extra information on flow size and direction depending upon the protocol. the data format is fully described in [i9]. we have a snapshot of five alive data covering, with gaps, approximately 6-19 may 2011. figure 6 shows the number of events per hour in this snapshot. this snapshot is available: on the gold mine hadoop cluster at\tin hdfs. the dates on the subdirectories indicate when it was loaded into the cluster and should be ignored. on mount mckinley at there is also a feed of streaming five alive data on the bhdist distillery cluster. it is a high-rate feed (around 1 million events a second) and is published in multiple splits. they can be imported in the shared instance using the subscrip- tion datafeed == \"fivealive\" && eventtype == \"flowrecord\" && split == \"n\" where n ranges from 0 to 11 (but this may be increased to accommodate additional bearers). dont leave out the split condition or youll get all the data in one feed. ideally you should run your initial processing on the same host as the data is published to reduce network load. this data could also be made available at bude to provide a multi-site high-rate feed. 70 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) f.1.3 hrmap ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "the contents of this dataset are classified top secret strap2 chordal. when a user requests a webpage from the internet, this is observed in sigint as an http get request. as well as the page requested it often contains the url of the previously viewed page. the hostname of the requested page is the host and the hostname of the previous page is the referrer. when we consider just the hostnames rather than the full uri then this is considered events data. this can be viewed as a directed graph of hostnames, and is given the name hrmap at gchq. it is a moderately high rate stream (around 20000 events per second) which should be suitable for the streaming eda and streaming expiring graphs topics. since many web pages point to other web pages on the same server, a large proportion of hrmap events have the hostname matching the referrer. many records will have no referrer. this happens if the user typed the url, uses a bookmark, or has configured their browser not to send the referrer attribute. as well as the host and referrer, an hrmap record also contains a timestamp (in seconds), the client ip address, the client port, and the client http header fingerprint (hhfp) which is a hash of various headers sent by the client and can be used to approximately distinguish clients behind a gateway [i38]. hrmap data is available in distillery on the bhdist cluster. it can be imported in the shared instance using the subscription datafeed == \"hrmap\" && eventtype == \"hostreferrer\". hrmap could also be made available at bude to give a multi-site streaming graph static hrmap is available on the sun storm hadoop cluster at and\tnow that the hagel awel hadoop cluster at bude is operational, data collected there will no longer be loaded onto sun storm. data collected at bude now instead is loaded onto hager awel at\tthe bude data at cheltenham will gradually age off and be deleted 6 months after its load date. f.1.4 skb ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "the contents of this dataset are classified top secret strap2 chordal ukeo. the signature knowledge base is a system for tracking file transfers made on the internet. a record is made each time we see certain file types being transferred. each file is identified by its format and a hash of some of its content. whilst this does mean we can store the data, hash collisions are inevitable. therefore one cannot guarantee that all records referring to the same hash are in fact the same file. further we only process a small number of different file formats. the dictionary of which file types are logged is given in [i86]. each single line record in the skb dataset has the format: date time src_ip dst_ip frag_# ip_id len protocol.# src_port dst_port seq_# ack_# file_offset file_type file_signature src_geo dst_geo e.g. 71 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) 22:59:58 03-08-2011 192.168.2.1 10.0.0.1 16384 45872 1398 6 80 53302 4032239316 4106241239 256 swf-compressed-v9 geo-ip-src 32 55.0436;37.3378;moscow;ru;5mmm geo-ip-dst 25 40.4;-3.68;madrid;es;7lmh for more details on how the logging is performed and the hashes calculated see [i67, i22]. the skb data is stored both in a qfd for analysts to query and in blackhole. we have an extract of 1 week on skb data\tif you require more data then it is possible to extract some using the blacktools interface. f.1.5 arrival processes ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "the contents of this dataset are classified secret strap 2. there are two standard datasets that have been used to evaluate all approaches to temporal correlation. these are known as the telephony and c2c datasets. they both consist of records of stochastic processes in the format \\t\\t and files containing pairs of identifiers to be scored in the format the data is stored in /data/himr_dm/data/arrival_processes. telephony data the original event times were taken from 18 weeks worth of telephony data. these event times were then transformed to give the times in the .sps files. random pairs of event times are generated this way: choose a pair of distinct originating numbers, a and b; choose from the set {1,..., 17}; circularly shift the event times of b by 5 weeks (i.e. modify the event times of b by adding 5 x 604800 to them modulo t = 18 x 604800, 604800 being the number of seconds in a week). the purpose of the cyclic shift is to reduce the effect of any random pairs in which some of as calls truly cause b to make calls. shifting by one-week multiples is done to retain the time-of-day and day-of-week structure of the data. if time interval [0, t) can be partitioned into two subintervals, one containing all of the events of a and the other containing all of the events of b, then (a, b) is rejected as a random pair for experimental purposes since presumably no one would consider that they might be correlated. the stochastic processes generated in this way are in the file^^^^^^^^s. this file contains 151,811 processes. bs name has 5 appended to show the size of the shift. for example if 441242221491 had been shifted 3 weeks it would be called 441242221491.03. causal pairs of event times are generated this way: generate a random pair (a, b); randomly select proportion p of as call initiation times; to each selected initiation time, add the duration of the corresponding call plus a delay drawn from an exponential distribution with mean f seconds; merge the resulting times into bs call initiation times. a proportion of as calls cause b to make a call, and b makes these calls after the causative call of a ends and after a 72 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) random delay. the causal stochastic processes are in files\ts. the standard one used in experiments is\ts. this file contains 155,746 processes. bs name has 5 and as name appended. for example if 441242221491 had been shifted 3 weeks and had a causal dependency on 441242226816 it would be called 441242221491.03.441242226816. both the random and causal pairs for clasp to score are listed in the file c2c data the event times were taken from 93 days of c2c presence activity. records are logged each time the identifier is seen performing an activity. the timestamps in the c2c data are unaltered to provide a realistic test dataset. the stochastic processes are in the file ip.all.sps.new.sun2. there are 457,305 processes in this file. there are also two pairs files. the file\tcontains 431,689 random pairs. the file\tcontains 45,932 pairs in which the proportion of causal pairs was thought by the data experts to be relatively high, compared to the proportion of causal pairs in the set of all identifier pairs. the exact criteria for making it onto these lists can be found in section 2.4 of [i49]. the names of identifiers consist of the username, a series of dots and dashes and then the identifier type. there are no transformations done to the names in the c2c data. f.1.6 solid ink and fluid ink ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "the contents of this dataset are classified secret strap1. these are quite old telephony datasets, but we feel it is worth highlighting them to himr researchers because the view they offer is so unusual. solid ink is three weeks of telephony events from 2007, as seen from billing records. fluid ink is an approximate subset of solid ink, but as seen via gchqs sigint collec- tion. our points of access mean that we mostly collect calls between the target country and the rest of the world; therefore in-country calls are likely to be missing from fluid ink. indeed, solid ink has 2.7 billion events involving 74 million numbers, while fluid ink has only 136 million events involving 15 million numbers. there are also various sources of sigint noise which are poorly understood, such as missing calls, duplicate calls, node mislabelling and timing errors. we only have anonymized versions of the datasets available: for legal reasons, we could not retain the unminimized versions this long. each ink data set has four fields: timestamp, user-1, user-2 and a number. unfortunately, the timestamp fields seem to have become corrupted somewhere along the line, and in different ways in each of the datasets. however, timestamp deltas within each set are probably still correct (in seconds). in fluid ink the call direction is user-1 to user-2, and the fourth field 73 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) is call duration in seconds. in solid ink the fourth field is a code in {1, 2, 3, 4}, where: 1\t= voice user-1 to user-2 2\t= sms user-1 to user-2 3\t= voice user-2 to user-1 4\t= sms user-2 to user-1 the datasets are available at\tand there are also versions, where events involving pizza nodes have been removed. a very interesting analysis of these datasets came out of the 2008 graph mining swamp at himr [i73], which revealed just how great the disparity between sigint and ground truth can be, for example when it comes to contact chaining. csec have also done some work that largely confirms and replicates those results [w4]. f.1.7 squeal hits ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "the contents of this dataset are classified top secret strap2 chordal ukeo. squeal is a signature-based system for detecting electronic attacks, see [w39]. when a poten- tial attack is detected a hit is forwarded to distillery. each hit contains the source and destination ips and ports, the timestamp, the hit details and geolocation for the ip addresses. by examining multiple hits we may be able to learn about the attacks. for example, we might look for multiple ip addresses that launch attacks in a similar way. a stream of squeal hits is initially created on the ahs explore distillery cluster, however this is also forwarded to the shared spl instance on the bhdist cluster. it can be imported using the subscription datafeed==\"squeal\" && eventtype==\"squealhit\". this is a low rate stream, around 75 events per second, and contains the hits from all sites. squeal hits are available on the sun storm hadoop cluster at /data/ead. this covers events collected from all sites. f.2 open-source graphs and events we also provide some open-source graphical and events based data which may be of specific relevance to this research. f.2.1 enron ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "the contents of this dataset are classified unclassified. enron was an american energy company that collapsed in 2001 due to massive financial fraud and eventual bankruptcy. after criminal proceedings were completed the complete emails of around 150 enron employees, mostly senior management, were publicly released. there are approximately half a million emails covering november 1998 to july 2002. there is a brief introduction to this dataset in [e22]. this gives a few summary statistics, such as number of emails per user and conversation thread length. we have a copy of enron.sql, the sql 74 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) database file which contains this data. the format of this is not particularly nice so we have also extracted a simpler data set, which hopefully contains the data needed for this work. if not it is not too hard to return to the original file to gather more data. this formatted file is called enron_transactions.txt. each email has one record for each recipient, however each line contains all relevant information. each record is tab separated with the following fields these data files can be found at f.2.2 us flights data ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "the contents of this dataset are classified unclassified. the american statistical associations data expo 09 asked for analysis of a large dataset of us flight arrivals and departures. the data was made available to the public by the us department of transports research arm, rita (research and innovative technology administration), and covers the years 1987 to 2008. the expo 09 website is mirrored at it con- tains a fuller description of the problem, as well as the winning posters produced by participants in the competition. when the home office decided to fund ukvac research (see section 5.8.2), it was decided ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "to provide the researchers with two unclassified challenge problems in order to focus their efforts. one was chosen by the humint agencies: to predict the next winners of nobel prizes. the second came from gchq, and was to do further analysis on the rita flights data. in fact, the second author of this problem book was largely responsible for selecting the problem and framing its statement, so it mirrors very closely the point of view of this problem book, ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "particularly section 5. the flights are meant to be an unclassified proxy for sigint events data, and although the dataset can just about be handled in core on modern hardware, ukvac participants were strongly encouraged to process the data in a stream. we hope that researchers will be able to compare their approaches, especially on visual- ization questions, with what the ukvac comes up with: having a common dataset should help with that. in case any direct collaboration emerges with ukvac participants, having the dataset they are working on to hand will obviously also be a significant help. the data consists of 22 bzipped csv files, one for each year. each record has 29 fields, described in table 4. supplemental csv files describe the codes used for airports, carriers and some individual planes: see the\tpage on the expo 09 mirror. f.2.3 wikipedia graph ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "the contents of this dataset are classified unclassified. this is not directly relevant for sigint, but there are several reasons why it might be handy to have around. many outside algorithms get tested on this graph, so it might be useful for benchmarking, or as test data to apply algorithms intended for external publication to. it is also a foil for hr map (appendix f.1.3): although that data set does not contain internal clicks ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "between wikipedia pages (so there is no direct comparison), nonetheless it might be interesting 75 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) index\tname\tdescription 1\tyear\t1987-2008 2\tmonth\t1-12 3\tdayofmonth\t1-31 ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "4\tdayofweek\t1 (monday) - 7 (sunday) 5\tdeptime\tactual departure time (local, hhmm) 6\tcrsdeptime\tscheduled departure time (local, hhmm) 7\tarrtime\tactual arrival time (local, hhmm) 8\tcrsarrtime\tscheduled arrival time (local, hhmm) 9\tuniquecarrier\tunique carrier code 10\tflightnum\tflight number 11\ttailnum\tplane tail number 12\tactualelapsedtime\tactual time in minutes 13\tcrselapsedtime\tscheduled time in minutes 14\tairtime\tair time in minutes 15\tarrdelay\tarrival delay, in minutes 16\tdepdelay\tdeparture delay, in minutes 17\torigin\torigin iata airport code 18\tdest\tdestination iata airport code 19\tdistance\tin miles 20\ttaxiln\ttaxi in time, in minutes 21\ttaxiout\ttaxi out time in minutes 22\tcancelled\twas the flight cancelled? 23\tcancellationcode\treason for cancellation (a = carrier, b = weather, c = nasair traffic control system failure, d = security) 24\tdiverted\t1 = yes, 0 = no 25\tcarrierdelay\tin minutes 26\tweatherdelay\tin minutes 27\tnasdelay\tin minutes 28\tsecuritydelay\tin minutes 29\tlateaircraftdelay\tin minutes table 4: flights data fields. 76 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) to compare in broad terms how algorithms perform on the dynamic hr map of clicks versus a static graph of links. the data files are in\tthere is a list of vertices, which are all the articles on the english wikipedia at a certain point in 2008. whenever an article links to another article, there is a corresponding line\tgiving the source and target of the link (as indices into the .title file). f.3 sigint reference data to help researchers enrich their research findings we provide lists of websites of interest and target selectors. we also provide lists of covert infrastructure and known payphones to support research on information flow in graphs and positive-only learning. f.3.1 websites of interest ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "the contents of this dataset are classified top secret strap2 ukeo. a list of websites of interest is available in a database on\t. these have been manually classified through open source research and contain radical and extremist sites along with many others. these may be useful when examining hrmap data to determine target density. to get a list of radical and extremist sites, first get a username and password from andrew ross (ajrossl). then connect to the database and run the query as follows: ~db2user/sqllib/bin/db2 connect to dist1 ~db2user/sqllib/bin/db2 \"select sitename, radicalism, type, url from where radicalism = radical or radicalism = extremist\" ~db2user/sqllib/bin/db2 connect reset it is also possible to use this data directly in distillery using the database toolkit. f.3.2 target selectors ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "the contents of this dataset are classified top secret strap2 ukeo. our target knowledge database is broad oak which includes the ability to task various selector types including phone numbers and email addresses. the resulting list of selectors is sometimes called the target dictionary and is delivered to our distillery clusters at least once a day, and is also available on our hadoop clusters. this data could be used to see if some result set contains an increased density of targets. for distillery, the telephony and c2c dictionaries are delivered in separate streams and can be imported with datafeed==\"broadoak\" && eventtype==\"targetselector\" and datafeed==\"broadoakc2c\" && eventtype==\"targetselector\" respectively. a re-send of the latest dictionary can be requested by sending a udp packet to (port 10450 for telephony, 10460 for c2c) containing the line resend. this could be sent with a udpsink operator. 77 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) on sun storm, the broad oak reference data (all target types) is in hdfs at when using selectors to examine parts of a graph then this is considered targetting and an hra log must be completed. see appendix e on page 67 for details. f.3.3 covert infrastructure ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "the contents of this dataset are classified top secret strap1. gchq has knowledge of, and collection from, cne acceses owned by foreign intelligence agencies. this is done without their permission and is known as fourth party collec- tion. as data is exfiltrated from target networks we should be able to see information flows over their infrastructure. data on foreign covert infrastructure can be found at we also have knowledge of our own covert infrastructure. however this data is understand- ably more sensitive. work is still ongoing to explore the possibility of making this dataset accessible to himr researchers. f.3.4 conficker botnet ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "the contents of this dataset are classified secret strap1. gchq has an interest in being able to detect botnets operating in the wild. this is cur- rently done using packet content fingerprinting and specific behaviours of certain bot software. however we would like to be able to detect botnets only by their generalisable activity. for the conficker botnet we have a list of ip addresses that hit against either the packet fin- gerprinting or a conficker specific activity profile. the fingerprinted ips can be found at this set should be largely reliable as the signature is believed to be highly discriminative. the behaviourally identified ips are at these are slightly more tentative and are based on the conficker software contacting remote ips on specific ports. of course this can happen randomly so only those ips which perform a significantly high number, after bonferoni correction, make the list. as conficker contains a peer-to-peer (p2p) component we believe that there may be information flows involving these potentially infected ips. f.3.5 payphones ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "the contents of this dataset are classified top secret strap1. analysts are interested in understanding telephone numbers in their analysis. a particular feature of a number they would like to know is whether the number is a payphone. the fact that a number is a payphone would suggest that contact chaining through the number is not recommended. on the other hand some target discovery work starts with a known modus op- erandi of payphone usage (which targets follow to make it hard to target their communication) and so looking for communication between payphones is the starting point. however gchq have lists of payphones for very few countries. the aim is start from partial lists of payphones in some countries and extend to full lists of payphones in those countries 78 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) country spain pakistan pakistan barbados surinam # known payphones 93,634 3,117 118 761 363 filename notes believed near complete partial partial (fata region only) partial partial table 5: known payphones and in other countries based on call meta-data. this problem is an example of positive-only learning. has provided lists of payphones in four countries as described in table 5. gchq have recently moved their telephony event data to the cloud and we do not have feature extraction algorithms for this data. however the basic features in [i3] should be easy to implement from scratch as an hadoop analytic using the data as described in appendix f.1.1. we also provide the source code for the original spiky rock feature extraction as c code. the use of payphones is an active interest so a complete hadoop feature extraction and classification analytic would be likely to be directly taken on by gchq and results fed into the the lucky strike database. the data and the old spiky rock source code is available in f.4 sigint truthed data to support the beyond supervised learning research we provide several sigint truthed datasets from recent research. f.4.1 logo recognition ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "the contents of this dataset are classified secret strap1. we are interested in automatically detecting the source of videos on the internet through the recognition of logos in the video. we have previously researched logo detection and have recently looked at supervised machine learning for logo recognition [i19].\thas provided the data from this research. the feature space is derived as follows: 1.\tlogo detection algorithms give us the logo and mask (i.e. the logo shape) as 8-bit images. the mask is binary in that values are either 0 or 255 (i.e. black or white). 2.\tboth the logo and mask are independently downscaled to 8 x 8. during these down- sampling processes the results are rescaled so that they retain their original pixel depth (i.e. 8-bit). 3.\tthese 2 resulting 8-bit images are pointwise multiplied to give a 16-bit image (with a range of 0-65535). 79 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) 4.\tthis 8 x 8 16-bit image is our feature vector. sam is happy to look at extracting other features if himr actively research this dataset. we provide 530 truthed samples. the data has been truthed to 109 classes. 7 classes have more than 20 examples, 67 classes have only 1 example. from ictr-mca is happy to work with jtrig to try and provide larger untruthed datasets if the researchers decide to work on this problem. the data is available\tthe first field class is a numeric representation of the class and the remaining fields are the features. f.4.2 spam detection ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "the contents of this dataset are classified secret strap1. spam emails are a large proportion of emails seen in sigint. gchq would like to reduce the impact of spam emails on data storage, processing and analysis. most external spam detectors work by analysing the content of an email however policy and processing mean this option is not always open to us. we must work on features derived from events alone. we therefore lower our target and instead aim to classify email addresses by the type of emails they send. has provided datasets from his teams research into this prob- lem. they built a classifier called myofibril [i44]. the dataset consists of an 1809 example email addresses with 143 features each truthed into 11 classes. note that one class is mul- tiple_classes and one class is uncertain. this data set is provided in\tthis directory also contains a pdf documenting the dataset in more detail [i43]. it would be possible to use the data\ton sun storm (reading these files with silver library is recommended) to generate untruthed feature vectors. however it should be noted that the collection posture of gchq has changed considerably since the truth data was collected. f.4.3 protocol classification ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "the contents of this dataset are classified secret strap1. gchq is interested in understanding c2c traffic on bearers. one approach is to use signa- tures of known applications but signatures can not cover all traffic. we therefore look at the alternative approach of classifying traffic based on its behaviour. such approaches may also provide a way to understand traffic in encrypted tunnels. we provide datasets from 7 different bearers provided by\t[i54] and used in [i70] (see [w1] for related research). each bearers data consists of a little over 100,000 example tcp flows with 51 features truthed to 15 broad classes (and 39 detailed classes). these classifications have been obtained by binary content signatures. note that one class is null which indicates that no signature hit on that flow. these datasets allow one to check the robustness of a classifier against concept drift both in time (the data spans a little over a year [i70]) and across bearers. the data is provided at\tnote each bearers data is arbit- rarily split into training and test sets but this split need not be preserved. 80 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) f.4.4 steganography detection ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "the contents of this dataset are classified top secret strap1. some targets try to hide their communications through the use of steganography. one approach is to slightly alter the coefficients in a jpeg image to encode the hidden data whilst trying to minimise visual changes in the jpeg. we would like a classifier that can identify such altered ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Confidential", 
        "paragraph_text": "images (commonly called stegged images). has provided data used to build random forest classifiers [i74]. there are a few interesting features of this dataset: this problem can be viewed either as a classification or a regression problem. one can either regress on the density of embedded data or classify whether there is any embedded data or not. the truthing process simulated embedding data into a large sample of images. some of these images might have started with steganography in them and so the truthing may not be accurate. this dataset has the most truthed examples. the original research had 50,000 clean and 50,000 stegged images (for each of 4 steg types) for training and 500,000 clean and 200,000 stegged images (per steg type) for validation and testing. the reason for such a large test and validation set is that we want to ensure a very low false positive rate. there are the most features of the truthed datasets. there are 661 features (introduced in [i74]). features are computed in classes and so could be used to experiment with cost-sensitive feature selection. data is available at\tas compressed csv files. the first two fields should be ignored and the final field of the stegged files contains the simulated stegging rate. the rest of the fields are the features (summarised in [i74]). f.4.5 genre classification ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "the contents of this dataset are classified secret strap1. a way to make analysts more efficient and also allow further analytics is to add labels to textual content to describe the genre of the content.\thas provided text data sets classified into genres along with the aura feature extractor [i83]. aura extracts 108 features from text documents as described in [i85, i84]. some features are from basic counts, some are based on email headers and some are based on more advanced textual analysis. aura can be run on a text document with: java -jar aura.jar  | head -108 the first 108 lines of auras output are the feature values. other information about the file is returned in the remaining lines. 81 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "three corpuses are provided. peec and genre-id are unclassified. news-personal is classified. each item is a file. the classification of items is encoded by the subdirectory an item is stored in. there are some duplicate items in these directories. the corpuses and aura are a if you are new to text classification then [i25] may be good background reading. f.4.6 website classification ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "the contents of this dataset are classified top secret strap1. we would like to label webpages by the type of information on the page. in this case we want to ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Confidential", 
        "paragraph_text": "identify pages that contain information on chemical, biological, radiological or nuclear (cbrn) weapons.\thas previously researched this as a supervised learning problem [i36] and has provided his data from this research. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [
          "nuclear"
        ], 
        "paragraph_classification": "Confidential", 
        "paragraph_text": "webpages have been labelled by an analyst into four classes: cw (chemical weapons), bw (biological weapons), rn (radiological/nuclear) and ni (not interesting). data is provided at\tin the arff format used by weka. this format can be treated as a csv file after removing the header lines. the most important file is\t. this file is the full dataset used to produce the original classifier. it contains vectors for all documents in the cbrn dataset, where each feature corresponds to a single word, and the value of each feature is the number of instances of the word in the document divided by total number of words in the document. also produced lists of the most prevalent words across each topic (in the folder as bvector, cvector, rvector, nvector and rnvector), and then developed a dataset where each feature was a count of words from each list found in the document (the two files).\treports that these features did not produce very good results compared to individual words, so the dataset wasnt refined much further, but you may find it interesting. if required the original html pages and classifications may be available but could not be easily found at the time of writing the problem book. f.5 fusion of scores data ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "the contents of this dataset are classified secret strap2 chordal ukeo. the fusion of scores problem can occur in several contexts. in the following we describe the creation of ip geolocation reference data. we want to know the geolocation of ip addresses for many analytic processes. in the main, there are two types of data we use: commercial various commercial providers provide estimates for ip address locations. ictr- ne have provided akamais edgescape dataset. sigint we find that commercial providers sometimes give poor locations in areas of the world of sigint interest. we therefore need to augment the commercial data and choose to do this through analysis of locations referenced in ip collection (e.g. in user profiles or web forms). we hope that these locations give evidence towards the location of the 82 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) users of that ip address. see [i69] for the scoring approach currently used. ictr-ne have provided data from five different types of ip data (called injunction, psychic salmon, raging bullfrog, robotic fish and timid toad). the aim is to use these different sources to come up with the best estimate of an ip addresss location. for simplicity we recommend considering geolocation to country-level only. the edgescape data comes as five gzipped text files; each file covers a different range of ip address space. each line describes a subnet (an ip address or ip address range). the first field gives the ip address range as a subnet and a subnet mask. the second field contains information about the subnet as key-value pairs. in particular the country_code field is their guess of the country and the first letter of the confidence field gives the confidence in their estimate. confidences are either high h, medium m or low l. each sigint system dataset also comes as a gzipped text file with each line describing a subnet. the full format is described in [i66] but we describe the important features here. the first field is the subnet and the second field the subnet mask (typically 24). the last field is a semi-colon separated field where the penultimate field is the country and the last character of the last field is the confidence. confidences are either high h, medium m or low l. these confidences should not be treated as being on the same scale as edgescape but should be comparable between the five sigint systems. the files can be found at 83 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) this page is intentionally left blank 84 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) references internal literature |\ta maximum-entropy algorithm for generating random graphs, 2008. report to appear: see slides discover 12747135. [12]\tmodeling and simulation of streaming dynamic graphs using the cray xmt. technical report mr/tech/010/09, r1, nsa, 2009. discover 11806816. [13] [14] [15] [16] [17] [18] spiky rock: automatic classification of telephone type via usage statistics. technical report mr/tech/003/04, nsa r1, march 2004. discover 12211328. comet: a recipe for learning and using large ensembles on massive data. arxiv, cs.lg/1103.2068, march 2011. discover 12192977. lossy counting and hierarchical heavy-hitter algorithms. in ace, may 2011. discover 12768692. comments on nsasag 07-04: correlation of temporal sequences. technical report, university of california, berkeley, october 2007. discover 12689034. discover 12134962, june 2009. random forests in mapreduce. technical report mr/tech/033/10, nsa r1, august 2010. discover 10833587. [i9]\ttechnical report, gchq, august 2011. discover 7996430 please contact\t(ictr-fsp) for access. [i10]\tadapting sigint timeseries data to account for variation in collec- tion posture. technical report opc-m/tech.b/58, gchq, february 2011. discover 7895676. [i11]\tbakers dozen - a method for batch phone discovery. technical report b/6749ba/5001/4/102, gchq, march 2008. discover 12585962. [112]\tthe la jolla scamp 2009 problem book - information processing. technical report scamp working paper l3/09, ida- ccr, 2009. discover 12907519. [113]\tdensity estimation techniques for detecting dns tunnels. in sanar, october 2010. discover 10833937. 85 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) [114]\ttrusses and fast graph clustering. slides from sanar, 2005. discover 12750235. [115]\ttrusses: cohesive subgraphs for social network analysis. technical report tr-r63-001-05, nsa/r63, 2005. discover 12892477. [116]\ttrapezes: more swinging than trusses. technical report tr-r63-004-09, nsa/r63, 2009. discover 12892478. [117]\tsemitrusses, semitrapezes, efficient computation, and streaming. technical report tr-r63-002-10, nsa/r63, 2010. discover 12892476. [118]\tinterpreting random forest classification. technical report, nsa r1, september 2009. discover 12193642. [119]\ttechnical report trmca/inf/656, ictr-mca, june 2010. discover 12667333. [120]\ta simple birth-and-death process for scoring anomalous behavior in a random steady-state graph. technical report scamp working paper l38/02, ida-ccr, 2003. discover 11775537. [121]\tbuilding 2-out+ graphs from streaming data. technical report h-tr-017-06, csec, november 2006. discover 12750234. [122]\tupgrade to tcp-file-signature-log - engineering specification. technical re- port b/6805ba/5001/1, gchq, february 2008. discover 12740356 please contact (ictr-fsp) for access. [123]\tclustering of multiple point process streams. technical report, university of florida, july 2007. discover 12680283. [124]\ta model-based approach to detecting correlated stochastic processes. technical report, nsa, september 2011. discover 13432581. [125]\ttext categorisation - a beginners guide. technical report b14/inf/569, gchq, february 2008. discover 7878359. [126]\tcreating probabilities and combining evidence in nsas evidence store. technical report trmca-inf-690, gchq, july 2010. discover 10835062. [127]\tcrouching squirrel v4: filtering and classifying using behavioural vector analysis. technical report b/7934/5001/3/104, gchq, december 2010. strap2/orcon: contact author for access or see slides discover 11925562. 86 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) [128] [129] [130] [131] [132] [133] [134] [135] role assignment in private messaging social networks. technical report b/7167ba/5001/4/102, gchq, december 2008. discover 13042933 please ask for access. bayesian block modelling. technical report b/7635ba/5001/4/101, gchq, november 2009. discover 13036032. weighted bayesian block modelling sanitised. technical report b/7713ba/5001/4/102, gchq, february 2010. discover 13036033. techniques for measur- ing the strength of communications in email event graphs. technical report b/6845ba/5001/4/102, ictr-dmr, february 2008. discover 12656488. the case for target discovery using closed loops against the islamist terrorist threat in the uk - a technical perspective. technical report b/7618ba/5001/4/102, ictr, gchq, 2009. discover 12861894. properties of sigint-collected communication graphs, 2003. technical report scamp working paper l39/03, ida-ccr, 2004. discover 11770806. properties of sigint-collected communication graphs. technical report scamp working paper l32/02, ida-ccr, 2003. discover 12502484. the netinf algorithm as a mapreduce job. technical report, nsa, may 2011. discover 13202916. [136]\tautomated categorisation of cbrn related webpages. technical report b/7470ba/5001/5/105, ictr-cisa, july 2009. discover 12669793. [137]\thistogramming in the streaming environment. in ace, 2007. discover 12632758. [138]\tictr-fsp. gchq tr-fsp http header fingerprint format. b/7535ba/5001/1, 2009. discover 2450313. [139]\tdetecting dependence among multiple point processes. technical report, university of pittsburgh, august 2007. discover 12681522. [140]\testimating set cardinality under streaming conditions. in ace, 2011. discover 12754015. [141]\ttiming patterns in call records data with i2 pattern tracer and remit. technical report b/4351ba/1700/16, gchq, july 2003. discover 12207962. [142]\ttiming analysis 2004 - using significant temporal chains for call records target development. technical report b/5372ba/1700/16, gchq, october 2004. discover 12200466. 87 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) [143]\t. pizza node classification - sharable data set for random forests classification. technical report b/6316ba/5001/4/102, gchq, december 2006. discover 12189035. [144]\tclassifying email addresses by their be- haviour in bulk events data. technical report oph-m/tech.a/458, gchq, december 2006. discover 12183192. [145]\tcreating, retaining and combining confidence estimates in a cloud-like world, july 2010. discover 10833599. [146]\ttopological measures of evolving graphs: dynamic betweenness cent- rality. technical report ccr working paper 1690, ida-ccr, 2008. discover 11770815. [147]\tdetecting correlated sequences of events. slides from sanar 2010, october 2010. discover 12595305. [148]\textending pairwise element similarity to set similarity efficiently (sanitized version). technical report mr/tech/032/10, nsa, december 2010. discover 12497649. [149]\tdetecting correlated sequences of events: sanitized version. technical report oph-m/tech.a/456, gchq, august 2006. discover 3730313. [150]\tand\telkan and notos learning classifi- ers from only positive and unlabeled data is fatally flawed. technical report mr/tech/009/10, nsa r1, february 2010. discover 10833916. [151]\tstreaming temporal relation additive probability. technical report, nsa, april 2009. discover 12594200. [152]\tclasping at straws: bootstrapping and clustering to improve product performance. technical report, nsa, in preparation 2011. discover 12588233. [153]\timprovements to geofusion scoring. technical report b/7854/5001/3/104, gchq, august 2010. discover 12839607. [154]\tapplication characterisation: data set specification. tech- nical report b/6728ba/5001/1, gchq, december 2007. discover 12189832. [155]\tembedding r within infosphere streams for online time series ana- lysis and predictions. technical report, gchq ictr-cisa, june 2011. discover 12267642. [156]\ttowards implementation of an algorithm for updating eigenvalues and eigenvectors of streaming graphs. technical report, ictr, gchq, 2011. discover 12663078. 88 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) [157] [158] [159] [160] [161] [162] [163] [164] [165] [166] [167] [168] [169] [170] [171] [172] i. generating realistic random graphs. technical report, himr, september 2008. discover 12747134. unsupervised learning on network data. discover 12589745. radonsharpen-b. discover 12838456, october 2010. 2008 bristol swamp: prob- lems in graph mining. technical report opc-m/tech.a/6, gchq, 2008. discover 12768417. streaming decision trees. http://wiki.gchq/images/3/37/ rdtrees.tar.gz, june 2007. discover 12134963. hidden otter: detection of multi-hop tem- poral chains in ip traffic. technical report b/7937ba/5001/3/104, gchq, december 2010. discover 7810599 ask\t(ictr-ne) for access. streaming prime time ap- plication design report. technical report inca1323d003-1.1, detica, december 2010. discover 12211763. new technique for correlating stochastic processes. technical report b/7523ba/5001/4/102, gchq, september 2009. discover 12214368. nsasag problem 07-04: correlation of temporal sequences. technical report, university of washington, 2007. discover 12687220. geofusion volsunga interface specification. technical report b/6745ba/5001/1, ictr-fsp, january 2008. discover 13550106. file signature bulk-logging technique - engineering specification. technical report b/6173ba/b13/106, gchq, july 2006. discover 12742157. internet flow classification: random forests and importance-sampled learning ensembles. in ace, october 2007. discover 12187796. a probabilistic score for ip geolocation from injunction-style data. technical report opc-mcr/tech.b/4, opc-mcr, november 2007. dis- cover 13548375. application characterisation: generalisation to the unknown. tech- nical report opc-m/tech.b/7, gchq, april 2008. discover 12187131. enhanced behavioural detection of botnet command-and-control servers. technical report opc-m/tech.b/53, gchq, july 2010. discover 12209112. traffic sketches for measuring bearer similarity and pairing. tech- nical report opc-m/tech.b/55, gchq, october 2011. discover 12750231. 89 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) [173]\ta comparison between billing records and the view in sigint: solid ink vs fluid ink. technical report opc-m/tech.b/17, gchq, 2009. discover 12676097. [174]\timproved generic detection of steganography in jpeg coefficients. tech- nical report opc-m/tech.a/452, gchq, april 2011. discover 12191941. [175]\tgchq research & innovation strategy 2011 - 2015. discover 12013908. [176]\tblocks, bridges and cutvertices in large commu- nications graphs. technical report opc-m/tech.b/19, himr, october 2008. dis- cover 12750236. [177]\tusing predictive modelling to identify cocaine drug smugglers. technical report b/4029ba/b1700/13, gchq, november 2002. discover 12815822. [178]\tresults document for call record timing analysis. technical report caa146d005-1.0, detica, november 2001. discover 12204886. [179]\ttdb. interface control document (icd) for the salamanca input handler - external generic feed interface. technical report pc/00117cpo/4542/pc0093/000/50, gchq, 2010. discover 12680902. [180]\tknowledge discovery at the new cri. in sanar, october 2010. discover 12208587. [181]\tupdating eigenvalues and eigenvectors of streaming graphs. technical report scamp working paper l22/09, ida-ccr, 2010. discover 11806837. [182]\tsawuneh 2010  cyber defence event mining. in ace, may 2011. discover 12754021. [183]\t^^discover 12369711. [184]\taura features: algorithmic description. discover 12380899. [185]\taura features: brief description. discover 12380897. [186]\tskb definitions. please ask\t(ictr-fsp) for access. 90 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) external literature [e1] [e2] [e3] [e4] [e5] [e6] [e7] [e8] [e9] the canonical tensor decomposition and its application to data analysis, june 2009. discover 12740014. an empirical study of dynamic graph algorithms. acm journal on experimental algorithmics, pages 192-201, 1996. discover 11402183. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "stinger: spatio-temporal interaction networks and graphs (sting) extensible rep- resentation, may 2009. discover 11821050. network science applications to global communications. in netsci, 2008. discover 12804967. and\tthe phase transition in inhomogen- eous random graphs. arxiv:math/0504589v3, june 2006. discover 12763412. forests. machine learning, 45, 2001. discover 13286408. editors. semi-supervised learning. mit press, 2010. data stream algorithms intro, sampling, entropy. slides from bristol maths workshop, 2008. discover 12805861. how does the data sampling strategy impact the discovery of information diffusion in social media? association for the advancement of artificial intelligence, 2010. discover 10763381. [e10 [e11] [e12] [e13] [e14] mapreduce: simplied data processing on large clusters. in osdi, 2004. discover 12192986. bayesian approaches to modeling the con- ditional dependence between multiple diagnostic tests. biometrics, 57:158-167, 2001. discover 12192608. i. massive streaming data analytics: a case study with clustering coefficients, 2010. discover 11821048. . learning classifiers from only positive and unlabeled data. in kdd, las vegas, august 2008. acm. discover 12195326. dynamic graph algorithms, 1999. discover 11402184. 91 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) [e15] graph distances in the data-stream model. siam journal on computing, 38(5):1709-1727, 2008. [e16]\thyperloglog: the analysis of a near-optimal cardinality estimation algorithm. aofa, 2007. discover 12747198. [e17]\tsemi-supervised ranking on very large graphs with rich metadata. in kdd, august 2011. available from microsoft researchs website. [e18]\tinferring networks of diffusion and influence. in kdd10, washington d.c., 2010. acm. discover 12762008. [e19]\testimating the error rates of diagnostic tests. biometrics, 36:167-171, 1980. [e20] instinct. have i got views for you?: gathering and analysing publicly available data to gain an understanding of current events. technical report, october 2011. discover 12626622. [e21]\tbayesian estimation of dis- ease prevalence and the parameters of diagnostic tests in the absence of a gold standard. american journal of epidemiology, 141(3):263-272, 1995. discover 12195321. [e22]\tintroducing the enron corpus. technical report, carne- gie mellon university, 2004. discover 12763413. [e23]\tmiforests: multiple-instance learn- ing with randomized trees, 2010. discover 12192687. [e24]\tsemi-supervised random forests, 2011. discover 12192698. [e25]\tsocial media analytics: part 1: information flow. slides, stanford university, august 2011. presented at kdd 2011 discover 13561614. [e26]\tand\tgraph evolution: densification and shrinking diameters. acm transactions on knowledge discovery from data, 1(1), 2007. discover 12761498. [e27]\tlearning with an unreliable teacher. pattern recognition, 25(1):79-87, 1992. [e28]\tcompact graph representations and parallel connectivity algorithms for massive dynamic network analysis. in 23rd ieee interna- tional parallel and distributed processing symposium (ipdps), may 2009. discover 11816428. 92 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) [e29] sparsification of influence networks. in kdd11, pages 529-537, san diego, ca, august 2011. acm. /discover13560696. [e30]\tthe pagerank citation ranking: bringing order to the web, 1998. [e31]\tsupervised learning from multiple experts: whom to trust when everyone lies a bit. in proceedings of the 26th international conference on machine learning, 2009. discover 12197907. [e32]\ttags, a program for the eval- uation of a test accuracy in the absence of a gold standard. preventative vetinary medicine, 53:67-81, 2002. [e33]\ta method for inferring label sampling mechanism in semi-supervised learning. in advances in neural information processing systems, volume 17, 2005. discover 13287597. [e34]\tcorrect- ing for missing data in information cascades. technical report, stanford university, december 2010. discover 10763155. [e35]\tcombined regression and ranking. in kdd. acm, july 2010. discover 12815522. [e36]\tlearning with labeled and unlabeled data. technical report, university of edinburgh, december 2002. discover 13287596. [e37]\tactive learning literature survey. technical report, university of wisconsin-madison, 2010. discover 12195329. [e38]\twhen do latent class models overstate accuracy for binary classifiers?: with applications to jury accuracy, survey response error, and diagnostic error. tech- nical report wp-08-10, northwestern university, may 2009. discover 12192699. [e39]\tstreaming data. wires computational statistics, january 2011. discover 12197914. [e40]\tfast counting of triangles in large real networks: al- gorithms and laws. in icdm, 2008. discover 12805858. [e41]\tthe future of data analysis. ann. math. stat., 1962. discover 12804965. [e42] [e43] exploratory data analysis. addison-wesley, 1977. design principles for developing stream processing applications. software - practice and experience, 2010. 93 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) [e44]\tmodeling information diffusion in implicit networks. technical report, stanford university, 2010. discover 12763414. [e45]\tboosting the scalability of botnet detection using adaptive traffic sampling. in asiaccs, march 2011. discover 12804966. [e46]\tsemi-supervised learning literature survey. technical report tr 1530, university of wisconsin-madison, july 2008. discover 13288447. websites [w1] application characterisation. [w2] auto assoc. [w3] birch (data clustering). [w4] carbon copy. [w5] cask: situational awareness for the 2012 olympics [w6] chart breaker. [w7] cne opsec pages. [w8] cno glossary. [w9] cran. [w10] decision tree learning on wikipedia. [w11] distillery. [w12] dynamic graph. [w13] ensemble learning on wikipedia. [w14] fused analysis and visualisation research. [w15] gcwiki. [w16] getting started on bhdist. [w17] grinning roach. 94 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) [w18] ground breaking intelligence capabilities used during recent g20 summit. [w19] hadoop fair scheduler guide. [w20] hadoop on gcwiki. [w21] himr it upgrade.\t. [w22] himr self help. [w23] hra logging. [w24] information flow in graphs gcwiki page. [w25] legal compliance. [w26] legalities sun storm/black hole. [w27] mamba. [w28] nsasag. [w29] pidgin setup. [w30] pirate carebear. [w31] random forests. [w32] relationship analysis. [w33] renoir. [w34] roc curves. [w35] safari books online.\t. [w36] salamanca. [w37] salty otter. [w38] semi-supervised learning on wikipedia. http://wikipedia.gchq/index.php [w39] squeal ead and cipher detection ppf app. 95 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only opc-m/tech.a/455 (v1.0, r206) [w40] streams processing language. [w41] supervised learning on wikipedia. [w42] swamp 2008. [w43] whats the relationship between cno and dni? [w44] whiteraven. [w45]\tkl-relative pagerank. 96 this information is exempt under the freedom of information act 2000 (foia) and may be exempt under other uk information legislation. refer any foia queries to gchq on\tor| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "uk top secret strap1 comint aus/can/nz/uk/us eyes only ", 
        "paragraph_relto": []
      }
    ], 
    "pdf_paths": [
      "Problem-Book-Redacted.pdf"
    ], 
    "overall_classification": "Top Secret", 
    "description": "This GCHQ research report dated 20 September 2011, cowritten by researchers at Heilbronn Institute for Mathematical Research based at the University of Bristol, concerns the use of data mining techniques to develop usable intelligence as well as the contradictions that arise from the use of algorithms to identify wrong doers, or potential wrong doers. The [\u2026]", 
    "plain_text": "\ufeffUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nReference:\tOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nDate:\t20 September 2011\r\n\r\nCopy no:\r\n\r\nHIMR Data Mining Research Problem Book\r\n\r\nOPC-MCR, GCHQ\r\n\r\nSummary\r\n\r\nIn this problem book we set out areas for long-term data mining research at the Heilbronn\r\nInstitute for Mathematical Research starting in October 2011 and continuing for at least three\r\nyears. The four areas are beyond supervised learning, information flow in graphs, streaming\r\nexploratory data analysis and streaming expiring graphs.\r\n\r\nCopy\tDistribution\r\n\r\n1\tNSA R1\r\n\r\n2\r\n\r\n3\r\n\r\n4\r\n\r\nI\r\n\r\n6\r\n\r\n7\r\n\r\n8\r\n9\r\n\r\n10\r\n\r\nII\r\n12\r\n\r\n13\r\n\r\n14\r\n\r\n15\r\n\r\n16\r\n\r\n17\r\n\r\n18\r\n\r\nNSA R4\r\nNSA R6\r\nLLNL\r\n\r\nCSEC\r\nCRI\r\nDSD\r\nGCSB\r\nICTR\r\nICTR-CISA\r\nICTR-DMR\r\nICTR-MCA\r\nNDIST\r\nIACT\r\nPTD I\r\n\r\nHIMR (circ.)\r\nOPC-MCR (circ.)\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n[96 pages]\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nTHIS PAGE IS INTENTIONALLY LEFT BLANK\r\n\r\n2\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nHIMR Data Mining Research Problem Book\r\n\r\n20 September 2011\r\n\r\nContents\r\n\r\n1\tIntroduction\t7\r\n\r\n2\tA brief introduction\tto SIGINT\t9\r\n\r\n2.1\tPassive SIGINT..................................................... 9\r\n\r\n2.1.1\tCollection................................................... 9\r\n\r\n2.1.2\tProcessing.................................................. 10\r\n\r\n2.1.3\tAnalysis, reporting and target development.................. 11\r\n\r\n2.2\tComputer network operations and the cyber mission................. 12\r\n\r\n2.2.1\tCyber....................................................... 12\r\n\r\n2.2.2\tAttack, exploit, defend, counter............................ 13\r\n\r\n2.2.3\tData mining for cyber discovery ............................ 14\r\n\r\n3\tBeyond Supervised Learning\t16\r\n\r\n3.1\tIntroduction...................................................... 16\r\n\r\n3.1.1\tSupervised learning prior work.............................. 17\r\n\r\n3.1.2\tSemi-supervised learning prior work......................... 18\r\n\r\n3.2\tSemi-supervised learning.......................................... 18\r\n\r\n3.2.1\tHow useful is semi-supervised learning?..................... 18\r\n\r\n3.2.2\tPositive-only learning...................................... 19\r\n\r\n3.2.3\tActive learning............................................. 19\r\n\r\n3.2.4\tNew algorithms and implementations ......................... 20\r\n\r\n3.3\tUnreliable marking of data ....................................... 20\r\n\r\n3.3.1\tWeak labels................................................. 20\r\n\r\n3.3.2\tFusion of scores............................................ 21\r\n\r\n3.4\tRelevant data..................................................... 22\r\n\r\n3.4.1\tTruthed datasets............................................ 22\r\n\r\n3.4.2\tFusion of scores data....................................... 23\r\n\r\n3.5\tCollaboration points.............................................. 23\r\n\r\n4\tInformation Flow in\tGraphs\t25\r\n\r\n4.1\tIntroduction...................................................... 25\r\n\r\n4.2\tPast work......................................................... 26\r\n\r\n4.2.1\tGraphical methods........................................... 26\r\n\r\n4.2.2\tTemporal correlation........................................ 28\r\n\r\n4.3\tWhat we care about now ........................................... 29\r\n\r\n3\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n4.3.1\tDefinition and Discovery...................................... 30\r\n\r\n4.3.2\tMissing data and noise........................................ 30\r\n\r\n4.4\tPotential future interests.......................................... 31\r\n\r\n4.4.1\tPerforming inference on flows................................. 31\r\n\r\n4.4.2\tInformation flow for graph generation......................... 32\r\n\r\n4.5\tRelevant data....................................................... 32\r\n\r\n4.6\tCollaboration points................................................ 32\r\n\r\n5\tEDA on Streams\t34\r\n\r\n5.1\tIntroduction........................................................ 34\r\n\r\n5.1.1\tEDA .......................................................... 34\r\n\r\n5.1.2\tStreams....................................................... 34\r\n\r\n5.1.3\tThe problems ................................................. 35\r\n\r\n5.2\tGraph problems with no sub-sampling................................. 35\r\n\r\n5.2.1\tThe framework of graphs and hypergraphs....................... 35\r\n\r\n5.2.2\tCliques and other motifs...................................... 36\r\n\r\n5.2.3\tTrusses ...................................................... 37\r\n\r\n5.2.4\tOther approaches.............................................. 37\r\n\r\n5.3\tVisualization....................................................... 38\r\n\r\n5.3.1\tVisualization in general...................................... 38\r\n\r\n5.3.2\tStreaming plots .............................................. 38\r\n\r\n5.4\tModelling and outlier detection..................................... 39\r\n\r\n5.4.1\tIdentifying outlier activity.................................. 39\r\n\r\n5.4.2\tBackground distributions for significance tests............... 39\r\n\r\n5.4.3\tWindow sizing................................................. 39\r\n\r\n5.5\tProfiling and correlation........................................... 40\r\n\r\n5.5.1\tCorrelations.................................................. 40\r\n\r\n5.5.2\tFinding behaviour that matches a model........................ 40\r\n\r\n5.6\tEasy entry problems................................................. 41\r\n\r\n5.7\tRelevant data....................................................... 41\r\n\r\n5.8\tCollaboration points................................................ 42\r\n\r\n5.8.1\tInternal...................................................... 42\r\n\r\n5.8.2\tExternal...................................................... 42\r\n\r\n6\tStreaming\tExpiring Graphs\t44\r\n\r\n6.1\tIntroduction........................................................ 44\r\n\r\n6.1.1\tThe Problems.................................................. 44\r\n\r\n6.2\tProperties to find and track........................................ 45\r\n\r\n6.2.1\tComponent Structure........................................... 45\r\n\r\n6.2.2\tGraph Distance................................................ 45\r\n\r\n6.2.3\tCliques and other motifs...................................... 45\r\n\r\n6.2.4\tCentrality Measures........................................... 46\r\n\r\n6.3\tQuestions relevant to all properties................................ 47\r\n\r\n6.3.1\tApproximation................................................. 47\r\n\r\n6.3.2\tComputational Cost ........................................... 47\r\n\r\n4\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n6.3.3\tExpiry Policy...................................................... 48\r\n\r\n6.4\tFurther Questions ....................................................... 48\r\n\r\n6.4.1\tParallel and Distributed processing................................ 48\r\n\r\n6.4.2\tBootstrapping ..................................................... 48\r\n\r\n6.4.3\tAnomaly Detection.................................................. 48\r\n\r\n6.4.4\tResilience......................................................... 49\r\n\r\n6.4.5\tQueries on graphs with attributes ................................. 49\r\n\r\n6.5\tRelevant Data............................................................ 49\r\n\r\n6.6\tCollaboration Points..................................................... 49\r\n\r\nA Ways of working\t51\r\n\r\nA.1\tFive-eyes collaboration.................................................. 51\r\n\r\nA.2\tKnowledge sharing........................................................ 51\r\n\r\nA.\t3\tAcademic engagement ..................................................... 52\r\n\r\nB DISTILLERY\t54\r\n\r\nB.\t1\tWhen would I use InfoSphere\tStreams? .................................... 54\r\n\r\nB.2\tDocumentation and Training............................................... 55\r\n\r\nB.3\tLogging on and Getting Started........................................... 55\r\n\r\nB.4\tData..................................................................... 56\r\n\r\nB.5\tConventions ............................................................. 58\r\n\r\nB.5.1 Use threaded ports on\tshared data................................... 58\r\n\r\nB.\t5.2 Operator Toolkits and\tNamespaces.................................. 58\r\n\r\nB.\t6\tFurther help and resources............................................... 59\r\n\r\nC Hadoop\t60\r\n\r\nC.\t1\tWhen would I use Hadoop?................................................. 60\r\n\r\nC.2\tDocumentation and Training............................................... 61\r\n\r\nC.3\tLogging on and Getting Started........................................... 61\r\n\r\nC.4\tData..................................................................... 62\r\n\r\nC.5\tConventions and restrictions............................................. 62\r\n\r\nC.\t5.1 Scheduler......................................................... 62\r\n\r\nC.5.2 HDFS /user/yoursid space ........................................... 63\r\n\r\nC.6\tRunning Hadoop on the LID\t.............................................. 63\r\n\r\nC.7\tFurther help and resources............................................... 65\r\n\r\nD Other computing resources\t66\r\n\r\nE Legalities\t67\r\n\r\nE.1\tOverview ................................................................ 67\r\n\r\nE.2\tProcedures .............................................................. 67\r\n\r\n5\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nF\tData\t69\r\n\r\nF.1 SIGINT\tevents............................................................... 69\r\n\r\nF.1.1\tSALAMANCA............................................................... 69\r\n\r\nF.1.2\tFIVE ALIVE.............................................................. 70\r\n\r\nF.1.3\tHRMap................................................................... 71\r\n\r\nF.1.4\tSKB..................................................................... 71\r\n\r\nF.1.5\tArrival Processes....................................................... 72\r\n\r\nF.1.6\tSOLID INK and FLUID INK................................................. 73\r\n\r\nF.1.7\tSqueal hits ............................................................ 74\r\n\r\nF.2 Open-source graphs and events.................................................. 74\r\n\r\nF.2.1\tEnron................................................................... 74\r\n\r\nF.2.2\tUS flights data......................................................... 75\r\n\r\nF.2.3\tWikipedia graph......................................................... 75\r\n\r\nF.3 SIGINT\treference data....................................................... 77\r\n\r\nF.3.1\tWebsites of interest ................................................... 77\r\n\r\nF.3.2\tTarget selectors........................................................ 77\r\n\r\nF.3.3\tCovert Infrastructure................................................... 78\r\n\r\nF.3.4\tConficker botnet........................................................ 78\r\n\r\nF.3.5\tPayphones............................................................... 78\r\n\r\nF.4 SIGINT\ttruthed data ........................................................ 79\r\n\r\nF.4.1\tLogo recognition........................................................ 79\r\n\r\nF.4.2\tSpam detection.......................................................... 80\r\n\r\nF.4.3\tProtocol classification................................................. 80\r\n\r\nF.4.4\tSteganography detection................................................. 81\r\n\r\nF.4.5\tGenre classification.................................................... 81\r\n\r\nF.4.6\tWebsite classification.................................................. 82\r\n\r\nF.5 Fusion\tof scores data ....................................................... 82\r\n\r\nReferences\t85\r\n\r\n6\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n1\tIntroduction\r\n\r\nThe Government Office for Science reviewed GCHQ technology research in 2010 and identified\r\nthat we could lengthen our technology research horizon. The Heilbronn Institute for Mathemat-\r\nical Research (HIMR) had shown its mettle during a one-off graph mining workshop [I60, W42]\r\nand thus the idea to more permanently expand HIMR research beyond pure maths and into\r\ndata mining was born. This also fits into GCHQ\u2019s overall research and innovation strategy for\r\nthe next few years [I75], where engagement with academia via HIMR is a key plank.\r\n\r\nLike many organisations, GCHQ is having to approach the \u201cBig Data\u201d problem. After\r\nreviewing our current research we identified four broad areas for long-term research in math-\r\nematics and algorithms at HIMR. All of the four problem areas are about improving our\r\nunderstanding of large datasets:\r\n\r\nBeyond supervised learning: Can we use semi-supervised learning and related techniques\r\nto improve the use of machine learning techniques?\r\n\r\nInformation flow in graphs: Can we identify information flowing across a communications\r\ngraph, typically from timing patterns alone?\r\n\r\nStreaming exploratory data analysis: Can we develop new techniques for understanding\r\nand visualising streaming data?\r\n\r\nStreaming expiring graphs: Can we efficiently maintain current situational awareness of a\r\nstreaming expiring graph?\r\n\r\nHIMR researchers are free to devote their effort amongst these problems as they see fit during\r\ntheir classified time.\r\n\r\nThese problems have been chosen due to their SIGINT relevance and SIGINT data is\r\nprovided for all these problems. However we also recognise that these problems have overlaps\r\nwith current academic research areas. Thus, conditional on security considerations, HIMR\r\nresearchers should be able to generalise from classified research to unclassified research and\r\npublications during their unclassified time.\r\n\r\nData is made available to HIMR researchers in the following forms:\r\n\r\nStreams: GCHQ are prototyping the use of the DISTILLERY streaming architecture (see\r\nAppendix B for details). Many data analysis problems can be efficiently approached in\r\nthe stream [E39] and processing in the stream brings the advantages of live situational\r\nawareness and the potential to reduce follow-on storage and processing costs.\r\n\r\nMapReduce: GCHQ store recent communications meta-data as distributed text files in Ha-\r\ndoop clusters which can then be processed with MapReduce [E10] (see Appendix C for\r\ndetails). This environment will allow researchers to use large datasets typically spanning\r\nthe last six months of collection.\r\n\r\nReference: We also provide some smaller datasets (e.g. reference data or data that has already\r\nbeen processed or truthed) as text files.\r\n\r\n7\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nThe development of techniques in Hadoop or DISTILLERY is recommended as that will enable\r\neasy technology transfer from HIMR into GCHQ.\r\n\r\nThe HIMR Deputy Director, the authors of this problem book and members of GCHQ\u2019s\r\nInformation and Communications Technology Research (ICTR) business unit should be seen\r\nas the primary points-of-contact for this research. However we will also identify various other\r\nareas for classified collaboration both in GCHQ and abroad.\r\n\r\nGCHQ imagines that the most useful outcomes of this research will come in one of the\r\nfollowing forms:\r\n\r\n\u2022\tClassified or unclassified research papers describing new techniques (or in limited cases a\r\nliterature review of existing techniques).\r\n\r\n\u2022\tClassified research papers describing new or existing techniques applied to SIGINT data.\r\n\r\n\u2022\tNew analytics (typically in Hadoop or DISTILLERY) and documentation.\r\n\r\nIn this problem book we adopt two conventions:\r\n\r\n\u2022\tWe distinguish between references to internal literature, external literature and websites.\r\nCitations are prefixed \u201cI\u201d, \u201cE\u201d and \u201cW\u201d respectively. Where possible literature is made\r\navailable in DISCOVER (see appendix D). We have deliberately aimed to be more com-\r\nprehensive in citing internal literature than external literature; external references should\r\nbe easier to find from citation paths and review papers.\r\n\r\n\u2022\tWe highlight problems with a \u25c4 in the right-hand margin.\r\n\r\nIn the interests of brevity, this problem book does not give full definitions for all terms in use\r\nin GCHQ and the use of GCWiki [W15] is a good place to find out more.\r\n\r\nWe would like to thank the many people across the 5-eyes community who have helped\r\nus with the problem book, both in formal contributions and in informal discussions at various\r\nconferences and visits over the last year. Within GCHQ we have had plenty of support from\r\nmembers of ICTR (in particular\tand\tand PTD (in particular\r\n\r\n).\r\n\r\nWe start the problem book with an overview of relevant SIGINT background before describ-\r\ning the problems in detail. In appendices we suggest some ways of working, describe GCHQ\u2019s\r\nimplementations of Hadoop and DISTILLERY and describe the datasets available.\r\n\r\n8\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n2\tA brief introduction to SIGINT\r\n\r\nThis is a very brief, high-level overview for people unfamiliar with the SIGINT system, focused\r\non what data miners need to know about the data available to them and how data mining can\r\nbe applied to problems in target discovery and cyber. Researchers are encouraged to find out\r\nmore by browsing GCWiki and asking questions that arise.\r\n\r\nSIGINT is intelligence derived from intercepted signals. Although this encompasses a huge\r\nvariety of emanations, we are principally concerned with COMINT: intercepted communica-\r\ntions.\r\n\r\nParliament\u2019s Joint Intelligence Committee (JIC) formulates a set of priorities and require-\r\nments for intelligence on various topics, which GCHQ tries to meet by producing End Product\r\nReports (EPR) based on intercepted communications. GCHQ has the legal authority to inter-\r\ncept communications for the specific purposes of safeguarding the UK\u2019s national security and\r\neconomic well-being, and to prevent and detect serious crime. GCHQ always acts in accordance\r\nwith UK law. All researchers who have access to SIGINT data will be given legalities training,\r\nand there is also some information in appendix E on how data should be handled.\r\n\r\n2.1\tPassive SIGINT\r\n\r\nThis section looks at some of the main stages in the \u2018intelligence cycle\u2019: how data gets collected,\r\nprocessed and analysed to produce reports for GCHQ\u2019s customers.\r\n\r\n2.1.1\tCollection\r\n\r\nThere are many ways of communicating, and consequently there are many sources of SIGINT\r\ndata. Traditionally, we collect signals using a variety of masts and dishes to pick up radio\r\nor satellite signals. Increasingly, we are interested in network communications (phone calls or\r\ninternet traffic), and in this case to intercept the communication we usually need an access point\r\nin the network. (Sometimes network data passes over a satellite link where we can pick it up\u2014\r\nCOMSAT collection\u2014but more often it doesn\u2019t.) Collection of this network communication\r\ndata is called Special Source collection, the details of which are covered by ECIs. Access to raw\r\ndata collected from Special Source is protected by a COI called CHORDAL. Some information\r\nabout what the underlying sensitivities are, and the processes we have in place to protect them,\r\nis provided in the CHORDAL briefing.\r\n\r\nOne final twist is that a UK service provider can be compelled by a warrant signed by the\r\nHome Secretary or the Foreign Secretary to provide us with the communications data for a\r\nspecific line or account for a specified time. This goes by several names: Lawful Intercept (LI),\r\nwarranted collection, and PRESTON.\r\n\r\nWe refer to a single internet link as a bearer. We collect data from a bearer using a probe,\r\nand our current technology can collect from a 10G bearer (i.e. a 10 gigabit-per-second link).\r\nWhen a bearer is connected to a probe and associated processing equipment we describe the\r\nbearer as being on cover. We have been building up our sustained collection of 10G bearers\r\nsince about 2008, and we now have approximately 200 bearers on sustained cover, spread across\r\nCheltenham, Bude and LECKWITH. We refer to these three sites as processing centres ; they\r\nare abbreviated to CPC, RPC-1 and OPC-1 respectively.\r\n\r\n9\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nWe have access to many more bearers than we can have on cover at any one time, and the\r\nset we have on cover is changed to meet operational needs.1 As well as the fact that bearers get\r\ntaken on and off, it is not unusual for technical problems to interrupt processing from a bearer,\r\nboth for short and prolonged periods. This means that one must be careful about making\r\nassumptions about how traffic volumes from a given end-point vary over time: see [I10] for a\r\ndetailed discussion of the problem and one way to deal with it.\r\n\r\n2.1.2\tProcessing\r\n\r\nA 10G bearer produces a phenomenal amount of data: far too much to store, or even to process\r\nin any complicated way. Our way of dealing with this is a multi-component system called MVR\r\n(massive volume reduction). To make things manageable, the first step is to discard the vast\r\nmajority of the packets we see. This is accomplished by the Packet Processing Framework\r\n(PPF), a software framework allowing a very limited set of matching operations to be run on\r\nspecialized hardware; packets that hit on these matches are then passed back to the software\r\nlayer, where more complicated processing (including sessionization, done by a platform called\r\nTERRAIN) can be performed on the selected subset of the data.\r\n\r\nCollected data falls into two categories: metadata and content. Roughly, metadata comes\r\nfrom the part of the signal needed to set up the communication, and content is everything\r\nelse. For telephony, this is simple: the originating and destination phone numbers are the\r\nmetadata, and the voice cut is the content. Internet communications are more complicated,\r\nand we lean on legal and policy interpretations that are not always intuitive. For example,\r\nin an HTTP request, the destination server name is metadata (because it, or rather its IP\r\naddress, is needed to transmit the packet), whereas the path-name part of the destination URI\r\nis considered content, as it is included inside the packet payload (usually after the string GET\r\nor POST). For an email, the to, from, cc and bcc headers are metadata (all used to address the\r\ncommunication), but other headers (in particular, the subject line) are content; of course, the\r\nbody of the email is also content.\r\n\r\nThere are extremely stringent legal and policy constraints on what we can do with content,\r\nbut we are much freer in how we can store and use metadata. Moreover, there is obviously a\r\nmuch higher volume of content than metadata. For these reasons, metadata feeds will usually\r\nbe unselected\u2014we pull everything we see; on the other hand, we generally only process content\r\nthat we have a good reason to target.2 GCHQ\u2019s targeting database is called BROAD OAK,\r\nand it provides selectors that the front-end processing systems can look for to decide when\r\nto process content. Examples of selectors might be telephone numbers, email addresses or IP\r\nranges. A selector whose communications are currently being targeted is said to be on cover.\r\n\r\nMetadata generally gives us information that we think of as events (\u2018A communicated with\r\nB at time t\u2019), and this terminology filters through into the name for the corporate processing\r\nand storage system for 10G bearers: Next Generation Events (NGE).\r\n\r\nxIn order to make decisions about which bearers to place on cover, we carry out a cyclic survey of all bearers.\r\nEach bearer is connected to a probe for 15 minutes and data collected about the traffic seen during that time.\r\nThis is stored in the Flexible-survey Knowledge Base or FKB.\r\n\r\n2We do collect some unselected content for survey and research purposes, but the requirements that our\r\nactivities be necessary and proportionate strictly limit what we can do with full-take content and who can have\r\naccess to it: in particular, analysts are not usually allowed to write reports based on it.\r\n\r\n10\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nOnce packets (or files or sessions created by assembling multiple packets) have been selected\r\nand they emerge from MVR, they go to several different places.\r\n\r\n\u2022\tContent databases. Traditional relational databases are still the ultimate point of rest\r\nfor corporate content data. There are also some legacy events database stores; soon, all\r\nof GCHQ\u2019s events processing and storage will move to the systems described in the next\r\nthree bullets.\r\n\r\n\u2022\tQFDs. Query-focused datasets (QFDs) pick out data and store it in a way that makes\r\nit easy to answer particular questions. For example, FIVE ALIVE is a dataset with a\r\nrecord for each IP event seen, consisting of the 5-tuple (timestamp, source IP, source\r\nport, destination IP, destination port) plus some information on session length and size.\r\nThis lets us answer questions about the network activity of a specific IP address.3\r\n\r\n\u2022\tDISTILLERY. A stream processing platform enabling near real time processing of data.\r\nSee appendix B.\r\n\r\n\u2022\tThe cloud. A scalable distributed filesystem along with a MapReduce processing frame-\r\nwork. See appendix C.\r\n\r\nIt is important to emphasize that even after MVR, the data volumes in the QFDs, cloud\r\nand DISTILLERY are still vast, and we don\u2019t want to ship everything back to Cheltenham.\r\nEverything is distributed across the processing centres, with limited amounts of information\r\nbeing sent between them: queries to the stored data are all federated to the separate processing\r\ncentres, with only the results being sent back to Cheltenham and the analyst\u2019s desktop.\r\n\r\n2.1.3\tAnalysis, reporting and target development\r\n\r\nTraditionally, an analyst would be given a particular target set to look at, and his or her aim\r\nwould be to use the communications of these targets to write reports answering questions of\r\ninterest to policymakers. For example, the target might be the Ruritanian Ministry of Foreign\r\nAffairs (MFA), and the aim to understand their posture in forthcoming negotiations with the\r\nUK; or it might be Kawastan\u2019s air force, and the aim to understand their general intentions\r\nand specific movements in a region where UK forces are currently deployed. The point is that\r\nthe target set is generally well understood, and while looking at the contacts of a known senior\r\nfigure in the MFA might reveal other government ministers or officials worth targeting, the\r\nproblem essentially involves analysing communications carefully selected to be likely to bear\r\non the questions under consideration.\r\n\r\nCounter-terrorism, and to a lesser extent increased work on serious crime, has changed\r\nthis landscape dramatically. The failure of the security services to prevent the 9/11 and 7/7\r\nattacks has been widely dissected, both in the press and in government inquiries here and in\r\nthe US. Targets are no longer neatly identified by their affiliation to a foreign MFA, military, or\r\nintelligence organization: finding the targets in the first place is now one of the most important\r\nproblems facing analysts, before they can even begin to assess their plans and intentions.\r\n\r\n3See appendix F.1.2 for more information on this QFD.\r\n\r\n11\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nContact chaining is the single most common method used for target discovery. Starting\r\nfrom a seed selector (perhaps obtained from HUMINT), by looking at the people whom the seed\r\ncommunicates with, and the people they in turn communicate with (the 2-out neighbourhood\r\nfrom the seed), the analyst begins a painstaking process of assembling information about a\r\nterrorist cell or network.\r\n\r\nBut what about those who simply are not on our radar at all, like the 7/7 bombers? The\r\nmain driver in target discovery has been to look for known modus operandi (MOs): if we have\r\nseen a group of targets behave in a deliberate and unusual way, we might want to look for\r\nother people doing the same thing. For this reason, a whole tranche of problems in this book\r\nlooks at ways of picking out behaviour matching a specific MO in a large dataset. Specific MOs\r\nshould be treated as particularly sensitive; knowledge of MOs can give SIGINT the edge over\r\nour targets who wish to remain undiscovered.\r\n\r\nFor example, sometimes targets will buy separate mobile phones and only use them to speak\r\nto each other, believing this to be good OpSec. In fact, this is unusual behavior that makes\r\nthem stand out. Analysts call these closed loops; to a mathematician looking at a telephony\r\ngraph, they are small components disconnected from the giant component that always forms in\r\ncommunications graphs. Another example is the use of payphones (commonly called telephone\r\nkiosks or TKs), which are an obvious way to communicate anonymously. Looking for calling\r\npatterns between TKs, or between a TK in the UK and a number in (let us say) Pakistan, has\r\nprovided valuable intelligence leads.\r\n\r\nMany of the problems in this book invite you to find new ways to use the data we have to\r\ndiscover things that analysts either could never find by themselves, or would never have the\r\ntime to find in practice. It is important to point out that tolerance for false positives is very\r\nlow: if an analyst is presented with three leads to look at, one of which is probably of interest,\r\nthen they might have the time to follow that up. If they get a list of three hundred, five of\r\nwhich are probably of interest, then that is not much use to them.\r\n\r\nOnce we have targets, clustering or community detection algorithms give us a way to expand\r\nthem into cells without laborious work by analysts. Doing this reliably and at scale is another\r\nfundamental challenge presented in this problem book.\r\n\r\nIt is also worth saying that techniques developed for counter-terrorism analysis can also\r\nfeed back into traditional diplomatic and military analysis. For example, DynamicGraph (see\r\nsection 6) is a way to visualize communication events around a seed set. Many of the ap-\r\nplications have been to counter-terrorism operations, but it was first developed to look at the\r\ncommunications of foreign government officials visiting London for a G20 summit in 2009 [W18].\r\n\r\n2.2\tComputer network operations and the cyber mission\r\n\r\n2.2.1\tCyber\r\n\r\nTraditional diplomatic and military theories imagine nation states engaging in various physical\r\ndomains: land, sea, air and space. The cyber domain is an increasingly important new site for\r\ninteractions between states, and will only become more so as time goes on. The UK government\r\nhas recognized the critical importance of cyber to our strategic position: in the Comprehensive\r\nSpending Review of 2010, it allocated a significant amount of new money to cyber, at a time\r\nwhen almost everything else was cut. Much of this investment will be entrusted to GCHQ, and\r\n\r\n12\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nin return it is imperative for us to use that money for the UK\u2019s advantage.\r\n\r\nSome of the problems in this book look at ways of leveraging GCHQ\u2019s passive SIGINT\r\ncapabilities to give us a cyber edge, but researchers should always be on the look-out for\r\nopportunities to advance the cyber agenda.\r\n\r\nThis section briefly discusses how sophisticated state actors (including ourselves and our\r\nfive-eyes partners) currently conduct themselves in cyberspace. It is important to bear in mind\r\nthat other states, in particular Russia and China, are not bound by the same legal framework\r\nand ideas of necessity and proportionality that we impose on ourselves. Moreover, there are\r\nmany other malicious actors in cyberspace, including criminals and hackers (sometimes motiv-\r\nated by ideology, sometimes just doing it for fun, and sometimes tied more or less closely to a\r\nnation state). We certainly cannot ignore these non-state actors.\r\n\r\n2.2.2\tAttack, exploit, defend, counter\r\n\r\nThere are four basic postures an actor can take in computer network operations (CNO).4\r\n\r\n\u2022\tAttack. This is obviously the most directly aggressive approach. It is commonly referred\r\nto as computer network attack (CNA); at GCHQ, one also hears it called effects. The actor\r\naccesses an adversary\u2019s network and deletes his files, destroys his network connectivity, or\r\ncauses other damage or inconvenience. There has been a lot of discussion, both internally\r\nand externally, about the possibility of a cyber-based attack that could cause physical\r\ndamage beyond the network, for example by shutting down a power station.\r\n\r\n\u2022\tExploit. GCHQ\u2019s first CNE (computer network exploitation) operation was carried out\r\nin the early nineties, and since then CNE has grown to the scale of a small industry\r\nin GCHQ. A typical operation involves establishing a long-term covert presence (an im-\r\nplant ) on a target computer, which sends back (\u2018exfiltrates\u2019) useful information over an\r\nextended time period. You will know from press reports and public statements by the\r\nhead of Security Service that UK networks and those of our allies\u2014both government and\r\ncommercial networks\u2014are in turn routinely targeted by other countries.\r\n\r\n\u2022\tDefend. CESG is responsible for protecting UK networks (primarily government net-\r\nworks, but the security of banks or other companies operating in the UK is also important\r\nfor economic well-being) from hostile CNA or CNE activity\u2014the acronym for this is CND,\r\nor computer network defence. It is important to be able to prevent attacks by rejecting\r\nmalicious packets at sensors or firewalls, and to understand who is attacking us (the\r\nattribution problem), why, and what they are looking for.\r\n\r\n\u2022\tCounter. This is a relatively new approach for GCHQ, which might better be called\r\nactive defence. As we come to understand the CNE infrastructure of a hostile actor, we\r\ncan target that infrastructure and attack it, disrupt its activities, or make use of the data\r\nthat someone else has exfiltrated from a network that is also of intelligence interest to\r\nus (fourth party collection). This is sometimes called C-CNE (counter-CNE), not to be\r\nconfused with CCNE, which was the name of PTD for a few years.\r\n\r\n4This area is rich in jargon: see [W8] for a comprehensive list, along with links to further details on the\r\nsubjects mentioned here.\r\n\r\n13\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nFigure 1: The Cyber Wheel.\r\n\r\n2.2.3\tData mining for cyber discovery\r\n\r\nCNE and CNA activity will leave traces in passive SIGINT. One of GCHQ\u2019s key contentions in\r\ndiscussions on spending for cyber has been that understanding the internet through SIGINT is\r\nthe best foundation on which to build any cyber capability, whether offensive or defensive. This\r\nis the very first stage in the Cyber Wheel (figure 1), which is meant to be a visual representation\r\nof all the aspects of cyber, with SIGINT at the centre. NSA produced a simpler and earlier\r\nvisualization [W43] of the same idea in 2007 (figure 2).\r\n\r\nDuring the initial exploitation of a target box, malicious data needs to be delivered to the\r\ntarget. We (as well as commercial anti-virus and security companies) try to produce signatures\r\nfor these infection vectors, which packets can be matched against.\r\n\r\nOnce machines have been implanted, they will usually perform certain characteristic activ-\r\nities on the network. Two major functions of an implant are beaconing, which involves sending\r\nshort periodic messages back to the implant\u2019s controller confirming that the implant is alive\r\nand available for tasking; and exfiltration, i.e. pulling back data from the target box.\r\n\r\nThe fact that these activities are visible in passive SIGINT presents an OpSec risk to\r\nus [W7], but also an opportunity for data mining to discover hostile CNE activity. The core\r\nof a particular actor\u2019s infrastructure might be quite small, and discovering it can open up a\r\nwhole chunk of their activity to be defended against or countered.\r\n\r\nBotnets are large collections of implanted machines under the control of a single bot-herder.\r\nThey are usually associated with organized criminals rather than intelligence agencies. Again\r\n\r\n14\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nFigure 2: Another view of the relationship between CNO and Digital Network Intelligence (DNI),\r\ni.e. passive network SIGINT.\r\n\r\nthere are stereotyped behaviour patterns associated with botnets: command and control ex-\r\nchanges (also called C&C or C2), which are analogous to beaconing for implants; and coordin-\r\nated activity in a short time window\u2014for example many machines in the botnet simultaneously\r\ntrying to access a website being targeted in a distributed denial of service (DDOS) attack.\r\n\r\nData mining offers the possibility of finding suspicious activity by detecting anomalies or\r\noutliers in bulk data. Temporal analysis and behavioural pattern-matching can be used to\r\ndetect hostile network activity from CNE and botnets, but at present there is very little being\r\ndone in this direction on our streaming data feeds. Several of the problem areas in the rest of\r\nthis document touch on applications to these important cyber problems.\r\n\r\n15\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n3\tBeyond Supervised Learning\r\n\r\n3.1\tIntroduction\r\n\r\nSupervised learning is the machine learning task of inferring a function from training data. The\r\ntraining data is a set of training examples. Each example is a pair consisting of a feature vector\r\nand a desired output value (also called truthed data or labelled data). A training algorithm\r\nanalyses this data and produces an inferred function, which is called a classifier (if the output\r\nis discrete) or a regression function (if the output is continuous). The inferred function should\r\npredict the correct output value for any valid input object. This requires the learning algorithm\r\nto generalise from the training data to unseen situations in a \u201creasonable\u201d way.5\r\n\r\nThere are a vast number of supervised machine learning algorithms which can often produce\r\nfunctions with high accuracies on real-world data sets. However, these techniques have had\r\nsurprisingly little impact in GCHQ. There are various reasons why this has been the case but\r\nthe principal reason has been the difficulty in creating training sets. In particular, the difficulty\r\ncomes from knowing the desired output value for many training examples, either due to the\r\nrequired human effort and/or uncertainty in the desired output value. This difficulty is unlikely\r\nto be a one-off issue for an operational application. The nature of communications and our data\r\nchanges with time and leads to \u201cconcept drift\u201d; any algorithm must be periodically retrained.\r\n\r\nThe aim of this research area is to improve the adoption of machine learning techniques.\r\nWe suggest three ways forward on this area:\r\n\r\n1.\tSemi-supervised learning alters the setup of supervised learning by only knowing the\r\ntrue value for a subset of training examples.\r\n\r\n2.\tA special case of semi-supervised learning is active learning: in this case the training\r\nalgorithm decides which examples it wants to be truthed. The aim is to make these the\r\nmost informative examples rather than waste human effort on randomly chosen cases.\r\nThis point-of-view also naturally works in a streaming context as a way of dealing with\r\nconcept drift.\r\n\r\n3.\tAllow ourselves to work with inaccurate truth data or weak labels. Such an approach\r\nwould allow more automated labelling or reduce the human effort required.\r\n\r\nWe provide some small example datasets that have come from supervised learning problems.\r\nAll examples in these datasets typically come with a label and a truth value. The scale of\r\nthese datasets should not limit your imagination and larger untruthed datasets should often\r\nbe obtainable either from the cloud or from a research area in GCHQ. If a very large number\r\nof unlabelled examples is found to be of value then streaming or MapReduce techniques will\r\nprobably be needed.\r\n\r\nIt is important to note that the aim of this research is not necessarily to maximise the\r\naccuracy of prediction on these datasets. In the main, these datasets are fully-truthed and thus\r\nwe expect that existing research on supervised learning will be competitive. Also these data\r\nsets are fixed and are thus not tracking customer interests or concept drift.\r\n\r\nWe also include the problem of fusion of scores that may be approachable by a natural\r\nextension of the weak labels research area.\r\n\r\n5Paragraph adapted from [W41].\r\n\r\n16\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n3.1.1\tSupervised learning prior work\r\n\r\nSupervised learning has had many applications in the research community but few applications\r\nhave been deployed operationally. Some research examples over the last ten years (along\r\nwith the classifier type used) are: steganography detection (Random Forest) [I74], website\r\nclassification (decision tree) [I36], protocol classification (Random Forest and neural network)\r\n[W1], spam detection (Random Forest) [I44], payphone detection (Random Forest) [I3] and\r\ndrug smuggler detection (logistic regression) [I77].\r\n\r\nRandom Forests\r\n\r\nA common theme in many SIGINT applications is the use of Random Forest classifiers [E6]6.\r\nRandom Forests are an ensemble learning technique [W13]. The base learners are unpruned\r\ndecision trees [W10] which then vote to reach decision. Randomness is inserted into each tree\r\nby two means. Firstly, each tree is built on a bootstrap sample of the training data. Secondly,\r\nthe trees are built in a top-down manner by choosing the best feature at each node from a\r\nrandom subset of the features.\r\n\r\nOne reason for the use of Random Forests may be because they typically produce high\r\naccuracies with little tuning. However our feature spaces may also naturally lend themselves\r\nto Random Forests. Properties of our feature spaces include:\r\n\r\n\u2022\tFeatures are typically based on categorical and count data. Random Forests can handle\r\na mixture of ordered and categorical feature types.\r\n\r\n\u2022\tOur data do not often show simple clusters. Some features (e.g. port numbers in the\r\nprotocol classification example) behave a bit like ordered features and a bit like categorical\r\nfeatures (nearby ports are sometimes associated but not always).\r\n\r\n\u2022\tOur features also show special values. A particular example could be a zero in a count\r\ncould derive from missing data due to limited SIGINT visibility rather than saying any-\r\nthing relevant about the property of interest.\r\n\r\nOne adaptation to Random Forests considered in-house to improve accuracy and help un-\r\nderstand the tuning of Random Forests is weighting of individual trees [I68].\r\n\r\nInterpretability\r\n\r\nA problem with the use of Random Forests is that their decisions can not be simply and intu-\r\nitively explained to an analyst. This black box nature can lower analyst trust in a prediction.\r\n\r\n(NSA R1) has been leading an effort to make Random Forests more interpretable\r\n[I18]. It would be good if semi-supervised models could have a broad-brush interpretability\r\neven if there are some complex exceptions that break these simple interpretations.\r\n\r\n6The NSA were very early adopters of Random Forests through direct contact with\tvia the\r\n\r\nNSA Statistical Advisory Group (NSASAG) [W31]. The NSASAG remain a useful conduit to statisticians at\r\nUS universities [W28].\r\n\r\n17\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nScale\r\n\r\nThe community has also considered scaling training of Random Forests to large datasets for\r\nthe rare cases where one has computer-based truthing.\r\n\r\nThe most trivial scaling is naive parallelisation per tree. To do this one duplicates the data\r\non multiple hosts, grows trees on each host independently and then combines the trees together\r\ninto a final forest. The author of [I74] found this approach helpful in building classifiers for\r\nsteganography detection.\r\n\r\nNSA have looked at ways to implement Random Forests in Hadoop [I8, I4]. In GCHQ we\r\nhave looked at streaming approaches with Random Decision Trees [I61] and Very Fast Decision\r\nTrees [I7].\r\n\r\n3.1.2\tSemi-supervised learning prior work\r\n\r\nSemi-supervised learning is an area of active research in academia (see [E7] for a text-book\r\nreference and [E46, E36] for literature reviews). Given our interest with Random Forests, the\r\nrecent paper on semi-supervised Random Forests may be of interest [E24].\r\n\r\nHowever semi-supervised learning is less well developed in the intelligence community.\r\nLLNL have been considering active learning approaches for finding cyber attacks [I13]. Fran-\r\ncois Theberge at CRI has looked at transductive learning (a special case of semi-supervised\r\nlearning where a predictive function is not learnt at anywhere other than pre-chosen values)\r\n\r\n[I80]. The GCHQ maths summer student programme (SSP) in 2011 have been asked to look\r\nat transductive learning in the context of determining the relationship between entities [W32].\r\n\r\n3.2\tSemi-supervised learning\r\n\r\nSemi-supervised learning algorithms \u201ctypically [use] a small amount of labeled data with a\r\nlarge amount of unlabeled data.\u201d [W38] This viewpoint is very desirable to GCHQ:\r\n\r\n\u2022\tLike many organisations we have large datasets of which only a tiny subset can be truthed\r\nby hand.\r\n\r\n\u2022\tWe have more metadata than content. For truthing we may require content but policy or\r\ndata volumes means that content is only available for a small fraction of the data covered\r\nby metadata. Therefore classifiers that run on metadata but are truthed based on limited\r\n(and not randomly selected) content are desirable.\r\n\r\nTraditionally we have approached these problems with supervised learning and ignored all the\r\nunlabelled data.\r\n\r\nThe overarching question of this research area is can we use semi-supervised learning to our\r\nadvantage? What shape must the problem have for there to be significant benefit?\r\n\r\n3.2.1\tHow useful is semi-supervised learning?\r\n\r\nThere do not seem to be strong theoretical results in academia to explain the benefits of semi-\r\nsupervised learning as opposed to supervised learning. Can we develop an applicable theoretical \u25c4\r\nunderstanding of semi-supervised learning?\r\n\r\n18\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nEven if a theoretical understanding eludes us can we develop useful empirical rules of thumb \u25c4\r\non the value of semi-supervised learning? A simple starting point might be to measure gains\r\nin accuracy based on different approaches for the example SIGINT datasets.\r\n\r\nThere are a range of known semi-supervised techniques; two major classes are: generative\r\nmodels and low-density separation [E7]. Can we tell what type of algorithm one might want \u25c4\r\nto use on a particular dataset?\r\n\r\nWhat is the nature of a good feature space for semi-supervised learning? Are there feature \u25c4\r\ntransformations that could be applied to help this?\r\n\r\nIf our truthing comes from an automated process then we may have untruthed examples\r\nthat have failed automated classification. Alternatively if we truth a meta-data classifier based\r\non content then our truthing will only exist where we have content. In both these examples,\r\nin contrast to the traditional viewpoint of semi-supervised learning, the truthed examples are\r\nlikely not to be independently distributed of the features or classes. In the missing value\r\nimputation literature such truthing would be called \u201cmissing not at random\u201d (MNAR). A\r\npotential approach to handle such truthing is described in [E33]. Can we build valid models\t\u25c4\r\n\r\nwhen the truthing is not independent of the feature space or classes?\r\n\r\nIn the above, we have assumed that each training example can be treated independently.\r\nMany SIGINT datasets have relationships between examples which can be represented as a\r\ngraph. Progress is being made externally on graph-based semi-supervised learning (see [E17]\t\u25c4\r\n\r\nand references therein) - can these external techniques be usefully applied to SIGINT problems?\r\n\r\n3.2.2\tPositive-only learning\r\n\r\nA special case of semi-supervised learning is when we only have labels for some members of\r\none class and want to learn a binary classifier. An example is payphone classification where we\r\nhave lists of some payphones and no labels for other phone numbers.\r\n\r\nIn the outside literature^^^ [E13] presented a Bayesian approach to positive-only learning\r\nbut internally\t[I50] pointed out an error in their approach. However, in the world of\r\n\r\nstatistical testing\thas pointed out that one can still identify the most powerful test\r\n\r\nby considering the quasi-power [I49]. This approach was successfully used in a positive-only\r\nlearning scenario for botnet detection [I71].\r\n\r\nasks, can we find or develop a theorem of the form: \u201ca binary classifier can\t\u25c4\r\n\r\nbe trained if and only if ...\u201d. Can positive-only learning be shown to work with no other\r\nconstraints? This type of theorem would also be relevant to the rest of the beyond supervised\r\nlearning problem area.\r\n\r\nCan we design a new classifier for positive-only learning?\t\u25c4\r\n\r\n3.2.3\tActive learning\r\n\r\nMany approaches to semi-supervised learning present a random subset of the data for truthing.\r\n\r\nThis approach means that human effort is probably wasted classifying examples that have\r\nlittle impact on the learnt function. Active learning instead sets up the truthing process as a\r\nsequential process where the algorithm sequentially chooses examples for truthing based on all\r\nthe information so far at its disposal. A useful review of external research in active learning is\r\n[E37].\r\n\r\n19\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nThe benefits of active learning are uncertain as an algorithm can focus on minor refinements\r\nto the current model and deliberately ignore examples that if truthed would lead to major\r\nchanges to the current model. Do active learning algorithms quickly converge to a good model \u25c4\r\nwhen allowed to choose which truthed items to use from the example datasets?\r\n\r\nA risk with active learning is that after many truthing examples one decides that the chosen\r\nalgorithm is not suitable for the data set. It may not be practical to ask for more truthing with\r\na different algorithm. What happens if you take the partially truthed dataset from one active \u25c4\r\nlearning run and use that dataset with a different semi-supervised learning algorithm?\r\n\r\nActive learning is a process where the algorithm and human are closely coupled and thus\r\nhuman factors are important.\tsuggests looking at active learning\r\n\r\nscenarios where the human is asked to rank two or three items rather then give a score or label.\r\n\r\nThis may be easier from a human factors point of view. Can we design algorithms for active \u25c4\r\nlearning based on ranking pairs? How does the number of example pairs required compare\r\nto the number of truthed examples in traditional active learning? See [E35] for an example\r\nsupervised approach.\r\n\r\n3.2.4\tNew algorithms and implementations\r\n\r\nThe asymptotic complexity of many semi-supervised learning algorithms is not good\r\n(e.g. O(n3), where n is the number of examples, or worse) [E46]. Such complexities are likely\r\nto be prohibitive on large datasets. Ideally we would like algorithms to run in O(n log n) or\r\nbetter.\r\n\r\nWe\u2019d be interested in new accurate and fast semi-supervised learning techniques. The \u25c4\r\nrequirement to scale to large datasets will hopefully lead to streaming and/or MapReduce\r\nimplementations.\r\n\r\nThe SIGINT datasets provided may also inspire new techniques to enhance classification\r\naccuracies.\r\n\r\n(NSA R6) suggests that we may often be in the scenario that we have our\r\ntruthed data as a small data set on which one can do a large amount of in-memory computation\r\nbut our untruthed data as a large dataset in Hadoop. Can a learning algorithm be developed\t\u25c4\r\n\r\nthat iterates between complex in-memory analysis of the truthed data and single table scans\r\nof the untruthed data?\r\n\r\n3.3\tUnreliable marking of data\r\n\r\nAn alternative approach to improve the applicability of machine learning techniques is to allow\r\ninaccurate truthing of data, so called \u201cweak labels\u201d. We think of this case as related to semi-\r\nsupervised learning; in traditional semi-supervised learning you have perfect knowledge of some\r\ncases and no knowledge of other cases - in the case of weak labels this knowledge is diffused\r\nacross the entire dataset.\r\n\r\n3.3.1\tWeak labels\r\n\r\nScenarios where weak labels could occur are:\r\n\r\n20\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nSemi-synthetic data: If suitable training data can not be found we may want to modify\r\ndata to have the properties we want. An example of this is steganography detection [I74].\r\n\r\nWe take a large number of images from SIGINT and add steganography into some the\r\nimages to make our truthed data. Errors will occur as some of these images may have\r\nsteganography before we start.\r\n\r\nAutomated labelling: We might base our labels on content based-signatures that may not\r\nbe accurate (e.g. for protocol classification [I70]).\r\n\r\nNatural error: Even experts make mistakes when labelling.\r\n\r\nExternally the field of weak labels has been rejuvenated by the use of the internet for\r\ntruthing by amateurs, e.g. using Amazon\u2019s Mechanical Turk where one may have multiple\r\nlabels per item [E31]. However, the field dates back many years; for example [E27] showed the\r\nimpact of weak labels on nearest-neighbour classifiers and ^-consistent estimators.\r\n\r\nAnother recent approach has been MIForests [E23] which shows an approach to adapt\r\nRandom Forests to binary classifiers based on sets of inaccurately marked data.\r\n\r\nAs mentioned in section 3.2.2 by looking at quasi-power [I49] we can work directly with\r\nweakly labelled items (with some constraints on the labelling) to identify a most powerful test.\r\n\r\nCan we understand the influence of labelling errors on different techniques? Do some \u25c4\r\ntraditional supervised learning techniques work out-of-the-box with weak labels?\r\n\r\nCan we develop algorithms that understand and compensate for the errors?\t\u25c4\r\n\r\n3.3.2\tFusion of scores\r\n\r\nA problem which might be a natural extension of this work is fusion of scores. For example,\r\nwe have multiple techniques to try to infer a relationship between entities (e.g. from contacts,\r\ntiming behaviour and geo behaviour). These techniques produce scores that are typically real\r\nnumbers between 0 (no relationship) and 1 (a relationship exists). If these were (proportional\r\nto) independent likelihoods then these scores could simply be multiplied. However, these scores\r\nwill not be independent and will not be likelihoods. How can we combine such scores in general? \u25c4\r\nCan we combine such scores to posterior probabilities? How large a deviation from independent\r\nlikelihoods can we cope with?\r\n\r\nThis problem is exactly the problem of weak labels if we treat one score as being a weak\r\nlabel and the rest of the scores as features. We have the added power that we can choose any\r\nfeature as the weak label.\r\n\r\nInternally we have considered score fusion in two main contexts:\r\n\r\nRelationship scoring: CHART BREAKER [I31] research initially looked at handling the\r\nmultiple scores derived from the email communication hypergraph but is currently being\r\nextended to handle multiple communication mediums as part of FIRST CONTACT.\r\n\r\nGeo-reference data: We have multiple sources of data giving us information on the geoloca-\r\ntion of an IP address. The GeoFusion project [I53] and RADONSHARPEN-B [I59] have\r\nlooked at combining country labels and confidences from multiple sources to come up\r\nwith a decision for an IP address\u2019s country.\r\n\r\n21\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nDataset\tRef\t# truthed\t#features\toutput\tnoisy\t+ve only\r\nLogo recognition\tF.4.1\t530\t64\t109 classes\tN\tN\r\nSpam detection\tF.4.2\t1809\t143\t11 classes\tN\tN\r\nProtocol classification\tF.4.3\t799,541\t51\t15 or 39 classes\tN\tN\r\nSteganography detection\tF.4.4\t1,550,000\t661\t(0,1) range\tY\tN\r\nGenre classification\tF.4.5\t~16,000\t108\t2-17 classes\tN\tN\r\nWebsite classification\tF.4.6\t6,705\t200\t4 classes\tN\tN\r\nPayphone detection\tF.3.5\t97,993\tN/A\tBinary\tN\tY\r\nArrival process correlation\tF.1.5\t763,392\tN/A\tBinary\tY\tN\r\n\r\nTable 1: Truthed data sets. Further details about these datasets can be found in appendix F as\r\nreferenced in the second column.\r\n\r\nIf we\u2019re dealing with labels rather than scores then there\u2019s a line of literature in medical\r\nstatistics looking at estimating the accuracy of diagnostic tests. These are based on the Hui-\r\nWalter method of independent tests [E19, E32, E21]. Extensions have now looked at correlated\r\ntests [E11]. [E38] makes the link between these approaches and latent class models and thus\r\nthis problem can be seen to be related to that being considered\tat LLNL for\r\n\r\nlearning with network data [I58]. [E31] shows an extension to real valued functions.\r\n\r\nNSA have also looked at this problem in the context of log-likelihoods that may not be\r\nindependent [I45] (their approach has been reviewed by GCHQ [I26]).\r\n\r\n3.4\tRelevant data\r\n\r\n3.4.1\tTruthed datasets\r\n\r\nWe provide various SIGINT truthed datasets as summarised in table 1. Most of these data\r\nsets consist of features and truthed output for all examples. There are a few exceptions:\r\n\r\n\u2022\tThe protocol classification set has some \u201cNULL\u201d labels for which automated signature-\r\nbased classification failed. This dataset can be seen as an example of a semi-supervised\r\nset where the truthed examples are not randomly chosen.\r\n\r\n\u2022\tThe payphone data set comes with no features. We do not have feature extraction in\r\nHadoop. Implementation of the features in [I3] should not be too large a task and\r\nimplementing a complete system would aid deployment.\r\n\r\n\u2022\tThe arrival process correlation data set has no features extracted. Also the truthing\r\ncomes as two sets where one set is richer in true cases than the other. This data is\r\nincluded as it is an active area of statistical research and overlaps with the information\r\nflow in graphs problem. If features are required for this set then the CLASP scores [I49]\r\ncould be useful features but new approaches would also be welcome.\r\n\r\nFor the fully-truthed data sets in table 1 it is imagined that semi-supervised or weak label\r\nexperiments can be conducted by hiding truth labels or perturbing truth labels.\r\n\r\n22\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nThe steganography detection dataset may also be a good dataset if we want to look at\r\ncost-sensitive feature extraction within the context of semi-supervised learning. The features\r\nare computed in classes, each with a cost. We can give some metrics on these costs if required.\r\n\r\nIt should be remembered that the aim of this problem area is not to maximise the accuracy\r\nof classification on these datasets. These datasets should be used to support improvements in\r\nunderstanding and algorithms.\r\n\r\nA flaw with these datasets is that they are mostly small (having derived from experiments\r\nwith supervised learning). The ability of algorithms to scale to larger sizes should be considered.\r\nThe payphone data may be the most promising one to look at at scale.\r\n\r\n3.4.2\tFusion of scores data\r\n\r\nWe provide fusion of scores data from GeoFusion. Scores in GeoFusion are typically ordered\r\nconfidence labels (\u201clow\u201d to \u201cvery high\u201d) rather than real numbers. We provide the country and\r\nconfidence from four SIGINT systems as well as the Akamai Edgescape commercial geolocation\r\ndataset. See appendix F.5 for more details on this data.\r\n\r\nWe hope that data for fusion of identifier relationship scores will be available soon. Al-\r\nternatively researchers could use existing software to compute scores from telephony or C2C\r\ndata on the cloud themselves - please consult the authors for more guidance on this route if\r\nrequired.\r\n\r\n3.5\tCollaboration points\r\n\r\nThere are several areas where one might find useful collaboration in this problem area:\r\n\r\nICTR-MCA: The Media Content Analysis team are looking to automatically determine\r\nthe relationship between entities based on communication content and think that semi-\r\nsupervised techniques are likely to be needed;\tis leading on this work.\r\n\r\nand\talso think that their work on speaker identification\r\n\r\nmay lead to a semi-supervised problems with weak labels.\tis also plan-\r\n\r\nning to revisit the problem of finding IED triggers in audio content and which may lead\r\nto a dataset with features derived from roughly continuous data (as opposed to many of\r\nthe provided sets being based on discrete data), see [W44] for more details.\r\n\r\nICTR-DMR:\tis leading a major research package on fusion of scores.\r\n\r\nwould also be interested in any developments based on the payphone detection\r\ndataset.\r\n\r\nUS National Labs: At\tand\r\n\r\nare working on active learning for finding anomalies in C2C data.\r\n\r\nat LLNL and\tteam at Sandia National Labs have been\r\n\r\nworking on large-scale machine learning algorithms.\tat LLNL was interested\r\n\r\nin latent class models (potentially linked to fusion of scores) but has now been posted to\r\nAustralia.\r\n\r\nNSA R6:\r\n\r\nis interested in large scale semi-supervised learning algorithms.\r\n\r\n23\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nNSA R1: ^^^^g is always interested in anything that can advance the arrival process\r\ncorrelation score. Also\tis interested in techniques that may improve the\r\n\r\ninterpretability of Random Forests (he particularly mentions the \u201cTreebeard\u201d technique\r\n\r\n[I18]\tas having further research possibilities).\r\n\r\nCRI:\tis working on transductive learning which is closely related to semi-\r\n\r\nsupervised learning.\r\n\r\nIBM Research:\tsuggests that unclassified engagement may be possible with\r\n\r\n(IBM Research) on active learning. ^^g also works with^^^^^^f\r\n^^Jfrom Yahoo Research who has also been working on fast online learning algorithms,\r\nexemplified by Vowpal Wabbit.\r\n\r\n24\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n4\tInformation Flow in Graphs\r\n\r\n4.1\tIntroduction\r\n\r\nThis section of the problem book concerns information flow in graphs. By this we mean the\r\nstudy and discovery of related information or messages being relayed over multiple edges in a\r\ncommunications graph. For this problem we will initially consider working on a static graph,\r\nalthough you should feel free to consider the streaming case if you desire. We get to observe a\r\nset of transactions taking place on the edges of the graph. Given these transactions we would\r\nlike to be able to infer something about likely information flows across multiple edges. In most\r\ncases we will know nothing of the content of the transactions. We therefore wish to focus mainly\r\non techniques which do not require any content knowledge. Data with content should therefore\r\nmainly be seen as truthed data for exploration and familiarisation with existing techniques.\r\n\r\nWe will now provide two motivating examples for our interest in information flow in graphs.\r\nThese are chosen to reflect intelligence interests over the last decade or so.\r\n\r\nThe first example is a target-centric communications network. Consider the graph formed\r\nby telephone calls around a certain target set. Each call, or transaction, serves the purpose of\r\nconveying information between participants. If significant flows could be extracted then this\r\nwould provide information on the structure of the target set\u2014perhaps identifying commanders,\r\nmiddlemen and operatives. Now, if one of the commanders was no longer part of the network\r\nwe could again examine how the flows have changed and therefore gain insight on any reorgan-\r\nisation that has taken place. Further, it may even be possible to identify a significant change\r\nin flows on the graph and identify a change in structure purely from transactional data.\r\n\r\nThe second example is the detection of botnet command and control infrastructure. For a\r\nbotnet to be effective it needs to be able to convey commands from its controller to all infected\r\nnodes. One can imagine that with some knowledge of infected nodes it may be possible to use\r\ninformation flows to trace out the infrastructure, discover further infections, or even track back\r\nto find the botnet\u2019s owner. This type of capability would be of enormous interest due to the\r\ncurrent emphasis on cyber defence.\r\n\r\nWe now define a cascade and discuss how we will use them to summarise the significant\r\ninformation flows.\r\n\r\nFigure 3: Examples of cascades. A downwards pointing triangle is a source and an upwards one\r\na sink. A diamond means the node is both the source and a sink.\r\n\r\n25\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nDefinition 1. A cascade is defined to be a directed connected subgraph with a single source\r\nand one or more sinks, consisting only of directed paths from the source to every sink. Being\r\na source or sink is considered an attribute rather than necessarily having no in or out edges\r\nrespectively.\r\n\r\nFigure 3 shows some example cascades. Subfigure 3(b) demonstrates a cascade where the\r\nsource is also a sink\u2014there is nothing in the definition which prohibits this. Further, we can\r\nimagine situations with an information flow like this. For instance consider a friend to ask their\r\nfriend for a favour and then having the response relayed back.\r\n\r\nCascades can be used to represent significant, repeated information flows on the graph. Each\r\ndirected edge in the cascade, starting from the source, should occur no earlier in time than its\r\npredecessors. Algorithms developed should probably output such representative cascades.\r\n\r\nWe are interested in techniques which do not depend upon having the content of transactions\r\nas this limits their applicability. This is because much metadata is of the form \u201cA communicated\r\nwith B at time t\u201d, with few or no clues to what the content of that communication was. Because\r\nour data is in this form we place a particular emphasis on temporal correlation when surveying\r\npast work.\r\n\r\nThis section of the problem book has a relatively small number of wide problems. This\r\nis because the main problem of information flow definition and discovery is meant to be open\r\nended with plenty of scope for exploration and experimentation7.\r\n\r\n4.2\tPast work\r\n\r\nWe will now describe past work in related areas of research, with a particular emphasis on\r\ninternal research. We will introduce key areas of work, give a sketch of their workings and\r\nprovide references for further reading. External work discussed should be seen as a sample\r\nrather than a definitive list.\r\n\r\nThis subsection will first discuss methods on graphs, starting with explicitly temporal ones\r\nand then moving on to static ones. We will then discuss the extensive research that has\r\nbeen conducted on temporal correlation of stochastic processes. We expect that research on\r\ninformation flow in graphs may want to draw on all areas, perhaps applying our knowledge on\r\ntemporal correlation in a graphical setting.\r\n\r\n4.2.1\tGraphical methods\r\n\r\nThere have been several approaches used to exploit timing information present in transactions\r\non graphs. If two vertices participate in timing patterns then it is likely that they are closely\r\nrelated. Further if one of these vertices is a target then the other may be worth investigating\r\nmore closely.\r\n\r\nThe first temporal graph algorithm in GCHQ was Remit, developed under contract by\r\nDetica for ICTR-DMR [I78]. A large amount of subsequent research can be seen to have been\r\ndirectly triggered by the Chains analytic within Remit. Chains is about the simplest approach\r\npossible to finding information flow in graphs. One simply defines a maximum time allowed\r\n\r\n7The problem \u201cFind and score related stochastic processes\u201d has already had many man-years of research\r\neffort expended across dozens of approaches.\r\n\r\n26\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nbetween transactions on adjacent edges and a minimum flow length. The Chains algorithm\r\nwill then find all flows satisfying these conditions. Despite this simplicity trials showed that\r\nit could produce useful intelligence when applied to a target-centric telephony graph [I41].\r\nUnsurprisingly, given its fixed time window, Chains had issues with flows spuriously going\r\nthrough vertices with a high activity rate. This motivated the next stage of research in temporal\r\ngraph methods.\r\n\r\nPRIME TIME [I42] was the next approach created. PRIME TIME introduced a statistical\r\nmodel to compensate for varying vertex activity levels. Specifically an exponential distribution\r\nis fitted to a vertex based upon its mean time between transactions. This exponential is used to\r\ncalculate a p-value on waiting times for transactions on pairs of adjacent edges. If the p-value is\r\nless than some critical value then the transactions will be considered related. Furthermore the\r\np-values are collected for future scoring of long and/or repeated flows. However the methods\r\nof combination used are ad-hoc and not statistically motivated. The original PRIME TIME\r\npaper talks of chains of related edges, although in practice only length 2 were computed. Even\r\nso this suggests the beginning of the study of information flow in graphs.\r\n\r\nCurrently a streaming version of PRIME TIME is being developed by Detica for the Stream-\r\ning Analysis team in ICTR [I63].\r\n\r\nHIDDEN OTTER is an ICTR-NE prototype that similarly tries to find temporal chains\r\nin communications data [I62]. In particular they are interested in finding things such as back-\r\nhaul networks, TOR networks and botnet structures. It has the simple approach of finding\r\ntemporally ordered chains of transactions on edges starting from a specified set of seed nodes.\r\nHIDDEN OTTER is essentially a reinvention of the Remit Chains algorithm, but in Hadoop.\r\n\r\nBAKER\u2019S DOZEN is a technique for finding batches of near-sequential phone numbers\r\nthat display causal behaviour [I11]. Given population-level telephony data it generates a list of\r\npairs of telephone numbers that are near-sequential. For each of these pairs it conducts tests to\r\ndiscover if they are causally related. One of these tests is temporally correlated communications\r\nwith the same third party. This third party condition is important at population level as\r\notherwise there are too many random coincidences due to identifiers merely being active at the\r\nsame time. CLASP8 was rejected for having little statistical power due to exactly this reason.\r\nThe BAKER\u2019S DOZEN test measures the proportion of events which involve a common third\r\nparty and occur within t minutes of each other. A beta distributed prior and most powerful\r\nvalue for t were learnt from the data. The causal threshold was learnt by evaluating the statistic\r\nfor 20 million random pairs and then choosing the value which led to a p-value of 10-6. This\r\nstatistic proved to be powerful in the sense of promoting many pairs above the causal threshold.\r\n\r\nThere has been a large amount of research on information diffusion and cascades in the\r\nexternal literature e.g. [E44, E18, E25, E29]. However the focus has tended to be on datasets\r\nwhere one can directly observe the pieces of information flowing through the network. Examples\r\ncould be hashtags through Twitter or the spread of disease through a contact network. R66\r\nat NSA have developed a MapReduce algorithm based on [E18] to track the passing of files\r\nbetween implanted machines [I35]. The reading rack for this problem (on [W24]) contains a\r\nnumber of citations of external papers considering information cascades and diffusion. Those\r\npapers should provide a good starting point in the literature, but is nowhere near exhaustive.\r\n\r\nInternally there has been some research on block modelling [I28, I29, I30]. Block modelling\r\n\r\n8Covered in subsection 4.2.2.\r\n\r\n27\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (vl.O, r206)\r\n\r\nTime\r\n\r\n----------------\u25ba\r\n\r\n0.2  i  1 i i\t0.3  L\t,  1  1\t\t\t0.4  L\t,  1  1\t\r\nl  l  i  i\t\t\t\t\t\r\n\r\nFigure 4: An example of the non-homogeneous Poisson process used in [149, 164, 152]. Here we\r\nare testing the hypothesis that R\u2019s events are triggered by As. We therefore \u201cproject\u201d \u00a3Ts events\r\nonto A's timeline: the first falls 0.2 of the way between two A events, the second 0.3 and the third\r\n0.4. This figure is adapted from [164]\r\n\r\nassumes that vertices in a graph each belong to different classes. The communication between\r\nvertices is then determined entirely by their classes. The job of a block modelling algorithm\r\nis therefore to assign vertices to classes and describe how the classes interact with each other.\r\nAlthough this has not so far considered information flows there is the possibility that they could\r\nbe useful for block modelling. Further the outputs of certain block models may be interpretable\r\nin a similar manner to potential applications of information flows. For instance both may be\r\nable to distinguish directors, middle managers and workers in a company hierarchy. Is it\r\npossible to use block modelling to inform the discovery of information flows?\r\n\r\n4.2.2\tTemporal correlation\r\n\r\nInternally there has been much research undertaken in understanding temporal correlation\r\nbetween stochastic processes. This work should be a great aid in tackling the information flow\r\nin graphs problem area, especially when the information cannot be directly observed flowing\r\nover the graph. If we are interested in comparing adjacent edges then this work is directly\r\napplicable by restricting the scored processes to those with a common vertex.\r\n\r\nThis research started in 2005, motivated by a desire to find cross-media temporal correla-\r\ntions. An example of a cross-media correlation would be A calling B to arrange for B to initiate\r\nan instant messenger conversation with him. [149] found that modelling the stochastic processes\r\nas non-homogeneous Poisson processes (NHPP) gave the best performance of the approaches\r\nattempted. This contrasts to PRIME TIME which models activity as a homogeneous Pois-\r\nson process. Assuming that one can model the rate function of the NHPP correctly then the\r\nevents of unrelated processes should fall uniformly with respect to each other. Figure 4 shows\r\nan example of this mapping. All tests seek to find deviations from this null hypothesis. The\r\noriginal paper proposed 14 tests for non-uniformity, some of which place particular emphasis\r\non the start of the interval.\r\n\r\nOngoing research on this strand of temporal correlation can be seen to fall into two areas:\r\n\r\n28\r\n\r\nThis information is exempt under the Freedom of Information Ac^OO^FOIA^nAriay b^xemp^mdei^theiAK\r\ninformation legislation. Refer any FOIA queries to GCFIQ on\tor\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\ntesting for non-uniformity and improving rate function estimation. The current best test for\r\nnon-uniformity is the PCG statistic [I64]. This uses the fact that if there are k points uniformly\r\ndistributed on (0,1) then the first of these is distributed according to a Beta(1,k) distribution.\r\nOne can then calculate a left-tail p-value for each interval and combine them using Fisher\u2019s\r\nmethod. This simple method beats more complicated approaches [I6, I39, I23, I65] on the\r\nstandard datasets. The current best technique for rate function estimation is described in\r\n[I52]. This is a two stage process. Firstly one clusters the set of stochastic processes. Secondly\r\none counts time not in seconds but in the number of events that have occurred within a process\u2019\r\ncluster. It is worth contemplating why this works. Consider the phones belonging to GCHQ\r\nemployees - these cannot be brought into the building and so are very quiet between 9 and 5. If\r\nan employee turns their phone on at the end of the day and responds to a voicemail left earlier\r\nin the day then this activity has been triggered despite the multi-hour gap. By performing this\r\ntransformation we turn this from a gap of many hours to one of a few events and we are better\r\nable to spot the causality.\r\n\r\nThe slide deck [I47] contain details of much of the research conducted before October 2010.\r\nThis does not however include the cluster-based rate estimation from [I52].\r\n\r\nResearch into a streaming implementation of the PCG algorithm has been conducted in R1\r\nat NSA [I51]. The work focuses mainly on data structures and approximations to allow the\r\nalgorithm to remain within main memory. However given the large size of some of the datasets\r\nfor this problem the techniques outlined may be useful should scaling prove to be a problem.\r\n\r\nR1 have started to investigate using inference on a parametric model for how causal time\r\nseries are generated [I24]. This proposes a mixture model where B\u2019s events happen either\r\naccording to an underlying Poisson process or because of a causal A event. They demonstrate\r\nthat this is a continous Markov process and formulate tests on whether given pairs of stochastic\r\nprocesses are likely to be correlated. When the model assumptions are correct their likelihood\r\nratio statistic is tens of times more powerful than the best general methods known at small\r\nsizes for some generating parameters.\r\n\r\nMany of these techniques are included in the CLASP software package, with new methods\r\nadded once demonstrated as useful.\tmaintains CLASP. It is available on the LID\r\n\r\nat /data/cryptomath_research/windata/infoproc/Software/CLASP/\r\n\r\nSAGA is a technique which extends a measure of item similarity to set similarity [I48]. It\r\nhas provably desirable properties and has case studies that have demonstrated its utility. In\r\nparticular it has been used as a method for performing temporal correlations. If one treats a\r\nstochastic process as a set of times and defines a similarity measure between times then SAGA\r\nmay be applied to measure the similarity of pairs of stochastic processes. This approach is\r\nradically different to anything else attempted and can perform surprisingly well on the standard\r\nCLASP datasets.\r\n\r\n4.3\tWhat we care about now\r\n\r\nThis subsection will set out the problems that are of interest regarding information flow in\r\ngraphs.\r\n\r\n29\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n4.3.1\tDefinition and Discovery\r\n\r\nThe first and most fundamental problem is the definition and discovery of information flows \u25c4\r\nin the graphs. This document deliberately declines to provide a mathematical definition of an\r\ninformation flow. There is not an immediately obvious definition and therefore it seems best\r\nto leave this as part of the problem. It was suggested by\tof R1 that it may\r\n\r\nbe a good idea to start from how you would define it given perfect information and then work\r\nbackwards. However hopefully the examples given in the introduction sufficiently illustrate the\r\ntype of things we hope to find. Further thinking about cascades as previously defined may help\r\nwith a definition.\r\n\r\nof R1 suggested an approach for defining repeated information flows. One could\r\nphrase it as learning a distribution over when/which edge will have a transaction next given\r\nprevious (and possibly future) activity on adjacent edges and further information, such as time\r\nof day. Repeated information flows could then be seen as high likelihood paths through this dis-\r\ntribution. Can such a probability distribution be written down in a form where (approximately) \u25c4\r\nevaluating it is tractable?\r\n\r\nThe Enron and SKB datasets are atypical of SIGINT data in that there is information\r\non the content available. However this should be very useful for formulating definitions of\r\ninformation flow as it will be easier to see the flows occurring. In the SKB the flows correspond\r\nto various media being passed around the internet. The circulation of extremist media is of\r\nparticular intelligence interest. It is suggested that these datasets be seen as truthed data and\r\nfor gaining familiarity with techniques suggested in the literature. We are less interested in\r\ndeveloping new techniques which depend upon having the content of transactions as this limits\r\ntheir applicability. We are therefore probably restricted to extracting flows which repeat rather\r\nthan occur singly. What do the SKB and Enron datasets tell us about how well we can extract\t\u25c4\r\n\r\ninformation flows without content? Can we perform exploratory data analysis on the SKB to\t\u25c4\r\n\r\ninform the definition and discovery of flows? Can we spot typical transfer patterns?\t\u25c4\r\n\r\nResearch on improving CLASP has been aided by the availability of two standard datasets.\r\nThese each consist of two subsets\u2014a random sample of processes for which there is no reason\r\nto believe any relationship exists, and a sample of pairs for which there is some external reason\r\nto believe a relationship may exists. This allows ROC curves [W34] to be compared between\r\ntechniques and an objective comparison to take place. Can similar datasets and comparison \u25c4\r\nmechanisms can be created for this problem and therefore help drive research collaboration?\r\n\r\nThere have been many different approaches to temporal correlation, both explicitly graph-\r\nbased and not, as demonstrated in the previous subsection. Can we find a theory that unifies \u25c4\r\nthese approaches? One possible direction is to consider having placed a prior distribution on\r\nthe probability of a significant temporal correlation being present. For example CLASP can\r\nbe seen as putting a uniform prior over all pairs of edges, while PRIME TIME is uniform only\r\nover edges sharing a common vertex.\r\n\r\n4.3.2\tMissing data and noise\r\n\r\nSIGINT data is almost always incomplete. In terms of this problem certain edges may not\r\nhave been observed or some transactions on edges may be missing. In experiments carried out\r\non billing records and SIGINT during the 2008 graph mining SWAMP at HIMR there was\r\n\r\n30\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nshown be a huge disparity between our view of the world and ground truth [I73]. CSEC have\r\nperform similar analyses with similar conclusions [W4]. It is therefore important to be resilient\r\nto missing data, especially where a flow may be cut in two. An internal example of coping with\r\nmissing edges is SALTY OTTER [W37]. It uses CLASP to find likely cross-media triggering\r\npatterns, for example telephone conversations typically causing instant messenger chats. The\r\ntool is essentially coping with the missing edge and allowing the information flow to carry on\r\nregardless.\r\n\r\nThere has been some external work on how sampling or missingness affects the appearance\r\nof information diffusion and cascades. [E9] evaluates how different sampling strategies affect\r\nthe view of hashtag diffusion in Twitter. Clearly we do not generally get to choose how our\r\ndata is sampled, but this work may help the understanding of how well/poorly we are likely\r\nto do. [E34] goes further in proposing a method to correct for missing data in information\r\ncascades. Their method assumes that cascades are k-trees, each vertex in the graph is sampled\r\nwith uniform probability and the graph structure is known for sampled vertices. Given these,\r\nthey claim to be successful in reconstructing properties of the original cascades. These external \u25c4\r\napproaches assume that we have the content of a transaction\u2014is there anything we can do\r\nwhen we do not?\r\n\r\nThe obvious approach to this problem is to remove edges/transactions from a dataset to\r\nsimulate poor collection. We can then evaluate different coping strategies by seeing how our\r\nperformance is impacted. Here the Enron dataset is probably a good place to start, as we\r\nhave ground truth and can uniquely guarantee that it is the complete dataset. However any\r\ntechnique developed must behave sensibly on SIGINT data.\r\n\r\nThe data that we do have has further problems beyond missingness. In particular the\r\nquality of the timing information is not as good as we might hope for. This presents at least\r\ntwo concrete problems. Firstly, our data tends to have second timestamps, which may be\r\ntoo coarse a measure for many applications. Does the granularity of the timestamps affect\t\u25c4\r\n\r\nour chances of finding causal flows? Secondly the clocks on our probes are not synchronised.\r\n\r\nThis means that there is likely to be a constant offset between events happening on different\r\nbearers. Any technique to correct for this offset will both aid this problem area and be of\r\ngeneral interest to the internal data mining and information processing community. Can we \u25c4\r\ncorrect for the clock offset between probes? Possible solutions may involve examining the same\r\nconnection being intercepted on different bearers.\r\n\r\n4.4\tPotential future interests\r\n\r\nThere are further problems in this area that may become tractable as the subject knowledge\r\ngrows.\r\n\r\n4.4.1\tPerforming inference on flows\r\n\r\nAssuming that information flows can successfully be identified and extracted we should then be\r\nable to perform inference on/with them. The obvious first area to investigate would be anomaly\r\nand change detection. The interest in this was hinted at in the introduction in investigating\r\nhow a target network changes after the removal of a commander. Given that this document\r\ndoes not even define a flow then it is not reasonable to scope this future problem any more\r\n\r\n31\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\ntightly. Should you reach a point where you can tackle this problem you should have a good\r\nidea of what anomalies and changes mean within the framework you have developed.\r\n\r\n4.4.2\tInformation flow for graph generation\r\n\r\nThere are many existing models for graph generation. Examples include the Forest Fire al-\r\ngorithm [E26] and Bollobas-Janson-Riordan family of graphs [E5]. However, these approaches,\r\nalthough sequential, do not describe how graphs are truly generated. That is, they do not\r\naccurately correspond to how a graph, and the transactions on it, are generated in reality. If\r\nthe definition and discovery of information flows is successful then it may be possible to use the\r\ndescriptive models for graph generation. This feels far closer to how graphs are really gener-\r\nated. Each transaction is undertaken to convey information. Therefore adequately modelling\r\nthe flows leads to the observations.\tof\tmay well be\r\n\r\ninterested in such ideas as he has stated dissatisfaction with the existing approaches. There is\r\nprobably limited SIGINT interest in this problem unless a convincing argument can be made\r\notherwise. We know of no internal work on any subject which has used any graph generation\r\nalgorithm.\r\n\r\n4.5\tRelevant data\r\n\r\nWe have several relevant datasets with truthed data, of which some have already been men-\r\ntioned in the main body of this section.\r\n\r\nThe Enron (appendix F.2.1) and SKB (appendix F.1.4) datasets are atypical as most\r\nSIGINT data does not have any content associated with it. They can be treated as truthed\r\ndatasets for the evaluation of algorithms for extracting significant information flows.\r\n\r\nWe also have a large dump of FIVE ALIVE (appendix F.1.2) that summarises all IP con-\r\nnections on research bearers. There is no content associated with this data. We do have some\r\ntruthing on flows that may exist in the data. Specifically, we have data on covert infrastructure\r\n(appendix F.3.3) used for exfiltrating data from CNE implants. These suspected flows can be\r\nused for both EDA and evaluation purposes. Further, we have lists of IPs that we suspect to\r\nbe infected with the Conficker botnet (appendix F.3.4), either due to signatures collected or\r\nbehavioural analysis. Again, we suspect that there are some information flows involving these\r\nIP addresses.\r\n\r\nWe also provide two standard datasets used for evaluating temporal correlation algorithms\r\n(appendix F.1.5). If you have any insights on how to perform temporal correlation due to your\r\nwork on this problem you may wish to use these for evaluation purposes.\r\n\r\n4.6\tCollaboration points\r\n\r\nThere are several collaboration opportunities available for information flow in graphs.\r\n\r\nNSA R1\tcoordinates the research into temporal correlation and is always happy\r\n\r\nto hear of new ideas and approaches. He also indicated an interest in this new research\r\narea.\r\n\r\n32\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nICTR-DMR The temporal analysis tools PRIME TIME and SALTY OTTER were developed\r\nin ICTR-DMR. Although they currently are not working in this area they would certainly\r\nbe interested in any results.\tshould be your first contact in ICTR-DMR.\r\n\r\nICTR-NE ICTR-NE are interested in using information flows to find Tor routes, identify\r\nbackhaul routes and map botnets. They currently have a Hadoop prototype called HID-\r\nDEN OTTER which performs simple temporal chaining. They would be very interested\r\nin any work you produce and may wish to collaborate. HIDDEN OTTER was produced\r\nby\tand|\r\n\r\nICTR-CISA The streaming analysis team have had a streaming PRIME TIME developed\r\nby Detica. They are always interested in streaming algorithms and deploying them as\r\nresearch prototypes. If your research takes you in a streaming direction then you should\r\ncontact the streaming analysis team led by\r\n\r\nCCS Bowie\tof Georgia Institute of Technology is a leading academic figure in\r\n\r\nlarge graph analysis. He is cleared and has previously worked as a consultant in NSA\r\nR1. He is now in the process of joining CCS Bowie in a similar role. He is interested in\r\nthis problem area and may be a possible collaborator on both classified and unclassified\r\nwork.\r\n\r\nUS National Labs At Sandia National Laboratory\r\n\r\nresearch on large graph processing for defensive analysis.\r\n\r\nand\r\n\r\nare leading\r\n\r\n33\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n5\tEDA on Streams\r\n\r\n5.1\tIntroduction\r\n\r\n5.1.1\tEDA\r\n\r\nExploratory data analysis (EDA) is all about trying to find interesting features of data\r\nwithout necessarily having pre-formed hypotheses to test. One of the pioneers of EDA was\r\nJ. Tukey [E41, E42], who argued for the value of EDA over the traditional statistical approach,\r\nwhich he called confirmatory data analysis, where one starts with an hypothesis and collects\r\ndata in order to test it. In EDA, the data comes first, and what counts is understanding the\r\ndata as it is.\r\n\r\nFor the data analyst, this is an open-ended problem that is not tightly defined, but for the\r\nmathematical researcher developing algorithms, things are much more concrete. The aim is to\r\nuse one\u2019s intuition, guided by domain-specific knowledge from the analysts, to develop precise\r\nalgorithms that provide human insight on the data.\r\n\r\nWe usually think of EDA as being concerned with\r\n\r\n\u2022\tpulling out global properties of data;\r\n\r\n\u2022\tbroad-brush visualizations of data.\r\n\r\nThe second is really a variant of the first: we can reduce the data to more discrete values\r\nthan a human could take in in a list or table, as long as there is a way to visualize them.\r\n(Compare summarizing pairs by a correlation coefficient, or in a scatter-plot.)\r\n\r\n5.1.2\tStreams\r\n\r\nIn a stream we do not have enough memory to store everything we see, and we only get to\r\nsee each piece of data once. Many problems admit simple approximate solutions in the static\r\nsetting by subsampling. In the stream, this option is not always available. The problems\r\nbecome much harder and controlling error estimates in approximate solutions is very difficult.\r\nOn the other hand, streaming analysis gives us the opportunity to get situational awareness\r\nand real-time tipping from our data, as well as letting us process bigger datasets than we can\r\nafford to store. These are key benefits that we strongly want to capitalize on.\r\n\r\nFor hands-on work, we are thinking of DISTILLERY, as opposed to Hadoop (see appen-\r\ndices B and C).\r\n\r\nOne way to think about the problem is in terms of data structures. There are only a\r\nfew structures that we typically use to keep track of data when we write programs: lists, trees,\r\nheaps, hash tables and so on. What carries through to the streaming setting? Which structures\r\ncan we update in a stream? If we can tolerate some loss, can we maintain approximations to\r\nfamiliar data structures in the stream? If so, can we quantify and bound the errors? These\r\nstreaming data structures are then the building blocks for streaming algorithms. Given a\r\nparticular data stream, what is an appropriate data structure that will capture what we need\r\nto know about the data in order to answer the SIGINT questions we have?\r\n\r\nA short survey summarizing various approaches to streaming data can be found in [E39].\r\nThe 2009 Information Processing SCAMP at La Jolla also produced relevant material [I12].\r\n\r\n34\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nNote on terminology\r\n\r\nWhen we speak of streaming graph algorithms at GCHQ, we are usually referring to what the\r\nexternal literature calls the semi-streaming paradigm. If the graph has n vertices, then we can\r\ntypically store a small amount of information for each vertex, but we are not able to store all\r\nthe edges or do any significant processing as each edge arrives. In other words, we assume we\r\nhave O(n log n) storage, and can do O(1) work per event. (Usually this can be O(1) amortized\r\nwork, as long as this does not cause undue back pressure: see section B.5.1.)\r\n\r\n5.1.3\tThe problems\r\n\r\nThe problem areas on this topic overlap at the edges, and also tend to merge into the streaming\r\nexpiring graphs problems, but to give some order to this section we loosely cluster them into\r\nfour areas:\r\n\r\n\u2022\tgraph problems with no sub-sampling allowed;\r\n\r\n\u2022\tvisualization;\r\n\r\n\u2022\tmodelling and outlier detection;\r\n\r\n\u2022\tprofiling and correlation.\r\n\r\n5.2\tGraph problems with no sub-sampling\r\n\r\n5.2.1\tThe framework of graphs and hypergraphs\r\n\r\nEvents data frequently has a natural representation as a graph, or more generally a hypergraph.\r\nOften, an event will be a communication between two entities, which we think of as an edge\r\nbetween two vertices, one vertex for each entity. There will normally be a notion of the\r\noriginator and recipient of the communication, which makes the graph into a directed graph.\r\nSometimes, a communication can involve more than two nodes, in which case we can think of\r\nit as a hyperedge, and the overall structure a hypergraph9. We also look at graphs other than\r\ncommunications graphs: for example, colocation graphs, where vertices are joined by an edge\r\nif they were geolocated to the same place at the same time; network graphs, whose edges are\r\nphysical links; or even semantic graphs, where nodes are concepts and edges relations between\r\nthem.\r\n\r\nFrequently, our data will come with additional information beyond the simple fact that\r\na communication took place. For example, each vertex will have a boolean attribute, \u2018Is\r\nthis entity a target in BROAD OAK?\u2019 Similarly, edges might have attributes like \u2018duration\r\nof communication\u2019. A common metaphor is to think of discrete attributes as colours and\r\ncontinuous attributes as weights. Although we often need to do algorithmic computations on\r\nthe underlying graph or digraph, taking account of the available attributes can enrich the\r\nSIGINT value of any analysis we do.\r\n\r\n9Some people prefer to think of simple hypergraphs as bipartite graphs, where the vertices and hyperedges\r\nare the two parts, and edges represent inclusion.\r\n\r\n35\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nWe are interested in finding global properties of graphs in a stream\u2014exactly if possible, but\r\nwe expect that approximate solutions will often be the best we can hope for. This is obviously\r\nclosely related to the streaming expiring graphs topic, but in our case we are not worried about\r\nexpiring edges, and we focus more on counting rather than identifying and extracting graph\r\nstructures. Probabilistic counting in general (not specifically in a graph context) has been an\r\narea of active research both internally [I72, I40, I5] and externally [E16, E8] in recent years.\r\n\r\n5.2.2\tCliques and other motifs\r\n\r\nAn n-clique is a subgraph isomorphic to a complete graph Kn. In a communication graph, this\r\ncorresponds to an intuitive idea of a strong, close community, where everyone communicates\r\nwith everyone else.\r\n\r\nFor EDA purposes, we would like to understand the clique structure of a streaming graph.\r\nWhat are the cliques? If a target node belongs to a k-clique, how surprising is that?\r\n\r\nOne way to answer the second question is to get a good random graph model for the\r\ncommunication graph, and do Monte Carlo simulations to find out how likely k-cliques are to\r\noccur in the model graphs. There has been a lot of work on this, for example [I1, I57], but it has\r\nproved very difficult to find models that capture all the relevant properties of SIGINT graphs,\r\nor even to understand exactly what \u2018relevant properties\u2019 we want to capture. An alternative\r\napproach is to just work empirically with the graph we see, and try to estimate how many\r\nk-cliques it has: this gives us some measure of how surprised we should be if target nodes\r\nbelong to such a clique.\r\n\r\nThis leads us to consider probabilistic counting. We might want to count not just cliques,\r\nbut other subgraphs too: perhaps a clique with one edge missing. A motif in a graph is a\r\nsubgraph isomorphic to a particular pattern graph: for example, when the pattern graph is a\r\nKn, the motifs matching it are the n-cliques. There are probabilistic algorithms for counting\r\nthe cardinality of a set: for example, Flajolet et al.\u2019s hyperloglog sketches [E16], proposed\r\non the outside and extended internally by\t[I72]. There are also a variety of\r\n\r\nalgorithms for counting triangles, i.e. 3-cliques. One example is [E40];\t[E8]\r\n\r\nhas produced a good survey.\r\n\r\nIs there a probabilistic counting algorithm for cliques or other motifs in a streaming graph? \u25c4\r\nWhat can we say about error bounds?\r\n\r\nBesides counting, we might also be interested in motif collection. If we have two fixed\r\ntarget nodes then motifs containing both nodes will give information about their common\r\nneighbours. For example, how many distinct V-shapes or squares contain them both? Some\r\nCSEC work [I21] from a few years ago may be relevant.\r\n\r\nCan we collect specified motifs containing a target node or nodes?\t\u25c4\r\n\r\nRemoving pizza nodes (i.e. very high-degree nodes) is likely to be an essential prior com-\r\nponent to get useful results. Intuitively, a pizza node is likely to be a large impersonal entity\r\nlike a pizza parlour or an electricity supplier: the fact that two people both communicate with\r\nthe pizza node gives us no reason to think that they are linked socially.\r\n\r\n36\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n5.2.3\tTrusses\r\n\r\nLet k > 3. A k-truss is a connected graph with > 2 vertices such that every edge of the graph is\r\nreinforced by at least k \u2014 2 pairs of edges that make a triangle with that edge. This concept was\r\ndeveloped\tat NSA: the idea is to weaken the definition of a clique (any k-clique\r\n\r\nis certainly a k-truss) to allow for a few missing edges, but still capture the notion of a cohesive\r\ncommunity, and at the same time produce something that is computationally tractable.\r\n\r\nPeople in the SIGINT community have looked quite a bit at trusses, following on from the\r\nfoundational theoretical work\t[I15, I14] on properties of trusses, their relationship\r\n\r\nto cores and cliques, and streaming algorithms to find them. In particular, there has been\r\nsome experimental work [I76] looking at trusses in communication graphs. The findings were\r\nsurprising: there turned out to be huge k-trusses for quite large values of k, like k = 17. This\r\nwas true even after splitting trusses at cut-points. A number of variants and generalizations\r\nhave also been proposed (for example [I16, I17]).\r\n\r\nWe would like to understand why these form. Is there a better definition of truss that \u25c4\r\ncaptures something like a closed-loop intuition (see section 2.1.3) without pulling in huge mon-\r\nstrosities?\r\n\r\nIn particular, as we have mentioned, a truss can have cut-points, i.e. single vertices whose \u25c4\r\nremoval disconnects the graph. On the other hand, trusses have high edge connectivity: one\r\nhas to remove at least k \u2014 1 edges from a k-truss to make it disconnected. Can we define truss-\r\nlike structures with a different balance of vertex and edge connectivity? Do giant structures\r\nstill form?\r\n\r\nCan we use a partial order derived from truss or core structures to perform hierarchical \u25c4\r\nclustering? If so, can we avoid forming giant clusters?\r\n\r\nCan we understand when community detection or clustering algorithms produce giant \u25c4\r\nclusters? Are there ways to prove (given some probabilistic model for the graph) that with\r\nhigh probability an algorithm will not produce large clusters? One specific suggestion by ^\r\nis to look at clique percolation [E4] where there are multiple labels per node.\r\n\r\nWhat is the background distribution of sizes of k-trusses? Is there a probabilistic solution \u25c4\r\n(cf. the previous section)?\r\n\r\n5.2.4\tOther approaches\r\n\r\nThere are also more open-ended questions about streaming algorithms for graphs.\r\n\r\nWhat graph invariants are both useful and can be found or approximated in a stream? \u25c4\r\n\r\nIn the academic world, there is a whole cottage industry devoted to coming up with new\r\nclustering algorithms. Many will not have much use beyond allowing someone to publish a\r\npaper. Is there a hidden gem in the open literature that the SIGINT community has missed? \u25c4\r\n\r\nThis problem obviously has the potential to lead one off down rabbit holes. As a concrete\r\nthing to look at, the first author has identified BIRCH [W3] as an algorithm that may deserve\r\na hearing.\r\n\r\nCan we compute any measurements of centrality or betweenness in a stream? (We are \u25c4\r\nmore interested in centrality measures in subgraphs around targets: CHART BREAKER [W6]\r\nvertex scores do something like this.) How stable are they as the graph evolves? Is there\r\nconcept drift?\r\n\r\n37\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nCan we approximate the graph distance distribution, and see how it varies with the pizza \u25c4\r\nthreshold?\r\n\r\nThis has a bearing on what hop distance we should choose for contact chaining. Conven-\r\ntionally, analysts focus on a 2-hop neighbourhood of their targets, but some work comparing\r\nbilling records with SIGINT [I73] found that one needed to chain much, much further through\r\nSIGINT to reach a 2-hop neighbourhood from billing data. Can we use the SIGINT to billing \u25c4\r\nmapping (SOLID INK to FLUID INK\u2014see appendix F.1.6) to help decide what the right thing\r\nto measure on a telephony graph is?\r\n\r\nCSEC have also done some work [W4] on comparing SIGINT and billing records. Billing\r\ndata is unlikely to be shareable, but for comparing results on different datasets, H4A would be\r\na natural point of collaboration.\r\n\r\n5.3 Visualization\r\n\r\n5.3.1\tVisualization in general\r\n\r\nFor most people, visualization is a crucial ingredient in the sense-making loop when given a\r\nlarge amount of data to analyse. GCHQ is actively developing tools for visual analytics. A\r\nlarge team in ICTR, split between MCA and DMR, works on semantic graphs and visualization\r\nresearch [W14], and a visual analytics tool called MAMBA [W27] is currently being developed\r\nin partnership with Detica. For graph visualization, NSA\u2019s Renoir application [W33] is also\r\nunder active development.\r\n\r\nAs HIMR researchers explore data for themselves, they will naturally develop their own\r\nvisualizations to help them understand it. We encourage them to record what they come up\r\nwith: perhaps some of these ad hoc visualizations could be useful to analysts too.\r\n\r\nHIMR\u2019s expertise is obviously in algorithms, not developing sophisticated visual analytics\r\nplatforms. Nonetheless, what dynamic or interactive visual tools would be helpful to explore \u25c4\r\nSIGINT data sets, if someone else could be enlisted to create them?\r\n\r\nGRINNING ROACH [W17] and PIRATE CAREBEAR [W30] are existing tools for visual-\r\nizing SIGINT events, developed by DMR: they both produce plots for pattern-of-life analysis.\r\n\r\nDashboarding is well-established for electronic attack events, both internally and by anti-\r\nvirus and security companies. Can similar methods be applied to provide useful visualizations \u25c4\r\nfor traditional SIGINT analysis?\r\n\r\nThere is some work in progress at GCHQ [W5] on dashboarding for the 2012 Olympics, but\r\nit is fair to say that the approaches so far are not mathematically sophisticated.\r\n\r\n5.3.2\tStreaming plots\r\n\r\nThere has been some work in R1 on binning streaming data for histograms [I37].\r\n\r\nWhat interesting plots can be produced in a stream?\t\u25c4\r\n\r\nsuggests starting with QQ-plots; this is closely related to the problem of\r\ncomputing approximate quantiles of streaming data.\r\n\r\nCISA have also done some work [I55] on time series modelling in a stream, including bund-\r\nling up R for use in DISTILLERY: this may be a good foundation to build on.\r\n\r\nIf any algorithms of the sort discussed in section 5.2.4 that calculate summary statistics are \u25c4\r\n\r\n38\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nproduced, could they be refined to produce plots (from which those statistics could be read\r\noff)?\r\n\r\n5.4\tModelling and outlier detection\r\n\r\n5.4.1\tIdentifying outlier activity\r\n\r\nOutliers (e.g. low-volume telephone numbers, small connected components) are often exactly\r\nwhat SIGINT is interested in. They are also exactly what gets lost in subsampling.\r\n\r\nHow can we find rare events with limited memory?\t\u25c4\r\n\r\nCan we take \u2018beyond supervised learning\u2019 to the limit, and find a way to classify normal \u25c4\r\nand abnormal behaviour from the data itself, without needing to train a classifier? A simple\r\nidea would be to choose an N in advance, classify the first N items in the stream as \u2018normal\u2019,\r\nthen use a positive-only learning algorithm to build a classifier to apply to the remainder of\r\nthe stream. Can we do anything more sophisticated to bootstrap a classifier out of the data \u25c4\r\nitself?\r\n\r\nWork from\tat LLNL is relevant to this. He is learning a Gaussian mixture\r\n\r\nmodel on cyber data with particle filters and asking about newness by looking at probability\r\ndensity. Can we ask about tail area instead? This question has also been posed to the 2011\r\nNSASAG [W28].\r\n\r\nCan we track new small connected components? This might be a group of targets who have \u25c4\r\ndumped their old SIM cards and replaced them.\r\n\r\n5.4.2\tBackground distributions for significance tests\r\n\r\nWe have already touched on the idea that we want a measure of surprise when we find outliers\r\n(section 5.2.2), and for this we want to know the background distribution: what does \u2018normal\u2019\r\nlook like, and how can we quantify that? This section gives some specific examples of outlying\r\nbehaviour that we look for, and for which we therefore want to find an empirical background\r\ndistribution. Any information along these lines could also feed into tests in Dynamic Graph.\r\n\r\nWhat is the distribution of the number of common neighbours of two nodes in a graph as a \u25c4\r\nfunction of their degree? This is one way to try to measure the strength of association of two\r\nentities.\r\n\r\nWhat is the distribution of component sizes? Terrorist cells and other target groups have \u25c4\r\nbeen found because they form small components (or \u2018closed loops\u2019, to use the analysts\u2019 term)\r\nisolated from the giant component. How surprising is it to see a node in a component of a\r\ngiven size? Likewise for other measures of connectivity.\r\n\r\nWhat significance do various CHART BREAKER [W6] relationship scores have? This \u25c4\r\ninvolves looking at an email hypergraph, rather than just a simple graph.\r\n\r\n5.4.3\tWindow sizing\r\n\r\nWe often want to pull off a finite chunk from a stream, either for offline analysis or for change\r\ndetection metrics.\r\n\r\nHow should we choose the window size? Is there a happy medium between a narrow window \u25c4\r\n\r\n39\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n(little data, so large variance) and a large window (concept drift, so large variance) that leads\r\nto small sample variance?\r\n\r\nCan we do something akin to ANOVA analysis to look at the effect on sample variance of \u25c4\r\nsample size versus concept drift across different window sizes?\r\n\r\n5.5\tProfiling and correlation\r\n\r\nWe are often interested in finding nodes that behave like a target node: they might be following\r\nthe same modus operandi, or be another selector for a known target.\r\n\r\n5.5.1\tCorrelations\r\n\r\nWith millions of entities, there is no hope of storing useful information on all pairs.\r\n\r\nIs there a sparse approximation to a correlation matrix?\t\u25c4\r\n\r\nAUTO ASSOC [W2] scores may provide a relevant example of a large correlation matrix.\r\nThese are similarity scores for pairs of target detection identifiers or TDIs, which are unique,\r\npersistent identifiers associated to particular users or machines that indicate their presence on\r\nthe network: the aim of AUTO ASSOC is to find out when multiple TDIs belong to the same\r\nuser or machine. See section 3.3.2 for further discussion of association scores.\r\n\r\nCan we keep an approximate list of the top N nodes most closely correlated with a given \u25c4\r\ntarget node?\r\n\r\nThere is also the underlying question of how to score association. This is not strictly about\r\nEDA on streams, but looking at how existing scores perform on streaming data might suggest\r\nways of improving them.\r\n\r\nHow can we score the association between two nodes? CHART BREAKER [W6] gives \u25c4\r\na significance score between pairs of nodes based on emails exchanged. There is an ad hoc\r\nbalancing between the value of an email where one side is sole recipient, cc\u2019d or bcc\u2019d (cf.\r\nassigning weights to golds, silvers and bronzes in medal tables). Is there a method with a\r\nbetter theoretical justification behind it?\r\n\r\nCan we correlate the \u2018busyness profiles\u2019 of nodes, for example to provide situational aware- \u25c4\r\nness of a DDOS attack?\r\n\r\n5.5.2\tFinding behaviour that matches a model\r\n\r\nFrequently we have a modus operandi known to be used by particular targets, and we want to\r\nsearch for events matching that model in streaming data. Recent work by\ton\r\n\r\nlow-rank approximations [E1] may be useful: she has a general framework called CPD analysis\r\nthat uses tensor decompositions to model multi-variable data and extract meaningful factors\r\nas rank 1 tensors. Reducing dimension should make it easier to match up features. (This also\r\nhas applications to link prediction, which is pertinent in SIGINT applications where we expect\r\nto have a lot of missing data.)\r\n\r\nIf a target disposes of his phone and buys a new one, can we rediscover it in data?\t\u25c4\r\n\r\nCan we find IP addresses fitting the profile of, for example, a box engaged in a denial-of-\t\u25c4\r\n\r\nservice attack, or an implanted box beaconing to a C2 server?\r\n\r\n40\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nMathematically, this may come down to something like solving an approximate subgraph\r\nisomorphism problem. CSEC\u2019s 2010 SAWUNEH did some exploratory work on data mining for\r\ncyber defence [I82], which gives some concrete examples of malicious behaviour to look for in\r\nevents data. There is also existing work along these lines for botnet detection in CROUCHING\r\nSQUIRREL [I27, I71], and it may be interesting to compare with external work on streaming\r\nbotnet detection by adaptive sampling [E45].\r\n\r\n5.6\tEasy entry problems\r\n\r\nThis section has some ideas for problems that do not have high entry requirements in terms of\r\nreading up on existing literature or doing lots of preliminary data manipulation: they might\r\nbe a good place to start for people who like to get into things quickly.\r\n\r\nMaths route:\r\n\r\n\u2022\tMotif finding\r\n\r\n\u2022\tProperties of trusses and their generalizations\r\n\r\n\u2022\tFinding outliers\r\n\r\nData route:\r\n\r\n\u2022\tVisualization\r\n\r\n\u2022\tStreaming QQ plots\r\n\r\n5.7\tRelevant data\r\n\r\nThis problem set has the advantage that EDA is needed for any and all of the streaming\r\ncommunication datasets we have available: the telephony, email, HRMap and cyber datasets\r\nall readily map to graphs (or hypergraphs), and present challenges for all four areas: streaming\r\ngraph analytics, visualization, outlier detection and correlation. There is also a graph of the\r\nlinks between Wikipedia articles (appendix F.2.3) in case researchers want a static graph of links\r\nto compare with the dynamic graph of clicks provided by HRMap. Appendices F.1.3, F.1.1,\r\nF.1.2 and F.1.6 describe some particularly appropriate datasets, but most of the datasets in\r\nappendix F could usefully be explored.\r\n\r\nSince EDA is such a general requirement, it is equally possible to work with unclassified\r\ndata sets. Appendix F.2.2 describes a dataset being analysed by the UKVAC (see section 5.8.2):\r\nbesides being another source of events data that is somewhat different in nature to commu-\r\nnication data, it would also be useful to work with this data should any collaboration develop\r\nwith UKVAC participants.\r\n\r\n41\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n5.8\tCollaboration points\r\n\r\n5.8.1\tInternal\r\n\r\nICTR-DMR.\thas the best knowledge of how analysts work and what will be useful\r\n\r\nto them. He also champions research on payphone activity.\tdeveloped\r\n\r\nsome of the fundamental algorithms currently used at GCHQ for contact chaining and\r\nscoring strength of association.\tleads on EDA, though not specifically\r\n\r\nfocused on streams. For visualization,\tand\tare involved\r\n\r\nwith the MAMBA project.\r\n\r\nICTR-CISA.\tis a DISTILLERY guru, and\ttracks research on\r\n\r\nstreaming algorithms across the community.\tis also a good source of in-\r\n\r\nformation on DISTILLERY and streaming implementations in general.\r\n\r\nNSA/R1: information processing group. There are already good contacts with R1 from\r\nHIMR\u2019s crypt work, and it would be good to build on that: for example,\r\nis a frequent visitor to HIMR and is always interested in questions about probability,\r\nrandom hypergraphs and stochastic processes.\t(currently sitting in LTS)\r\n\r\nhas published on EDA on streams, and is planning to write a book on the subject.\r\n\r\nKACHINA. Sandia National Lab in the USA has a multi-year project called KACHINA\r\nto look at large graph processing for defence analysis. A good point of contact is\r\n(NSA/R4).\r\n\r\nPod 58: cyber exploration. In particular\r\nin the past.\r\n\r\n(NSA/R1), who has visited HIMR\r\n\r\n5.8.2\tExternal\r\n\r\nUKVAC (UK Visual Analytics Consortium). One of the two challenge problems for\r\nPhase 2 (approximately 18 months from May 2011, subject to funding) asks for visual\r\nanalysis of 120M events (several years\u2019 worth of flight arrivals and departures in the\r\nUS\u2014see section F.2.2). The brief they have been given is very closely aligned with the\r\nstreaming events model described in this section, and there is as much of an overlap with\r\nthe problems here as is possible at UNCLASSIFIED. If anyone in the SIGINT community\r\nis going to collaborate directly with UKVAC, it will probably be HIMR.\r\n\r\nThere are five fairly independent groups working as part of the UKVAC. Imperial\r\n) and Oxforddo substantive mathematics. Middlesex\r\nand\tdo substantive non-mathematics. Bangor\r\n\r\nseem most engaged with this dataset so far. The best thing is probably to spot promising\r\nactivity that emerges, get in touch with the people doing it, contribute suggestions and\r\nhope that this leads to collaboration. In the fairly likely event that it is difficult to\r\ntrack what is happening and who is doing what,\t(Middlesex) has high\r\n\r\nbetweenness-centrality in the graph of UKVAC participants, and would be a good first\r\npoint of contact.\r\n\r\n42\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nINSTINCT. The UKVAC is sponsored by INSTINCT, a UK government project to use data\r\nmining for counter-terrorism, led out of the Home Office. They organize other activities\r\ntoo, most recently a public competition on ways of fusing data streams [E20]. Some of\r\ntheir projects will be more relevant than others, but it may be worth keeping an eye on\r\nwhat they are doing. Upcoming projects usually get mentioned on blogs on GCWeb;\r\nwill also be able to suggest contacts if required.\r\n\r\n(AT&T). An expert in probabilistic counting; has been keen to engage\r\nwith GCHQ at the UNCLASSIFIED level.\r\n\r\nIBM Safer Planet. This is a big corporate project covering some of the same ground as this\r\nproblem book.\tis in touch with the organizers, and is keen to look for\r\n\r\nopportunities to get GCHQ and HIMR involved.\r\n\r\n43\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n6\tStreaming Expiring Graphs\r\n\r\n6.1\tIntroduction\r\n\r\nStreams of transactional events often arise in SIGINT problems. A classic example would be\r\ntelephony events where we have a directed event from one telephone number to another when\r\nwe detect a phone call. In this case we would typically have a relatively small number of target\r\nnumbers we are interested in and would collect the events around these - we call this a seeded\r\ngraph. An event or transaction is a (normally timestamped) observation of an edge, and so\r\nfor each edge in the graph we may see multiple events. In some recent problems, for example\r\nelectronic attack events, we have been interested in looking for structure in the entire graph.\r\nA denial of service attack might be visible for example as a vertex which suddenly has many\r\nincoming edges.\r\n\r\nWe have techniques for handling the seeded case in a streaming way, expiring old edges\r\nand maintaining a current view of a graph, for example GCHQ Dynamic Graph [W12] and\r\nassociated simulations completed by NSA [I2]. This research area is about investigating the\r\nsecond case where we are interested in tracking the full graph as it varies over time. We imagine\r\nthat we want to expire old events or edges somehow. This might be by maintaining a buffer\r\nof the most recent n events, maintaining the n most recently seen edges, or by decaying edge\r\nweights over time and expiring those with the lowest weights. Other decay strategies might also\r\nbe appropriate. For some problems we may not need to store the full window, and can instead\r\nfind an analytic that produces equivalent results. Any algorithm should ideally parallelise so\r\nthat we aren\u2019t restricted to the memory or network bandwidth available on a single computer.\r\n\r\nIn a dynamic graph problem the typical aim is to maintain a data structure for answering\r\nqueries whilst also receiving updates to the graph. The aim is to maintain information that\r\ncan be updated efficiently given the stream of changes to the graph, and to avoid total re-\r\ncomputation for each query. We say a graph problem is fully dynamic if the updates include\r\nboth insertions and deletions of edges. A problem permitting only one type of update (insertion\r\nor deletion) is sometimes described as partially dynamic. Some literature uses the term evolving\r\ngraph instead. An old but good overview of some dynamic graph algorithms is given in [E14].\r\n\r\nAn expiring graph can be thought of as being a dynamic graph where we allow arbitrary\r\nedge insertion, but edge deletion is restricted to one of a small subset of the edges, for example\r\nthe oldest or lowest weight edges.\r\n\r\nAs in the EDA on Streams problem (section 5), we expect solutions to run in a streaming\r\nfashion on the DISTILLERY platform. We are also interested in how we might bootstrap such\r\nan algorithm using a map-reduce job on a Hadoop cluster where that makes sense, however\r\nthis is not the main focus.\r\n\r\n6.1.1\tThe Problems\r\n\r\nIn section 6.2 we list graph properties which we would like to be able to find and track as the\r\ngraph evolves. We allow some freedom in how the graph evolves. Edges may decay over time\r\nwith low weight edges being expired. We might maintain the most recently observed edges,\r\nor we might retain a window of the most recent events, either chosen to be a fixed size or\r\nover a fixed time period. We expect different problems to be possible with different expiry\r\n\r\n44\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nmechanisms so the choice should be considered separately for each problem.\r\n\r\nFor each property we list, we are interested in answers to the questions posed in section\r\n6.3. We list some further extensions in section 6.4.\r\n\r\n6.2\tProperties to find and track\r\n\r\nIn this section we assume a graph G(V, E) with n vertices in vertex set V and with edge set\r\nE. We use dv to mean the degree of vertex v.\r\n\r\n6.2.1\tComponent Structure\r\n\r\nIn most SIGINT graphs we empirically expect to find a giant component containing most of\r\nthe vertices (see for example [I34] and [I33]). It has been shown in the past that examining\r\nthe remaining components can yield valuable intelligence [I32]. For example a HUMINT agent\r\nand their handler might use specific phones to speak to each other and never use these phones\r\notherwise. Terrorist cells might have separate phones for calling each other; again these would\r\nnever contact numbers in the giant component of the graph. We are therefore interested in\r\nfinding these small components (note that this interest is very sensitive).\r\n\r\nComponent tracking has been studied for dynamic graphs for example [E2].\r\n\r\nCan we identify small components in an expiring graph? The query could include a time \u25c4\r\nsince which edges should be considered, or such a time might be implicit in the expiry strategy.\r\n\r\nCan we track the component structure of an expiring graph to be able to answer a query\t\u25c4\r\n\r\nsuch as \u201cis there a path between A and B with all edges having been observed since time t?\u201d\r\n\r\nGiven an approximate solution to these problems, can we provide an error estimate, for \u25c4\r\nexample upper and lower bounds? These might for example take the form of the maximum\r\nproportion of queries for which we provide the wrong answer.\r\n\r\n6.2.2\tGraph Distance\r\n\r\nThe distance between two nodes in a graph can be an indicator of how related they are, for\r\nexample in contact-chaining analysts will often look at the two-hop contact network of a target.\r\n\r\nFor some graphs we might like to be able to answer queries of the form \u201cwhat is the distance\r\nfrom A to B with all edges having been observed since time t?\u201d. We can think of the graph as\r\nbeing either directed or undirected, and weighted or unweighted. We would typically remove\r\nhigh degree vertices before asking such a question. External work in the area includes [E15].\r\n\r\nGive an approximate answer for the distance between any two vertices for edges observed \u25c4\r\nsince time t, including error bounds.\r\n\r\nA related problem is to provide alerts when the graph distance between two sets of vertices\r\ngoes below some threshold, for example if two groups of targets are seen to communicate.\r\n\r\nCan we track the distance between two (possibly dynamic) sets of vertices. Can we efficiently\r\nidentify when two sets of vertices have a length d path between them?\r\n\r\n6.2.3\tCliques and other motifs\r\n\r\nIn section 5.2.2 we describe the problem of counting cliques and other motifs. Network analysis\r\nsuggests that some structure may be important for example in target identification or malware\r\n\r\n45\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nA A\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\ndetection. Where we expect a structure to be rare, the appearance of such structures may be\r\nan anomaly we wish to investigate.\r\n\r\nIn telephony data, cliques or near cliques with few connections to the remainder of the\r\ngraph is a known MO of certain target groups. The members are in frequent contact with each\r\nother, but rarely call others. In the case where they never call other numbers we describe it\r\nas a closed loop (see section 6.2.1 on the preceding page). Can we find and track cliques or \u25c4\r\nnear-cliques which are persistent in the graph over time? If a new number enters a clique (or\r\nnear clique) at the same time as another member ceases communication we might infer that a\r\nuser has changed phone number. Can we identify such occurrences?\t\u25c4\r\n\r\nBounds here are likely to be based around the size of the clique found, for example given\r\nthere exists a k-clique in the graph what size sub-clique does the algorithm guarantee to find?\r\n\r\nOur graph also has a time element - edges are observed repeatedly. Given a timestamp, \u25c4\r\ncan we extract all cliques or near-cliques of some size where all edges have been observed since\r\nthat timestamp? Can we do this for other motifs?\t\u25c4\r\n\r\n6.2.4\tCentrality Measures\r\n\r\nThe centrality of a vertex in a graph measures the relative importance of that vertex. For\r\nexample it might show how important a person is within a social network, or how important\r\na website is in terms of reachability of other sites. Common centrality measures include the\r\ndegree, betweenness, and eigenvector centrality.\r\n\r\nThe simplest is the degree centrality, defined for each vertex as the number of incident links,\r\nscaled by the possible number, that is\r\n\r\nCd (v)\r\n\r\ndv\r\n\r\nn \u2014 1 \u2019\r\n\r\nTracking the (approximate) degree centrality in O(n) space is relatively easy without expiry\t\u25c4\r\n\r\nof edges, but can we track it for each vertex in the case of an expiring graph, for both the\r\nweighted and unweighted cases.\r\n\r\nThe vertex betweenness centrality of vertex v is (informally) the proportion of all shortest\r\npaths in the graph which pass through vertex v. If aab is the number of shortest paths between\r\na and b, and aab(v) is the number of shortest paths between a and b passing through v then\r\n\r\nCb (v)\r\n\r\nE\r\n\r\na=v=b\u20acV\r\n\r\nVab(v)\r\n\r\n\u00aeab\r\n\r\nWe are not particularly interested in the global betweenness centrality, but would be inter-\r\nested in ways to track it for specific subgraphs, for example the 2-hop graph around some set\r\nof seed vertices.\r\n\r\nIs it possible to maintain an approximation to the betweenness centrality for a set of vertices \u25c4\r\nas the graph (and the vertex set) evolves? Some internal work in this field is described in [I46].\r\n\r\nThe eigenvector centrality scores nodes in such a way that high scoring nodes contribute\r\nmore score to their neighbours than low scoring nodes. A variant is the Google PageRank\r\nalgorithm [E30]. In the basic case, the eigenvector centrality of vertex v is the corresponding\r\nentry in the eigenvector of the adjacency matrix of G corresponding to the largest eigenvalue.\r\n\r\n46\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nAgain we aren\u2019t directly interested in the global eigenvector centrality measures, but would\r\nbe interested to track local variants, for example Personalized PageRank or the internally\r\ndeveloped KL-Relative PageRank [W45].\r\n\r\nCan we track any personalized variants of the eigenvector centrality for some (possibly \u25c4\r\nchanging) set of vertices in an expiring graph? There has been internal work on updating\r\neigenvectors and eigenvalues as more edges are observed at the Information Processing SCAMP\r\nin 2009, see [I81], along with a report on its possible implementation [I56].\r\n\r\n6.3 Questions relevant to all properties\r\n\r\n6.3.1\tApproximation\r\n\r\nTypically it is not necessary to know the exact values of the properties listed above, and we can\r\nmake do with an approximation. For an approximation to be useful it should include some form\r\nof error bounds, although the form these take will depend on the specific problem. They could\r\ninclude e-6 bounds, strict upper and lower bounds, errors with a known statistical distribution,\r\netc.\r\n\r\nAre there approximate solutions to any of the problems listed? Where an exact solution \u25c4\r\nexists, how does the computational cost (time and memory) compare?\r\n\r\n6.3.2\tComputational Cost\r\n\r\nFor each of the problems listed in section 6.2 we would like to know the cost of evaluating the\r\nproperties in this way. For our purposes cost is CPU time and memory usage as a function of\r\nthe data size (asymptotics are important but we also care about the constants as derived from\r\nexperiments).\r\n\r\nWe typically work under the semi-streaming graph model where we allow ourselves\r\nO(n log(n)) space. For example, we might imagine storing a component ID for each vertex.\r\n\r\nFor most problems it would be possible to collect a window of data from the stream and re-\r\ncompute the required statistics at the desired query interval. Whether this is practical depends\r\non the window size, the frequency of updates to the graph, and the frequency (and latency)\r\nwith which an answer to the query must be returned. The trade-offs should be considered -\r\nincremental updates might take more compute overall, but in situations where we can take\r\nsome automated action based on the results then we might be willing to accept the cost to gain\r\nthe low latency.\r\n\r\nIn most settings it is unnecessary to know the answer to a question for every edge addition\r\nor deletion, and it is instead sufficient to be able to compute the answer after each batch update,\r\nso long as those updates are sufficiently fast.\r\n\r\nFurthermore, the online process may track and store data to allow efficient updates, but\r\nto get the desired answer may then require us to further process the data we have stored.\r\n\r\nWe might then choose to run this further processing less often, for instance at the request of\r\nan analyst. This is a perfectly valid approach, and could be particularly valuable if the data\r\nstructure lends itself to answering multiple types of query.\r\n\r\nConcrete questions include:\r\n\r\n\u2022 What is the (mean) cost of an update? What is the worst-case cost?\t\u25c4\r\n\r\n47\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n\u2022\tAt what query frequency does the total computational cost of incremental updates become \u25c4\r\nlower than the cost of total re-computation on each query? How does this depend on\r\nbatch size?\r\n\r\n\u2022\tHow does the computational cost vary depending on features of the graph, for example \u25c4\r\ndiameter or average distance.\r\n\r\n\u2022\tHow does the cost vary depending on the window size or the decay rate?\t\u25c4\r\n\r\n6.3.3\tExpiry Policy\r\n\r\nAs well as affecting the speed and computational cost of an algorithm, the choice of expiry\r\nmechanism will affect the accuracy of the results.\r\n\r\nFor windowed data, how should we choose the window size to ensure we get realistic results \u25c4\r\nat a reasonable speed? Is it possible to dynamically change the window size?\t\u25c4\r\n\r\nFor decaying data, how should we chose our decay rate to maintain realistic results? Can \u25c4\r\nwe change the decay rate without restarting the algorithm?\r\n\r\n6.4\tFurther Questions\r\n\r\n6.4.1\tParallel and Distributed processing\r\n\r\nFor high rate data feeds it may be necessary to process the data on multiple nodes of a cluster.\r\n\r\nThe data feed would be split between nodes and these streams cannot be combined until their\r\nrate is sufficiently reduced. Which of the graph properties can be computed in a parallel way? \u25c4\r\nSome SIGINT data sources are split between multiple geographical sites, with limited band-\r\nwidth between them. Is it possible to solve any of these problems for the (virtual) stream of \u25c4\r\njoined data? In this case we would expect to process each feed at the collection site and send\r\na much smaller set of data between sites, either periodically or in order to answer a query.\r\n\r\n6.4.2\tBootstrapping\r\n\r\nFor some properties it may be possible to get an initial approximation to the correct values by\r\nrunning a map-reduce query on an events Hadoop cluster. Can we make use of bootstrapping to \u25c4\r\nimprove the efficiency of our processing? This might be particularly relevant when we process\r\nthe stream in parallel and wish to split the vertices over multiple nodes of a cluster with each\r\nnode being responsible for some proportion of the vertices.\r\n\r\n6.4.3\tAnomaly Detection\r\n\r\nFor many of the properties we wish to compute, we would also like to be able to produce an\r\nalert for anomalies in the data. For example, in the web graph, if a vertex is suddenly connected\r\nto a large number of other vertices this may indicate a denial of service attack. Alerts may\r\nbe used to trigger additional processing, for example capture and storage of relevant data or\r\nadditional processing to categorise the event. Some internal research in this area can be found\r\nin [I20].\r\n\r\nCan we detect significant changes in the properties we are tracking? How soon are we able \u25c4\r\n\r\n48\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nto detect the change after it initially occurs?\r\n\r\n6.4.4\tResilience\r\n\r\nOver time our collection posture changes. Bearers are tasked and de-tasked, and\r\nsystems can fail. This can have a significant effect, especially when monitoring for\r\nHow are the algorithms affected by variations in data volumes?\r\n\r\nIf we identify that a change is due to a processing failure, can we account for\r\ngenerating future alerts once the processing resumes? See for example [I10].\r\n\r\n6.4.5\tQueries on graphs with attributes\r\n\r\nMany SIGINT graphs have some form of attributes associated with vertices and edges, for\r\nexample the location of a phone. It can be useful to answer queries where we restrict ourselves\r\nto vertices with a particular value for some attribute. Is it possible to modify your algorithm \u25c4\r\nto enable queries on vertices with particular attributes?\r\n\r\n6.5\tRelevant Data\r\n\r\nAny streaming graphical data is suitable for these problems, giving a variety of options. Ex-\r\namples include HRMap, telephony, email, SQUEAL alerts and IP flow metadata. All provide a\r\nstream of events with some notion of a source and destination vertex, along with the timestamp\r\nof the event.\r\n\r\nIn addition we have various reference datasets. For example section F.3.1 describes a\r\ndatabase of websites of interest to counter terrorism and BROAD OAK lists known target\r\nphone numbers and email addresses (see section F.3.2). These could be used to identify if an\r\nextracted graph structure has a higher density of targets than would be expected.\r\n\r\nThe idea of wanting to process a stream of edges is not specific to the intelligence community,\r\nand so external collaboration should be possible given a suitable dataset.\r\n\r\n6.6\tCollaboration Points\r\n\r\nThere are the following potential collaboration opportunities both within and outside the in-\r\ntelligence community.\r\n\r\nKACHINA: Sandia National Lab in the USA has a multi-year effort called KACHINA which\r\nincludes the Questa project to look at large graph processing for defence analysis. They\r\nhold security clearances, and would be an obvious group to collaborate with. Points of\r\ncontact are^^^^^^^^| (NSA employee deployed to Sandia) and^^^^^J\r\n\r\nis engaged both in external research at Georgia Tech and as a researcher\r\nin R1 at NSA. His external research in the field includes [E3, E12, E28]. Collaboration\r\nshould be possible on both classified and unclassified problems.\r\n\r\nPod58 \u2014 Cyber Exploration:\tThe Pod runs until the end of January 2012, and aims to use\r\n\r\nanalysis frameworks including DISTILLERY to support analysis of Cyber data.\r\ns the R1 research lead in the Pod.\r\n\r\n49\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nprocessing\r\n\r\nanomalies.\r\n\r\n\u25c4\r\n\r\nthat when \u25c4\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nNSA/R: Various people around the research division at NSA would be good people with\r\nwhom to collaborate. Specific names include\tand\twho normally\r\n\r\nattend the various five-eyes conferences.\tis a GCHQ integree at NSA\r\n\r\nworking on data mining problems including the integration of streaming analysis and\r\nMapReduce based analysis.\r\n\r\nICTR-CISA: This team is responsible for streaming analysis research at GCHQ. Much of\r\ntheir work revolves around the platform (DISTILLERY) however they are also active in\r\ndeveloping algorithms.\tis the team lead.\r\n\r\nIBM Research: As part of the InfoSphere Streams (DISTILLERY) platform, IBM are devel-\r\noping a \u201cGraph Analytics Toolkit\u201d. This is in its early phases and there is potential to\r\ncollaborate on this (at an UNCLASSIFIED level), and potentially have any algorithms\r\ndeveloped incorporated into the toolkit. Initial contact can be made through\r\nin ICTR.\r\n\r\n50\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nA Ways of working\r\n\r\nThis section gives a few thoughts on ways of working. The aim is to build on the positive culture\r\nalready established in the Institute\u2019s crypt work. HIMR researchers are given considerable\r\nfreedom to work in whatever way suits them best, but we hope these ideas will provide a good\r\nstarting-point.\r\n\r\nA.1 Five-eyes collaboration\r\n\r\nAs on the crypt side, we hope that UKUSA collaboration will be a foundation-stone of the data\r\nmining effort at HIMR. This problem book is full of links to related research being carried out\r\nby our five-eyes partners, and researchers are very strongly urged to pursue collaborative angles\r\nwherever possible\u2014above all, to get to know the people working on the same problems and\r\nbuild direct relationships. Researchers are encouraged to attend and present at community-\r\nwide conferences (principally SANAR and ACE), as funding and opportunity allows.\r\n\r\nWe hope that informal short visits to and from HIMR will also be a normal part of data\r\nmining life. HIMR has a tradition of holding short workshops to focus intensively on particular\r\ntopics, where possible with participation from experts across the five eyes community. Fre-\r\nquently these are held during university vacations, to allow our cleared academic consultants\r\nto take part. Each summer, HIMR hosts a SWAMP: a two-month long extended workshop\r\non (traditionally) two topics of high importance, similar to the SCAMPs organized by IDA.\r\nWe hope that HIMR researchers will feel inspired to suggest possible data mining sub-topics\r\nfor future SWAMPs.\r\n\r\nA.2 Knowledge sharing\r\n\r\nInevitably, there is a formal side to reporting results: technical papers, conference talks, code\r\nhanded over to corporate processing, and so on. But informal dissemination of ideas, results,\r\nprogress, set-backs and mistakes is also extremely valuable. This is especially true at HIMR,\r\nfor several reasons.\r\n\r\n\u2022\tThere is a high turnover of people, and it is important that a researcher\u2019s ideas (even the\r\nhalf-baked ones) don\u2019t leave with him or her.\r\n\r\n\u2022\tAcademic consultants form an important part of the research effort: they may only have\r\naccess to classified spaces a few times a year for a few days at a time, so being able to\r\ncatch up quickly with what\u2019s happened since their last visit is crucial to help them make\r\nthe most of their time working with us.\r\n\r\n\u2022\tHIMR is physically detached from the rest of GCHQ, and it\u2019s important to have as many\r\nchannels of communication as possible\u2014preferably bidirectional!\u2014so that this detach-\r\nment doesn\u2019t become isolation. The same goes even more so for second party partners as\r\nwell.\r\n\r\nIn HIMR\u2019s METEOR SHOWER work, knowledge sharing is now primarily accomplished\r\nthrough two compartmented wikis hosted by CCR Princeton. For data mining, there should\r\nbe more flexibility, since almost none of the methods and results produced will be ECI, and\r\n\r\n51\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nin fact they will usually be STRAP1 or lower. Paradoxically, however, the fact that work can\r\nbe more widely shared can mean that there is less of a feeling of a community of interest with\r\nwhom one particularly aims to share it: witness the fact that there is no shining model of data\r\nmining knowledge sharing elsewhere in the community for HIMR to copy!\r\n\r\nWe suggest that as far as possible, data miners at HIMR build up a set of pages on GCWiki\r\n(which can then be read and edited by all five-eyes partners) in a similar way to how crypt\r\nresearch is recorded on the CCR wikis. They can then encourage contacts at GCHQ and\r\nelsewhere to watch, edit and comment on relevant pages. In particular, the practice of holding\r\nregular bull sessions10 and taking live wiki notes during them is highly recommended.\r\n\r\nIf any researchers feel so inclined, GCBlog and the other collaborative tools on GCWeb are\r\navailable, and quite suitable for all STRAP1 work. For informal communications with people\r\nfrom MCR and ICTR, there is a chat-room called himr_dm: anyone involved in the HIMR data\r\nmining effort can keep this open in the background day by day. There is also a distillery\r\nroom that is sadly under-used: in principle, it discusses SPL and the corporate DISTILLERY\r\ninstallations.\r\n\r\nFor any STRAP2 work that comes along, there are currently no good collaborative options:\r\ncreating an email distribution list would be one possibility.\r\n\r\nA.3 Academic engagement\r\n\r\nThe first test for HIMR\u2019s classified work must be its applicability and usefulness for SIGINT,\r\nbut given that constraint, GCHQ is keen to encourage HIMR researchers to build relationships\r\nand collaborate with academic data miners, and publish their results in the open literature.\r\nOf course, security and policy will impose some red lines on what exactly is possible, but the\r\nbasic principle is that when it comes to data mining, SIGINT data is sensitive, but generally-\r\napplicable techniques used to analyse that data often are not. Just about everyone nowadays,\r\nwhether they are in academia, industry or government, has to deal with big data, and by and\r\nlarge they all want to do the same things to it: count it, classify it and cluster it. If researchers\r\ndevelop a new technique that can be published in an open journal once references to SIGINT\r\nare excised, and after doing a small amount of extra work to collect results from applying it to\r\nan open source dataset too, then this should be a win-win situation: the researcher adds to his\r\nor her publication tally, and HIMR builds a reputation for data mining excellence.\r\n\r\nOf course, there may be occasions when publication is not appropriate, for example where\r\na problem comes from a very specific SIGINT situation with no plausible unclassified analogy.\r\nDay-to-day contact with the Deputy Director at HIMR should flag up cases like this early on.\r\nThere are also cases where we feel we have an algorithmic advantage over the outside that is\r\nworth trying to maintain, and this can be further complicated if equity from other partners is\r\ninvolved, or if a technique brings in ideas from areas like crypt where strict secrecy is the norm.\r\nThe Deputy Director should be consulted before discussing anything that might be classified in\r\na non-secure setting: he or she can further refer the question to Ops Policy if necessary. Over\r\n\r\n10Informal meetings at blackboards where people briefly describe work they have been doing and problems\r\nthey have encountered, with accompanying discussion from others in the room. The rules: people who wish to\r\nspeak bid the number of minutes they need (including time for questions). Talks are ordered from low to high\r\nbid, with ties broken arbitrarily. You can ask questions at any time. You can leave at any time. If you manage\r\nto take the chalk from the speaker, you can give the talk.\r\n\r\n52\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\ntime, researchers will build up a good idea of what is sensitive and what is not, but in the first\r\ninstance, erring on the side of caution is a sound starting point where classified information is\r\ninvolved.\r\n\r\nSimilarly, if there are grey areas about when work should count as part of a researcher\u2019s\r\nclassified or unclassified effort, this can be settled by an informal conversation with the HIMR\r\nDirector or Deputy Director.\r\n\r\n53\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nB DISTILLERY\r\n\r\nDISTILLERY is a project to deliver a platform for near-real-time streaming analytics. It\r\nis a research partnership between NSA and IBM Research, with GCHQ also having been\r\ninvolved for a number of years. DISTILLERY was released by IBM as a commercial product\r\nin 2010 as IBM InfoSphere Streams, often shortened to just Streams. We use the three terms\r\nsynonymously. For more on the DISTILLERY platform, and links to plenty of other useful\r\npages see [W11].\r\n\r\nCentral to the DISTILLERY platform is the stream processing paradigm. We use the\r\nterminology of the Streams documentation. A Streams application is made up of one or more\r\ncomposite operators. A composite operator contains one or more operators, each of which\r\nhas zero or more input ports and zero or more output ports. Data takes the form of tuples\r\nconforming to a schema, where the schema defines the names and types of the entries which\r\nmake up a tuple. Streams of tuples flow along the edges of the flow graph between the operator\r\nports and the operators carry out some kind of transformation on these streams. When built\r\nand launched into the Streams platform, operators are placed in a series of processing elements\r\nor PEs connected according to the application flow graph. Each PE contains one or more\r\noperators (by default exactly one, but we can combine multiple operators into a single PE for\r\nefficiency).\r\n\r\nCrucially, we can process data as it arrives. If we know in advance what questions we would\r\nlike to ask of the data then we may never need to store the data. Instead, we build a processing\r\nflow to answer the question on the stream of data. Our output is a stream of answers. As well\r\nas saving storage, processing data provides other advantages. An obvious one is near-real-time\r\ntipping. Given some event of interest, we can alert an analyst as soon as we observe that\r\nevent. We can typically provide a tip-off within a second of the event occurring, although the\r\nlatency of the analyst is somewhat higher. However we do not restrict ourselves to tipping a\r\nhuman. Observing an event might cause us to take some other action, for example collecting\r\nmore detailed data for identifiers that appear in the initial event.\r\n\r\nStreams applications are written in SPL, the Streams Processing Language [W40], and are\r\nrun on InfoSphere Streams version 2. Older applications were written in SPADE and run on\r\nInfoSphere Streams version 1. We are currently converting our applications from SPADE to\r\nSPL, and we plan for most new applications to be written in SPL.\r\n\r\nB.1 When would I use InfoSphere Streams?\r\n\r\nStream based processing is useful any time where you want to produce results as soon as possible\r\nafter the relevant events occur or when we cannot reasonably store all the data required for a\r\nproblem. In these situations we can use Streams to handle the plumbing between our operators.\r\nIt provides parallelism over multiple hosts in a cluster whilst also providing some resiliency\r\nagainst system failures. Through the use of Import and Export operators an application can\r\nbe developed and deployed in stages, and data streams can be shared with other users.\r\n\r\nImport operators will also allow you to take advantage of the data streams already available\r\non the cluster. In this case, someone else will already have arranged for the feed to be delivered\r\nfrom our front-end collection systems, and your application need not be concerned with format\r\nchanges.\r\n\r\n54\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nB.2 Documentation and Training\r\n\r\nDocumentation is linked from\r\n\r\nand\tFurther documentation\r\n\r\ncan be found on a Streams cluster at\r\nThe SPL documentation consists of:\r\n\r\n\u2022\tSPL Introductory Tutorial: start here after following the instructions on Getting Started\r\nbelow.\r\n\r\n\u2022\tSPL Language Specification: describes the language itself.\r\n\r\n\u2022\tSPL Standard Toolkit Reference: describes the operators provided in Streams.\r\n\r\n\u2022\tSPL Standard Toolkit Types and Function: describes the built in functions.\r\n\r\n\u2022\tSPL Config Reference: covers additional configuration options which allow you to alter\r\nthe behaviour of operators or the runtime platform.\r\n\r\n\u2022\tSPL Compiler Usage Reference: describes the many compiler options in detail.\r\n\r\n\u2022\tSPL Operator Model Reference: the information you need to write a new operator.\r\n\r\n\u2022\tSPL Streams Debugger Reference: describes how to use the debugger.\r\n\r\n\u2022\tStudio Installation and User\u2019s Guide: describes the Eclipse development tools available\r\nto help you write SPL.\r\n\r\n\u2022\tInstallation and Administration Guide: covers how to install Streams and to configure a\r\nStreams instance.\r\n\r\nTraining may be available from IBM UK organised through QA - contact\r\n\r\nor details of upcoming courses. IBM, NSA and GCHQ have published a paper on\r\ndesign principles which may be useful [E43].\r\n\r\nB.3 Logging on and Getting Started\r\n\r\nAccess to a DISTILLERY cluster is via ssh, and you will initially use the BHDIST\r\ncluster (see below). Use one of\r\n\r\nOnce you log on for the first time you should go through the\r\nsteps listed on the getting started GCWiki page [W16], although the following steps should be\r\nsufficient to get you started.\r\n\r\nConfigure key based ssh access (accept the defaults presented by ssh-keygen):\r\n\r\nssh-keygen -t dsa\r\ncd ~/.ssh\r\n\r\ncat id_dsa.pub > authorized_keys\r\nchmod 600 *\r\n\r\n55\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nYou should then be able to type \u2018ssh localhost\u2019 and it won\u2019t ask for a password. This is essential\r\nas DISTILLERY uses ssh to launch commands and processes on all nodes (even when running\r\nonly on localhost).\r\n\r\nAdd the following to your .bashrc file:\r\n\r\n# Source global definitions\r\nif [ -f /etc/bashrc ]; then\r\n. /etc/bashrc\r\nfi\r\n\r\numask 0027\r\n\r\nexport JAVA_HOME=/opt/ibm/java-x86_64-60/\r\n\r\nexport ECLIPSE_HOME=/opt/eclipse-spl\r\n\r\nexport PATH=$JAVA_HOME/bin:opt/eclipse-spl:$PATH\r\n\r\nexport STREAMS_SPLPATH=/opt/distillery/toolkits\r\nsource /\r\n\r\nConfigure a streams public/private keypair (to avoid needing a password to stop/start jobs)\r\nwith:\r\n\r\nstreamtool genkey\r\n\r\nSet up a hostfile to tell Streams which hosts to use. The hosts file is in\r\n\r\ne and for now should contain a single line with the host you\u2019re\r\nusing but in the blackhole.net domain as this uses a faster network switch, e.g.\r\n\r\nYou should now be able to follow the SPL Introductory Tutorial linked from\r\n\r\nFor using the Eclipse tools, including the ability to view your jobs in a flow graph, then use\r\neclipse with\tThis should be in your path if you followed\r\n\r\nthe instructions above. Figure 5 shows an example of multiple jobs connected together in a\r\nshared DISTILLERY instance, as seen through the Streams Live Graph view in Eclipse.\r\n\r\nMany people choose to run a VNC session on the cluster to provide a desktop environment.\r\nFor instructions see the DISTILLERY pages on GCWiki.\r\n\r\nThe two main clusters used for research work are listed in table 2. To get an account on\r\neither contact\r\n\r\nB.4 Data\r\n\r\nData typically arrives into a DISTILLERY cluster via either a UDP or TCP socket from our\r\nfront-end processing systems. UDP is used where we need to avoid delays in our processing\r\ncausing delays earlier in the processing chain - instead we just drop the extra data. We are\r\nmoving to using TCP and then using a threaded port on the next operator so we can measure\r\nour data losses (see section B.5.1 on page 58).\r\n\r\nYour home directory is shared over the cluster, as is\t. Applications need\r\n\r\nto be run from a shared location so all nodes can access them. Results should be saved to\r\nrather than your home directory as the filesystem is local to the cluster.\r\n\r\n56\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nFigure 5: Streams Live Graph view: interlinked jobs in the AHS EXPLORE DISTILLERY cluster.\r\n\r\nNode names\tNumber of nodes\tAccount  management\tPurpose\r\n\t10\tICTR\tDevelopment and operational prototypes. Data from ICTR re- search probes.\r\n\t3\tAHS\tDevelopment and \u201cExplore\u201d prototypes. Data from MVR and mailorder.\r\n\r\nTable 2: DISTILLERY clusters available for use.\r\n\r\n57\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nB.5 Conventions\r\n\r\nThe DISTILLERY clusters contain operational prototypes as well as development code, so it\r\nis important to consider the impact on others when running jobs.\r\n\r\nWhen running jobs on the live data feeds, try to do initial processing and data reduction\r\non the same host as the data import to avoid unnecessary network use. Avoid causing back\r\npressure to the live feeds - see section B.5.1. Ideally you should test your code on a small\r\nsample before connecting to the live data feeds, although this may not always be possible.\r\n\r\nB.5.1 Use threaded ports on shared data\r\n\r\nIf the incoming data rate is faster than you can process then by default you will cause the\r\nincoming data to slow down, causing back pressure. If you are reading from a shared data\r\nstream then this affects everyone reading from that stream - all processing will be slowed\r\ndown. This may cause data to be lost further up the chain, for example at the point where it\r\nis received from the front-end probes.\r\n\r\nTo avoid causing this problem, you should normally configure the first operator of a job\r\nto drop tuples if it has too many already waiting to be processed. Typically this would be an\r\nImport() operator, which is configured as follows:\r\n\r\nstream I1 = ImportO {\r\n\r\nparam subscription : DataFeed == \"SomeData\";\r\n\r\n}\r\n\r\nstream I2 = Functor(Il) {\r\n\r\nconfig threadedPort : queue(I1, Sys.DropLast);\r\n\r\n}\r\n\r\nThe queue function has an optional third parameter which specifies the buffer size (in tuples),\r\nand the second option can be replaced by Sys.DropFirst.\r\n\r\nWhen reading from a file then you should not set such a buffering configuration, since you\r\nwant to read the data as fast as you can process it but without discarding any tuples.\r\n\r\nB.5.2 Operator Toolkits and Namespaces\r\n\r\nSPL (DISTILLERY) code is stored in toolkits. These split into two broad types - tookits\r\nof operators and toolkits containing applications. The Five Eyes repositories of toolkits are\r\nheld in MadForge and are described at\r\n\r\n. When we wish to share our operators (typically once they are\r\ntried and tested) then we will add them to MadForge. Before that we store the code in a\r\nGit repository on http://github.ar.gchq, with the repository name matching the toolkit\r\nname but prefixed with \u201cspl-\u201d. Instructions for creating a new repository can be found at\r\n\r\nMost of the repositories get built at least once a week and deployed to the cluster. To add\r\na repository to the build list contact\tor\tTo have\r\n\r\nnew versions of your toolkit be automatically deployed you must ensure that you increment the\r\ntoolkit version number. Toolkits are installed to /opt/distillery/toolkits and can then be\r\n\r\n58\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nused in your applications. Rather than hard-code this path we put it into the STREAMS_SPLPATH\r\nenvironment variable.\r\n\r\nToolkits containing operators are placed in the gchq.* namespace, for example\r\ngchq.ingest contains the TcpLineReader operator for multi-threaded reading of SIGINT data.\r\nApplication toolkits are in the gchq.app.* namespace to differentiate them. These are not in-\r\nstalled into /opt/distillery/toolkits but are instead checkout out into /streams/apps if\r\nyou want to run them.\r\n\r\nOne particularly important toolkit is\t. Despite the name, this is in fact\r\n\r\ninstalled into\tand contains the schemas for the data available in\r\n\r\nthe cluster. This is needed when importing data into your application. As an example, HRMap\r\ndata matches the HRMapRecord schema. Details for all the datasets described in section F can be\r\nfound in\r\n\r\nB.6 Further help and resources\r\n\r\nThe DISTILLERY team in ICTR-CISA are the best points of contact for questions.\r\n\r\nis the team lead and can cover most types of issue.\tis the best contact for\r\n\r\ninfrastructure issues. In OPC-MCR the best contact for DISTILLERY questions is\r\n\r\nThere is a distillery room on the instant messaging server (accessed using Pidgin, see\r\nappendix D). This can be used to ask questions on SPADE, SPL, and the infrastructure.\r\nAlthough the ICTR team do not make much use of it at present, there is normally someone\r\nthere who can help.\r\n\r\nAll relevant resources, are linked from\r\n\r\n59\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nC Hadoop\r\n\r\nHadoop is a software framework that supports static data-intensive distributed applications.\r\nIts design is heavily based on that of Google\u2019s infrastructure as disclosed in [E10]. It is designed\r\nto be scalable rather than fast and efficient. This means that for any given task there is likely\r\nto exist a more efficient solution. However the ease of parallelism more than counteracts this\r\nin most cases. In this model of parallelism the computation is shipped to the data, rather than\r\ndata to computation, therefore saving large amounts of network traffic. Typically Hadoop is\r\ninstalled across a cluster of computers, which are often referred to as clouds. Indeed the only\r\nreason to install it on a single computer is for testing purposes.\r\n\r\nHadoop consists of two main components, the Hadoop Distributed File System (HDFS)\r\nand MapReduce. As a user it should not be necessary to worry about how the file system\r\nis implemented. Instead one can consider it to act just like a very large filesystem. However\r\nshould one wish to use Hadoop to process data then knowledge of MapReduce is required.\r\nFortunately the key concepts of MapReduce are simple and easily understood. As the name\r\nsuggests there are two stages to any MapReduce job\u2014a Map and a Reduce. In the map stage\r\none receives successive input records. For each input one produces zero, one or many output\r\nrecords in the form of key-value pairs. These output records then go into a shuffle phase, in\r\nwhich all records are sorted so that the reduce stage receives all records with a common key\r\ntogether. This reduce group is then processed together and again zero, one or many output\r\nrecords may be produced. As the entire output of the Mapper is being sorted it is possible to\r\nperform a secondary sort to provide data to the Reducer in an advantageous order. This is\r\ndone by specifying that grouping should only consider part of the key, whereas ordering should\r\nconsider all of it. A common use of this is to provide time ordered data in a reducer for a\r\nparticular identifier.\r\n\r\nThe Hadoop framework is written in Java. Java is therefore a popular choice for writing\r\nHadoop MapReduce applications. Using Java one has access to the full functionality of Hadoop\r\nand is recommended for sustainable code. However it is not necessary to know any Java to get\r\nMapReduce jobs running on Hadoop using the Streaming package. Streaming is invoked from\r\nthe command line on a Hadoop node. Any script or program that accepts data on STDIN and\r\noutputs it to STDOUT can be specified as a Mapper or Reducer. This significantly lowers the\r\nentry barrier and is ideal for quickly trying out ideas where the full Java treatment seems like\r\noverkill.\r\n\r\nC.1 When would I use Hadoop?\r\n\r\nThe short answer is whenever you want to batch process a large amount of static data. There\r\nis not really any other option for such computations within GCHQ.\r\n\r\nA slightly longer answer is that Hadoop clusters are where GCHQ has chosen to keep its\r\nbulk events data. This is due to the large amount of data processing power Hadoop offers. With\r\nhundreds of hard disks working simultaneously multiple gigabytes can be read per second. This\r\nallows the processing of the multi-terabyte datasets we intercept. By having the data in its raw\r\nstate it is possible to ask a huge number of different questions of it. This can be contrasted\r\nwith the QFDs which also store very large amounts of data, but are databases optimised for\r\na specific type of analyst queries. The QFDs therefore do not offer a sensible data mining\r\n\r\n60\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nplatform.\r\n\r\nHadoop generally excels when your algorithm can be expressed in a small number of MapRe-\r\nduce steps. It is less efficient when implementing iterative algorithms. This is because between\r\niterations all state must be written down to disk and then read back in again. This extra\r\nI/O cost can easily end up swamping the time taken to perform the computations. Sometimes\r\nthere may be no other way of performing an algorithm given the size of the data and the only\r\nsolution is patience11.\r\n\r\nC.2 Documentation and Training\r\n\r\nThe standard Hadoop documentation is available linked from\r\nThis consists of:\r\n\r\n\u2022\tA MapReduce Tutorial that shows you how to write MapReduce applications in Java.\r\n\r\n\u2022\tAn introduction to Hadoop Streaming. Although not a full tutorial all the information\r\nyou need to run Streaming jobs is there.\r\n\r\n\u2022\tAn overview of the Hadoop command line arguments.\r\n\r\n\u2022\tThe Java documentation of the Hadoop API. If writing Hadoop in Java this is extremely\r\nuseful.\r\n\r\nThe Hadoop page on GCWiki [W20] has many resources, including:\r\n\r\n\u2022\t6 lectures and 2 exercises from Cloudera, a Hadoop consultancy company.\r\n\r\n\u2022\tAn overview of Hadoop by IBM\u2019s Jimeng Sun.\r\n\r\nTom White\u2019s book Hadoop: The Definitive Guide is probably the best book currently\r\navailable on Hadoop. It is also available on NSA\u2019s Safari book library [W35].\r\n\r\nClassroom based training should also be available. TDB have organised internal training\r\nled by GCHQ employees. Some people have also attended a multi-day training course offered\r\nby Cloudera.\r\n\r\nC.3 Logging on and Getting Started\r\n\r\nAccess to Hadoop clusters is via ssh. You will ssh to an edge node. These are not part of the\r\ncompute cluster but do allow you to submit jobs and interact with HDFS.\r\n\r\nInstructions for accessing SUN STORM, the largest cluster, are available at\r\n\r\nThe other clusters are detailed in table 3.\r\n\r\nSome useful aliases for your .bashrc are given below. Adding these will save you a huge\r\namount of typing and make interacting with HDFS feel more like using a regular filesystem.\r\n\r\n11ICTR-DMR are currently developing Bagel an implementation of Google\u2019s Pregel distributed graph mining\r\nsolution. While still in its early stages Bagel keeps its state in memory and therefore avoids this extra I/O cost\r\nbetween steps.\r\n\r\n61\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nCluster name\tNum nodes\tPurpose\r\nSUN STORM\t897\tCheltenham events cluster\r\nGOLD MINE\t125\tCyber/content cluster\r\nHAGER AWEL\t800\tBude events cluster\r\nWoody\t133\tICTR research cluster\r\nBuzz\t42\tICTR research cluster\r\n\r\nTable 3: GCHQ\u2019s Hadoop clusters\r\n\r\nexport HADOOP_HOME=/opt/hadoop/current\r\nalias hadoop=${HADOOP_HOME}/bin/hadoop\r\n\r\nalias hstream=\u2019hadoop jar $HADOOP_HOME/contrib/streaming/hadoop-streaming-0.20.10.jar\u2019\r\n\r\nalias hl=\u2019hadoop fs -ls\u2019\r\n\r\nalias hjobl=\u2019hadoop job -list\u2019\r\n\r\nalias hjobk=\u2019hadoop job -kill\u2019\r\n\r\nalias hjob=\u2019hadoop job\u2019\r\n\r\nalias hjar=\u2019hadoop jar\u2019\r\n\r\nalias hc=\u2019hadoop fs -count\u2019\r\n\r\nalias hput=\u2019hadoop fs -put\u2019\r\n\r\nalias hget=\u2019hadoop fs -get\u2019\r\n\r\nalias hf=\u2019hadoop fs\u2019\r\n\r\nalias hcat=\u2019hadoop fs -cat\u2019\r\n\r\nalias hdu=\u2019hadoop fs -du\u2019\r\n\r\nexport TMOUT=36000000\r\n\r\nC.4 Data\r\n\r\nThere are a large number of datasets available on the corporate clusters. These typically each\r\noccupy a subdirectory under data. The datasets on SUNSTORM are listed at\r\n\r\nhas equivalent datasets containing data\r\n\r\nprocessed at Bude rather than Cheltenham.\r\n\r\nC.5 Conventions and restrictions\r\n\r\nThe three corporate clusters are all configured similarly. This subsection refers to their\r\nconfigurations\u2014for the research clusters all bets are off and ICTR-DMR should advise you\r\nof any restrictions should you gain access.\r\n\r\nC.5.1 Scheduler\r\n\r\nThe clusters all have the Fair Scheduler installed [W19]. This replaces the vanilla FIFO that\r\nHadoop has installed by default. Fair scheduling is a method of assigning resources to jobs\r\nsuch that all jobs get, on average, an equal share of resources over time. When there is a single\r\njob running, that job uses the entire cluster. When other jobs are submitted, task slots that\r\nfree up are assigned to the new jobs, so that each job gets roughly the same amount of CPU\r\ntime.\r\n\r\n62\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nEach user (and special processing users) are assigned their own pool. The scheduler tries to\r\ngive each pool an equal amount of time on the cluster. Processing users also have a minimum\r\nnumber of map and reduce slots below which they will not drop if they request them. Further\r\neach user is restricted to having a single concurrent running job.\r\n\r\nC.5.2 HDFS /user/yoursid space\r\n\r\nOn logging into a corporate cluster you will have a HDFS home directory created at\r\n/user/yoursid. This is where the results of your Hadoop jobs will end up by default. That\r\nis, if you don\u2019t specify an absolute path,it will be taken relative to your home directory. Your\r\nhome directory has a size limit on it (believed to be 2TB). If you need more space than this\r\nthen you should contact the cluster administrators to find a solution.\r\n\r\nC.6 Running Hadoop on the LID\r\n\r\nIt is discouraged to use either SUN STORM or HAGER AWEL for developing code as they\r\nare both somewhat production systems. It is therefore a good idea to iron out bugs elsewhere\r\nif possible to ensure your code will not bring the cluster down. The easiest way to do this\r\nis probably on a pseudo-distributed Hadoop installation, following the instructions given in\r\nthe standard Hadoop documentation. If you wish to do this on the LID then you need to do\r\nslightly more to get around issues with localhost not always being the same depending which\r\nbox you are on. Following these instructions should give you working Hadoop instance. If the\r\nstandard ports are already in use then more configuration properties need to be added. At this\r\npoint it\u2019s probably best to either try another machine or ask for some advice.\r\n\r\n1.\tMake sure you can execute a passwordless ssh to your machine. This must be done using\r\nthe machine\u2019s hostname, not localhost. This is because there are multiple different LID\r\nservers, each with a different idea of what localhost is. By adding one machine\u2019s localhost\r\nto the known_hosts file you will cause yourself problems. If passwordless ssh does not\r\nwork execute the following commands.\r\n\r\nssh-keygen -t rsa -P \u2019\u2019 -f ~/.ssh/id_rsa\r\n\r\ncat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys\r\n\r\n2.\tChoose a directory in which to install Hadoop. This should be somewhere visible from\r\nall LID machines. Following shell scripting we will refer to this as $HADOOP_HOME. In fact\r\nyou might want to put the following into your .userprofile along with the other aliases\r\ngiven previously.\r\n\r\nexport HADOOP_HOME=/path/to/Hadoop/dir/\r\n\r\n3.\tUntar the hadoop tarball into $HADOOP_HOME.\r\n\r\n4.\tIn $HADOOP_HOME/conf/hadoop-env.sh add the line\r\n\r\nexport JAVA_HOME=/usr/lib/jvm/java-1.6.0/\r\n\r\n63\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n5.\tMake the directories $HADOOP_HOME/data and $HADOOP_HOME/name\r\n\r\n6.\tIn $HADOOP_HOME/conf/hdfs-site.xml add the entries\r\n\r\n\r\n\r\n\r\n\r\ndfs.replication\r\n\r\n1\r\n\r\n\r\n\r\n\r\n\r\ndfs.data.dir\r\n\r\nHADOOP_HOME/data\r\n\r\n\r\n\r\n\r\n\r\ndfs.name.dir\r\n\r\nHADOOP_HOME/name\r\n\r\n\r\n\r\n\r\n\r\nWhere HADOOPHOME is replaced with the Hadoop home directory. Using shell vari-\r\nables won\u2019t work here as the configuration files are read verbatim.\r\n\r\n7. In $HADOOP_HOME/conf/mapred-site.xml add the entries\r\n\r\n\r\n\r\n\r\n\r\nmapred.job.tracker\r\n\r\nHOSTNAME:9001\r\n\r\n\r\n\r\n\r\n\r\nWhere HOSTNAME is replaced with the hostname of the machine you are on.\r\n8. In $HADOOP_HOME/conf/core-site.xml add the entries\r\n\r\n\r\n\r\n\r\n\r\nfs.default.name\r\n\r\nHOSTNAME:9000\r\n\r\n\r\n\r\n\r\n\r\nWhere HOSTNAME is replaced with the hostname of the machine you are on.\r\n\r\n9. In $HADOOP_HOME/conf/masters and $HADOOP_HOME/conf/slaves replace localhost\r\nwith the hostname of the machine you are on.\r\n\r\n10.\tRun $HADOOP_HOME/bin/hadoop namenode -format to format the namenode.\r\n\r\n11.\tRun $HADOOP_HOME/bin/start-all.sh to start the Hadoop daemons.\r\n\r\n64\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n12.\tTo check this has worked OK go to http://HOSTNAME:50070/ to check on the status of\r\nthe namenode and http://HOSTNAME:50030/ for the jobtracker.\r\n\r\n13.\tNow you can try to run a toy Hadoop job. Copy the input files into the distrib-\r\nuted filesystem: $HADOOP_HOME/bin/hadoop fs -put conf input. Now run some of\r\nthe examples provided: $HADOOP_HOME/bin/hadoop jar hadoop-*-examples.jar grep\r\ninput output \u2019dfs[a-z.] + \u2019.\r\n\r\nWhen you log out of this LID session the Hadoop daemons will be killed by the logoff script.\r\nYou will therefore need to restart them in your next LID session. However each time you log\r\ninto the LID you cannot guarantee which machine you will be allocated. If you are allocated\r\na different machine to that where you installed Hadoop you will not be able to directly restart\r\nit. Instead you will need to do so over ssh:\r\n\r\nssh HOSTNAME \u2019HADOOP_HOME/bin/start-all.sh\u2019\r\n\r\nAgain HOSTNAME is the machine on which you originally installed Hadoop. You can then\r\nsubmit jobs and interact with HDFS from any LID machine, i.e. including the one you currently\r\nhave a session on. Hadoop will then carry on running until the end of the next session you are\r\nassigned on the machine on which you installed it.\r\n\r\nC.7 Further help and resources\r\n\r\nIn OPC-MCR^^^^^^^^^^| is the best contact for Hadoop questions,\tcan also\r\n\r\noffer advice, particularly on Streaming. Outside of MCR there is a large community of Hadoop\r\nusers and administrators. The best way to contact this community is probably through the\r\nrough_diamond chatroom on the Jabber server.\r\n\r\nThere are a large number of resources available on GCWiki. Some highlights, in no partic-\r\nular order:\r\n\r\n\u2022\t_(Work_Package): The main page for\r\nSILVER LINING, the work package within TDB that provides Hadoop clusters. It links\r\nto many places and may stay more up to date than this document.\r\n\r\n\u2022\t_-_User_Guide: An initial user guide for the\r\nSUN STORM cluster. However many of the tips hold in general across all Hadoop\r\nclusters.\r\n\r\n\u2022\t_-_Streaming_interface: A short guide to\r\nuser Hadoop Streaming with code examples to run on data on SUN STORM.\r\n\r\n\u2022\t: SILVER LIBRARY is a library of Ha-\r\ndoop parsers, writables and other utility classes to simplify development of MapReduce\r\nanalytics in Java. This pages describes at least some of it. Links to Utilities and Search\r\nare on the right hand side. The library is strongly recommded for Java MapReduce on\r\nthe corporate clusters as it has built in parsers that save users having to understand how\r\nthe events are structured.\r\n\r\n65\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nD Other computing resources\r\n\r\nThere are various computing options available to HIMR researchers beyond the bulk data\r\nsources of Hadoop and DISTILLERY. There is expertise in these environments at HIMR so we\r\nonly briefly document these options here. Further information can be found at [W22, W21].\r\n\r\nFirstly researchers have access to the Microsoft Windows environment of VALHALLA.\r\nVALHALLA is the standard desktop and provides email, Microsoft Office, web browsing, in-\r\nstant messaging and a gateway to other systems. The /data/himr_dm/ filesystem should be\r\naccessible in Windows with VALHALLA (at the time of writing the Windows mount location\r\nis not known).\r\n\r\nInstant messaging is accessible via the Pidgin application. Many employees of GCHQ can\r\nbe found online both for direct messaging and in chat rooms. The following chat rooms are\r\nof particular note: himr_dm (HIMR data mining research), distillery (DISTILLERY users),\r\nrough_diamond (Hadoop users), hecsupport (compute clusters queries) and lid_support (LID\r\nsupport). Instructions for getting going on Pidgin can be found at [W29].\r\n\r\nFrom VALHALLA researchers can access DISCOVER. This is GCHQ\u2019s document repos-\r\nitory. Literature for this research task has been filed at DISCOVER 10499535. Other sources\r\nof information that are of particular note are the the collaborative GCWiki [W15], which con-\r\ntains information about many GCHQ activities, and the Safari online bookshelf [W35], which\r\nprovides electronic versions of many technical books.\r\n\r\nThe primary interactive data analysis environment will be the Linux Interactive Desktop\r\n(LID). The LID provides a remote desktop onto a RedHat Linux box. Various mathematical\r\ntools such as R, Matlab, Mathematica, Maple, Sage and Magma are available. Scripting\r\nlanguages are available: Perl is the most commonly used scripting language in GCHQ but\r\nPython is starting to gain traction. Compilers are also available for C, C++ and Fortran. It\r\nis worth noting that GCHQ have imported the general repository for R packages, CRAN, at\r\n[W9] and implementations of many machine learning techniques can be found there.\r\n\r\nThere are two Linux compute clusters available. MOUNT MCKINLEY is probably\r\nthe machine of choice and has 652 compute nodes each with 8 cores, giving a total of 5216\r\ncores. The cores are clocked at 2.4GHz. Each node has 32GB of RAM and there is a fast\r\ninterconnect between nodes. MOUNT MCKINLEY can be accessed from VALHALLA. The\r\ncatch with MOUNT MCKINLEY is there are few user tools available and hence it should\r\nprimarily be seen as a place to run compiled code (Perl and Python scripting is also available).\r\nMOUNT MCKINLEY is also used for operational processing so researchers will need to abide\r\nby conventions around HIMR\u2019s use. An older compute cluster called SEPANG is also available\r\nbut is expected to be decommissioned shortly. SEPANG is firewalled from the rest of the GCHQ\r\nnetwork and does not have easy access to any of the data sources described; however it does\r\nhave a wide range of user tools installed and is reserved for HIMR\u2019s sole use.\r\n\r\nBoth the LID and MOUNT MCKINLEY user nodes mount\tIf you want\r\n\r\nto analyse data from Hadoop or DISTILLERY on LID or MOUNT MCKINLEY then you will\r\nneed to transfer the data with scp.\r\n\r\n66\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nE Legalities\r\n\r\nThis appendix is intended as a brief guide to the legal information of most relevance to your\r\nwork at HIMR. However [W25] and your legalities training should be treated as the definitive\r\nreferences.\r\n\r\nE.1 Overview\r\n\r\nGCHQ always complies with UK law12. In particular we are bound by the Regulation of\r\nInvestigatory Powers Act (RIPA) and Intelligence Services Act (ISA). RIPA requires GCHQ to\r\nhave arrangements in place to minimise its retention and dissemination of intercepted material.\r\nRIPA also applies specific protection to the communications of people in the UK. ISA requires\r\nGCHQ to have arrangements in place to ensure that it obtains or discloses information only in\r\nthe proper discharge of its functions or for the purpose of any criminal proceedings.\r\n\r\nThe complete and official compliance guide can be found in [W25]. In general we must be\r\nable to demonstrate that our actions are both necessary and proportionate. We show that our\r\nactions are necessary and proportionate by producing an accountable record for oversight and\r\naudit. This typically takes the form of an HRA (Human Rights Act) justification. The Human\r\nRights Acts defines the basic rights everyone must have respected. In particular there is a right\r\nto privacy which can only be violated \u201cin the interests of national security, public safety or the\r\neconomic well-being of the country, for the prevention of disorder or crime, for the protection of\r\nhealth and morals, or for the protection of the rights and freedoms of others.\u201d For GCHQ this\r\nmeans we must justify our activities as being in the interests of national security, the economic\r\nwell-being of the UK, or in support of the prevention or detection of serious crime.\r\n\r\nYou should bear in mind that you have signed and are bound by the Official Secrets Act\r\n(OSA). In particular you should take care in discussing or releasing potentially classified data\r\nand techniques. If you are unsure on an item\u2019s classification then you should seek guidance from\r\nthe data owner. Our data and information is also exempt from the Freedom of Information\r\nAct (FOIA). All documents should carry the same caveat as this document.\r\n\r\nAs accessing the content of an individual\u2019s communications is regarded as more invasive\r\nthan examining its metadata there are tighter restrictions imposed on such data. Content need\r\nnot necessarily be an email or phone call. For example, the content of a URI beyond the first\r\nslash is considered content, as are the specifics of someone\u2019s online mapping activity.\r\n\r\nE.2 Procedures\r\n\r\nWe now highlight some specific procedures that should be followed when working with bulk\r\nmetadata.\r\n\r\nDetailed policy guidance for corporate Hadoop clusters can be found at [W26]. We give the\r\nmost relevant information here. If you are extracting a dataset or performing analyses in a way\r\nwhich is not expected to target an individual then there is no need to do anything. However if\r\nthe criteria specify individuals, or behaviours which are sufficiently precise that they apply to\r\nonly a few individuals, then you will need to complete a manual HRA log [W23]. You do not\r\nneed to complete this every time that you perform the same extraction, or perform follow-on\r\n\r\n12The bulk of our work is also compliant with the policies and laws of five-eyes partners.\r\n\r\n67\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nanalysis using similar techniques and for a similar purpose, so long as you write your first log in\r\na way that is just general enough to cover your current work. Further if your analyses specify\r\nfive-eyes individuals or organisations, or if the query includes data that is designated as content\r\nthen you will need Sensitive Targeting Approval in addition to completing a manual HRA log.\r\n\r\nWhen completing a manual HRA log the application name should be \u201cSILVER_LINING\u201d\r\nif working on a Hadoop cluster. The reason should be \u201cNS\u201d (national security), a JIC pri-\r\nority of \u201c1\u201d and MIRANDA number of \u201c20135\u201d (\u201cIntelligence in support of GCHQ research\r\nwork intended to maintain and develop general purpose capabilities in the field of target com-\r\nmunications in order to be able to meet such intelligence requirements as may be specified\r\nnow and in the future\u201d). If you are developing new techniques then the query type should\r\nbe \u201cQFD-DEVELOPMENT\u201d, or if selecting data that focuses down to a few individuals then\r\n\u201cBULKEXTRACT\u201d.\r\n\r\nQueries in DISTILLERY should also be logged using the manual HRA logging service and\r\nmost of the guidance above applies. Until \u201cDISTILLERY\u201d is added to the list of applications,\r\nplease use \u201cBLACK_HOLE\u201d. The data source should be the source most closely matching the\r\nfeeds you are using, otherwise use \u201cAD_HOC_EXTERNAL_DATA\u201d. In order to complete the\r\n\u201cNumber of Results Returned\u201d field you will need to submit the log after you have run the\r\nquery - there is currently no way for you to update a manual HRA log.\r\n\r\n68\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nF Data\r\n\r\nIn this appendix we summarise the datasets made available at the outset of this research.\r\nResearchers are encouraged to work with GCHQ staff to find other datasets if required.\r\n\r\nF.1 SIGINT events\r\n\r\nFirstly we describe datasets of raw SIGINT events: typically these are available as live datasets\r\nin Hadoop or DISTILLERY.\r\n\r\nF.1.1 SALAMANCA\r\n\r\nThe contents of this dataset are classified TOP SECRET STRAP2 CHORDAL.\r\n\r\nGCHQ collects telephone call record events from a wide variety of sources, and these are stored\r\nin a database called SALAMANCA [W36]. This data is also fed to the SUN STORM cloud\r\nand the BHDIST DISTILLERY cluster (and other DISTILLERY clusters). This data is a\r\nrelatively low rate feed of user events, around 5000 events per second, and can be viewed as\r\neither a directed or undirected graph. It could be used for the streaming EDA and streaming\r\nexpiring graphs topics as well as feature extraction for payphones for the beyond supervised\r\nlearning topic.\r\n\r\nIn general we have better collection of calls where the two sides are in different countries,\r\nalthough for some countries we also have good collection of in-country calls. This means the\r\ngraph can have some unusual features and it is worth bearing these in mind when examining\r\nfeatures of the graph. Some properties of SIGINT collected telephony graphs are discussed in\r\n[I33, I34]. A comparison between SIGINT collected call records and billing records is given in\r\n\r\n[I73].\t_________________\r\n\r\nOn SUN STORM the data can be found under\tin folders named by\r\n\r\ndate. The full format is as described in the Interface Control Document [I79] but with an\r\nadditional field at the end which uniquely identifies the event within SUN STORM.\r\n\r\nIn DISTILLERY the data is forwarded into the shared SPL instance on the BHDIST cluster\r\nby running a VlTCPSource in client mode. The resulting stream can be subscribed to using\r\nthe subscription DataFeed==\"Salamanca\" && EventType==\"FullCallRecord\".\r\n\r\nThe full data contains many attributes, but the relevant ones are the timestamp and\r\ncallLength along with identifiers. Records will typically have some of dialledNumber, di-\r\nalledNumberNorm, callerID and callerIDNorm, where the \u201cNorm\u201d versions may have been\r\nnormalised, for example by adding the country code. The normalised versions are in E.164\r\nformat and give the fully qualified number as opposed to the digits actually dialled which could\r\ninclude just the local number.\r\n\r\nSome identifiers are specific to mobile telephony, including the IMSI (which is an ID for a\r\nSIM card), the IMEI (which is an ID for a mobile phone handset), and the MSISDN (which\r\nshould match one of dialledNumberNorm and callerIDNorm). To know which side of the call\r\nthese attributes refer to you must also read the CallDirection attribute which is either \u201cMO\u201d\r\nfor mobile originated (i.e. the IMSI and IMEI relate to the callerID) or \u201cMT\u201d for mobile\r\nterminated (i.e. the IMSI and IMEI relate to the dialledNumber).\r\n\r\n69\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nMay 01\tMay 06\tMay 11\tMay 16\tMay 21\r\n\r\nTime\r\n\r\nFigure 6: Plot of events counts per hour in our snapshot of FIVE ALIVE data. The period from\r\nMay 6-11 is clearly the best quality.\r\n\r\nF.1.2 FIVE ALIVE\r\n\r\nFIVE ALIVE is an ICTR prototype Query Focused Dataset (QFD) providing access to bulk\r\nIP-IP connection events, giving a unique unselected view of all activity on SIGINT bearers.\r\nEach record in FIVE ALIVE summarises a flow between two IP addresses. This summary\r\nconsists of:\r\n\r\n\u2022\tThe start of flow time, unfortunately at second granularity in the static dataset, but\r\nmicrosecond granularity in DISTILLERY.\r\n\r\n\u2022\tThe source and destination IPs and ports and the protocol\u2014together these are known as\r\nthe 5-tuple, hence the name FIVE ALIVE.\r\n\r\n\u2022\tOptionally extra information on flow size and direction depending upon the protocol.\r\nThe data format is fully described in [I9].\r\n\r\nWe have a snapshot of FIVE ALIVE data covering, with gaps, approximately 6-19 May\r\n2011. Figure 6 shows the number of events per hour in this snapshot. This snapshot is available:\r\n\r\n\u2022\tOn the GOLD MINE Hadoop cluster at\tin hdfs. The\r\n\r\ndates on the subdirectories indicate when it was loaded into the cluster and should be\r\nignored.\r\n\r\n\u2022\tOn Mount McKinley at\r\n\r\nThere is also a feed of streaming FIVE ALIVE data on the BHDIST DISTILLERY\r\ncluster. It is a high-rate feed (around 1 million events a second) and is published in\r\nmultiple \u201cSplits\u201d. They can be imported in the shared instance using the subscrip-\r\ntion DataFeed == \"FiveAlive\" && EventType == \"FlowRecord\" && Split == \"N\" where\r\nN ranges from 0 to 11 (but this may be increased to accommodate additional bearers). Don\u2019t\r\nleave out the Split condition or you\u2019ll get all the data in one feed. Ideally you should run your\r\ninitial processing on the same host as the data is published to reduce network load. This data\r\ncould also be made available at Bude to provide a multi-site high-rate feed.\r\n\r\n70\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nF.1.3 HRMap\r\n\r\nThe contents of this dataset are classified TOP SECRET STRAP2 CHORDAL.\r\n\r\nWhen a user requests a webpage from the internet, this is observed in SIGINT as an HTTP\r\nGET request. As well as the page requested it often contains the URL of the previously viewed\r\npage. The hostname of the requested page is the \u201cHOST\u201d and the hostname of the previous\r\npage is the \u201cREFERRER\u201d. When we consider just the hostnames rather than the full URI\r\nthen this is considered events data. This can be viewed as a directed graph of hostnames, and\r\nis given the name HRMap at GCHQ. It is a moderately high rate stream (around 20000 events\r\nper second) which should be suitable for the streaming EDA and streaming expiring graphs\r\ntopics.\r\n\r\nSince many web pages point to other web pages on the same server, a large proportion of\r\nHRMap events have the hostname matching the referrer. Many records will have no referrer.\r\nThis happens if the user typed the URL, uses a bookmark, or has configured their browser not\r\nto send the referrer attribute.\r\n\r\nAs well as the host and referrer, an HRMap record also contains a timestamp (in seconds),\r\nthe client IP address, the client port, and the client HTTP header fingerprint (HHFP) which\r\nis a hash of various headers sent by the client and can be used to approximately distinguish\r\nclients behind a gateway [I38].\r\n\r\nHRMap data is available in DISTILLERY on the bhdist cluster.\r\nIt can be imported in the shared instance using the subscription\r\nDataFeed == \"HRMap\" && EventType == \"HostReferrer\". HRMap could also be made\r\navailable at Bude to give a multi-site streaming graph\r\n\r\nStatic HRMap is available on the SUN STORM Hadoop cluster at\r\nand\tNow that the HAGEL AWEL Hadoop cluster at Bude is\r\n\r\noperational, data collected there will no longer be loaded onto SUN STORM. Data collected\r\nat Bude now instead is loaded onto HAGER AWEL at\tThe Bude data\r\n\r\nat Cheltenham will gradually age off and be deleted 6 months after its load date.\r\n\r\nF.1.4 SKB\r\n\r\nThe contents of this dataset are classified TOP SECRET STRAP2 CHORDAL UKEO.\r\n\r\nThe Signature Knowledge Base is a system for tracking file transfers made on the internet. A\r\nrecord is made each time we see certain file types being transferred. Each file is identified by\r\nits format and a hash of some of its content. Whilst this does mean we can store the data,\r\nhash collisions are inevitable. Therefore one cannot guarantee that all records referring to the\r\nsame hash are in fact the same file. Further we only process a small number of different file\r\nformats. The dictionary of which file types are logged is given in [I86].\r\n\r\nEach single line record in the SKB dataset has the format:\r\n\r\ndate time src_IP dst_IP frag_# IP_ID len protocol.# src_port dst_port seq_#\r\nack_# file_offset file_type file_signature src_geo dst_geo\r\n\r\ne.g.\r\n\r\n71\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n22:59:58 03-08-2011 192.168.2.1 10.0.0.1 16384 45872 1398 6 80 53302 4032239316\r\n4106241239 256 SWF-Compressed-V9 Geo-IP-Src 32\r\n55.0436;37.3378;MOSCOW;RU;5MMM Geo-IP-Dst 25 40.4;-3.68;MADRID;ES;7LMH\r\n\r\nFor more details on how the logging is performed and the hashes calculated see [I67, I22].\r\nThe SKB data is stored both in a QFD for analysts to query and in BLACKHOLE. We\r\nhave an extract of 1 week on SKB data\tIf you require more data\r\n\r\nthen it is possible to extract some using the blacktools interface.\r\n\r\nF.1.5 Arrival Processes\r\n\r\nThe contents of this dataset are classified SECRET STRAP 2.\r\n\r\nThere are two standard datasets that have been used to evaluate all approaches to temporal\r\ncorrelation. These are known as the telephony and C2C datasets. They both consist of records\r\nof stochastic processes in the format\r\n\r\n\\t\\t\r\n\r\nand files containing pairs of identifiers to be scored in the format\r\n\r\n \r\n\r\nThe data is stored in /data/himr_dm/data/arrival_processes.\r\n\r\nTelephony data\r\n\r\nThe original event times were taken from 18 weeks worth of telephony data. These event times\r\nwere then transformed to give the times in the .sps files.\r\n\r\nRandom pairs of event times are generated this way: choose a pair of distinct originating\r\nnumbers, A and B; choose from the set {1,..., 17}; circularly shift the event times of B by 5\r\nweeks (i.e. modify the event times of B by adding 5 x 604800 to them modulo T = 18 x 604800,\r\n604800 being the number of seconds in a week). The purpose of the cyclic shift is to reduce the\r\neffect of any \u201crandom\u201d pairs in which some of A\u2019s calls truly cause B to make calls. Shifting\r\nby one-week multiples is done to retain the time-of-day and day-of-week structure of the data.\r\nIf time interval [0, T) can be partitioned into two subintervals, one containing all of the events\r\nof A and the other containing all of the events of B, then (A, B) is rejected as a random\r\npair for experimental purposes since presumably no one would consider that they might be\r\ncorrelated. The stochastic processes generated in this way are in the file^^^^^^^^s. This\r\nfile contains 151,811 processes. B\u2019s name has 5 appended to show the size of the shift. For\r\nexample if 441242221491 had been shifted 3 weeks it would be called 441242221491.03.\r\n\r\nCausal pairs of event times are generated this way: generate a random pair (A, B); randomly\r\nselect proportion p of A\u2019s call initiation times; to each selected initiation time, add the duration\r\nof the corresponding call plus a delay drawn from an exponential distribution with mean f\r\nseconds; merge the resulting times into B\u2019s call initiation times. A proportion of A\u2019s calls\r\ncause B to make a call, and B makes these calls after the causative call of A ends and after a\r\n\r\n72\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nrandom delay. The causal stochastic processes are in files\ts. The standard\r\n\r\none used in experiments is\ts. This file contains 155,746 processes. B\u2019s\r\n\r\nname has 5 and A\u2019s name appended. For example if 441242221491 had been shifted 3 weeks and\r\nhad a causal dependency on 441242226816 it would be called 441242221491.03.441242226816.\r\nBoth the random and causal pairs for CLASP to score are listed in the file\r\n\r\nC2C data\r\n\r\nThe event times were taken from 93 days of C2C presence activity. Records are logged each time\r\nthe identifier is seen performing an activity. The timestamps in the C2C data are unaltered to\r\nprovide a realistic test dataset. The stochastic processes are in the file ip.all.sps.new.sun2.\r\nThere are 457,305 processes in this file.\r\n\r\nThere are also two pairs files. The file\tcontains 431,689 random pairs.\r\n\r\nThe file\tcontains 45,932 pairs in which the proportion of causal pairs was\r\n\r\nthought by the data experts to be relatively high, compared to the proportion of causal pairs\r\nin the set of all identifier pairs. The exact criteria for making it onto these lists can be found\r\nin section 2.4 of [I49]. The names of identifiers consist of the username, a series of dots and\r\ndashes and then the identifier type. There are no transformations done to the names in the\r\nC2C data.\r\n\r\nF.1.6 SOLID INK and FLUID INK\r\n\r\nThe contents of this dataset are classified SECRET STRAP1.\r\n\r\nThese are quite old telephony datasets, but we feel it is worth highlighting them to HIMR\r\nresearchers because the view they offer is so unusual.\r\n\r\nSOLID INK is three weeks of telephony events from 2007, as seen from billing records.\r\nFLUID INK is an approximate subset of SOLID INK, but as seen via GCHQ\u2019s SIGINT collec-\r\ntion. Our points of access mean that we mostly collect calls between the target country and the\r\nrest of the world; therefore in-country calls are likely to be missing from FLUID INK. Indeed,\r\nSOLID INK has 2.7 billion events involving 74 million numbers, while FLUID INK has only\r\n136 million events involving 15 million numbers.\r\n\r\nThere are also various sources of SIGINT noise which are poorly understood, such as missing\r\ncalls, duplicate calls, node mislabelling and timing errors. We only have anonymized versions\r\nof the datasets available: for legal reasons, we could not retain the unminimized versions this\r\nlong.\r\n\r\nEach INK data set has four fields: timestamp, user-1, user-2 and a number. Unfortunately,\r\nthe timestamp fields seem to have become corrupted somewhere along the line, and in different\r\nways in each of the datasets. However, timestamp deltas within each set are probably still\r\ncorrect (in seconds). In FLUID INK the call direction is user-1 to user-2, and the fourth field\r\n\r\n73\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nis call duration in seconds. In SOLID INK the fourth field is a code in {1, 2, 3, 4}, where:\r\n\r\n1\t= Voice user-1 to user-2\r\n\r\n2\t= SMS user-1 to user-2\r\n\r\n3\t= Voice user-2 to user-1\r\n\r\n4\t= SMS user-2 to user-1\r\n\r\nThe datasets are available at\tand\r\n\r\nThere are also\r\n\r\nversions, where events involving pizza nodes have been removed.\r\n\r\nA very interesting analysis of these datasets came out of the 2008 graph mining SWAMP at\r\nHIMR [I73], which revealed just how great the disparity between SIGINT and \u2018ground truth\u2019\r\ncan be, for example when it comes to contact chaining. CSEC have also done some work that\r\nlargely confirms and replicates those results [W4].\r\n\r\nF.1.7 Squeal hits\r\n\r\nThe contents of this dataset are classified TOP SECRET STRAP2 CHORDAL UKEO.\r\n\r\nSqueal is a signature-based system for detecting electronic attacks, see [W39]. When a poten-\r\ntial attack is detected a hit is forwarded to DISTILLERY. Each hit contains the source and\r\ndestination IPs and ports, the timestamp, the hit details and geolocation for the IP addresses.\r\nBy examining multiple hits we may be able to learn about the attacks. For example, we might\r\nlook for multiple IP addresses that launch attacks in a similar way.\r\n\r\nA stream of Squeal hits is initially created on the AHS Explore DISTILLERY cluster,\r\nhowever this is also forwarded to the shared SPL instance on the BHDIST cluster. It can be\r\nimported using the subscription DataFeed==\"Squeal\" && EventType==\"SquealHit\". This is\r\na low rate stream, around 75 events per second, and contains the hits from all sites.\r\n\r\nSqueal hits are available on the SUN STORM Hadoop cluster at /data/ead. This covers\r\nevents collected from all sites.\r\n\r\nF.2 Open-source graphs and events\r\n\r\nWe also provide some open-source graphical and events based data which may be of specific\r\nrelevance to this research.\r\n\r\nF.2.1 Enron\r\n\r\nThe contents of this dataset are classified UNCLASSIFIED.\r\n\r\nEnron was an American energy company that collapsed in 2001 due to massive financial fraud\r\nand eventual bankruptcy. After criminal proceedings were completed the complete emails of\r\naround 150 Enron employees, mostly senior management, were publicly released. There are\r\napproximately half a million emails covering November 1998 to July 2002. There is a brief\r\nintroduction to this dataset in [E22]. This gives a few summary statistics, such as number\r\nof emails per user and conversation thread length. We have a copy of enron.sql, the SQL\r\n\r\n74\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\ndatabase file which contains this data. The format of this is not particularly nice so we have\r\nalso extracted a simpler data set, which hopefully contains the data needed for this work. If\r\nnot it is not too hard to return to the original file to gather more data. This formatted file is\r\ncalled enron_transactions.txt. Each email has one record for each recipient, however each\r\nline contains all relevant information. Each record is tab separated with the following fields\r\n\r\n      \r\n\r\nThese data files can be found at\r\nF.2.2 US flights data\r\n\r\nThe contents of this dataset are classified UNCLASSIFIED.\r\n\r\nThe American Statistical Association\u2019s Data Expo \u201909 asked for analysis of a large dataset\r\nof US flight arrivals and departures. The data was made available to the public by the\r\nUS Department of Transport\u2019s research arm, RITA (Research and Innovative Technology\r\nAdministration), and covers the years 1987 to 2008. The Expo \u201909 website is mirrored at\r\n\r\nIt con-\r\ntains a fuller description of the problem, as well as the winning posters produced by participants\r\nin the competition.\r\n\r\nWhen the Home Office decided to fund UKVAC research (see section 5.8.2), it was decided\r\nto provide the researchers with two unclassified challenge problems in order to focus their\r\nefforts. One was chosen by the HUMINT agencies: to predict the next winners of Nobel prizes.\r\nThe second came from GCHQ, and was to do further analysis on the RITA flights data. In\r\nfact, the second author of this problem book was largely responsible for selecting the problem\r\nand framing its statement, so it mirrors very closely the point of view of this problem book,\r\nparticularly section 5. The flights are meant to be an unclassified proxy for SIGINT events\r\ndata, and although the dataset can just about be handled in core on modern hardware, UKVAC\r\nparticipants were strongly encouraged to process the data in a stream.\r\n\r\nWe hope that researchers will be able to compare their approaches, especially on visual-\r\nization questions, with what the UKVAC comes up with: having a common dataset should\r\nhelp with that. In case any direct collaboration emerges with UKVAC participants, having the\r\ndataset they are working on to hand will obviously also be a significant help.\r\n\r\nThe data consists of 22 bzipped CSV files, one for each year. Each record has 29 fields,\r\ndescribed in table 4. Supplemental CSV files describe the codes used for airports, carriers and\r\nsome individual planes: see the\tpage on the Expo \u201909 mirror.\r\n\r\nF.2.3 Wikipedia graph\r\n\r\nThe contents of this dataset are classified UNCLASSIFIED.\r\n\r\nThis is not directly relevant for SIGINT, but there are several reasons why it might be handy\r\nto have around. Many outside algorithms get tested on this graph, so it might be useful for\r\nbenchmarking, or as test data to apply algorithms intended for external publication to. It is\r\nalso a foil for HR map (appendix F.1.3): although that data set does not contain internal clicks\r\nbetween Wikipedia pages (so there is no direct comparison), nonetheless it might be interesting\r\n\r\n75\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nIndex\tName\tDescription\r\n1\tYear\t1987-2008\r\n2\tMonth\t1-12\r\n3\tDayofMonth\t1-31\r\n4\tDayOfWeek\t1 (Monday) - 7 (Sunday)\r\n5\tDepTime\tactual departure time (local, hhmm)\r\n6\tCRSDepTime\tscheduled departure time (local, hhmm)\r\n7\tArrTime\tactual arrival time (local, hhmm)\r\n8\tCRSArrTime\tscheduled arrival time (local, hhmm)\r\n9\tUniqueCarrier\tunique carrier code\r\n10\tFlightNum\tflight number\r\n11\tTailNum\tplane tail number\r\n12\tActualElapsedTime\tactual time in minutes\r\n13\tCRSElapsedTime\tscheduled time in minutes\r\n14\tAirTime\tair time in minutes\r\n15\tArrDelay\tarrival delay, in minutes\r\n16\tDepDelay\tdeparture delay, in minutes\r\n17\tOrigin\torigin IATA airport code\r\n18\tDest\tdestination IATA airport code\r\n19\tDistance\tin miles\r\n20\tTaxiln\ttaxi in time, in minutes\r\n21\tTaxiOut\ttaxi out time in minutes\r\n22\tCancelled\twas the flight cancelled?\r\n23\tCancellationCode\treason for cancellation (A = carrier, B = weather, C = NAS\u2014air traffic control system failure, D = security)\r\n24\tDiverted\t1 = yes, 0 = no\r\n25\tCarrierDelay\tin minutes\r\n26\tWeatherDelay\tin minutes\r\n27\tNASDelay\tin minutes\r\n28\tSecurityDelay\tin minutes\r\n29\tLateAircraftDelay\tin minutes\r\n\r\nTable 4: Flights data fields.\r\n\r\n76\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nto compare in broad terms how algorithms perform on the dynamic HR map of clicks versus a\r\nstatic graph of links.\r\n\r\nThe data files are in\tThere is a list of vertices,\r\n\r\nwhich are all the articles on the English Wikipedia at a\r\ncertain point in 2008. Whenever an article links to another article, there is a corresponding\r\nline\tgiving the source and target of the link (as indices into\r\n\r\nthe .title file).\r\n\r\nF.3 SIGINT reference data\r\n\r\nTo help researchers enrich their research findings we provide lists of websites of interest and\r\ntarget selectors. We also provide lists of covert infrastructure and known payphones to support\r\nresearch on information flow in graphs and positive-only learning.\r\n\r\nF.3.1 Websites of interest\r\n\r\nThe contents of this dataset are classified TOP SECRET STRAP2 UKEO.\r\n\r\nA list of websites of interest is available in a database on\t. These\r\n\r\nhave been manually classified through open source research and contain radical and extremist\r\nsites along with many others. These may be useful when examining HRMap data to determine\r\ntarget density.\r\n\r\nTo get a list of radical and extremist sites, first get a username and password from Andrew\r\nRoss (ajrossl). Then connect to the database and run the query as follows:\r\n\r\n~db2user/sqllib/bin/db2 connect to DIST1\r\n\r\n~db2user/sqllib/bin/db2 \"select SITENAME, RADICALISM, Type, URL\r\nfrom\r\n\r\nwhere RADICALISM = \u2019Radical\u2019 or RADICALISM = \u2019Extremist\u2019\"\r\n\r\n~db2user/sqllib/bin/db2 connect reset\r\n\r\nIt is also possible to use this data directly in DISTILLERY using the Database toolkit.\r\nF.3.2 Target selectors\r\n\r\nThe contents of this dataset are classified TOP SECRET STRAP2 UKEO.\r\n\r\nOur target knowledge database is BROAD OAK which includes the ability to task various\r\nselector types including phone numbers and email addresses. The resulting list of selectors is\r\nsometimes called the target dictionary and is delivered to our DISTILLERY clusters at least\r\nonce a day, and is also available on our Hadoop clusters. This data could be used to see if some\r\nresult set contains an increased density of targets.\r\n\r\nFor DISTILLERY, the telephony and C2C dictionaries are delivered in separate streams\r\nand can be imported with DataFeed==\"BroadOak\" && EventType==\"TargetSelector\" and\r\nDataFeed==\"BroadOakC2C\" && EventType==\"TargetSelector\" respectively. A re-send of the\r\nlatest dictionary can be requested by sending a UDP packet to\r\n\r\n(port 10450 for telephony, 10460 for C2C) containing the line resend. This could be sent with\r\na UDPSink operator.\r\n\r\n77\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nOn SUN STORM, the BROAD OAK reference data (all target types) is in HDFS at\r\n\r\nWhen using selectors to examine parts of a graph then this is considered targetting and an\r\nHRA log must be completed. See appendix E on page 67 for details.\r\n\r\nF.3.3 Covert Infrastructure\r\n\r\nThe contents of this dataset are classified TOP SECRET STRAP1.\r\n\r\nGCHQ has knowledge of, and collection from, CNE acceses owned by foreign intelligence\r\nagencies. This is done without their permission and is known as fourth party collec-\r\ntion. As data is exfiltrated from target networks we should be able to see information\r\nflows over their infrastructure. Data on foreign covert infrastructure can be found at\r\n\r\nWe also have knowledge of our own covert infrastructure. However this data is understand-\r\nably more sensitive. Work is still ongoing to explore the possibility of making this dataset\r\naccessible to HIMR researchers.\r\n\r\nF.3.4 Conficker botnet\r\n\r\nThe contents of this dataset are classified SECRET STRAP1.\r\n\r\nGCHQ has an interest in being able to detect botnets operating in the wild. This is cur-\r\nrently done using packet content fingerprinting and specific behaviours of certain bot software.\r\nHowever we would like to be able to detect botnets only by their generalisable activity. For\r\nthe Conficker botnet we have a list of IP addresses that hit against either the packet fin-\r\ngerprinting or a Conficker specific activity profile. The fingerprinted IPs can be found at\r\n\r\nThis set should be largely reliable as\r\nthe signature is believed to be highly discriminative. The behaviourally identified IPs are at\r\n\r\nThese are slightly more tentative and\r\nare based on the Conficker software contacting remote IPs on specific ports. Of course this can\r\nhappen randomly so only those IPs which perform a significantly high number, after Bonferoni\r\ncorrection, make the list. As Conficker contains a peer-to-peer (P2P) component we believe\r\nthat there may be information flows involving these potentially infected IPs.\r\n\r\nF.3.5 Payphones\r\n\r\nThe contents of this dataset are classified TOP SECRET STRAP1.\r\n\r\nAnalysts are interested in understanding telephone numbers in their analysis. A particular\r\nfeature of a number they would like to know is whether the number is a payphone. The fact\r\nthat a number is a payphone would suggest that contact chaining through the number is not\r\nrecommended. On the other hand some target discovery work starts with a known modus op-\r\nerandi of payphone usage (which targets follow to make it hard to target their communication)\r\nand so looking for communication between payphones is the starting point.\r\n\r\nHowever GCHQ have lists of payphones for very few countries. The aim is start from partial\r\nlists of payphones in some countries and extend to full lists of payphones in those countries\r\n\r\n78\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nCountry\r\n\r\nSpain\r\n\r\nPakistan\r\n\r\nPakistan\r\n\r\nBarbados\r\n\r\nSurinam\r\n\r\n# known payphones\r\n93,634\r\n3,117\r\n118\r\n761\r\n363\r\n\r\nFilename\r\n\r\nNotes\r\n\r\nBelieved near complete\r\nPartial\r\n\r\nPartial (FATA region only)\r\n\r\nPartial\r\n\r\nPartial\r\n\r\nTable 5: Known payphones\r\n\r\nand in other countries based on call meta-data. This problem is an example of positive-only\r\nlearning.\r\n\r\nhas provided lists of payphones in four countries as described in\r\n\r\ntable 5.\r\n\r\nGCHQ have recently moved their telephony event data to the cloud and we do not have\r\nfeature extraction algorithms for this data. However the basic features in [I3] should be easy to\r\nimplement from scratch as an Hadoop analytic using the data as described in appendix F.1.1.\r\n\r\nWe also provide the source code for the original SPIKY ROCK feature extraction as C code.\r\n\r\nThe use of payphones is an active interest so a complete Hadoop feature extraction and \u25c4\r\nclassification analytic would be likely to be directly taken on by GCHQ and results fed into\r\nthe the LUCKY STRIKE database.\r\n\r\nThe data and the old SPIKY ROCK source code is available in\r\n\r\nF.4 SIGINT truthed data\r\n\r\nTo support the beyond supervised learning research we provide several SIGINT truthed datasets\r\nfrom recent research.\r\n\r\nF.4.1 Logo recognition\r\n\r\nThe contents of this dataset are classified SECRET STRAP1.\r\n\r\nWe are interested in automatically detecting the source of videos on the internet through the\r\nrecognition of logos in the video. We have previously researched logo detection and have recently\r\nlooked at supervised machine learning for logo recognition [I19].\thas\r\n\r\nprovided the data from this research.\r\n\r\nThe feature space is derived as follows:\r\n\r\n1.\tLogo detection algorithms give us the logo and mask (i.e. the logo shape) as 8-bit images.\r\nThe mask is binary in that values are either 0 or 255 (i.e. black or white).\r\n\r\n2.\tBoth the logo and mask are independently downscaled to 8 x 8. During these down-\r\nsampling processes the results are rescaled so that they retain their original pixel depth\r\n(i.e. 8-bit).\r\n\r\n3.\tThese 2 resulting 8-bit images are pointwise multiplied to give a 16-bit image (with a\r\nrange of 0-65535).\r\n\r\n79\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n4.\tThis 8 x 8 16-bit image is our feature vector.\r\n\r\nSam is happy to look at extracting other features if HIMR actively research this dataset.\r\n\r\nWe provide 530 truthed samples. The data has been truthed to 109 classes. 7 classes have\r\nmore than 20 examples, 67 classes have only 1 example.\r\n\r\nfrom ICTR-MCA is happy to work with JTRIG to try and provide larger\r\nuntruthed datasets if the researchers decide to work on this problem.\r\n\r\nThe data is available\tThe first field \u201cClass\u201d is\r\n\r\na numeric representation of the class and the remaining fields are the features.\r\n\r\nF.4.2 Spam detection\r\n\r\nThe contents of this dataset are classified SECRET STRAP1.\r\n\r\nSpam emails are a large proportion of emails seen in SIGINT. GCHQ would like to reduce the\r\nimpact of spam emails on data storage, processing and analysis. Most external spam detectors\r\nwork by analysing the content of an email however policy and processing mean this option is\r\nnot always open to us. We must work on features derived from events alone. We therefore\r\nlower our target and instead aim to classify email addresses by the type of emails they send.\r\n\r\nhas provided datasets from his team\u2019s research into this prob-\r\nlem. They built a classifier called MYOFIBRIL [I44]. The dataset consists of an 1809 example\r\nemail addresses with 143 features each truthed into 11 classes. Note that one class is \u201cmul-\r\ntiple_classes\u201d and one class is \u201cuncertain\u201d.\r\n\r\nThis data set is provided in\tThis directory also contains a\r\n\r\nPDF documenting the dataset in more detail [I43].\r\n\r\nIt would be possible to use the data\ton SUN STORM (reading\r\n\r\nthese files with SILVER LIBRARY is recommended) to generate untruthed feature vectors.\r\nHowever it should be noted that the collection posture of GCHQ has changed considerably\r\nsince the truth data was collected.\r\n\r\nF.4.3 Protocol classification\r\n\r\nThe contents of this dataset are classified SECRET STRAP1.\r\n\r\nGCHQ is interested in understanding C2C traffic on bearers. One approach is to use signa-\r\ntures of known applications but signatures can not cover all traffic. We therefore look at the\r\nalternative approach of classifying traffic based on its behaviour. Such approaches may also\r\nprovide a way to understand traffic in encrypted tunnels.\r\n\r\nWe provide datasets from 7 different bearers provided by\t[I54]\r\n\r\nand used in [I70] (see [W1] for related research). Each bearer\u2019s data consists of a little over\r\n100,000 example TCP flows with 51 features truthed to 15 broad classes (and 39 detailed\r\nclasses). These classifications have been obtained by binary content signatures. Note that one\r\nclass is \u201cNULL\u201d which indicates that no signature hit on that flow.\r\n\r\nThese datasets allow one to check the robustness of a classifier against concept drift both\r\nin time (the data spans a little over a year [I70]) and across bearers.\r\n\r\nThe data is provided at\tNote each bearer\u2019s data is arbit-\r\n\r\nrarily split into training and test sets but this split need not be preserved.\r\n\r\n80\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nF.4.4 Steganography detection\r\n\r\nThe contents of this dataset are classified TOP SECRET STRAP1.\r\n\r\nSome targets try to hide their communications through the use of steganography. One approach\r\nis to slightly alter the coefficients in a JPEG image to encode the hidden data whilst trying to\r\nminimise visual changes in the JPEG. We would like a classifier that can identify such altered\r\nimages (commonly called stegged images).\r\n\r\nhas provided data used to build Random Forest classifiers [I74].\r\nThere are a few interesting features of this dataset:\r\n\r\n\u2022\tThis problem can be viewed either as a classification or a regression problem. One can\r\neither regress on the density of embedded data or classify whether there is any embedded\r\ndata or not.\r\n\r\n\u2022\tThe truthing process simulated embedding data into a large sample of images. Some of\r\nthese images might have started with steganography in them and so the truthing may\r\nnot be accurate.\r\n\r\n\u2022\tThis dataset has the most truthed examples. The original research had 50,000 clean\r\nand 50,000 stegged images (for each of 4 steg types) for training and 500,000 clean and\r\n200,000 stegged images (per steg type) for validation and testing. The reason for such a\r\nlarge test and validation set is that we want to ensure a very low false positive rate.\r\n\r\n\u2022 There are the most features of the truthed datasets. There are 661 features (introduced\r\nin [I74]). Features are computed in classes and so could be used to experiment with\r\ncost-sensitive feature selection.\r\n\r\nData is available at\tas compressed CSV files. The first two\r\n\r\nfields should be ignored and the final field of the stegged files contains the simulated stegging\r\nrate. The rest of the fields are the features (summarised in [I74]).\r\n\r\nF.4.5 Genre classification\r\n\r\nThe contents of this dataset are classified SECRET STRAP1.\r\n\r\nA way to make analysts more efficient and also allow further analytics is to add labels to textual\r\ncontent to describe the genre of the content.\thas provided text\r\n\r\ndata sets classified into genres along with the AURA feature extractor [I83].\r\n\r\nAURA extracts 108 features from text documents as described in [I85, I84]. Some features\r\nare from basic counts, some are based on email headers and some are based on more advanced\r\ntextual analysis. AURA can be run on a text document with:\r\n\r\njava -jar aura.jar  | head -108\r\n\r\nThe first 108 lines of AURA\u2019s output are the feature values. Other information about the file\r\nis returned in the remaining lines.\r\n\r\n81\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nThree corpuses are provided. PEEC and genre-id are UNCLASSIFIED. News-Personal is\r\nclassified. Each item is a file. The classification of items is encoded by the subdirectory an\r\nitem is stored in. There are some duplicate items in these directories.\r\n\r\nThe corpuses and AURA are a\r\n\r\nIf you are new to text classification then [I25] may be good background reading.\r\n\r\nF.4.6 Website classification\r\n\r\nThe contents of this dataset are classified TOP SECRET STRAP1.\r\n\r\nWe would like to label webpages by the type of information on the page. In this case we want to\r\nidentify pages that contain information on chemical, biological, radiological or nuclear (CBRN)\r\nweapons.\thas previously researched this as a supervised learning\r\n\r\nproblem [I36] and has provided his data from this research.\r\n\r\nWebpages have been labelled by an analyst into four classes: CW (chemical weapons), BW\r\n(biological weapons), RN (radiological/nuclear) and NI (not interesting).\r\n\r\nData is provided at\tin the \u201carff\u201d format used by Weka.\r\n\r\nThis format can be treated as a CSV file after removing the header lines.\r\n\r\nThe most important file is\t. This file is the full dataset\r\n\r\nused to produce the original classifier. It contains vectors for all documents in the CBRN\r\ndataset, where each feature corresponds to a single word, and the value of each feature is the\r\nnumber of instances of the word in the document divided by total number of words in the\r\ndocument.\r\n\r\nalso produced lists of the most prevalent words across each topic (in the folder as\r\nBvector, Cvector, Rvector, Nvector and RNvector), and then developed a dataset where each\r\nfeature was a count of words from each list found in the document (the two\r\n\r\nfiles).\treports that these features did not produce very good results compared to\r\n\r\nindividual words, so the dataset wasn\u2019t refined much further, but you may find it interesting.\r\n\r\nIf required the original HTML pages and classifications may be available but could not be\r\neasily found at the time of writing the problem book.\r\n\r\nF.5 Fusion of scores data\r\n\r\nThe contents of this dataset are classified SECRET STRAP2 CHORDAL UKEO.\r\n\r\nThe fusion of scores problem can occur in several contexts. In the following we describe the\r\ncreation of IP geolocation reference data.\r\n\r\nWe want to know the geolocation of IP addresses for many analytic processes. In the main,\r\nthere are two types of data we use:\r\n\r\nCommercial Various commercial providers provide estimates for IP address locations. ICTR-\r\nNE have provided Akamai\u2019s Edgescape dataset.\r\n\r\nSIGINT We find that commercial providers sometimes give poor locations in areas of the\r\nworld of SIGINT interest. We therefore need to augment the commercial data and choose\r\nto do this through analysis of locations referenced in IP collection (e.g. in user profiles\r\nor web forms). We hope that these locations give evidence towards the location of the\r\n\r\n82\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nusers of that IP address. See [I69] for the scoring approach currently used. ICTR-NE\r\nhave provided data from five different types of IP data (called INJUNCTION, PSYCHIC\r\nSALMON, RAGING BULLFROG, ROBOTIC FISH and TIMID TOAD).\r\n\r\nThe aim is to use these different sources to come up with the best estimate of an IP address\u2019s\r\nlocation. For simplicity we recommend considering geolocation to country-level only.\r\n\r\nThe Edgescape data comes as five gzipped text files; each file covers a different range of\r\nIP address space. Each line describes a subnet (an IP address or IP address range). The first\r\nfield gives the IP address range as a subnet and a subnet mask. The second field contains\r\ninformation about the subnet as key-value pairs. In particular the \u201ccountry_code\u201d field is their\r\nguess of the country and the first letter of the \u201cconfidence\u201d field gives the confidence in their\r\nestimate. Confidences are either high \u201cH\u201d, medium \u201cM\u201d or low \u201cL\u201d.\r\n\r\nEach SIGINT system dataset also comes as a gzipped text file with each line describing a\r\nsubnet. The full format is described in [I66] but we describe the important features here. The\r\nfirst field is the subnet and the second field the subnet mask (typically 24). The last field is\r\na semi-colon separated field where the penultimate field is the country and the last character\r\nof the last field is the confidence. Confidences are either high \u201cH\u201d, medium \u201cM\u201d or low \u201cL\u201d.\r\nThese confidences should not be treated as being on the same scale as Edgescape but should\r\nbe comparable between the five SIGINT systems.\r\n\r\nThe files can be found at\r\n\r\n83\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nTHIS PAGE IS INTENTIONALLY LEFT BLANK\r\n\r\n84\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nReferences\r\n\r\n\u2014 Internal Literature \u2014\r\n\r\n|\tA maximum-entropy algorithm for generating random graphs, 2008.\r\n\r\nReport to appear: see slides DISCOVER 12747135.\r\n\r\n[12]\tModeling and simulation of streaming dynamic graphs using the Cray\r\nXMT. Technical Report MR/TECH/010/09, R1, NSA, 2009. DISCOVER 11806816.\r\n\r\n[13]\r\n\r\n[14]\r\n\r\n[15]\r\n\r\n[16]\r\n\r\n[17]\r\n\r\n[18]\r\n\r\nSPIKY ROCK: Automatic classification of telephone type via usage statistics. Technical\r\nReport MR/TECH/003/04, NSA R1, March 2004. DISCOVER 12211328.\r\n\r\nCOMET: A recipe for learning and using large ensembles on\r\nmassive data. arXiv, cs.LG/1103.2068, March 2011. DISCOVER 12192977.\r\n\r\nLossy counting and\r\n\r\nhierarchical heavy-hitter algorithms. In ACE, May 2011. DISCOVER 12768692.\r\n\r\nComments on NSASAG 07-04: Correlation\r\nof temporal sequences. Technical report, University of California, Berkeley, October\r\n2007. DISCOVER 12689034.\r\n\r\nDISCOVER 12134962, June 2009.\r\n\r\nRandom Forests in MapReduce. Technical Report\r\nMR/TECH/033/10, NSA R1, August 2010. DISCOVER 10833587.\r\n\r\n[I9]\tTechnical report, GCHQ,\r\n\r\nAugust 2011. DISCOVER 7996430 Please contact\t(ICTR-FSP) for access.\r\n\r\n[I10]\tAdapting SIGINT timeseries data to account for variation in collec-\r\n\r\ntion posture. Technical Report OPC-M/Tech.B/58, GCHQ, February 2011. DISCOVER\r\n7895676.\r\n\r\n[I11]\tBAKER\u2019S DOZEN - a method for batch phone\r\n\r\ndiscovery. Technical Report B/6749BA/5001/4/102, GCHQ, March 2008. DISCOVER\r\n12585962.\r\n\r\n[112]\tThe La Jolla SCAMP 2009 problem\r\nbook - information processing. Technical Report SCAMP Working Paper L3/09, IDA-\r\nCCR, 2009. DISCOVER 12907519.\r\n\r\n[113]\tDensity estimation techniques for detecting DNS tunnels. In SANAR,\r\nOctober 2010. DISCOVER 10833937.\r\n\r\n85\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n[114]\tTrusses and fast graph clustering. Slides from SANAR, 2005. DISCOVER\r\n12750235.\r\n\r\n[115]\tTrusses: cohesive subgraphs for social network analysis. Technical Report\r\nTR-R63-001-05, NSA/R63, 2005. DISCOVER 12892477.\r\n\r\n[116]\tTrapezes: more swinging than trusses. Technical Report TR-R63-004-09,\r\nNSA/R63, 2009. DISCOVER 12892478.\r\n\r\n[117]\tSemitrusses, semitrapezes, efficient computation, and streaming. Technical\r\nReport TR-R63-002-10, NSA/R63, 2010. DISCOVER 12892476.\r\n\r\n[118]\tInterpreting\r\nrandom forest classification. Technical report, NSA R1, September 2009. DISCOVER\r\n12193642.\r\n\r\n[119]\tTechnical Report\r\nTRMCA/Inf/656, ICTR-MCA, June 2010. DISCOVER 12667333.\r\n\r\n[120]\tA simple birth-and-death process for scoring\r\nanomalous behavior in a random steady-state graph. Technical Report SCAMP Working\r\nPaper L38/02, IDA-CCR, 2003. DISCOVER 11775537.\r\n\r\n[121]\tBuilding 2-out+ graphs from streaming data. Technical\r\nReport H-TR-017-06, CSEC, November 2006. DISCOVER 12750234.\r\n\r\n[122]\tUpgrade to tcp-file-signature-log - engineering specification. Technical Re-\r\nport B/6805BA/5001/1, GCHQ, February 2008. DISCOVER 12740356 Please contact\r\n\r\n(ICTR-FSP) for access.\r\n\r\n[123]\tClustering of multiple point process streams. Technical report, University\r\nof Florida, July 2007. DISCOVER 12680283.\r\n\r\n[124]\tA model-based approach\r\nto detecting correlated stochastic processes. Technical report, NSA, September 2011.\r\nDISCOVER 13432581.\r\n\r\n[125]\tText categorisation - a beginners guide. Technical Report B14/INF/569,\r\nGCHQ, February 2008. DISCOVER 7878359.\r\n\r\n[126]\tCreating probabilities and combining evidence in NSA\u2019s evidence store.\r\nTechnical Report TRMCA-INF-690, GCHQ, July 2010. DISCOVER 10835062.\r\n\r\n[127]\tCROUCHING SQUIRREL\r\nv4: Filtering and classifying using behavioural vector analysis. Technical Report\r\nB/7934/5001/3/104, GCHQ, December 2010. STRAP2/ORCON: contact author for\r\naccess or see slides DISCOVER 11925562.\r\n\r\n86\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n[128]\r\n\r\n[129]\r\n\r\n[130]\r\n\r\n[131]\r\n\r\n[132]\r\n\r\n[133]\r\n\r\n[134]\r\n\r\n[135]\r\n\r\nRole assignment in private messaging social networks. Technical Report\r\nB/7167BA/5001/4/102, GCHQ, December 2008. DISCOVER 13042933 Please ask\r\nfor access.\r\n\r\nBayesian block modelling. Technical Report B/7635BA/5001/4/101,\r\nGCHQ, November 2009. DISCOVER 13036032.\r\n\r\nWeighted bayesian block modelling sanitised. Technical Report\r\nB/7713BA/5001/4/102, GCHQ, February 2010. DISCOVER 13036033.\r\n\r\nTechniques for measur-\r\ning the strength of communications in email event graphs. Technical Report\r\nB/6845BA/5001/4/102, ICTR-DMR, February 2008. DISCOVER 12656488.\r\n\r\nThe case for target discovery using closed loops against the Islamist terrorist\r\nthreat in the UK - a technical perspective. Technical Report B/7618BA/5001/4/102,\r\nICTR, GCHQ, 2009. DISCOVER 12861894.\r\n\r\nProperties of SIGINT-collected communication graphs, 2003. Technical\r\nReport SCAMP Working Paper L39/03, IDA-CCR, 2004. DISCOVER 11770806.\r\n\r\nProperties of SIGINT-collected communication graphs. Technical\r\nReport SCAMP Working Paper L32/02, IDA-CCR, 2003. DISCOVER 12502484.\r\n\r\nThe NetInf algorithm as a MapReduce job. Technical report, NSA, May\r\n2011. DISCOVER 13202916.\r\n\r\n[136]\tAutomated categorisation of CBRN related webpages. Technical Report\r\nB/7470BA/5001/5/105, ICTR-CISA, July 2009. DISCOVER 12669793.\r\n\r\n[137]\tHistogramming in the streaming environment.\r\nIn ACE, 2007. DISCOVER 12632758.\r\n\r\n[138]\tICTR-FSP. GCHQ TR-FSP HTTP header fingerprint format. B/7535BA/5001/1, 2009.\r\nDISCOVER 2450313.\r\n\r\n[139]\tDetecting dependence among multiple point processes. Technical report,\r\nUniversity of Pittsburgh, August 2007. DISCOVER 12681522.\r\n\r\n[140]\tEstimating set cardinality under streaming conditions. In ACE, 2011.\r\nDISCOVER 12754015.\r\n\r\n[141]\tTiming patterns in call records data with i2 Pattern Tracer and Remit.\r\nTechnical Report B/4351BA/1700/16, GCHQ, July 2003. DISCOVER 12207962.\r\n\r\n[142]\tTiming analysis 2004 - using significant temporal chains\r\nfor call records target development. Technical Report B/5372BA/1700/16, GCHQ,\r\nOctober 2004. DISCOVER 12200466.\r\n\r\n87\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n[143]\t. Pizza node classification - sharable data\r\nset for Random Forests classification. Technical Report B/6316BA/5001/4/102, GCHQ,\r\nDecember 2006. DISCOVER 12189035.\r\n\r\n[144]\tClassifying email addresses by their be-\r\nhaviour in bulk events data. Technical Report OPH-M/TECH.A/458, GCHQ, December\r\n2006. DISCOVER 12183192.\r\n\r\n[145]\tCreating, retaining and combining confidence estimates in a cloud-like\r\nworld, July 2010. DISCOVER 10833599.\r\n\r\n[146]\tTopological measures of evolving graphs: Dynamic betweenness cent-\r\nrality. Technical Report CCR Working Paper 1690, IDA-CCR, 2008. DISCOVER\r\n11770815.\r\n\r\n[147]\tDetecting correlated sequences of events. Slides from SANAR 2010, October\r\n2010. DISCOVER 12595305.\r\n\r\n[148]\tExtending pairwise element similarity to set similarity efficiently (sanitized\r\nversion). Technical Report MR/TECH/032/10, NSA, December 2010. DISCOVER\r\n12497649.\r\n\r\n[149]\tDetecting correlated sequences of events: sanitized\r\nversion. Technical Report OPH-M/Tech.A/456, GCHQ, August 2006. DISCOVER\r\n3730313.\r\n\r\n[150]\tand\tElkan and Noto\u2019s \u201cLearning classifi-\r\n\r\ners from only positive and unlabeled data\u201d is fatally flawed. Technical Report\r\nMR/TECH/009/10, NSA R1, February 2010. DISCOVER 10833916.\r\n\r\n[151]\tStreaming temporal relation additive probability. Technical report, NSA,\r\nApril 2009. DISCOVER 12594200.\r\n\r\n[152]\tCLASPing at straws: Bootstrapping and clustering to\r\nimprove product performance. Technical report, NSA, In Preparation 2011. DISCOVER\r\n12588233.\r\n\r\n[153]\tImprovements to GeoFusion scoring. Technical Report B/7854/5001/3/104,\r\nGCHQ, August 2010. DISCOVER 12839607.\r\n\r\n[154]\tApplication characterisation: Data set specification. Tech-\r\nnical Report B/6728BA/5001/1, GCHQ, December 2007. DISCOVER 12189832.\r\n\r\n[155]\tEmbedding R within InfoSphere Streams for online time series ana-\r\nlysis and predictions. Technical report, GCHQ ICTR-CISA, June 2011. DISCOVER\r\n12267642.\r\n\r\n[156]\tTowards implementation of an algorithm for updating eigenvalues and\r\neigenvectors of streaming graphs. Technical report, ICTR, GCHQ, 2011. DISCOVER\r\n12663078.\r\n\r\n88\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n[157]\r\n\r\n[158]\r\n\r\n[159]\r\n\r\n[160]\r\n\r\n[161]\r\n\r\n[162]\r\n\r\n[163]\r\n\r\n[164]\r\n\r\n[165]\r\n\r\n[166]\r\n\r\n[167]\r\n\r\n[168]\r\n\r\n[169]\r\n\r\n[170]\r\n\r\n[171]\r\n\r\n[172]\r\n\r\nI. Generating realistic random graphs. Technical report,\r\nHIMR, September 2008. DISCOVER 12747134.\r\n\r\nUnsupervised learning on network data. DISCOVER 12589745.\r\n\r\nRADONSHARPEN-B. DISCOVER 12838456, October 2010.\r\n\r\n2008 Bristol SWAMP: Prob-\r\nlems in graph mining. Technical Report OPC-M/TECH.A/6, GCHQ, 2008. DISCOVER\r\n12768417.\r\n\r\nStreaming decision trees. http://wiki.gchq/images/3/37/\r\nRDTrees.tar.gz, June 2007. DISCOVER 12134963.\r\n\r\nHIDDEN OTTER: Detection of multi-hop tem-\r\n\r\nporal chains in IP traffic. Technical Report B/7937BA/5001/3/104, GCHQ, December\r\n2010. DISCOVER 7810599 Ask\t(ICTR-NE) for access.\r\n\r\nStreaming PRIME TIME ap-\r\n\r\nplication design report. Technical Report INCA1323D003-1.1, Detica, December 2010.\r\nDISCOVER 12211763.\r\n\r\nnew technique for correlating stochastic processes. Technical Report\r\nB/7523BA/5001/4/102, GCHQ, September 2009. DISCOVER 12214368.\r\n\r\nNSASAG problem 07-04: Correlation of temporal sequences.\r\nTechnical report, University of Washington, 2007. DISCOVER 12687220.\r\n\r\nGeoFusion VOLSUNGA interface specification. Technical Report\r\nB/6745BA/5001/1, ICTR-FSP, January 2008. DISCOVER 13550106.\r\n\r\nFile signature bulk-logging technique - engineering specification.\r\nTechnical Report B/6173BA/B13/106, GCHQ, July 2006. DISCOVER 12742157.\r\n\r\nInternet flow classification: Random forests and importance-sampled\r\nlearning ensembles. In ACE, October 2007. DISCOVER 12187796.\r\n\r\nA probabilistic score for IP geolocation from INJUNCTION-style\r\ndata. Technical Report OPC-MCR/TECH.B/4, OPC-MCR, November 2007. DIS-\r\nCOVER 13548375.\r\n\r\nApplication characterisation: Generalisation to the unknown. Tech-\r\nnical Report OPC-m/tECH.B/7, GCHQ, April 2008. DISCOVER 12187131.\r\n\r\nEnhanced behavioural detection of botnet command-and-control\r\nservers. Technical Report OPC-M/TECH.B/53, GCHQ, July 2010. DISCOVER\r\n12209112.\r\n\r\nTraffic sketches for measuring bearer similarity and pairing. Tech-\r\nnical Report OPC-M/TECH.B/55, GCHQ, October 2011. DISCOVER 12750231.\r\n\r\n89\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n[173]\tA comparison between billing records and the\r\nview in SIGINT: SOLID INK vs FLUID INK. Technical Report OPC-M/TECH.B/17,\r\nGCHQ, 2009. DISCOVER 12676097.\r\n\r\n[174]\tImproved generic detection of steganography in JPEG coefficients. Tech-\r\nnical Report OPC-M/TECH.A/452, GCHQ, April 2011. DISCOVER 12191941.\r\n\r\n[175]\tGCHQ research & innovation strategy 2011 - 2015. DISCOVER 12013908.\r\n\r\n[176]\tBlocks, bridges and cutvertices in large commu-\r\nnications graphs. Technical Report OPC-M/TECH.B/19, HIMR, October 2008. DIS-\r\nCOVER 12750236.\r\n\r\n[177]\tUsing predictive modelling to identify cocaine drug smugglers. Technical\r\nReport B/4029BA/B1700/13, GCHQ, November 2002. DISCOVER 12815822.\r\n\r\n[178]\tResults document for call\r\nrecord timing analysis. Technical Report CAA146D005-1.0, Detica, November 2001.\r\nDISCOVER 12204886.\r\n\r\n[179]\tTDB. Interface control document (ICD) for the SALAMANCA input handler - external\r\ngeneric feed interface. Technical Report PC/00117CPO/4542/PC0093/000/50, GCHQ,\r\n2010. DISCOVER 12680902.\r\n\r\n[180]\tKnowledge discovery at the new CRI. In SANAR, October 2010.\r\nDISCOVER 12208587.\r\n\r\n[181]\tUpdating eigenvalues and eigenvectors of streaming graphs. Technical\r\nReport SCAMP Working Paper L22/09, IDA-CCR, 2010. DISCOVER 11806837.\r\n\r\n[182]\tSAWUNEH 2010 \u2014 cyber defence\r\nevent mining. In ACE, May 2011. DISCOVER 12754021.\r\n\r\n[183]\t^^DISCOVER 12369711.\r\n\r\n[184]\tAura features: Algorithmic description. DISCOVER 12380899.\r\n\r\n[185]\tAura features: Brief description. DISCOVER 12380897.\r\n\r\n[186]\tSKB definitions.\r\n\r\nPlease ask\t(ICTR-FSP) for access.\r\n\r\n90\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n\u2014 External Literature \u2014\r\n\r\n[E1]\r\n\r\n[E2]\r\n\r\n[E3]\r\n\r\n[E4]\r\n\r\n[E5]\r\n\r\n[E6]\r\n\r\n[E7]\r\n\r\n[E8]\r\n\r\n[E9]\r\n\r\nThe canonical tensor decomposition\r\n\r\nand its application to data analysis, June 2009. DISCOVER 12740014.\r\n\r\nAn empirical study of\r\n\r\ndynamic graph algorithms. ACM Journal on Experimental Algorithmics, pages 192-201,\r\n1996. DISCOVER 11402183.\r\n\r\nSTINGER: Spatio-temporal interaction networks and graphs (STING) extensible rep-\r\nresentation, May 2009. DISCOVER 11821050.\r\n\r\nNetwork science applications to global communications. In\r\nNetSci, 2008. DISCOVER 12804967.\r\n\r\nand\tThe phase transition in inhomogen-\r\n\r\neous random graphs. arXiv:math/0504589v3, June 2006. DISCOVER 12763412.\r\n\r\nForests. Machine Learning, 45, 2001. DISCOVER 13286408.\r\n\r\neditors. Semi-supervised\r\n\r\nlearning. MIT Press, 2010.\r\n\r\nData stream algorithms intro, sampling, entropy. Slides from Bristol\r\nMaths workshop, 2008. DISCOVER 12805861.\r\n\r\nHow does the data sampling strategy impact the discovery of\r\ninformation diffusion in social media? Association for the Advancement of Artificial\r\nIntelligence, 2010. DISCOVER 10763381.\r\n\r\n[E10\r\n\r\n[E11]\r\n\r\n[E12]\r\n\r\n[E13]\r\n\r\n[E14]\r\n\r\nMapReduce: Simplied data processing on large\r\n\r\nclusters. In OSDI, 2004. DISCOVER 12192986.\r\n\r\nBayesian approaches to modeling the con-\r\n\r\nditional dependence between multiple diagnostic tests. Biometrics, 57:158-167, 2001.\r\nDISCOVER 12192608.\r\n\r\nI. Massive streaming data\r\n\r\nanalytics: A case study with clustering coefficients, 2010. DISCOVER 11821048.\r\n\r\n. Learning classifiers from only positive and unlabeled\r\ndata. In KDD, Las Vegas, August 2008. ACM. DISCOVER 12195326.\r\n\r\nDynamic graph algorithms, 1999.\r\n\r\nDISCOVER 11402184.\r\n\r\n91\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n[E15]\r\n\r\nGraph distances in the data-stream model. SIAM Journal on Computing,\r\n38(5):1709-1727, 2008.\r\n\r\n[E16]\tHyperLogLog: the analysis of a near-optimal\r\n\r\ncardinality estimation algorithm. AofA, 2007. DISCOVER 12747198.\r\n\r\n[E17]\tSemi-supervised ranking on\r\n\r\nvery large graphs with rich metadata. In KDD, August 2011. Available from Microsoft\r\nResearch\u2019s website.\r\n\r\n[E18]\tInferring networks\r\n\r\nof diffusion and influence. In KDD\u201910, Washington D.C., 2010. ACM. DISCOVER\r\n12762008.\r\n\r\n[E19]\tEstimating the error rates of diagnostic tests. Biometrics,\r\n\r\n36:167-171, 1980.\r\n\r\n[E20] INSTINCT. Have I got \u201cviews\u201d for you?: gathering and analysing publicly available data\r\nto gain an understanding of current events. Technical report, October 2011. DISCOVER\r\n12626622.\r\n\r\n[E21]\tBayesian estimation of dis-\r\n\r\nease prevalence and the parameters of diagnostic tests in the absence of a gold standard.\r\nAmerican Journal of Epidemiology, 141(3):263-272, 1995. DISCOVER 12195321.\r\n\r\n[E22]\tIntroducing the Enron corpus. Technical report, Carne-\r\n\r\ngie Mellon University, 2004. DISCOVER 12763413.\r\n\r\n[E23]\tMIForests: Multiple-instance learn-\r\n\r\ning with randomized trees, 2010. DISCOVER 12192687.\r\n\r\n[E24]\tSemi-supervised\r\n\r\nrandom forests, 2011. DISCOVER 12192698.\r\n\r\n[E25]\tSocial media analytics: Part 1: Information flow. Slides, Stanford\r\n\r\nUniversity, August 2011. Presented at KDD 2011 DISCOVER 13561614.\r\n\r\n[E26]\tand\tGraph evolution: Densification\r\n\r\nand shrinking diameters. ACM Transactions on Knowledge Discovery from Data, 1(1),\r\n2007. DISCOVER 12761498.\r\n\r\n[E27]\tLearning with an unreliable teacher. Pattern Recognition, 25(1):79-87,\r\n\r\n1992.\r\n\r\n[E28]\tCompact graph representations and parallel\r\n\r\nconnectivity algorithms for massive dynamic network analysis. In 23rd IEEE Interna-\r\ntional Parallel and Distributed Processing Symposium (IPDPS), May 2009. DISCOVER\r\n11816428.\r\n\r\n92\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n[E29]\r\n\r\nSparsification of influence networks. In KDD\u201911, pages 529-537, San Diego,\r\nCA, August 2011. ACM. /discover13560696.\r\n\r\n[E30]\tThe PageRank citation ranking:\r\n\r\nBringing order to the web, 1998.\r\n\r\n[E31]\tSupervised learning from multiple experts: Whom to trust when\r\n\r\neveryone lies a bit. In Proceedings of the 26th International Conference on Machine\r\nLearning, 2009. DISCOVER 12197907.\r\n\r\n[E32]\t\u201cTAGS\u201d, a program for the eval-\r\n\r\nuation of a test accuracy in the absence of a gold standard. Preventative Vetinary\r\nMedicine, 53:67-81, 2002.\r\n\r\n[E33]\tA method for inferring label\r\n\r\nsampling mechanism in semi-supervised learning. In Advances in Neural Information\r\nProcessing Systems, volume 17, 2005. DISCOVER 13287597.\r\n\r\n[E34]\tCorrect-\r\n\r\ning for missing data in information cascades. Technical report, Stanford University,\r\nDecember 2010. DISCOVER 10763155.\r\n\r\n[E35]\tCombined regression and ranking. In KDD. ACM, July 2010. DISCOVER\r\n\r\n12815522.\r\n\r\n[E36]\tLearning with labeled and unlabeled data. Technical report, University\r\n\r\nof Edinburgh, December 2002. DISCOVER 13287596.\r\n\r\n[E37]\tActive learning literature survey. Technical report, University of\r\n\r\nWisconsin-Madison, 2010. DISCOVER 12195329.\r\n\r\n[E38]\tWhen do latent class models overstate accuracy for binary classifiers?:\r\n\r\nWith applications to jury accuracy, survey response error, and diagnostic error. Tech-\r\nnical Report WP-08-10, Northwestern University, May 2009. DISCOVER 12192699.\r\n\r\n[E39]\tStreaming data. WIREs Computational Statistics, January 2011.\r\n\r\nDISCOVER 12197914.\r\n\r\n[E40]\tFast counting of triangles in large real networks: al-\r\n\r\ngorithms and laws. In ICDM, 2008. DISCOVER 12805858.\r\n\r\n[E41]\tThe future of data analysis. Ann. Math. Stat., 1962. DISCOVER\r\n\r\n12804965.\r\n\r\n[E42]\r\n\r\n[E43]\r\n\r\nExploratory data analysis. Addison-Wesley, 1977.\r\n\r\nDesign principles for\r\n\r\ndeveloping stream processing applications. Software - Practice and Experience, 2010.\r\n\r\n93\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n[E44]\tModeling information diffusion in implicit networks.\r\n\r\nTechnical report, Stanford University, 2010. DISCOVER 12763414.\r\n\r\n[E45]\tBoosting the scalability of botnet detection using adaptive traffic\r\n\r\nsampling. In ASIACCS, March 2011. DISCOVER 12804966.\r\n\r\n[E46]\tSemi-supervised learning literature survey. Technical Report TR 1530,\r\n\r\nUniversity of Wisconsin-Madison, July 2008. DISCOVER 13288447.\r\n\r\n\u2014 Websites \u2014\r\n\r\n[W1] Application characterisation.\r\n\r\n[W2] AUTO ASSOC.\r\n\r\n[W3] BIRCH (data clustering).\r\n\r\n[W4] CARBON COPY.\r\n\r\n[W5] CASK: situational awareness for the 2012 Olympics\r\n\r\n[W6] CHART BREAKER.\r\n\r\n[W7] CNE OpSec pages.\r\n\r\n[W8] CNO glossary.\r\n\r\n[W9] CRAN.\r\n\r\n[W10] Decision tree learning on Wikipedia.\r\n\r\n[W11] DISTILLERY.\r\n\r\n[W12] Dynamic Graph.\r\n\r\n[W13] Ensemble learning on Wikipedia.\r\n\r\n[W14] Fused analysis and visualisation research.\r\n\r\n[W15] GCWiki.\r\n\r\n[W16] Getting started on BHDIST.\r\n[W17] GRINNING ROACH.\r\n\r\n94\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n[W18] Ground breaking intelligence capabilities used during recent G20\r\nsummit.\r\n\r\n[W19] Hadoop Fair Scheduler guide.\r\n\r\n[W20] Hadoop on GCWiki.\r\n\r\n[W21] HIMR IT upgrade.\t.\r\n\r\n[W22] HIMR self help.\r\n\r\n[W23] HRA logging.\r\n\r\n[W24] Information flow in graphs GCWiki page.\r\n\r\n[W25] Legal compliance.\r\n\r\n[W26] Legalities SUN STORM/BLACK HOLE.\r\n\r\n[W27] MAMBA.\r\n\r\n[W28] NSASAG.\r\n\r\n[W29] Pidgin setup.\r\n\r\n[W30] PIRATE CAREBEAR.\r\n\r\n[W31] Random Forests.\r\n\r\n[W32] Relationship analysis.\r\n\r\n[W33] Renoir.\r\n\r\n[W34] ROC curves.\r\n\r\n[W35] Safari books online.\t.\r\n\r\n[W36] SALAMANCA.\r\n\r\n[W37] SALTY OTTER.\r\n\r\n[W38] Semi-supervised learning on Wikipedia. http://wikipedia.gchq/index.php\r\n[W39] Squeal eAD and cipher detection PPF app.\r\n\r\n95\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n[W40] Streams Processing Language.\r\n\r\n[W41] Supervised learning on Wikipedia.\r\n\r\n[W42] SWAMP 2008.\r\n\r\n[W43] What\u2019s the relationship between CNO and DNI?\r\n\r\n[W44] WHITERAVEN.\r\n\r\n[W45]\tKL-Relative PageRank.\r\n\r\n96\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY", 
    "sigads": [], 
    "overall_relto": [], 
    "countries_mentioned": [
      "Australia (AUS/AU)", 
      "Barbados (BRB/BB)", 
      "China (CHN/CN)", 
      "Georgia (GEO/GE)", 
      "Pakistan (PAK/PK)", 
      "Russia (RUS/RU)", 
      "Spain (ESP/ES)", 
      "United Kingdom (GBR/GB)", 
      "United States (USA/US)"
    ], 
    "link": "https://edwardsnowden.com/2016/02/02/himr-data-mining-research-problem-book/", 
    "document_topic": [
      "Internet Content"
    ], 
    "pub_date": "Tue, 02 Feb 2016 18:51:45 +0000", 
    "article_links": [
      "https://boingboing.net/2016/02/02/doxxing-sherlock-3.html"
    ], 
    "categories": [
      "Revealed documents", 
      "AT&T", 
      "auto assoc", 
      "baker's dozen", 
      "bearer", 
      "birch", 
      "bowie", 
      "bristol", 
      "broad oak", 
      "bude", 
      "buzz", 
      "cesg", 
      "chart breaker", 
      "cheltenham", 
      "chordal", 
      "clasp", 
      "cna", 
      "cne", 
      "cno", 
      "comsat", 
      "cpc", 
      "data mining", 
      "discover", 
      "distillery", 
      "five alive", 
      "fluid ink", 
      "gchq_orig", 
      "gcwiki", 
      "gold mine", 
      "grinning roach", 
      "hager awel", 
      "heilbronn", 
      "hidden otter", 
      "himr", 
      "ictr-dmr", 
      "ictr-mca", 
      "injunction", 
      "instinct", 
      "internet_content", 
      "kachina", 
      "leckwith", 
      "lucky strike", 
      "mamba", 
      "mapreduce", 
      "meteor shower", 
      "miranda", 
      "mount mckinley", 
      "myofibril", 
      "olympics", 
      "opc-1", 
      "pirate carebear", 
      "preston", 
      "prime time", 
      "psychic salmon", 
      "raging bullfrog", 
      "robotic fish", 
      "rpc-1", 
      "salamanca", 
      "salty otter", 
      "sawuneh", 
      "scamp", 
      "sepang", 
      "silver library", 
      "silver lining", 
      "solid ink", 
      "spiky rock", 
      "sun storm", 
      "swamp", 
      "terrain", 
      "timid toad", 
      "ukusa", 
      "ukvac", 
      "us national labs", 
      "valhalla", 
      "woody"
    ], 
    "title": "HIMR Data Mining Research Problem Book", 
    "doc_text": "\ufeffUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nReference:\tOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nDate:\t20 September 2011\r\n\r\nCopy no:\r\n\r\nHIMR Data Mining Research Problem Book\r\n\r\nOPC-MCR, GCHQ\r\n\r\nSummary\r\n\r\nIn this problem book we set out areas for long-term data mining research at the Heilbronn\r\nInstitute for Mathematical Research starting in October 2011 and continuing for at least three\r\nyears. The four areas are beyond supervised learning, information flow in graphs, streaming\r\nexploratory data analysis and streaming expiring graphs.\r\n\r\nCopy\tDistribution\r\n\r\n1\tNSA R1\r\n\r\n2\r\n\r\n3\r\n\r\n4\r\n\r\nI\r\n\r\n6\r\n\r\n7\r\n\r\n8\r\n9\r\n\r\n10\r\n\r\nII\r\n12\r\n\r\n13\r\n\r\n14\r\n\r\n15\r\n\r\n16\r\n\r\n17\r\n\r\n18\r\n\r\nNSA R4\r\nNSA R6\r\nLLNL\r\n\r\nCSEC\r\nCRI\r\nDSD\r\nGCSB\r\nICTR\r\nICTR-CISA\r\nICTR-DMR\r\nICTR-MCA\r\nNDIST\r\nIACT\r\nPTD I\r\n\r\nHIMR (circ.)\r\nOPC-MCR (circ.)\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n[96 pages]\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nTHIS PAGE IS INTENTIONALLY LEFT BLANK\r\n\r\n2\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nHIMR Data Mining Research Problem Book\r\n\r\n20 September 2011\r\n\r\nContents\r\n\r\n1\tIntroduction\t7\r\n\r\n2\tA brief introduction\tto SIGINT\t9\r\n\r\n2.1\tPassive SIGINT..................................................... 9\r\n\r\n2.1.1\tCollection................................................... 9\r\n\r\n2.1.2\tProcessing.................................................. 10\r\n\r\n2.1.3\tAnalysis, reporting and target development.................. 11\r\n\r\n2.2\tComputer network operations and the cyber mission................. 12\r\n\r\n2.2.1\tCyber....................................................... 12\r\n\r\n2.2.2\tAttack, exploit, defend, counter............................ 13\r\n\r\n2.2.3\tData mining for cyber discovery ............................ 14\r\n\r\n3\tBeyond Supervised Learning\t16\r\n\r\n3.1\tIntroduction...................................................... 16\r\n\r\n3.1.1\tSupervised learning prior work.............................. 17\r\n\r\n3.1.2\tSemi-supervised learning prior work......................... 18\r\n\r\n3.2\tSemi-supervised learning.......................................... 18\r\n\r\n3.2.1\tHow useful is semi-supervised learning?..................... 18\r\n\r\n3.2.2\tPositive-only learning...................................... 19\r\n\r\n3.2.3\tActive learning............................................. 19\r\n\r\n3.2.4\tNew algorithms and implementations ......................... 20\r\n\r\n3.3\tUnreliable marking of data ....................................... 20\r\n\r\n3.3.1\tWeak labels................................................. 20\r\n\r\n3.3.2\tFusion of scores............................................ 21\r\n\r\n3.4\tRelevant data..................................................... 22\r\n\r\n3.4.1\tTruthed datasets............................................ 22\r\n\r\n3.4.2\tFusion of scores data....................................... 23\r\n\r\n3.5\tCollaboration points.............................................. 23\r\n\r\n4\tInformation Flow in\tGraphs\t25\r\n\r\n4.1\tIntroduction...................................................... 25\r\n\r\n4.2\tPast work......................................................... 26\r\n\r\n4.2.1\tGraphical methods........................................... 26\r\n\r\n4.2.2\tTemporal correlation........................................ 28\r\n\r\n4.3\tWhat we care about now ........................................... 29\r\n\r\n3\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n4.3.1\tDefinition and Discovery...................................... 30\r\n\r\n4.3.2\tMissing data and noise........................................ 30\r\n\r\n4.4\tPotential future interests.......................................... 31\r\n\r\n4.4.1\tPerforming inference on flows................................. 31\r\n\r\n4.4.2\tInformation flow for graph generation......................... 32\r\n\r\n4.5\tRelevant data....................................................... 32\r\n\r\n4.6\tCollaboration points................................................ 32\r\n\r\n5\tEDA on Streams\t34\r\n\r\n5.1\tIntroduction........................................................ 34\r\n\r\n5.1.1\tEDA .......................................................... 34\r\n\r\n5.1.2\tStreams....................................................... 34\r\n\r\n5.1.3\tThe problems ................................................. 35\r\n\r\n5.2\tGraph problems with no sub-sampling................................. 35\r\n\r\n5.2.1\tThe framework of graphs and hypergraphs....................... 35\r\n\r\n5.2.2\tCliques and other motifs...................................... 36\r\n\r\n5.2.3\tTrusses ...................................................... 37\r\n\r\n5.2.4\tOther approaches.............................................. 37\r\n\r\n5.3\tVisualization....................................................... 38\r\n\r\n5.3.1\tVisualization in general...................................... 38\r\n\r\n5.3.2\tStreaming plots .............................................. 38\r\n\r\n5.4\tModelling and outlier detection..................................... 39\r\n\r\n5.4.1\tIdentifying outlier activity.................................. 39\r\n\r\n5.4.2\tBackground distributions for significance tests............... 39\r\n\r\n5.4.3\tWindow sizing................................................. 39\r\n\r\n5.5\tProfiling and correlation........................................... 40\r\n\r\n5.5.1\tCorrelations.................................................. 40\r\n\r\n5.5.2\tFinding behaviour that matches a model........................ 40\r\n\r\n5.6\tEasy entry problems................................................. 41\r\n\r\n5.7\tRelevant data....................................................... 41\r\n\r\n5.8\tCollaboration points................................................ 42\r\n\r\n5.8.1\tInternal...................................................... 42\r\n\r\n5.8.2\tExternal...................................................... 42\r\n\r\n6\tStreaming\tExpiring Graphs\t44\r\n\r\n6.1\tIntroduction........................................................ 44\r\n\r\n6.1.1\tThe Problems.................................................. 44\r\n\r\n6.2\tProperties to find and track........................................ 45\r\n\r\n6.2.1\tComponent Structure........................................... 45\r\n\r\n6.2.2\tGraph Distance................................................ 45\r\n\r\n6.2.3\tCliques and other motifs...................................... 45\r\n\r\n6.2.4\tCentrality Measures........................................... 46\r\n\r\n6.3\tQuestions relevant to all properties................................ 47\r\n\r\n6.3.1\tApproximation................................................. 47\r\n\r\n6.3.2\tComputational Cost ........................................... 47\r\n\r\n4\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n6.3.3\tExpiry Policy...................................................... 48\r\n\r\n6.4\tFurther Questions ....................................................... 48\r\n\r\n6.4.1\tParallel and Distributed processing................................ 48\r\n\r\n6.4.2\tBootstrapping ..................................................... 48\r\n\r\n6.4.3\tAnomaly Detection.................................................. 48\r\n\r\n6.4.4\tResilience......................................................... 49\r\n\r\n6.4.5\tQueries on graphs with attributes ................................. 49\r\n\r\n6.5\tRelevant Data............................................................ 49\r\n\r\n6.6\tCollaboration Points..................................................... 49\r\n\r\nA Ways of working\t51\r\n\r\nA.1\tFive-eyes collaboration.................................................. 51\r\n\r\nA.2\tKnowledge sharing........................................................ 51\r\n\r\nA.\t3\tAcademic engagement ..................................................... 52\r\n\r\nB DISTILLERY\t54\r\n\r\nB.\t1\tWhen would I use InfoSphere\tStreams? .................................... 54\r\n\r\nB.2\tDocumentation and Training............................................... 55\r\n\r\nB.3\tLogging on and Getting Started........................................... 55\r\n\r\nB.4\tData..................................................................... 56\r\n\r\nB.5\tConventions ............................................................. 58\r\n\r\nB.5.1 Use threaded ports on\tshared data................................... 58\r\n\r\nB.\t5.2 Operator Toolkits and\tNamespaces.................................. 58\r\n\r\nB.\t6\tFurther help and resources............................................... 59\r\n\r\nC Hadoop\t60\r\n\r\nC.\t1\tWhen would I use Hadoop?................................................. 60\r\n\r\nC.2\tDocumentation and Training............................................... 61\r\n\r\nC.3\tLogging on and Getting Started........................................... 61\r\n\r\nC.4\tData..................................................................... 62\r\n\r\nC.5\tConventions and restrictions............................................. 62\r\n\r\nC.\t5.1 Scheduler......................................................... 62\r\n\r\nC.5.2 HDFS /user/yoursid space ........................................... 63\r\n\r\nC.6\tRunning Hadoop on the LID\t.............................................. 63\r\n\r\nC.7\tFurther help and resources............................................... 65\r\n\r\nD Other computing resources\t66\r\n\r\nE Legalities\t67\r\n\r\nE.1\tOverview ................................................................ 67\r\n\r\nE.2\tProcedures .............................................................. 67\r\n\r\n5\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nF\tData\t69\r\n\r\nF.1 SIGINT\tevents............................................................... 69\r\n\r\nF.1.1\tSALAMANCA............................................................... 69\r\n\r\nF.1.2\tFIVE ALIVE.............................................................. 70\r\n\r\nF.1.3\tHRMap................................................................... 71\r\n\r\nF.1.4\tSKB..................................................................... 71\r\n\r\nF.1.5\tArrival Processes....................................................... 72\r\n\r\nF.1.6\tSOLID INK and FLUID INK................................................. 73\r\n\r\nF.1.7\tSqueal hits ............................................................ 74\r\n\r\nF.2 Open-source graphs and events.................................................. 74\r\n\r\nF.2.1\tEnron................................................................... 74\r\n\r\nF.2.2\tUS flights data......................................................... 75\r\n\r\nF.2.3\tWikipedia graph......................................................... 75\r\n\r\nF.3 SIGINT\treference data....................................................... 77\r\n\r\nF.3.1\tWebsites of interest ................................................... 77\r\n\r\nF.3.2\tTarget selectors........................................................ 77\r\n\r\nF.3.3\tCovert Infrastructure................................................... 78\r\n\r\nF.3.4\tConficker botnet........................................................ 78\r\n\r\nF.3.5\tPayphones............................................................... 78\r\n\r\nF.4 SIGINT\ttruthed data ........................................................ 79\r\n\r\nF.4.1\tLogo recognition........................................................ 79\r\n\r\nF.4.2\tSpam detection.......................................................... 80\r\n\r\nF.4.3\tProtocol classification................................................. 80\r\n\r\nF.4.4\tSteganography detection................................................. 81\r\n\r\nF.4.5\tGenre classification.................................................... 81\r\n\r\nF.4.6\tWebsite classification.................................................. 82\r\n\r\nF.5 Fusion\tof scores data ....................................................... 82\r\n\r\nReferences\t85\r\n\r\n6\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n1\tIntroduction\r\n\r\nThe Government Office for Science reviewed GCHQ technology research in 2010 and identified\r\nthat we could lengthen our technology research horizon. The Heilbronn Institute for Mathemat-\r\nical Research (HIMR) had shown its mettle during a one-off graph mining workshop [I60, W42]\r\nand thus the idea to more permanently expand HIMR research beyond pure maths and into\r\ndata mining was born. This also fits into GCHQ\u2019s overall research and innovation strategy for\r\nthe next few years [I75], where engagement with academia via HIMR is a key plank.\r\n\r\nLike many organisations, GCHQ is having to approach the \u201cBig Data\u201d problem. After\r\nreviewing our current research we identified four broad areas for long-term research in math-\r\nematics and algorithms at HIMR. All of the four problem areas are about improving our\r\nunderstanding of large datasets:\r\n\r\nBeyond supervised learning: Can we use semi-supervised learning and related techniques\r\nto improve the use of machine learning techniques?\r\n\r\nInformation flow in graphs: Can we identify information flowing across a communications\r\ngraph, typically from timing patterns alone?\r\n\r\nStreaming exploratory data analysis: Can we develop new techniques for understanding\r\nand visualising streaming data?\r\n\r\nStreaming expiring graphs: Can we efficiently maintain current situational awareness of a\r\nstreaming expiring graph?\r\n\r\nHIMR researchers are free to devote their effort amongst these problems as they see fit during\r\ntheir classified time.\r\n\r\nThese problems have been chosen due to their SIGINT relevance and SIGINT data is\r\nprovided for all these problems. However we also recognise that these problems have overlaps\r\nwith current academic research areas. Thus, conditional on security considerations, HIMR\r\nresearchers should be able to generalise from classified research to unclassified research and\r\npublications during their unclassified time.\r\n\r\nData is made available to HIMR researchers in the following forms:\r\n\r\nStreams: GCHQ are prototyping the use of the DISTILLERY streaming architecture (see\r\nAppendix B for details). Many data analysis problems can be efficiently approached in\r\nthe stream [E39] and processing in the stream brings the advantages of live situational\r\nawareness and the potential to reduce follow-on storage and processing costs.\r\n\r\nMapReduce: GCHQ store recent communications meta-data as distributed text files in Ha-\r\ndoop clusters which can then be processed with MapReduce [E10] (see Appendix C for\r\ndetails). This environment will allow researchers to use large datasets typically spanning\r\nthe last six months of collection.\r\n\r\nReference: We also provide some smaller datasets (e.g. reference data or data that has already\r\nbeen processed or truthed) as text files.\r\n\r\n7\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nThe development of techniques in Hadoop or DISTILLERY is recommended as that will enable\r\neasy technology transfer from HIMR into GCHQ.\r\n\r\nThe HIMR Deputy Director, the authors of this problem book and members of GCHQ\u2019s\r\nInformation and Communications Technology Research (ICTR) business unit should be seen\r\nas the primary points-of-contact for this research. However we will also identify various other\r\nareas for classified collaboration both in GCHQ and abroad.\r\n\r\nGCHQ imagines that the most useful outcomes of this research will come in one of the\r\nfollowing forms:\r\n\r\n\u2022\tClassified or unclassified research papers describing new techniques (or in limited cases a\r\nliterature review of existing techniques).\r\n\r\n\u2022\tClassified research papers describing new or existing techniques applied to SIGINT data.\r\n\r\n\u2022\tNew analytics (typically in Hadoop or DISTILLERY) and documentation.\r\n\r\nIn this problem book we adopt two conventions:\r\n\r\n\u2022\tWe distinguish between references to internal literature, external literature and websites.\r\nCitations are prefixed \u201cI\u201d, \u201cE\u201d and \u201cW\u201d respectively. Where possible literature is made\r\navailable in DISCOVER (see appendix D). We have deliberately aimed to be more com-\r\nprehensive in citing internal literature than external literature; external references should\r\nbe easier to find from citation paths and review papers.\r\n\r\n\u2022\tWe highlight problems with a \u25c4 in the right-hand margin.\r\n\r\nIn the interests of brevity, this problem book does not give full definitions for all terms in use\r\nin GCHQ and the use of GCWiki [W15] is a good place to find out more.\r\n\r\nWe would like to thank the many people across the 5-eyes community who have helped\r\nus with the problem book, both in formal contributions and in informal discussions at various\r\nconferences and visits over the last year. Within GCHQ we have had plenty of support from\r\nmembers of ICTR (in particular\tand\tand PTD (in particular\r\n\r\n).\r\n\r\nWe start the problem book with an overview of relevant SIGINT background before describ-\r\ning the problems in detail. In appendices we suggest some ways of working, describe GCHQ\u2019s\r\nimplementations of Hadoop and DISTILLERY and describe the datasets available.\r\n\r\n8\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n2\tA brief introduction to SIGINT\r\n\r\nThis is a very brief, high-level overview for people unfamiliar with the SIGINT system, focused\r\non what data miners need to know about the data available to them and how data mining can\r\nbe applied to problems in target discovery and cyber. Researchers are encouraged to find out\r\nmore by browsing GCWiki and asking questions that arise.\r\n\r\nSIGINT is intelligence derived from intercepted signals. Although this encompasses a huge\r\nvariety of emanations, we are principally concerned with COMINT: intercepted communica-\r\ntions.\r\n\r\nParliament\u2019s Joint Intelligence Committee (JIC) formulates a set of priorities and require-\r\nments for intelligence on various topics, which GCHQ tries to meet by producing End Product\r\nReports (EPR) based on intercepted communications. GCHQ has the legal authority to inter-\r\ncept communications for the specific purposes of safeguarding the UK\u2019s national security and\r\neconomic well-being, and to prevent and detect serious crime. GCHQ always acts in accordance\r\nwith UK law. All researchers who have access to SIGINT data will be given legalities training,\r\nand there is also some information in appendix E on how data should be handled.\r\n\r\n2.1\tPassive SIGINT\r\n\r\nThis section looks at some of the main stages in the \u2018intelligence cycle\u2019: how data gets collected,\r\nprocessed and analysed to produce reports for GCHQ\u2019s customers.\r\n\r\n2.1.1\tCollection\r\n\r\nThere are many ways of communicating, and consequently there are many sources of SIGINT\r\ndata. Traditionally, we collect signals using a variety of masts and dishes to pick up radio\r\nor satellite signals. Increasingly, we are interested in network communications (phone calls or\r\ninternet traffic), and in this case to intercept the communication we usually need an access point\r\nin the network. (Sometimes network data passes over a satellite link where we can pick it up\u2014\r\nCOMSAT collection\u2014but more often it doesn\u2019t.) Collection of this network communication\r\ndata is called Special Source collection, the details of which are covered by ECIs. Access to raw\r\ndata collected from Special Source is protected by a COI called CHORDAL. Some information\r\nabout what the underlying sensitivities are, and the processes we have in place to protect them,\r\nis provided in the CHORDAL briefing.\r\n\r\nOne final twist is that a UK service provider can be compelled by a warrant signed by the\r\nHome Secretary or the Foreign Secretary to provide us with the communications data for a\r\nspecific line or account for a specified time. This goes by several names: Lawful Intercept (LI),\r\nwarranted collection, and PRESTON.\r\n\r\nWe refer to a single internet link as a bearer. We collect data from a bearer using a probe,\r\nand our current technology can collect from a 10G bearer (i.e. a 10 gigabit-per-second link).\r\nWhen a bearer is connected to a probe and associated processing equipment we describe the\r\nbearer as being on cover. We have been building up our sustained collection of 10G bearers\r\nsince about 2008, and we now have approximately 200 bearers on sustained cover, spread across\r\nCheltenham, Bude and LECKWITH. We refer to these three sites as processing centres ; they\r\nare abbreviated to CPC, RPC-1 and OPC-1 respectively.\r\n\r\n9\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nWe have access to many more bearers than we can have on cover at any one time, and the\r\nset we have on cover is changed to meet operational needs.1 As well as the fact that bearers get\r\ntaken on and off, it is not unusual for technical problems to interrupt processing from a bearer,\r\nboth for short and prolonged periods. This means that one must be careful about making\r\nassumptions about how traffic volumes from a given end-point vary over time: see [I10] for a\r\ndetailed discussion of the problem and one way to deal with it.\r\n\r\n2.1.2\tProcessing\r\n\r\nA 10G bearer produces a phenomenal amount of data: far too much to store, or even to process\r\nin any complicated way. Our way of dealing with this is a multi-component system called MVR\r\n(massive volume reduction). To make things manageable, the first step is to discard the vast\r\nmajority of the packets we see. This is accomplished by the Packet Processing Framework\r\n(PPF), a software framework allowing a very limited set of matching operations to be run on\r\nspecialized hardware; packets that hit on these matches are then passed back to the software\r\nlayer, where more complicated processing (including sessionization, done by a platform called\r\nTERRAIN) can be performed on the selected subset of the data.\r\n\r\nCollected data falls into two categories: metadata and content. Roughly, metadata comes\r\nfrom the part of the signal needed to set up the communication, and content is everything\r\nelse. For telephony, this is simple: the originating and destination phone numbers are the\r\nmetadata, and the voice cut is the content. Internet communications are more complicated,\r\nand we lean on legal and policy interpretations that are not always intuitive. For example,\r\nin an HTTP request, the destination server name is metadata (because it, or rather its IP\r\naddress, is needed to transmit the packet), whereas the path-name part of the destination URI\r\nis considered content, as it is included inside the packet payload (usually after the string GET\r\nor POST). For an email, the to, from, cc and bcc headers are metadata (all used to address the\r\ncommunication), but other headers (in particular, the subject line) are content; of course, the\r\nbody of the email is also content.\r\n\r\nThere are extremely stringent legal and policy constraints on what we can do with content,\r\nbut we are much freer in how we can store and use metadata. Moreover, there is obviously a\r\nmuch higher volume of content than metadata. For these reasons, metadata feeds will usually\r\nbe unselected\u2014we pull everything we see; on the other hand, we generally only process content\r\nthat we have a good reason to target.2 GCHQ\u2019s targeting database is called BROAD OAK,\r\nand it provides selectors that the front-end processing systems can look for to decide when\r\nto process content. Examples of selectors might be telephone numbers, email addresses or IP\r\nranges. A selector whose communications are currently being targeted is said to be on cover.\r\n\r\nMetadata generally gives us information that we think of as events (\u2018A communicated with\r\nB at time t\u2019), and this terminology filters through into the name for the corporate processing\r\nand storage system for 10G bearers: Next Generation Events (NGE).\r\n\r\nxIn order to make decisions about which bearers to place on cover, we carry out a cyclic survey of all bearers.\r\nEach bearer is connected to a probe for 15 minutes and data collected about the traffic seen during that time.\r\nThis is stored in the Flexible-survey Knowledge Base or FKB.\r\n\r\n2We do collect some unselected content for survey and research purposes, but the requirements that our\r\nactivities be necessary and proportionate strictly limit what we can do with full-take content and who can have\r\naccess to it: in particular, analysts are not usually allowed to write reports based on it.\r\n\r\n10\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nOnce packets (or files or sessions created by assembling multiple packets) have been selected\r\nand they emerge from MVR, they go to several different places.\r\n\r\n\u2022\tContent databases. Traditional relational databases are still the ultimate point of rest\r\nfor corporate content data. There are also some legacy events database stores; soon, all\r\nof GCHQ\u2019s events processing and storage will move to the systems described in the next\r\nthree bullets.\r\n\r\n\u2022\tQFDs. Query-focused datasets (QFDs) pick out data and store it in a way that makes\r\nit easy to answer particular questions. For example, FIVE ALIVE is a dataset with a\r\nrecord for each IP event seen, consisting of the 5-tuple (timestamp, source IP, source\r\nport, destination IP, destination port) plus some information on session length and size.\r\nThis lets us answer questions about the network activity of a specific IP address.3\r\n\r\n\u2022\tDISTILLERY. A stream processing platform enabling near real time processing of data.\r\nSee appendix B.\r\n\r\n\u2022\tThe cloud. A scalable distributed filesystem along with a MapReduce processing frame-\r\nwork. See appendix C.\r\n\r\nIt is important to emphasize that even after MVR, the data volumes in the QFDs, cloud\r\nand DISTILLERY are still vast, and we don\u2019t want to ship everything back to Cheltenham.\r\nEverything is distributed across the processing centres, with limited amounts of information\r\nbeing sent between them: queries to the stored data are all federated to the separate processing\r\ncentres, with only the results being sent back to Cheltenham and the analyst\u2019s desktop.\r\n\r\n2.1.3\tAnalysis, reporting and target development\r\n\r\nTraditionally, an analyst would be given a particular target set to look at, and his or her aim\r\nwould be to use the communications of these targets to write reports answering questions of\r\ninterest to policymakers. For example, the target might be the Ruritanian Ministry of Foreign\r\nAffairs (MFA), and the aim to understand their posture in forthcoming negotiations with the\r\nUK; or it might be Kawastan\u2019s air force, and the aim to understand their general intentions\r\nand specific movements in a region where UK forces are currently deployed. The point is that\r\nthe target set is generally well understood, and while looking at the contacts of a known senior\r\nfigure in the MFA might reveal other government ministers or officials worth targeting, the\r\nproblem essentially involves analysing communications carefully selected to be likely to bear\r\non the questions under consideration.\r\n\r\nCounter-terrorism, and to a lesser extent increased work on serious crime, has changed\r\nthis landscape dramatically. The failure of the security services to prevent the 9/11 and 7/7\r\nattacks has been widely dissected, both in the press and in government inquiries here and in\r\nthe US. Targets are no longer neatly identified by their affiliation to a foreign MFA, military, or\r\nintelligence organization: finding the targets in the first place is now one of the most important\r\nproblems facing analysts, before they can even begin to assess their plans and intentions.\r\n\r\n3See appendix F.1.2 for more information on this QFD.\r\n\r\n11\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nContact chaining is the single most common method used for target discovery. Starting\r\nfrom a seed selector (perhaps obtained from HUMINT), by looking at the people whom the seed\r\ncommunicates with, and the people they in turn communicate with (the 2-out neighbourhood\r\nfrom the seed), the analyst begins a painstaking process of assembling information about a\r\nterrorist cell or network.\r\n\r\nBut what about those who simply are not on our radar at all, like the 7/7 bombers? The\r\nmain driver in target discovery has been to look for known modus operandi (MOs): if we have\r\nseen a group of targets behave in a deliberate and unusual way, we might want to look for\r\nother people doing the same thing. For this reason, a whole tranche of problems in this book\r\nlooks at ways of picking out behaviour matching a specific MO in a large dataset. Specific MOs\r\nshould be treated as particularly sensitive; knowledge of MOs can give SIGINT the edge over\r\nour targets who wish to remain undiscovered.\r\n\r\nFor example, sometimes targets will buy separate mobile phones and only use them to speak\r\nto each other, believing this to be good OpSec. In fact, this is unusual behavior that makes\r\nthem stand out. Analysts call these closed loops; to a mathematician looking at a telephony\r\ngraph, they are small components disconnected from the giant component that always forms in\r\ncommunications graphs. Another example is the use of payphones (commonly called telephone\r\nkiosks or TKs), which are an obvious way to communicate anonymously. Looking for calling\r\npatterns between TKs, or between a TK in the UK and a number in (let us say) Pakistan, has\r\nprovided valuable intelligence leads.\r\n\r\nMany of the problems in this book invite you to find new ways to use the data we have to\r\ndiscover things that analysts either could never find by themselves, or would never have the\r\ntime to find in practice. It is important to point out that tolerance for false positives is very\r\nlow: if an analyst is presented with three leads to look at, one of which is probably of interest,\r\nthen they might have the time to follow that up. If they get a list of three hundred, five of\r\nwhich are probably of interest, then that is not much use to them.\r\n\r\nOnce we have targets, clustering or community detection algorithms give us a way to expand\r\nthem into cells without laborious work by analysts. Doing this reliably and at scale is another\r\nfundamental challenge presented in this problem book.\r\n\r\nIt is also worth saying that techniques developed for counter-terrorism analysis can also\r\nfeed back into traditional diplomatic and military analysis. For example, DynamicGraph (see\r\nsection 6) is a way to visualize communication events around a seed set. Many of the ap-\r\nplications have been to counter-terrorism operations, but it was first developed to look at the\r\ncommunications of foreign government officials visiting London for a G20 summit in 2009 [W18].\r\n\r\n2.2\tComputer network operations and the cyber mission\r\n\r\n2.2.1\tCyber\r\n\r\nTraditional diplomatic and military theories imagine nation states engaging in various physical\r\ndomains: land, sea, air and space. The cyber domain is an increasingly important new site for\r\ninteractions between states, and will only become more so as time goes on. The UK government\r\nhas recognized the critical importance of cyber to our strategic position: in the Comprehensive\r\nSpending Review of 2010, it allocated a significant amount of new money to cyber, at a time\r\nwhen almost everything else was cut. Much of this investment will be entrusted to GCHQ, and\r\n\r\n12\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nin return it is imperative for us to use that money for the UK\u2019s advantage.\r\n\r\nSome of the problems in this book look at ways of leveraging GCHQ\u2019s passive SIGINT\r\ncapabilities to give us a cyber edge, but researchers should always be on the look-out for\r\nopportunities to advance the cyber agenda.\r\n\r\nThis section briefly discusses how sophisticated state actors (including ourselves and our\r\nfive-eyes partners) currently conduct themselves in cyberspace. It is important to bear in mind\r\nthat other states, in particular Russia and China, are not bound by the same legal framework\r\nand ideas of necessity and proportionality that we impose on ourselves. Moreover, there are\r\nmany other malicious actors in cyberspace, including criminals and hackers (sometimes motiv-\r\nated by ideology, sometimes just doing it for fun, and sometimes tied more or less closely to a\r\nnation state). We certainly cannot ignore these non-state actors.\r\n\r\n2.2.2\tAttack, exploit, defend, counter\r\n\r\nThere are four basic postures an actor can take in computer network operations (CNO).4\r\n\r\n\u2022\tAttack. This is obviously the most directly aggressive approach. It is commonly referred\r\nto as computer network attack (CNA); at GCHQ, one also hears it called effects. The actor\r\naccesses an adversary\u2019s network and deletes his files, destroys his network connectivity, or\r\ncauses other damage or inconvenience. There has been a lot of discussion, both internally\r\nand externally, about the possibility of a cyber-based attack that could cause physical\r\ndamage beyond the network, for example by shutting down a power station.\r\n\r\n\u2022\tExploit. GCHQ\u2019s first CNE (computer network exploitation) operation was carried out\r\nin the early nineties, and since then CNE has grown to the scale of a small industry\r\nin GCHQ. A typical operation involves establishing a long-term covert presence (an im-\r\nplant ) on a target computer, which sends back (\u2018exfiltrates\u2019) useful information over an\r\nextended time period. You will know from press reports and public statements by the\r\nhead of Security Service that UK networks and those of our allies\u2014both government and\r\ncommercial networks\u2014are in turn routinely targeted by other countries.\r\n\r\n\u2022\tDefend. CESG is responsible for protecting UK networks (primarily government net-\r\nworks, but the security of banks or other companies operating in the UK is also important\r\nfor economic well-being) from hostile CNA or CNE activity\u2014the acronym for this is CND,\r\nor computer network defence. It is important to be able to prevent attacks by rejecting\r\nmalicious packets at sensors or firewalls, and to understand who is attacking us (the\r\nattribution problem), why, and what they are looking for.\r\n\r\n\u2022\tCounter. This is a relatively new approach for GCHQ, which might better be called\r\nactive defence. As we come to understand the CNE infrastructure of a hostile actor, we\r\ncan target that infrastructure and attack it, disrupt its activities, or make use of the data\r\nthat someone else has exfiltrated from a network that is also of intelligence interest to\r\nus (fourth party collection). This is sometimes called C-CNE (counter-CNE), not to be\r\nconfused with CCNE, which was the name of PTD for a few years.\r\n\r\n4This area is rich in jargon: see [W8] for a comprehensive list, along with links to further details on the\r\nsubjects mentioned here.\r\n\r\n13\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nFigure 1: The Cyber Wheel.\r\n\r\n2.2.3\tData mining for cyber discovery\r\n\r\nCNE and CNA activity will leave traces in passive SIGINT. One of GCHQ\u2019s key contentions in\r\ndiscussions on spending for cyber has been that understanding the internet through SIGINT is\r\nthe best foundation on which to build any cyber capability, whether offensive or defensive. This\r\nis the very first stage in the Cyber Wheel (figure 1), which is meant to be a visual representation\r\nof all the aspects of cyber, with SIGINT at the centre. NSA produced a simpler and earlier\r\nvisualization [W43] of the same idea in 2007 (figure 2).\r\n\r\nDuring the initial exploitation of a target box, malicious data needs to be delivered to the\r\ntarget. We (as well as commercial anti-virus and security companies) try to produce signatures\r\nfor these infection vectors, which packets can be matched against.\r\n\r\nOnce machines have been implanted, they will usually perform certain characteristic activ-\r\nities on the network. Two major functions of an implant are beaconing, which involves sending\r\nshort periodic messages back to the implant\u2019s controller confirming that the implant is alive\r\nand available for tasking; and exfiltration, i.e. pulling back data from the target box.\r\n\r\nThe fact that these activities are visible in passive SIGINT presents an OpSec risk to\r\nus [W7], but also an opportunity for data mining to discover hostile CNE activity. The core\r\nof a particular actor\u2019s infrastructure might be quite small, and discovering it can open up a\r\nwhole chunk of their activity to be defended against or countered.\r\n\r\nBotnets are large collections of implanted machines under the control of a single bot-herder.\r\nThey are usually associated with organized criminals rather than intelligence agencies. Again\r\n\r\n14\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nFigure 2: Another view of the relationship between CNO and Digital Network Intelligence (DNI),\r\ni.e. passive network SIGINT.\r\n\r\nthere are stereotyped behaviour patterns associated with botnets: command and control ex-\r\nchanges (also called C&C or C2), which are analogous to beaconing for implants; and coordin-\r\nated activity in a short time window\u2014for example many machines in the botnet simultaneously\r\ntrying to access a website being targeted in a distributed denial of service (DDOS) attack.\r\n\r\nData mining offers the possibility of finding suspicious activity by detecting anomalies or\r\noutliers in bulk data. Temporal analysis and behavioural pattern-matching can be used to\r\ndetect hostile network activity from CNE and botnets, but at present there is very little being\r\ndone in this direction on our streaming data feeds. Several of the problem areas in the rest of\r\nthis document touch on applications to these important cyber problems.\r\n\r\n15\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n3\tBeyond Supervised Learning\r\n\r\n3.1\tIntroduction\r\n\r\nSupervised learning is the machine learning task of inferring a function from training data. The\r\ntraining data is a set of training examples. Each example is a pair consisting of a feature vector\r\nand a desired output value (also called truthed data or labelled data). A training algorithm\r\nanalyses this data and produces an inferred function, which is called a classifier (if the output\r\nis discrete) or a regression function (if the output is continuous). The inferred function should\r\npredict the correct output value for any valid input object. This requires the learning algorithm\r\nto generalise from the training data to unseen situations in a \u201creasonable\u201d way.5\r\n\r\nThere are a vast number of supervised machine learning algorithms which can often produce\r\nfunctions with high accuracies on real-world data sets. However, these techniques have had\r\nsurprisingly little impact in GCHQ. There are various reasons why this has been the case but\r\nthe principal reason has been the difficulty in creating training sets. In particular, the difficulty\r\ncomes from knowing the desired output value for many training examples, either due to the\r\nrequired human effort and/or uncertainty in the desired output value. This difficulty is unlikely\r\nto be a one-off issue for an operational application. The nature of communications and our data\r\nchanges with time and leads to \u201cconcept drift\u201d; any algorithm must be periodically retrained.\r\n\r\nThe aim of this research area is to improve the adoption of machine learning techniques.\r\nWe suggest three ways forward on this area:\r\n\r\n1.\tSemi-supervised learning alters the setup of supervised learning by only knowing the\r\ntrue value for a subset of training examples.\r\n\r\n2.\tA special case of semi-supervised learning is active learning: in this case the training\r\nalgorithm decides which examples it wants to be truthed. The aim is to make these the\r\nmost informative examples rather than waste human effort on randomly chosen cases.\r\nThis point-of-view also naturally works in a streaming context as a way of dealing with\r\nconcept drift.\r\n\r\n3.\tAllow ourselves to work with inaccurate truth data or weak labels. Such an approach\r\nwould allow more automated labelling or reduce the human effort required.\r\n\r\nWe provide some small example datasets that have come from supervised learning problems.\r\nAll examples in these datasets typically come with a label and a truth value. The scale of\r\nthese datasets should not limit your imagination and larger untruthed datasets should often\r\nbe obtainable either from the cloud or from a research area in GCHQ. If a very large number\r\nof unlabelled examples is found to be of value then streaming or MapReduce techniques will\r\nprobably be needed.\r\n\r\nIt is important to note that the aim of this research is not necessarily to maximise the\r\naccuracy of prediction on these datasets. In the main, these datasets are fully-truthed and thus\r\nwe expect that existing research on supervised learning will be competitive. Also these data\r\nsets are fixed and are thus not tracking customer interests or concept drift.\r\n\r\nWe also include the problem of fusion of scores that may be approachable by a natural\r\nextension of the weak labels research area.\r\n\r\n5Paragraph adapted from [W41].\r\n\r\n16\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n3.1.1\tSupervised learning prior work\r\n\r\nSupervised learning has had many applications in the research community but few applications\r\nhave been deployed operationally. Some research examples over the last ten years (along\r\nwith the classifier type used) are: steganography detection (Random Forest) [I74], website\r\nclassification (decision tree) [I36], protocol classification (Random Forest and neural network)\r\n[W1], spam detection (Random Forest) [I44], payphone detection (Random Forest) [I3] and\r\ndrug smuggler detection (logistic regression) [I77].\r\n\r\nRandom Forests\r\n\r\nA common theme in many SIGINT applications is the use of Random Forest classifiers [E6]6.\r\nRandom Forests are an ensemble learning technique [W13]. The base learners are unpruned\r\ndecision trees [W10] which then vote to reach decision. Randomness is inserted into each tree\r\nby two means. Firstly, each tree is built on a bootstrap sample of the training data. Secondly,\r\nthe trees are built in a top-down manner by choosing the best feature at each node from a\r\nrandom subset of the features.\r\n\r\nOne reason for the use of Random Forests may be because they typically produce high\r\naccuracies with little tuning. However our feature spaces may also naturally lend themselves\r\nto Random Forests. Properties of our feature spaces include:\r\n\r\n\u2022\tFeatures are typically based on categorical and count data. Random Forests can handle\r\na mixture of ordered and categorical feature types.\r\n\r\n\u2022\tOur data do not often show simple clusters. Some features (e.g. port numbers in the\r\nprotocol classification example) behave a bit like ordered features and a bit like categorical\r\nfeatures (nearby ports are sometimes associated but not always).\r\n\r\n\u2022\tOur features also show special values. A particular example could be a zero in a count\r\ncould derive from missing data due to limited SIGINT visibility rather than saying any-\r\nthing relevant about the property of interest.\r\n\r\nOne adaptation to Random Forests considered in-house to improve accuracy and help un-\r\nderstand the tuning of Random Forests is weighting of individual trees [I68].\r\n\r\nInterpretability\r\n\r\nA problem with the use of Random Forests is that their decisions can not be simply and intu-\r\nitively explained to an analyst. This black box nature can lower analyst trust in a prediction.\r\n\r\n(NSA R1) has been leading an effort to make Random Forests more interpretable\r\n[I18]. It would be good if semi-supervised models could have a broad-brush interpretability\r\neven if there are some complex exceptions that break these simple interpretations.\r\n\r\n6The NSA were very early adopters of Random Forests through direct contact with\tvia the\r\n\r\nNSA Statistical Advisory Group (NSASAG) [W31]. The NSASAG remain a useful conduit to statisticians at\r\nUS universities [W28].\r\n\r\n17\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nScale\r\n\r\nThe community has also considered scaling training of Random Forests to large datasets for\r\nthe rare cases where one has computer-based truthing.\r\n\r\nThe most trivial scaling is naive parallelisation per tree. To do this one duplicates the data\r\non multiple hosts, grows trees on each host independently and then combines the trees together\r\ninto a final forest. The author of [I74] found this approach helpful in building classifiers for\r\nsteganography detection.\r\n\r\nNSA have looked at ways to implement Random Forests in Hadoop [I8, I4]. In GCHQ we\r\nhave looked at streaming approaches with Random Decision Trees [I61] and Very Fast Decision\r\nTrees [I7].\r\n\r\n3.1.2\tSemi-supervised learning prior work\r\n\r\nSemi-supervised learning is an area of active research in academia (see [E7] for a text-book\r\nreference and [E46, E36] for literature reviews). Given our interest with Random Forests, the\r\nrecent paper on semi-supervised Random Forests may be of interest [E24].\r\n\r\nHowever semi-supervised learning is less well developed in the intelligence community.\r\nLLNL have been considering active learning approaches for finding cyber attacks [I13]. Fran-\r\ncois Theberge at CRI has looked at transductive learning (a special case of semi-supervised\r\nlearning where a predictive function is not learnt at anywhere other than pre-chosen values)\r\n\r\n[I80]. The GCHQ maths summer student programme (SSP) in 2011 have been asked to look\r\nat transductive learning in the context of determining the relationship between entities [W32].\r\n\r\n3.2\tSemi-supervised learning\r\n\r\nSemi-supervised learning algorithms \u201ctypically [use] a small amount of labeled data with a\r\nlarge amount of unlabeled data.\u201d [W38] This viewpoint is very desirable to GCHQ:\r\n\r\n\u2022\tLike many organisations we have large datasets of which only a tiny subset can be truthed\r\nby hand.\r\n\r\n\u2022\tWe have more metadata than content. For truthing we may require content but policy or\r\ndata volumes means that content is only available for a small fraction of the data covered\r\nby metadata. Therefore classifiers that run on metadata but are truthed based on limited\r\n(and not randomly selected) content are desirable.\r\n\r\nTraditionally we have approached these problems with supervised learning and ignored all the\r\nunlabelled data.\r\n\r\nThe overarching question of this research area is can we use semi-supervised learning to our\r\nadvantage? What shape must the problem have for there to be significant benefit?\r\n\r\n3.2.1\tHow useful is semi-supervised learning?\r\n\r\nThere do not seem to be strong theoretical results in academia to explain the benefits of semi-\r\nsupervised learning as opposed to supervised learning. Can we develop an applicable theoretical \u25c4\r\nunderstanding of semi-supervised learning?\r\n\r\n18\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nEven if a theoretical understanding eludes us can we develop useful empirical rules of thumb \u25c4\r\non the value of semi-supervised learning? A simple starting point might be to measure gains\r\nin accuracy based on different approaches for the example SIGINT datasets.\r\n\r\nThere are a range of known semi-supervised techniques; two major classes are: generative\r\nmodels and low-density separation [E7]. Can we tell what type of algorithm one might want \u25c4\r\nto use on a particular dataset?\r\n\r\nWhat is the nature of a good feature space for semi-supervised learning? Are there feature \u25c4\r\ntransformations that could be applied to help this?\r\n\r\nIf our truthing comes from an automated process then we may have untruthed examples\r\nthat have failed automated classification. Alternatively if we truth a meta-data classifier based\r\non content then our truthing will only exist where we have content. In both these examples,\r\nin contrast to the traditional viewpoint of semi-supervised learning, the truthed examples are\r\nlikely not to be independently distributed of the features or classes. In the missing value\r\nimputation literature such truthing would be called \u201cmissing not at random\u201d (MNAR). A\r\npotential approach to handle such truthing is described in [E33]. Can we build valid models\t\u25c4\r\n\r\nwhen the truthing is not independent of the feature space or classes?\r\n\r\nIn the above, we have assumed that each training example can be treated independently.\r\nMany SIGINT datasets have relationships between examples which can be represented as a\r\ngraph. Progress is being made externally on graph-based semi-supervised learning (see [E17]\t\u25c4\r\n\r\nand references therein) - can these external techniques be usefully applied to SIGINT problems?\r\n\r\n3.2.2\tPositive-only learning\r\n\r\nA special case of semi-supervised learning is when we only have labels for some members of\r\none class and want to learn a binary classifier. An example is payphone classification where we\r\nhave lists of some payphones and no labels for other phone numbers.\r\n\r\nIn the outside literature^^^ [E13] presented a Bayesian approach to positive-only learning\r\nbut internally\t[I50] pointed out an error in their approach. However, in the world of\r\n\r\nstatistical testing\thas pointed out that one can still identify the most powerful test\r\n\r\nby considering the quasi-power [I49]. This approach was successfully used in a positive-only\r\nlearning scenario for botnet detection [I71].\r\n\r\nasks, can we find or develop a theorem of the form: \u201ca binary classifier can\t\u25c4\r\n\r\nbe trained if and only if ...\u201d. Can positive-only learning be shown to work with no other\r\nconstraints? This type of theorem would also be relevant to the rest of the beyond supervised\r\nlearning problem area.\r\n\r\nCan we design a new classifier for positive-only learning?\t\u25c4\r\n\r\n3.2.3\tActive learning\r\n\r\nMany approaches to semi-supervised learning present a random subset of the data for truthing.\r\n\r\nThis approach means that human effort is probably wasted classifying examples that have\r\nlittle impact on the learnt function. Active learning instead sets up the truthing process as a\r\nsequential process where the algorithm sequentially chooses examples for truthing based on all\r\nthe information so far at its disposal. A useful review of external research in active learning is\r\n[E37].\r\n\r\n19\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nThe benefits of active learning are uncertain as an algorithm can focus on minor refinements\r\nto the current model and deliberately ignore examples that if truthed would lead to major\r\nchanges to the current model. Do active learning algorithms quickly converge to a good model \u25c4\r\nwhen allowed to choose which truthed items to use from the example datasets?\r\n\r\nA risk with active learning is that after many truthing examples one decides that the chosen\r\nalgorithm is not suitable for the data set. It may not be practical to ask for more truthing with\r\na different algorithm. What happens if you take the partially truthed dataset from one active \u25c4\r\nlearning run and use that dataset with a different semi-supervised learning algorithm?\r\n\r\nActive learning is a process where the algorithm and human are closely coupled and thus\r\nhuman factors are important.\tsuggests looking at active learning\r\n\r\nscenarios where the human is asked to rank two or three items rather then give a score or label.\r\n\r\nThis may be easier from a human factors point of view. Can we design algorithms for active \u25c4\r\nlearning based on ranking pairs? How does the number of example pairs required compare\r\nto the number of truthed examples in traditional active learning? See [E35] for an example\r\nsupervised approach.\r\n\r\n3.2.4\tNew algorithms and implementations\r\n\r\nThe asymptotic complexity of many semi-supervised learning algorithms is not good\r\n(e.g. O(n3), where n is the number of examples, or worse) [E46]. Such complexities are likely\r\nto be prohibitive on large datasets. Ideally we would like algorithms to run in O(n log n) or\r\nbetter.\r\n\r\nWe\u2019d be interested in new accurate and fast semi-supervised learning techniques. The \u25c4\r\nrequirement to scale to large datasets will hopefully lead to streaming and/or MapReduce\r\nimplementations.\r\n\r\nThe SIGINT datasets provided may also inspire new techniques to enhance classification\r\naccuracies.\r\n\r\n(NSA R6) suggests that we may often be in the scenario that we have our\r\ntruthed data as a small data set on which one can do a large amount of in-memory computation\r\nbut our untruthed data as a large dataset in Hadoop. Can a learning algorithm be developed\t\u25c4\r\n\r\nthat iterates between complex in-memory analysis of the truthed data and single table scans\r\nof the untruthed data?\r\n\r\n3.3\tUnreliable marking of data\r\n\r\nAn alternative approach to improve the applicability of machine learning techniques is to allow\r\ninaccurate truthing of data, so called \u201cweak labels\u201d. We think of this case as related to semi-\r\nsupervised learning; in traditional semi-supervised learning you have perfect knowledge of some\r\ncases and no knowledge of other cases - in the case of weak labels this knowledge is diffused\r\nacross the entire dataset.\r\n\r\n3.3.1\tWeak labels\r\n\r\nScenarios where weak labels could occur are:\r\n\r\n20\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nSemi-synthetic data: If suitable training data can not be found we may want to modify\r\ndata to have the properties we want. An example of this is steganography detection [I74].\r\n\r\nWe take a large number of images from SIGINT and add steganography into some the\r\nimages to make our truthed data. Errors will occur as some of these images may have\r\nsteganography before we start.\r\n\r\nAutomated labelling: We might base our labels on content based-signatures that may not\r\nbe accurate (e.g. for protocol classification [I70]).\r\n\r\nNatural error: Even experts make mistakes when labelling.\r\n\r\nExternally the field of weak labels has been rejuvenated by the use of the internet for\r\ntruthing by amateurs, e.g. using Amazon\u2019s Mechanical Turk where one may have multiple\r\nlabels per item [E31]. However, the field dates back many years; for example [E27] showed the\r\nimpact of weak labels on nearest-neighbour classifiers and ^-consistent estimators.\r\n\r\nAnother recent approach has been MIForests [E23] which shows an approach to adapt\r\nRandom Forests to binary classifiers based on sets of inaccurately marked data.\r\n\r\nAs mentioned in section 3.2.2 by looking at quasi-power [I49] we can work directly with\r\nweakly labelled items (with some constraints on the labelling) to identify a most powerful test.\r\n\r\nCan we understand the influence of labelling errors on different techniques? Do some \u25c4\r\ntraditional supervised learning techniques work out-of-the-box with weak labels?\r\n\r\nCan we develop algorithms that understand and compensate for the errors?\t\u25c4\r\n\r\n3.3.2\tFusion of scores\r\n\r\nA problem which might be a natural extension of this work is fusion of scores. For example,\r\nwe have multiple techniques to try to infer a relationship between entities (e.g. from contacts,\r\ntiming behaviour and geo behaviour). These techniques produce scores that are typically real\r\nnumbers between 0 (no relationship) and 1 (a relationship exists). If these were (proportional\r\nto) independent likelihoods then these scores could simply be multiplied. However, these scores\r\nwill not be independent and will not be likelihoods. How can we combine such scores in general? \u25c4\r\nCan we combine such scores to posterior probabilities? How large a deviation from independent\r\nlikelihoods can we cope with?\r\n\r\nThis problem is exactly the problem of weak labels if we treat one score as being a weak\r\nlabel and the rest of the scores as features. We have the added power that we can choose any\r\nfeature as the weak label.\r\n\r\nInternally we have considered score fusion in two main contexts:\r\n\r\nRelationship scoring: CHART BREAKER [I31] research initially looked at handling the\r\nmultiple scores derived from the email communication hypergraph but is currently being\r\nextended to handle multiple communication mediums as part of FIRST CONTACT.\r\n\r\nGeo-reference data: We have multiple sources of data giving us information on the geoloca-\r\ntion of an IP address. The GeoFusion project [I53] and RADONSHARPEN-B [I59] have\r\nlooked at combining country labels and confidences from multiple sources to come up\r\nwith a decision for an IP address\u2019s country.\r\n\r\n21\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nDataset\tRef\t# truthed\t#features\toutput\tnoisy\t+ve only\r\nLogo recognition\tF.4.1\t530\t64\t109 classes\tN\tN\r\nSpam detection\tF.4.2\t1809\t143\t11 classes\tN\tN\r\nProtocol classification\tF.4.3\t799,541\t51\t15 or 39 classes\tN\tN\r\nSteganography detection\tF.4.4\t1,550,000\t661\t(0,1) range\tY\tN\r\nGenre classification\tF.4.5\t~16,000\t108\t2-17 classes\tN\tN\r\nWebsite classification\tF.4.6\t6,705\t200\t4 classes\tN\tN\r\nPayphone detection\tF.3.5\t97,993\tN/A\tBinary\tN\tY\r\nArrival process correlation\tF.1.5\t763,392\tN/A\tBinary\tY\tN\r\n\r\nTable 1: Truthed data sets. Further details about these datasets can be found in appendix F as\r\nreferenced in the second column.\r\n\r\nIf we\u2019re dealing with labels rather than scores then there\u2019s a line of literature in medical\r\nstatistics looking at estimating the accuracy of diagnostic tests. These are based on the Hui-\r\nWalter method of independent tests [E19, E32, E21]. Extensions have now looked at correlated\r\ntests [E11]. [E38] makes the link between these approaches and latent class models and thus\r\nthis problem can be seen to be related to that being considered\tat LLNL for\r\n\r\nlearning with network data [I58]. [E31] shows an extension to real valued functions.\r\n\r\nNSA have also looked at this problem in the context of log-likelihoods that may not be\r\nindependent [I45] (their approach has been reviewed by GCHQ [I26]).\r\n\r\n3.4\tRelevant data\r\n\r\n3.4.1\tTruthed datasets\r\n\r\nWe provide various SIGINT truthed datasets as summarised in table 1. Most of these data\r\nsets consist of features and truthed output for all examples. There are a few exceptions:\r\n\r\n\u2022\tThe protocol classification set has some \u201cNULL\u201d labels for which automated signature-\r\nbased classification failed. This dataset can be seen as an example of a semi-supervised\r\nset where the truthed examples are not randomly chosen.\r\n\r\n\u2022\tThe payphone data set comes with no features. We do not have feature extraction in\r\nHadoop. Implementation of the features in [I3] should not be too large a task and\r\nimplementing a complete system would aid deployment.\r\n\r\n\u2022\tThe arrival process correlation data set has no features extracted. Also the truthing\r\ncomes as two sets where one set is richer in true cases than the other. This data is\r\nincluded as it is an active area of statistical research and overlaps with the information\r\nflow in graphs problem. If features are required for this set then the CLASP scores [I49]\r\ncould be useful features but new approaches would also be welcome.\r\n\r\nFor the fully-truthed data sets in table 1 it is imagined that semi-supervised or weak label\r\nexperiments can be conducted by hiding truth labels or perturbing truth labels.\r\n\r\n22\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nThe steganography detection dataset may also be a good dataset if we want to look at\r\ncost-sensitive feature extraction within the context of semi-supervised learning. The features\r\nare computed in classes, each with a cost. We can give some metrics on these costs if required.\r\n\r\nIt should be remembered that the aim of this problem area is not to maximise the accuracy\r\nof classification on these datasets. These datasets should be used to support improvements in\r\nunderstanding and algorithms.\r\n\r\nA flaw with these datasets is that they are mostly small (having derived from experiments\r\nwith supervised learning). The ability of algorithms to scale to larger sizes should be considered.\r\nThe payphone data may be the most promising one to look at at scale.\r\n\r\n3.4.2\tFusion of scores data\r\n\r\nWe provide fusion of scores data from GeoFusion. Scores in GeoFusion are typically ordered\r\nconfidence labels (\u201clow\u201d to \u201cvery high\u201d) rather than real numbers. We provide the country and\r\nconfidence from four SIGINT systems as well as the Akamai Edgescape commercial geolocation\r\ndataset. See appendix F.5 for more details on this data.\r\n\r\nWe hope that data for fusion of identifier relationship scores will be available soon. Al-\r\nternatively researchers could use existing software to compute scores from telephony or C2C\r\ndata on the cloud themselves - please consult the authors for more guidance on this route if\r\nrequired.\r\n\r\n3.5\tCollaboration points\r\n\r\nThere are several areas where one might find useful collaboration in this problem area:\r\n\r\nICTR-MCA: The Media Content Analysis team are looking to automatically determine\r\nthe relationship between entities based on communication content and think that semi-\r\nsupervised techniques are likely to be needed;\tis leading on this work.\r\n\r\nand\talso think that their work on speaker identification\r\n\r\nmay lead to a semi-supervised problems with weak labels.\tis also plan-\r\n\r\nning to revisit the problem of finding IED triggers in audio content and which may lead\r\nto a dataset with features derived from roughly continuous data (as opposed to many of\r\nthe provided sets being based on discrete data), see [W44] for more details.\r\n\r\nICTR-DMR:\tis leading a major research package on fusion of scores.\r\n\r\nwould also be interested in any developments based on the payphone detection\r\ndataset.\r\n\r\nUS National Labs: At\tand\r\n\r\nare working on active learning for finding anomalies in C2C data.\r\n\r\nat LLNL and\tteam at Sandia National Labs have been\r\n\r\nworking on large-scale machine learning algorithms.\tat LLNL was interested\r\n\r\nin latent class models (potentially linked to fusion of scores) but has now been posted to\r\nAustralia.\r\n\r\nNSA R6:\r\n\r\nis interested in large scale semi-supervised learning algorithms.\r\n\r\n23\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nNSA R1: ^^^^g is always interested in anything that can advance the arrival process\r\ncorrelation score. Also\tis interested in techniques that may improve the\r\n\r\ninterpretability of Random Forests (he particularly mentions the \u201cTreebeard\u201d technique\r\n\r\n[I18]\tas having further research possibilities).\r\n\r\nCRI:\tis working on transductive learning which is closely related to semi-\r\n\r\nsupervised learning.\r\n\r\nIBM Research:\tsuggests that unclassified engagement may be possible with\r\n\r\n(IBM Research) on active learning. ^^g also works with^^^^^^f\r\n^^Jfrom Yahoo Research who has also been working on fast online learning algorithms,\r\nexemplified by Vowpal Wabbit.\r\n\r\n24\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n4\tInformation Flow in Graphs\r\n\r\n4.1\tIntroduction\r\n\r\nThis section of the problem book concerns information flow in graphs. By this we mean the\r\nstudy and discovery of related information or messages being relayed over multiple edges in a\r\ncommunications graph. For this problem we will initially consider working on a static graph,\r\nalthough you should feel free to consider the streaming case if you desire. We get to observe a\r\nset of transactions taking place on the edges of the graph. Given these transactions we would\r\nlike to be able to infer something about likely information flows across multiple edges. In most\r\ncases we will know nothing of the content of the transactions. We therefore wish to focus mainly\r\non techniques which do not require any content knowledge. Data with content should therefore\r\nmainly be seen as truthed data for exploration and familiarisation with existing techniques.\r\n\r\nWe will now provide two motivating examples for our interest in information flow in graphs.\r\nThese are chosen to reflect intelligence interests over the last decade or so.\r\n\r\nThe first example is a target-centric communications network. Consider the graph formed\r\nby telephone calls around a certain target set. Each call, or transaction, serves the purpose of\r\nconveying information between participants. If significant flows could be extracted then this\r\nwould provide information on the structure of the target set\u2014perhaps identifying commanders,\r\nmiddlemen and operatives. Now, if one of the commanders was no longer part of the network\r\nwe could again examine how the flows have changed and therefore gain insight on any reorgan-\r\nisation that has taken place. Further, it may even be possible to identify a significant change\r\nin flows on the graph and identify a change in structure purely from transactional data.\r\n\r\nThe second example is the detection of botnet command and control infrastructure. For a\r\nbotnet to be effective it needs to be able to convey commands from its controller to all infected\r\nnodes. One can imagine that with some knowledge of infected nodes it may be possible to use\r\ninformation flows to trace out the infrastructure, discover further infections, or even track back\r\nto find the botnet\u2019s owner. This type of capability would be of enormous interest due to the\r\ncurrent emphasis on cyber defence.\r\n\r\nWe now define a cascade and discuss how we will use them to summarise the significant\r\ninformation flows.\r\n\r\nFigure 3: Examples of cascades. A downwards pointing triangle is a source and an upwards one\r\na sink. A diamond means the node is both the source and a sink.\r\n\r\n25\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nDefinition 1. A cascade is defined to be a directed connected subgraph with a single source\r\nand one or more sinks, consisting only of directed paths from the source to every sink. Being\r\na source or sink is considered an attribute rather than necessarily having no in or out edges\r\nrespectively.\r\n\r\nFigure 3 shows some example cascades. Subfigure 3(b) demonstrates a cascade where the\r\nsource is also a sink\u2014there is nothing in the definition which prohibits this. Further, we can\r\nimagine situations with an information flow like this. For instance consider a friend to ask their\r\nfriend for a favour and then having the response relayed back.\r\n\r\nCascades can be used to represent significant, repeated information flows on the graph. Each\r\ndirected edge in the cascade, starting from the source, should occur no earlier in time than its\r\npredecessors. Algorithms developed should probably output such representative cascades.\r\n\r\nWe are interested in techniques which do not depend upon having the content of transactions\r\nas this limits their applicability. This is because much metadata is of the form \u201cA communicated\r\nwith B at time t\u201d, with few or no clues to what the content of that communication was. Because\r\nour data is in this form we place a particular emphasis on temporal correlation when surveying\r\npast work.\r\n\r\nThis section of the problem book has a relatively small number of wide problems. This\r\nis because the main problem of information flow definition and discovery is meant to be open\r\nended with plenty of scope for exploration and experimentation7.\r\n\r\n4.2\tPast work\r\n\r\nWe will now describe past work in related areas of research, with a particular emphasis on\r\ninternal research. We will introduce key areas of work, give a sketch of their workings and\r\nprovide references for further reading. External work discussed should be seen as a sample\r\nrather than a definitive list.\r\n\r\nThis subsection will first discuss methods on graphs, starting with explicitly temporal ones\r\nand then moving on to static ones. We will then discuss the extensive research that has\r\nbeen conducted on temporal correlation of stochastic processes. We expect that research on\r\ninformation flow in graphs may want to draw on all areas, perhaps applying our knowledge on\r\ntemporal correlation in a graphical setting.\r\n\r\n4.2.1\tGraphical methods\r\n\r\nThere have been several approaches used to exploit timing information present in transactions\r\non graphs. If two vertices participate in timing patterns then it is likely that they are closely\r\nrelated. Further if one of these vertices is a target then the other may be worth investigating\r\nmore closely.\r\n\r\nThe first temporal graph algorithm in GCHQ was Remit, developed under contract by\r\nDetica for ICTR-DMR [I78]. A large amount of subsequent research can be seen to have been\r\ndirectly triggered by the Chains analytic within Remit. Chains is about the simplest approach\r\npossible to finding information flow in graphs. One simply defines a maximum time allowed\r\n\r\n7The problem \u201cFind and score related stochastic processes\u201d has already had many man-years of research\r\neffort expended across dozens of approaches.\r\n\r\n26\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nbetween transactions on adjacent edges and a minimum flow length. The Chains algorithm\r\nwill then find all flows satisfying these conditions. Despite this simplicity trials showed that\r\nit could produce useful intelligence when applied to a target-centric telephony graph [I41].\r\nUnsurprisingly, given its fixed time window, Chains had issues with flows spuriously going\r\nthrough vertices with a high activity rate. This motivated the next stage of research in temporal\r\ngraph methods.\r\n\r\nPRIME TIME [I42] was the next approach created. PRIME TIME introduced a statistical\r\nmodel to compensate for varying vertex activity levels. Specifically an exponential distribution\r\nis fitted to a vertex based upon its mean time between transactions. This exponential is used to\r\ncalculate a p-value on waiting times for transactions on pairs of adjacent edges. If the p-value is\r\nless than some critical value then the transactions will be considered related. Furthermore the\r\np-values are collected for future scoring of long and/or repeated flows. However the methods\r\nof combination used are ad-hoc and not statistically motivated. The original PRIME TIME\r\npaper talks of chains of related edges, although in practice only length 2 were computed. Even\r\nso this suggests the beginning of the study of information flow in graphs.\r\n\r\nCurrently a streaming version of PRIME TIME is being developed by Detica for the Stream-\r\ning Analysis team in ICTR [I63].\r\n\r\nHIDDEN OTTER is an ICTR-NE prototype that similarly tries to find temporal chains\r\nin communications data [I62]. In particular they are interested in finding things such as back-\r\nhaul networks, TOR networks and botnet structures. It has the simple approach of finding\r\ntemporally ordered chains of transactions on edges starting from a specified set of seed nodes.\r\nHIDDEN OTTER is essentially a reinvention of the Remit Chains algorithm, but in Hadoop.\r\n\r\nBAKER\u2019S DOZEN is a technique for finding batches of near-sequential phone numbers\r\nthat display causal behaviour [I11]. Given population-level telephony data it generates a list of\r\npairs of telephone numbers that are near-sequential. For each of these pairs it conducts tests to\r\ndiscover if they are causally related. One of these tests is temporally correlated communications\r\nwith the same third party. This third party condition is important at population level as\r\notherwise there are too many random coincidences due to identifiers merely being active at the\r\nsame time. CLASP8 was rejected for having little statistical power due to exactly this reason.\r\nThe BAKER\u2019S DOZEN test measures the proportion of events which involve a common third\r\nparty and occur within t minutes of each other. A beta distributed prior and most powerful\r\nvalue for t were learnt from the data. The causal threshold was learnt by evaluating the statistic\r\nfor 20 million random pairs and then choosing the value which led to a p-value of 10-6. This\r\nstatistic proved to be powerful in the sense of promoting many pairs above the causal threshold.\r\n\r\nThere has been a large amount of research on information diffusion and cascades in the\r\nexternal literature e.g. [E44, E18, E25, E29]. However the focus has tended to be on datasets\r\nwhere one can directly observe the pieces of information flowing through the network. Examples\r\ncould be hashtags through Twitter or the spread of disease through a contact network. R66\r\nat NSA have developed a MapReduce algorithm based on [E18] to track the passing of files\r\nbetween implanted machines [I35]. The reading rack for this problem (on [W24]) contains a\r\nnumber of citations of external papers considering information cascades and diffusion. Those\r\npapers should provide a good starting point in the literature, but is nowhere near exhaustive.\r\n\r\nInternally there has been some research on block modelling [I28, I29, I30]. Block modelling\r\n\r\n8Covered in subsection 4.2.2.\r\n\r\n27\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (vl.O, r206)\r\n\r\nTime\r\n\r\n----------------\u25ba\r\n\r\n0.2  i  1 i i\t0.3  L\t,  1  1\t\t\t0.4  L\t,  1  1\t\r\nl  l  i  i\t\t\t\t\t\r\n\r\nFigure 4: An example of the non-homogeneous Poisson process used in [149, 164, 152]. Here we\r\nare testing the hypothesis that R\u2019s events are triggered by As. We therefore \u201cproject\u201d \u00a3Ts events\r\nonto A's timeline: the first falls 0.2 of the way between two A events, the second 0.3 and the third\r\n0.4. This figure is adapted from [164]\r\n\r\nassumes that vertices in a graph each belong to different classes. The communication between\r\nvertices is then determined entirely by their classes. The job of a block modelling algorithm\r\nis therefore to assign vertices to classes and describe how the classes interact with each other.\r\nAlthough this has not so far considered information flows there is the possibility that they could\r\nbe useful for block modelling. Further the outputs of certain block models may be interpretable\r\nin a similar manner to potential applications of information flows. For instance both may be\r\nable to distinguish directors, middle managers and workers in a company hierarchy. Is it\r\npossible to use block modelling to inform the discovery of information flows?\r\n\r\n4.2.2\tTemporal correlation\r\n\r\nInternally there has been much research undertaken in understanding temporal correlation\r\nbetween stochastic processes. This work should be a great aid in tackling the information flow\r\nin graphs problem area, especially when the information cannot be directly observed flowing\r\nover the graph. If we are interested in comparing adjacent edges then this work is directly\r\napplicable by restricting the scored processes to those with a common vertex.\r\n\r\nThis research started in 2005, motivated by a desire to find cross-media temporal correla-\r\ntions. An example of a cross-media correlation would be A calling B to arrange for B to initiate\r\nan instant messenger conversation with him. [149] found that modelling the stochastic processes\r\nas non-homogeneous Poisson processes (NHPP) gave the best performance of the approaches\r\nattempted. This contrasts to PRIME TIME which models activity as a homogeneous Pois-\r\nson process. Assuming that one can model the rate function of the NHPP correctly then the\r\nevents of unrelated processes should fall uniformly with respect to each other. Figure 4 shows\r\nan example of this mapping. All tests seek to find deviations from this null hypothesis. The\r\noriginal paper proposed 14 tests for non-uniformity, some of which place particular emphasis\r\non the start of the interval.\r\n\r\nOngoing research on this strand of temporal correlation can be seen to fall into two areas:\r\n\r\n28\r\n\r\nThis information is exempt under the Freedom of Information Ac^OO^FOIA^nAriay b^xemp^mdei^theiAK\r\ninformation legislation. Refer any FOIA queries to GCFIQ on\tor\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\ntesting for non-uniformity and improving rate function estimation. The current best test for\r\nnon-uniformity is the PCG statistic [I64]. This uses the fact that if there are k points uniformly\r\ndistributed on (0,1) then the first of these is distributed according to a Beta(1,k) distribution.\r\nOne can then calculate a left-tail p-value for each interval and combine them using Fisher\u2019s\r\nmethod. This simple method beats more complicated approaches [I6, I39, I23, I65] on the\r\nstandard datasets. The current best technique for rate function estimation is described in\r\n[I52]. This is a two stage process. Firstly one clusters the set of stochastic processes. Secondly\r\none counts time not in seconds but in the number of events that have occurred within a process\u2019\r\ncluster. It is worth contemplating why this works. Consider the phones belonging to GCHQ\r\nemployees - these cannot be brought into the building and so are very quiet between 9 and 5. If\r\nan employee turns their phone on at the end of the day and responds to a voicemail left earlier\r\nin the day then this activity has been triggered despite the multi-hour gap. By performing this\r\ntransformation we turn this from a gap of many hours to one of a few events and we are better\r\nable to spot the causality.\r\n\r\nThe slide deck [I47] contain details of much of the research conducted before October 2010.\r\nThis does not however include the cluster-based rate estimation from [I52].\r\n\r\nResearch into a streaming implementation of the PCG algorithm has been conducted in R1\r\nat NSA [I51]. The work focuses mainly on data structures and approximations to allow the\r\nalgorithm to remain within main memory. However given the large size of some of the datasets\r\nfor this problem the techniques outlined may be useful should scaling prove to be a problem.\r\n\r\nR1 have started to investigate using inference on a parametric model for how causal time\r\nseries are generated [I24]. This proposes a mixture model where B\u2019s events happen either\r\naccording to an underlying Poisson process or because of a causal A event. They demonstrate\r\nthat this is a continous Markov process and formulate tests on whether given pairs of stochastic\r\nprocesses are likely to be correlated. When the model assumptions are correct their likelihood\r\nratio statistic is tens of times more powerful than the best general methods known at small\r\nsizes for some generating parameters.\r\n\r\nMany of these techniques are included in the CLASP software package, with new methods\r\nadded once demonstrated as useful.\tmaintains CLASP. It is available on the LID\r\n\r\nat /data/cryptomath_research/windata/infoproc/Software/CLASP/\r\n\r\nSAGA is a technique which extends a measure of item similarity to set similarity [I48]. It\r\nhas provably desirable properties and has case studies that have demonstrated its utility. In\r\nparticular it has been used as a method for performing temporal correlations. If one treats a\r\nstochastic process as a set of times and defines a similarity measure between times then SAGA\r\nmay be applied to measure the similarity of pairs of stochastic processes. This approach is\r\nradically different to anything else attempted and can perform surprisingly well on the standard\r\nCLASP datasets.\r\n\r\n4.3\tWhat we care about now\r\n\r\nThis subsection will set out the problems that are of interest regarding information flow in\r\ngraphs.\r\n\r\n29\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n4.3.1\tDefinition and Discovery\r\n\r\nThe first and most fundamental problem is the definition and discovery of information flows \u25c4\r\nin the graphs. This document deliberately declines to provide a mathematical definition of an\r\ninformation flow. There is not an immediately obvious definition and therefore it seems best\r\nto leave this as part of the problem. It was suggested by\tof R1 that it may\r\n\r\nbe a good idea to start from how you would define it given perfect information and then work\r\nbackwards. However hopefully the examples given in the introduction sufficiently illustrate the\r\ntype of things we hope to find. Further thinking about cascades as previously defined may help\r\nwith a definition.\r\n\r\nof R1 suggested an approach for defining repeated information flows. One could\r\nphrase it as learning a distribution over when/which edge will have a transaction next given\r\nprevious (and possibly future) activity on adjacent edges and further information, such as time\r\nof day. Repeated information flows could then be seen as high likelihood paths through this dis-\r\ntribution. Can such a probability distribution be written down in a form where (approximately) \u25c4\r\nevaluating it is tractable?\r\n\r\nThe Enron and SKB datasets are atypical of SIGINT data in that there is information\r\non the content available. However this should be very useful for formulating definitions of\r\ninformation flow as it will be easier to see the flows occurring. In the SKB the flows correspond\r\nto various media being passed around the internet. The circulation of extremist media is of\r\nparticular intelligence interest. It is suggested that these datasets be seen as truthed data and\r\nfor gaining familiarity with techniques suggested in the literature. We are less interested in\r\ndeveloping new techniques which depend upon having the content of transactions as this limits\r\ntheir applicability. We are therefore probably restricted to extracting flows which repeat rather\r\nthan occur singly. What do the SKB and Enron datasets tell us about how well we can extract\t\u25c4\r\n\r\ninformation flows without content? Can we perform exploratory data analysis on the SKB to\t\u25c4\r\n\r\ninform the definition and discovery of flows? Can we spot typical transfer patterns?\t\u25c4\r\n\r\nResearch on improving CLASP has been aided by the availability of two standard datasets.\r\nThese each consist of two subsets\u2014a random sample of processes for which there is no reason\r\nto believe any relationship exists, and a sample of pairs for which there is some external reason\r\nto believe a relationship may exists. This allows ROC curves [W34] to be compared between\r\ntechniques and an objective comparison to take place. Can similar datasets and comparison \u25c4\r\nmechanisms can be created for this problem and therefore help drive research collaboration?\r\n\r\nThere have been many different approaches to temporal correlation, both explicitly graph-\r\nbased and not, as demonstrated in the previous subsection. Can we find a theory that unifies \u25c4\r\nthese approaches? One possible direction is to consider having placed a prior distribution on\r\nthe probability of a significant temporal correlation being present. For example CLASP can\r\nbe seen as putting a uniform prior over all pairs of edges, while PRIME TIME is uniform only\r\nover edges sharing a common vertex.\r\n\r\n4.3.2\tMissing data and noise\r\n\r\nSIGINT data is almost always incomplete. In terms of this problem certain edges may not\r\nhave been observed or some transactions on edges may be missing. In experiments carried out\r\non billing records and SIGINT during the 2008 graph mining SWAMP at HIMR there was\r\n\r\n30\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nshown be a huge disparity between our view of the world and ground truth [I73]. CSEC have\r\nperform similar analyses with similar conclusions [W4]. It is therefore important to be resilient\r\nto missing data, especially where a flow may be cut in two. An internal example of coping with\r\nmissing edges is SALTY OTTER [W37]. It uses CLASP to find likely cross-media triggering\r\npatterns, for example telephone conversations typically causing instant messenger chats. The\r\ntool is essentially coping with the missing edge and allowing the information flow to carry on\r\nregardless.\r\n\r\nThere has been some external work on how sampling or missingness affects the appearance\r\nof information diffusion and cascades. [E9] evaluates how different sampling strategies affect\r\nthe view of hashtag diffusion in Twitter. Clearly we do not generally get to choose how our\r\ndata is sampled, but this work may help the understanding of how well/poorly we are likely\r\nto do. [E34] goes further in proposing a method to correct for missing data in information\r\ncascades. Their method assumes that cascades are k-trees, each vertex in the graph is sampled\r\nwith uniform probability and the graph structure is known for sampled vertices. Given these,\r\nthey claim to be successful in reconstructing properties of the original cascades. These external \u25c4\r\napproaches assume that we have the content of a transaction\u2014is there anything we can do\r\nwhen we do not?\r\n\r\nThe obvious approach to this problem is to remove edges/transactions from a dataset to\r\nsimulate poor collection. We can then evaluate different coping strategies by seeing how our\r\nperformance is impacted. Here the Enron dataset is probably a good place to start, as we\r\nhave ground truth and can uniquely guarantee that it is the complete dataset. However any\r\ntechnique developed must behave sensibly on SIGINT data.\r\n\r\nThe data that we do have has further problems beyond missingness. In particular the\r\nquality of the timing information is not as good as we might hope for. This presents at least\r\ntwo concrete problems. Firstly, our data tends to have second timestamps, which may be\r\ntoo coarse a measure for many applications. Does the granularity of the timestamps affect\t\u25c4\r\n\r\nour chances of finding causal flows? Secondly the clocks on our probes are not synchronised.\r\n\r\nThis means that there is likely to be a constant offset between events happening on different\r\nbearers. Any technique to correct for this offset will both aid this problem area and be of\r\ngeneral interest to the internal data mining and information processing community. Can we \u25c4\r\ncorrect for the clock offset between probes? Possible solutions may involve examining the same\r\nconnection being intercepted on different bearers.\r\n\r\n4.4\tPotential future interests\r\n\r\nThere are further problems in this area that may become tractable as the subject knowledge\r\ngrows.\r\n\r\n4.4.1\tPerforming inference on flows\r\n\r\nAssuming that information flows can successfully be identified and extracted we should then be\r\nable to perform inference on/with them. The obvious first area to investigate would be anomaly\r\nand change detection. The interest in this was hinted at in the introduction in investigating\r\nhow a target network changes after the removal of a commander. Given that this document\r\ndoes not even define a flow then it is not reasonable to scope this future problem any more\r\n\r\n31\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\ntightly. Should you reach a point where you can tackle this problem you should have a good\r\nidea of what anomalies and changes mean within the framework you have developed.\r\n\r\n4.4.2\tInformation flow for graph generation\r\n\r\nThere are many existing models for graph generation. Examples include the Forest Fire al-\r\ngorithm [E26] and Bollobas-Janson-Riordan family of graphs [E5]. However, these approaches,\r\nalthough sequential, do not describe how graphs are truly generated. That is, they do not\r\naccurately correspond to how a graph, and the transactions on it, are generated in reality. If\r\nthe definition and discovery of information flows is successful then it may be possible to use the\r\ndescriptive models for graph generation. This feels far closer to how graphs are really gener-\r\nated. Each transaction is undertaken to convey information. Therefore adequately modelling\r\nthe flows leads to the observations.\tof\tmay well be\r\n\r\ninterested in such ideas as he has stated dissatisfaction with the existing approaches. There is\r\nprobably limited SIGINT interest in this problem unless a convincing argument can be made\r\notherwise. We know of no internal work on any subject which has used any graph generation\r\nalgorithm.\r\n\r\n4.5\tRelevant data\r\n\r\nWe have several relevant datasets with truthed data, of which some have already been men-\r\ntioned in the main body of this section.\r\n\r\nThe Enron (appendix F.2.1) and SKB (appendix F.1.4) datasets are atypical as most\r\nSIGINT data does not have any content associated with it. They can be treated as truthed\r\ndatasets for the evaluation of algorithms for extracting significant information flows.\r\n\r\nWe also have a large dump of FIVE ALIVE (appendix F.1.2) that summarises all IP con-\r\nnections on research bearers. There is no content associated with this data. We do have some\r\ntruthing on flows that may exist in the data. Specifically, we have data on covert infrastructure\r\n(appendix F.3.3) used for exfiltrating data from CNE implants. These suspected flows can be\r\nused for both EDA and evaluation purposes. Further, we have lists of IPs that we suspect to\r\nbe infected with the Conficker botnet (appendix F.3.4), either due to signatures collected or\r\nbehavioural analysis. Again, we suspect that there are some information flows involving these\r\nIP addresses.\r\n\r\nWe also provide two standard datasets used for evaluating temporal correlation algorithms\r\n(appendix F.1.5). If you have any insights on how to perform temporal correlation due to your\r\nwork on this problem you may wish to use these for evaluation purposes.\r\n\r\n4.6\tCollaboration points\r\n\r\nThere are several collaboration opportunities available for information flow in graphs.\r\n\r\nNSA R1\tcoordinates the research into temporal correlation and is always happy\r\n\r\nto hear of new ideas and approaches. He also indicated an interest in this new research\r\narea.\r\n\r\n32\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nICTR-DMR The temporal analysis tools PRIME TIME and SALTY OTTER were developed\r\nin ICTR-DMR. Although they currently are not working in this area they would certainly\r\nbe interested in any results.\tshould be your first contact in ICTR-DMR.\r\n\r\nICTR-NE ICTR-NE are interested in using information flows to find Tor routes, identify\r\nbackhaul routes and map botnets. They currently have a Hadoop prototype called HID-\r\nDEN OTTER which performs simple temporal chaining. They would be very interested\r\nin any work you produce and may wish to collaborate. HIDDEN OTTER was produced\r\nby\tand|\r\n\r\nICTR-CISA The streaming analysis team have had a streaming PRIME TIME developed\r\nby Detica. They are always interested in streaming algorithms and deploying them as\r\nresearch prototypes. If your research takes you in a streaming direction then you should\r\ncontact the streaming analysis team led by\r\n\r\nCCS Bowie\tof Georgia Institute of Technology is a leading academic figure in\r\n\r\nlarge graph analysis. He is cleared and has previously worked as a consultant in NSA\r\nR1. He is now in the process of joining CCS Bowie in a similar role. He is interested in\r\nthis problem area and may be a possible collaborator on both classified and unclassified\r\nwork.\r\n\r\nUS National Labs At Sandia National Laboratory\r\n\r\nresearch on large graph processing for defensive analysis.\r\n\r\nand\r\n\r\nare leading\r\n\r\n33\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n5\tEDA on Streams\r\n\r\n5.1\tIntroduction\r\n\r\n5.1.1\tEDA\r\n\r\nExploratory data analysis (EDA) is all about trying to find interesting features of data\r\nwithout necessarily having pre-formed hypotheses to test. One of the pioneers of EDA was\r\nJ. Tukey [E41, E42], who argued for the value of EDA over the traditional statistical approach,\r\nwhich he called confirmatory data analysis, where one starts with an hypothesis and collects\r\ndata in order to test it. In EDA, the data comes first, and what counts is understanding the\r\ndata as it is.\r\n\r\nFor the data analyst, this is an open-ended problem that is not tightly defined, but for the\r\nmathematical researcher developing algorithms, things are much more concrete. The aim is to\r\nuse one\u2019s intuition, guided by domain-specific knowledge from the analysts, to develop precise\r\nalgorithms that provide human insight on the data.\r\n\r\nWe usually think of EDA as being concerned with\r\n\r\n\u2022\tpulling out global properties of data;\r\n\r\n\u2022\tbroad-brush visualizations of data.\r\n\r\nThe second is really a variant of the first: we can reduce the data to more discrete values\r\nthan a human could take in in a list or table, as long as there is a way to visualize them.\r\n(Compare summarizing pairs by a correlation coefficient, or in a scatter-plot.)\r\n\r\n5.1.2\tStreams\r\n\r\nIn a stream we do not have enough memory to store everything we see, and we only get to\r\nsee each piece of data once. Many problems admit simple approximate solutions in the static\r\nsetting by subsampling. In the stream, this option is not always available. The problems\r\nbecome much harder and controlling error estimates in approximate solutions is very difficult.\r\nOn the other hand, streaming analysis gives us the opportunity to get situational awareness\r\nand real-time tipping from our data, as well as letting us process bigger datasets than we can\r\nafford to store. These are key benefits that we strongly want to capitalize on.\r\n\r\nFor hands-on work, we are thinking of DISTILLERY, as opposed to Hadoop (see appen-\r\ndices B and C).\r\n\r\nOne way to think about the problem is in terms of data structures. There are only a\r\nfew structures that we typically use to keep track of data when we write programs: lists, trees,\r\nheaps, hash tables and so on. What carries through to the streaming setting? Which structures\r\ncan we update in a stream? If we can tolerate some loss, can we maintain approximations to\r\nfamiliar data structures in the stream? If so, can we quantify and bound the errors? These\r\nstreaming data structures are then the building blocks for streaming algorithms. Given a\r\nparticular data stream, what is an appropriate data structure that will capture what we need\r\nto know about the data in order to answer the SIGINT questions we have?\r\n\r\nA short survey summarizing various approaches to streaming data can be found in [E39].\r\nThe 2009 Information Processing SCAMP at La Jolla also produced relevant material [I12].\r\n\r\n34\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nNote on terminology\r\n\r\nWhen we speak of streaming graph algorithms at GCHQ, we are usually referring to what the\r\nexternal literature calls the semi-streaming paradigm. If the graph has n vertices, then we can\r\ntypically store a small amount of information for each vertex, but we are not able to store all\r\nthe edges or do any significant processing as each edge arrives. In other words, we assume we\r\nhave O(n log n) storage, and can do O(1) work per event. (Usually this can be O(1) amortized\r\nwork, as long as this does not cause undue back pressure: see section B.5.1.)\r\n\r\n5.1.3\tThe problems\r\n\r\nThe problem areas on this topic overlap at the edges, and also tend to merge into the streaming\r\nexpiring graphs problems, but to give some order to this section we loosely cluster them into\r\nfour areas:\r\n\r\n\u2022\tgraph problems with no sub-sampling allowed;\r\n\r\n\u2022\tvisualization;\r\n\r\n\u2022\tmodelling and outlier detection;\r\n\r\n\u2022\tprofiling and correlation.\r\n\r\n5.2\tGraph problems with no sub-sampling\r\n\r\n5.2.1\tThe framework of graphs and hypergraphs\r\n\r\nEvents data frequently has a natural representation as a graph, or more generally a hypergraph.\r\nOften, an event will be a communication between two entities, which we think of as an edge\r\nbetween two vertices, one vertex for each entity. There will normally be a notion of the\r\noriginator and recipient of the communication, which makes the graph into a directed graph.\r\nSometimes, a communication can involve more than two nodes, in which case we can think of\r\nit as a hyperedge, and the overall structure a hypergraph9. We also look at graphs other than\r\ncommunications graphs: for example, colocation graphs, where vertices are joined by an edge\r\nif they were geolocated to the same place at the same time; network graphs, whose edges are\r\nphysical links; or even semantic graphs, where nodes are concepts and edges relations between\r\nthem.\r\n\r\nFrequently, our data will come with additional information beyond the simple fact that\r\na communication took place. For example, each vertex will have a boolean attribute, \u2018Is\r\nthis entity a target in BROAD OAK?\u2019 Similarly, edges might have attributes like \u2018duration\r\nof communication\u2019. A common metaphor is to think of discrete attributes as colours and\r\ncontinuous attributes as weights. Although we often need to do algorithmic computations on\r\nthe underlying graph or digraph, taking account of the available attributes can enrich the\r\nSIGINT value of any analysis we do.\r\n\r\n9Some people prefer to think of simple hypergraphs as bipartite graphs, where the vertices and hyperedges\r\nare the two parts, and edges represent inclusion.\r\n\r\n35\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nWe are interested in finding global properties of graphs in a stream\u2014exactly if possible, but\r\nwe expect that approximate solutions will often be the best we can hope for. This is obviously\r\nclosely related to the streaming expiring graphs topic, but in our case we are not worried about\r\nexpiring edges, and we focus more on counting rather than identifying and extracting graph\r\nstructures. Probabilistic counting in general (not specifically in a graph context) has been an\r\narea of active research both internally [I72, I40, I5] and externally [E16, E8] in recent years.\r\n\r\n5.2.2\tCliques and other motifs\r\n\r\nAn n-clique is a subgraph isomorphic to a complete graph Kn. In a communication graph, this\r\ncorresponds to an intuitive idea of a strong, close community, where everyone communicates\r\nwith everyone else.\r\n\r\nFor EDA purposes, we would like to understand the clique structure of a streaming graph.\r\nWhat are the cliques? If a target node belongs to a k-clique, how surprising is that?\r\n\r\nOne way to answer the second question is to get a good random graph model for the\r\ncommunication graph, and do Monte Carlo simulations to find out how likely k-cliques are to\r\noccur in the model graphs. There has been a lot of work on this, for example [I1, I57], but it has\r\nproved very difficult to find models that capture all the relevant properties of SIGINT graphs,\r\nor even to understand exactly what \u2018relevant properties\u2019 we want to capture. An alternative\r\napproach is to just work empirically with the graph we see, and try to estimate how many\r\nk-cliques it has: this gives us some measure of how surprised we should be if target nodes\r\nbelong to such a clique.\r\n\r\nThis leads us to consider probabilistic counting. We might want to count not just cliques,\r\nbut other subgraphs too: perhaps a clique with one edge missing. A motif in a graph is a\r\nsubgraph isomorphic to a particular pattern graph: for example, when the pattern graph is a\r\nKn, the motifs matching it are the n-cliques. There are probabilistic algorithms for counting\r\nthe cardinality of a set: for example, Flajolet et al.\u2019s hyperloglog sketches [E16], proposed\r\non the outside and extended internally by\t[I72]. There are also a variety of\r\n\r\nalgorithms for counting triangles, i.e. 3-cliques. One example is [E40];\t[E8]\r\n\r\nhas produced a good survey.\r\n\r\nIs there a probabilistic counting algorithm for cliques or other motifs in a streaming graph? \u25c4\r\nWhat can we say about error bounds?\r\n\r\nBesides counting, we might also be interested in motif collection. If we have two fixed\r\ntarget nodes then motifs containing both nodes will give information about their common\r\nneighbours. For example, how many distinct V-shapes or squares contain them both? Some\r\nCSEC work [I21] from a few years ago may be relevant.\r\n\r\nCan we collect specified motifs containing a target node or nodes?\t\u25c4\r\n\r\nRemoving pizza nodes (i.e. very high-degree nodes) is likely to be an essential prior com-\r\nponent to get useful results. Intuitively, a pizza node is likely to be a large impersonal entity\r\nlike a pizza parlour or an electricity supplier: the fact that two people both communicate with\r\nthe pizza node gives us no reason to think that they are linked socially.\r\n\r\n36\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n5.2.3\tTrusses\r\n\r\nLet k > 3. A k-truss is a connected graph with > 2 vertices such that every edge of the graph is\r\nreinforced by at least k \u2014 2 pairs of edges that make a triangle with that edge. This concept was\r\ndeveloped\tat NSA: the idea is to weaken the definition of a clique (any k-clique\r\n\r\nis certainly a k-truss) to allow for a few missing edges, but still capture the notion of a cohesive\r\ncommunity, and at the same time produce something that is computationally tractable.\r\n\r\nPeople in the SIGINT community have looked quite a bit at trusses, following on from the\r\nfoundational theoretical work\t[I15, I14] on properties of trusses, their relationship\r\n\r\nto cores and cliques, and streaming algorithms to find them. In particular, there has been\r\nsome experimental work [I76] looking at trusses in communication graphs. The findings were\r\nsurprising: there turned out to be huge k-trusses for quite large values of k, like k = 17. This\r\nwas true even after splitting trusses at cut-points. A number of variants and generalizations\r\nhave also been proposed (for example [I16, I17]).\r\n\r\nWe would like to understand why these form. Is there a better definition of truss that \u25c4\r\ncaptures something like a closed-loop intuition (see section 2.1.3) without pulling in huge mon-\r\nstrosities?\r\n\r\nIn particular, as we have mentioned, a truss can have cut-points, i.e. single vertices whose \u25c4\r\nremoval disconnects the graph. On the other hand, trusses have high edge connectivity: one\r\nhas to remove at least k \u2014 1 edges from a k-truss to make it disconnected. Can we define truss-\r\nlike structures with a different balance of vertex and edge connectivity? Do giant structures\r\nstill form?\r\n\r\nCan we use a partial order derived from truss or core structures to perform hierarchical \u25c4\r\nclustering? If so, can we avoid forming giant clusters?\r\n\r\nCan we understand when community detection or clustering algorithms produce giant \u25c4\r\nclusters? Are there ways to prove (given some probabilistic model for the graph) that with\r\nhigh probability an algorithm will not produce large clusters? One specific suggestion by ^\r\nis to look at clique percolation [E4] where there are multiple labels per node.\r\n\r\nWhat is the background distribution of sizes of k-trusses? Is there a probabilistic solution \u25c4\r\n(cf. the previous section)?\r\n\r\n5.2.4\tOther approaches\r\n\r\nThere are also more open-ended questions about streaming algorithms for graphs.\r\n\r\nWhat graph invariants are both useful and can be found or approximated in a stream? \u25c4\r\n\r\nIn the academic world, there is a whole cottage industry devoted to coming up with new\r\nclustering algorithms. Many will not have much use beyond allowing someone to publish a\r\npaper. Is there a hidden gem in the open literature that the SIGINT community has missed? \u25c4\r\n\r\nThis problem obviously has the potential to lead one off down rabbit holes. As a concrete\r\nthing to look at, the first author has identified BIRCH [W3] as an algorithm that may deserve\r\na hearing.\r\n\r\nCan we compute any measurements of centrality or betweenness in a stream? (We are \u25c4\r\nmore interested in centrality measures in subgraphs around targets: CHART BREAKER [W6]\r\nvertex scores do something like this.) How stable are they as the graph evolves? Is there\r\nconcept drift?\r\n\r\n37\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nCan we approximate the graph distance distribution, and see how it varies with the pizza \u25c4\r\nthreshold?\r\n\r\nThis has a bearing on what hop distance we should choose for contact chaining. Conven-\r\ntionally, analysts focus on a 2-hop neighbourhood of their targets, but some work comparing\r\nbilling records with SIGINT [I73] found that one needed to chain much, much further through\r\nSIGINT to reach a 2-hop neighbourhood from billing data. Can we use the SIGINT to billing \u25c4\r\nmapping (SOLID INK to FLUID INK\u2014see appendix F.1.6) to help decide what the right thing\r\nto measure on a telephony graph is?\r\n\r\nCSEC have also done some work [W4] on comparing SIGINT and billing records. Billing\r\ndata is unlikely to be shareable, but for comparing results on different datasets, H4A would be\r\na natural point of collaboration.\r\n\r\n5.3 Visualization\r\n\r\n5.3.1\tVisualization in general\r\n\r\nFor most people, visualization is a crucial ingredient in the sense-making loop when given a\r\nlarge amount of data to analyse. GCHQ is actively developing tools for visual analytics. A\r\nlarge team in ICTR, split between MCA and DMR, works on semantic graphs and visualization\r\nresearch [W14], and a visual analytics tool called MAMBA [W27] is currently being developed\r\nin partnership with Detica. For graph visualization, NSA\u2019s Renoir application [W33] is also\r\nunder active development.\r\n\r\nAs HIMR researchers explore data for themselves, they will naturally develop their own\r\nvisualizations to help them understand it. We encourage them to record what they come up\r\nwith: perhaps some of these ad hoc visualizations could be useful to analysts too.\r\n\r\nHIMR\u2019s expertise is obviously in algorithms, not developing sophisticated visual analytics\r\nplatforms. Nonetheless, what dynamic or interactive visual tools would be helpful to explore \u25c4\r\nSIGINT data sets, if someone else could be enlisted to create them?\r\n\r\nGRINNING ROACH [W17] and PIRATE CAREBEAR [W30] are existing tools for visual-\r\nizing SIGINT events, developed by DMR: they both produce plots for pattern-of-life analysis.\r\n\r\nDashboarding is well-established for electronic attack events, both internally and by anti-\r\nvirus and security companies. Can similar methods be applied to provide useful visualizations \u25c4\r\nfor traditional SIGINT analysis?\r\n\r\nThere is some work in progress at GCHQ [W5] on dashboarding for the 2012 Olympics, but\r\nit is fair to say that the approaches so far are not mathematically sophisticated.\r\n\r\n5.3.2\tStreaming plots\r\n\r\nThere has been some work in R1 on binning streaming data for histograms [I37].\r\n\r\nWhat interesting plots can be produced in a stream?\t\u25c4\r\n\r\nsuggests starting with QQ-plots; this is closely related to the problem of\r\ncomputing approximate quantiles of streaming data.\r\n\r\nCISA have also done some work [I55] on time series modelling in a stream, including bund-\r\nling up R for use in DISTILLERY: this may be a good foundation to build on.\r\n\r\nIf any algorithms of the sort discussed in section 5.2.4 that calculate summary statistics are \u25c4\r\n\r\n38\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nproduced, could they be refined to produce plots (from which those statistics could be read\r\noff)?\r\n\r\n5.4\tModelling and outlier detection\r\n\r\n5.4.1\tIdentifying outlier activity\r\n\r\nOutliers (e.g. low-volume telephone numbers, small connected components) are often exactly\r\nwhat SIGINT is interested in. They are also exactly what gets lost in subsampling.\r\n\r\nHow can we find rare events with limited memory?\t\u25c4\r\n\r\nCan we take \u2018beyond supervised learning\u2019 to the limit, and find a way to classify normal \u25c4\r\nand abnormal behaviour from the data itself, without needing to train a classifier? A simple\r\nidea would be to choose an N in advance, classify the first N items in the stream as \u2018normal\u2019,\r\nthen use a positive-only learning algorithm to build a classifier to apply to the remainder of\r\nthe stream. Can we do anything more sophisticated to bootstrap a classifier out of the data \u25c4\r\nitself?\r\n\r\nWork from\tat LLNL is relevant to this. He is learning a Gaussian mixture\r\n\r\nmodel on cyber data with particle filters and asking about newness by looking at probability\r\ndensity. Can we ask about tail area instead? This question has also been posed to the 2011\r\nNSASAG [W28].\r\n\r\nCan we track new small connected components? This might be a group of targets who have \u25c4\r\ndumped their old SIM cards and replaced them.\r\n\r\n5.4.2\tBackground distributions for significance tests\r\n\r\nWe have already touched on the idea that we want a measure of surprise when we find outliers\r\n(section 5.2.2), and for this we want to know the background distribution: what does \u2018normal\u2019\r\nlook like, and how can we quantify that? This section gives some specific examples of outlying\r\nbehaviour that we look for, and for which we therefore want to find an empirical background\r\ndistribution. Any information along these lines could also feed into tests in Dynamic Graph.\r\n\r\nWhat is the distribution of the number of common neighbours of two nodes in a graph as a \u25c4\r\nfunction of their degree? This is one way to try to measure the strength of association of two\r\nentities.\r\n\r\nWhat is the distribution of component sizes? Terrorist cells and other target groups have \u25c4\r\nbeen found because they form small components (or \u2018closed loops\u2019, to use the analysts\u2019 term)\r\nisolated from the giant component. How surprising is it to see a node in a component of a\r\ngiven size? Likewise for other measures of connectivity.\r\n\r\nWhat significance do various CHART BREAKER [W6] relationship scores have? This \u25c4\r\ninvolves looking at an email hypergraph, rather than just a simple graph.\r\n\r\n5.4.3\tWindow sizing\r\n\r\nWe often want to pull off a finite chunk from a stream, either for offline analysis or for change\r\ndetection metrics.\r\n\r\nHow should we choose the window size? Is there a happy medium between a narrow window \u25c4\r\n\r\n39\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n(little data, so large variance) and a large window (concept drift, so large variance) that leads\r\nto small sample variance?\r\n\r\nCan we do something akin to ANOVA analysis to look at the effect on sample variance of \u25c4\r\nsample size versus concept drift across different window sizes?\r\n\r\n5.5\tProfiling and correlation\r\n\r\nWe are often interested in finding nodes that behave like a target node: they might be following\r\nthe same modus operandi, or be another selector for a known target.\r\n\r\n5.5.1\tCorrelations\r\n\r\nWith millions of entities, there is no hope of storing useful information on all pairs.\r\n\r\nIs there a sparse approximation to a correlation matrix?\t\u25c4\r\n\r\nAUTO ASSOC [W2] scores may provide a relevant example of a large correlation matrix.\r\nThese are similarity scores for pairs of target detection identifiers or TDIs, which are unique,\r\npersistent identifiers associated to particular users or machines that indicate their presence on\r\nthe network: the aim of AUTO ASSOC is to find out when multiple TDIs belong to the same\r\nuser or machine. See section 3.3.2 for further discussion of association scores.\r\n\r\nCan we keep an approximate list of the top N nodes most closely correlated with a given \u25c4\r\ntarget node?\r\n\r\nThere is also the underlying question of how to score association. This is not strictly about\r\nEDA on streams, but looking at how existing scores perform on streaming data might suggest\r\nways of improving them.\r\n\r\nHow can we score the association between two nodes? CHART BREAKER [W6] gives \u25c4\r\na significance score between pairs of nodes based on emails exchanged. There is an ad hoc\r\nbalancing between the value of an email where one side is sole recipient, cc\u2019d or bcc\u2019d (cf.\r\nassigning weights to golds, silvers and bronzes in medal tables). Is there a method with a\r\nbetter theoretical justification behind it?\r\n\r\nCan we correlate the \u2018busyness profiles\u2019 of nodes, for example to provide situational aware- \u25c4\r\nness of a DDOS attack?\r\n\r\n5.5.2\tFinding behaviour that matches a model\r\n\r\nFrequently we have a modus operandi known to be used by particular targets, and we want to\r\nsearch for events matching that model in streaming data. Recent work by\ton\r\n\r\nlow-rank approximations [E1] may be useful: she has a general framework called CPD analysis\r\nthat uses tensor decompositions to model multi-variable data and extract meaningful factors\r\nas rank 1 tensors. Reducing dimension should make it easier to match up features. (This also\r\nhas applications to link prediction, which is pertinent in SIGINT applications where we expect\r\nto have a lot of missing data.)\r\n\r\nIf a target disposes of his phone and buys a new one, can we rediscover it in data?\t\u25c4\r\n\r\nCan we find IP addresses fitting the profile of, for example, a box engaged in a denial-of-\t\u25c4\r\n\r\nservice attack, or an implanted box beaconing to a C2 server?\r\n\r\n40\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nMathematically, this may come down to something like solving an approximate subgraph\r\nisomorphism problem. CSEC\u2019s 2010 SAWUNEH did some exploratory work on data mining for\r\ncyber defence [I82], which gives some concrete examples of malicious behaviour to look for in\r\nevents data. There is also existing work along these lines for botnet detection in CROUCHING\r\nSQUIRREL [I27, I71], and it may be interesting to compare with external work on streaming\r\nbotnet detection by adaptive sampling [E45].\r\n\r\n5.6\tEasy entry problems\r\n\r\nThis section has some ideas for problems that do not have high entry requirements in terms of\r\nreading up on existing literature or doing lots of preliminary data manipulation: they might\r\nbe a good place to start for people who like to get into things quickly.\r\n\r\nMaths route:\r\n\r\n\u2022\tMotif finding\r\n\r\n\u2022\tProperties of trusses and their generalizations\r\n\r\n\u2022\tFinding outliers\r\n\r\nData route:\r\n\r\n\u2022\tVisualization\r\n\r\n\u2022\tStreaming QQ plots\r\n\r\n5.7\tRelevant data\r\n\r\nThis problem set has the advantage that EDA is needed for any and all of the streaming\r\ncommunication datasets we have available: the telephony, email, HRMap and cyber datasets\r\nall readily map to graphs (or hypergraphs), and present challenges for all four areas: streaming\r\ngraph analytics, visualization, outlier detection and correlation. There is also a graph of the\r\nlinks between Wikipedia articles (appendix F.2.3) in case researchers want a static graph of links\r\nto compare with the dynamic graph of clicks provided by HRMap. Appendices F.1.3, F.1.1,\r\nF.1.2 and F.1.6 describe some particularly appropriate datasets, but most of the datasets in\r\nappendix F could usefully be explored.\r\n\r\nSince EDA is such a general requirement, it is equally possible to work with unclassified\r\ndata sets. Appendix F.2.2 describes a dataset being analysed by the UKVAC (see section 5.8.2):\r\nbesides being another source of events data that is somewhat different in nature to commu-\r\nnication data, it would also be useful to work with this data should any collaboration develop\r\nwith UKVAC participants.\r\n\r\n41\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n5.8\tCollaboration points\r\n\r\n5.8.1\tInternal\r\n\r\nICTR-DMR.\thas the best knowledge of how analysts work and what will be useful\r\n\r\nto them. He also champions research on payphone activity.\tdeveloped\r\n\r\nsome of the fundamental algorithms currently used at GCHQ for contact chaining and\r\nscoring strength of association.\tleads on EDA, though not specifically\r\n\r\nfocused on streams. For visualization,\tand\tare involved\r\n\r\nwith the MAMBA project.\r\n\r\nICTR-CISA.\tis a DISTILLERY guru, and\ttracks research on\r\n\r\nstreaming algorithms across the community.\tis also a good source of in-\r\n\r\nformation on DISTILLERY and streaming implementations in general.\r\n\r\nNSA/R1: information processing group. There are already good contacts with R1 from\r\nHIMR\u2019s crypt work, and it would be good to build on that: for example,\r\nis a frequent visitor to HIMR and is always interested in questions about probability,\r\nrandom hypergraphs and stochastic processes.\t(currently sitting in LTS)\r\n\r\nhas published on EDA on streams, and is planning to write a book on the subject.\r\n\r\nKACHINA. Sandia National Lab in the USA has a multi-year project called KACHINA\r\nto look at large graph processing for defence analysis. A good point of contact is\r\n(NSA/R4).\r\n\r\nPod 58: cyber exploration. In particular\r\nin the past.\r\n\r\n(NSA/R1), who has visited HIMR\r\n\r\n5.8.2\tExternal\r\n\r\nUKVAC (UK Visual Analytics Consortium). One of the two challenge problems for\r\nPhase 2 (approximately 18 months from May 2011, subject to funding) asks for visual\r\nanalysis of 120M events (several years\u2019 worth of flight arrivals and departures in the\r\nUS\u2014see section F.2.2). The brief they have been given is very closely aligned with the\r\nstreaming events model described in this section, and there is as much of an overlap with\r\nthe problems here as is possible at UNCLASSIFIED. If anyone in the SIGINT community\r\nis going to collaborate directly with UKVAC, it will probably be HIMR.\r\n\r\nThere are five fairly independent groups working as part of the UKVAC. Imperial\r\n) and Oxforddo substantive mathematics. Middlesex\r\nand\tdo substantive non-mathematics. Bangor\r\n\r\nseem most engaged with this dataset so far. The best thing is probably to spot promising\r\nactivity that emerges, get in touch with the people doing it, contribute suggestions and\r\nhope that this leads to collaboration. In the fairly likely event that it is difficult to\r\ntrack what is happening and who is doing what,\t(Middlesex) has high\r\n\r\nbetweenness-centrality in the graph of UKVAC participants, and would be a good first\r\npoint of contact.\r\n\r\n42\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nINSTINCT. The UKVAC is sponsored by INSTINCT, a UK government project to use data\r\nmining for counter-terrorism, led out of the Home Office. They organize other activities\r\ntoo, most recently a public competition on ways of fusing data streams [E20]. Some of\r\ntheir projects will be more relevant than others, but it may be worth keeping an eye on\r\nwhat they are doing. Upcoming projects usually get mentioned on blogs on GCWeb;\r\nwill also be able to suggest contacts if required.\r\n\r\n(AT&T). An expert in probabilistic counting; has been keen to engage\r\nwith GCHQ at the UNCLASSIFIED level.\r\n\r\nIBM Safer Planet. This is a big corporate project covering some of the same ground as this\r\nproblem book.\tis in touch with the organizers, and is keen to look for\r\n\r\nopportunities to get GCHQ and HIMR involved.\r\n\r\n43\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n6\tStreaming Expiring Graphs\r\n\r\n6.1\tIntroduction\r\n\r\nStreams of transactional events often arise in SIGINT problems. A classic example would be\r\ntelephony events where we have a directed event from one telephone number to another when\r\nwe detect a phone call. In this case we would typically have a relatively small number of target\r\nnumbers we are interested in and would collect the events around these - we call this a seeded\r\ngraph. An event or transaction is a (normally timestamped) observation of an edge, and so\r\nfor each edge in the graph we may see multiple events. In some recent problems, for example\r\nelectronic attack events, we have been interested in looking for structure in the entire graph.\r\nA denial of service attack might be visible for example as a vertex which suddenly has many\r\nincoming edges.\r\n\r\nWe have techniques for handling the seeded case in a streaming way, expiring old edges\r\nand maintaining a current view of a graph, for example GCHQ Dynamic Graph [W12] and\r\nassociated simulations completed by NSA [I2]. This research area is about investigating the\r\nsecond case where we are interested in tracking the full graph as it varies over time. We imagine\r\nthat we want to expire old events or edges somehow. This might be by maintaining a buffer\r\nof the most recent n events, maintaining the n most recently seen edges, or by decaying edge\r\nweights over time and expiring those with the lowest weights. Other decay strategies might also\r\nbe appropriate. For some problems we may not need to store the full window, and can instead\r\nfind an analytic that produces equivalent results. Any algorithm should ideally parallelise so\r\nthat we aren\u2019t restricted to the memory or network bandwidth available on a single computer.\r\n\r\nIn a dynamic graph problem the typical aim is to maintain a data structure for answering\r\nqueries whilst also receiving updates to the graph. The aim is to maintain information that\r\ncan be updated efficiently given the stream of changes to the graph, and to avoid total re-\r\ncomputation for each query. We say a graph problem is fully dynamic if the updates include\r\nboth insertions and deletions of edges. A problem permitting only one type of update (insertion\r\nor deletion) is sometimes described as partially dynamic. Some literature uses the term evolving\r\ngraph instead. An old but good overview of some dynamic graph algorithms is given in [E14].\r\n\r\nAn expiring graph can be thought of as being a dynamic graph where we allow arbitrary\r\nedge insertion, but edge deletion is restricted to one of a small subset of the edges, for example\r\nthe oldest or lowest weight edges.\r\n\r\nAs in the EDA on Streams problem (section 5), we expect solutions to run in a streaming\r\nfashion on the DISTILLERY platform. We are also interested in how we might bootstrap such\r\nan algorithm using a map-reduce job on a Hadoop cluster where that makes sense, however\r\nthis is not the main focus.\r\n\r\n6.1.1\tThe Problems\r\n\r\nIn section 6.2 we list graph properties which we would like to be able to find and track as the\r\ngraph evolves. We allow some freedom in how the graph evolves. Edges may decay over time\r\nwith low weight edges being expired. We might maintain the most recently observed edges,\r\nor we might retain a window of the most recent events, either chosen to be a fixed size or\r\nover a fixed time period. We expect different problems to be possible with different expiry\r\n\r\n44\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nmechanisms so the choice should be considered separately for each problem.\r\n\r\nFor each property we list, we are interested in answers to the questions posed in section\r\n6.3. We list some further extensions in section 6.4.\r\n\r\n6.2\tProperties to find and track\r\n\r\nIn this section we assume a graph G(V, E) with n vertices in vertex set V and with edge set\r\nE. We use dv to mean the degree of vertex v.\r\n\r\n6.2.1\tComponent Structure\r\n\r\nIn most SIGINT graphs we empirically expect to find a giant component containing most of\r\nthe vertices (see for example [I34] and [I33]). It has been shown in the past that examining\r\nthe remaining components can yield valuable intelligence [I32]. For example a HUMINT agent\r\nand their handler might use specific phones to speak to each other and never use these phones\r\notherwise. Terrorist cells might have separate phones for calling each other; again these would\r\nnever contact numbers in the giant component of the graph. We are therefore interested in\r\nfinding these small components (note that this interest is very sensitive).\r\n\r\nComponent tracking has been studied for dynamic graphs for example [E2].\r\n\r\nCan we identify small components in an expiring graph? The query could include a time \u25c4\r\nsince which edges should be considered, or such a time might be implicit in the expiry strategy.\r\n\r\nCan we track the component structure of an expiring graph to be able to answer a query\t\u25c4\r\n\r\nsuch as \u201cis there a path between A and B with all edges having been observed since time t?\u201d\r\n\r\nGiven an approximate solution to these problems, can we provide an error estimate, for \u25c4\r\nexample upper and lower bounds? These might for example take the form of the maximum\r\nproportion of queries for which we provide the wrong answer.\r\n\r\n6.2.2\tGraph Distance\r\n\r\nThe distance between two nodes in a graph can be an indicator of how related they are, for\r\nexample in contact-chaining analysts will often look at the two-hop contact network of a target.\r\n\r\nFor some graphs we might like to be able to answer queries of the form \u201cwhat is the distance\r\nfrom A to B with all edges having been observed since time t?\u201d. We can think of the graph as\r\nbeing either directed or undirected, and weighted or unweighted. We would typically remove\r\nhigh degree vertices before asking such a question. External work in the area includes [E15].\r\n\r\nGive an approximate answer for the distance between any two vertices for edges observed \u25c4\r\nsince time t, including error bounds.\r\n\r\nA related problem is to provide alerts when the graph distance between two sets of vertices\r\ngoes below some threshold, for example if two groups of targets are seen to communicate.\r\n\r\nCan we track the distance between two (possibly dynamic) sets of vertices. Can we efficiently\r\nidentify when two sets of vertices have a length d path between them?\r\n\r\n6.2.3\tCliques and other motifs\r\n\r\nIn section 5.2.2 we describe the problem of counting cliques and other motifs. Network analysis\r\nsuggests that some structure may be important for example in target identification or malware\r\n\r\n45\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nA A\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\ndetection. Where we expect a structure to be rare, the appearance of such structures may be\r\nan anomaly we wish to investigate.\r\n\r\nIn telephony data, cliques or near cliques with few connections to the remainder of the\r\ngraph is a known MO of certain target groups. The members are in frequent contact with each\r\nother, but rarely call others. In the case where they never call other numbers we describe it\r\nas a closed loop (see section 6.2.1 on the preceding page). Can we find and track cliques or \u25c4\r\nnear-cliques which are persistent in the graph over time? If a new number enters a clique (or\r\nnear clique) at the same time as another member ceases communication we might infer that a\r\nuser has changed phone number. Can we identify such occurrences?\t\u25c4\r\n\r\nBounds here are likely to be based around the size of the clique found, for example given\r\nthere exists a k-clique in the graph what size sub-clique does the algorithm guarantee to find?\r\n\r\nOur graph also has a time element - edges are observed repeatedly. Given a timestamp, \u25c4\r\ncan we extract all cliques or near-cliques of some size where all edges have been observed since\r\nthat timestamp? Can we do this for other motifs?\t\u25c4\r\n\r\n6.2.4\tCentrality Measures\r\n\r\nThe centrality of a vertex in a graph measures the relative importance of that vertex. For\r\nexample it might show how important a person is within a social network, or how important\r\na website is in terms of reachability of other sites. Common centrality measures include the\r\ndegree, betweenness, and eigenvector centrality.\r\n\r\nThe simplest is the degree centrality, defined for each vertex as the number of incident links,\r\nscaled by the possible number, that is\r\n\r\nCd (v)\r\n\r\ndv\r\n\r\nn \u2014 1 \u2019\r\n\r\nTracking the (approximate) degree centrality in O(n) space is relatively easy without expiry\t\u25c4\r\n\r\nof edges, but can we track it for each vertex in the case of an expiring graph, for both the\r\nweighted and unweighted cases.\r\n\r\nThe vertex betweenness centrality of vertex v is (informally) the proportion of all shortest\r\npaths in the graph which pass through vertex v. If aab is the number of shortest paths between\r\na and b, and aab(v) is the number of shortest paths between a and b passing through v then\r\n\r\nCb (v)\r\n\r\nE\r\n\r\na=v=b\u20acV\r\n\r\nVab(v)\r\n\r\n\u00aeab\r\n\r\nWe are not particularly interested in the global betweenness centrality, but would be inter-\r\nested in ways to track it for specific subgraphs, for example the 2-hop graph around some set\r\nof seed vertices.\r\n\r\nIs it possible to maintain an approximation to the betweenness centrality for a set of vertices \u25c4\r\nas the graph (and the vertex set) evolves? Some internal work in this field is described in [I46].\r\n\r\nThe eigenvector centrality scores nodes in such a way that high scoring nodes contribute\r\nmore score to their neighbours than low scoring nodes. A variant is the Google PageRank\r\nalgorithm [E30]. In the basic case, the eigenvector centrality of vertex v is the corresponding\r\nentry in the eigenvector of the adjacency matrix of G corresponding to the largest eigenvalue.\r\n\r\n46\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nAgain we aren\u2019t directly interested in the global eigenvector centrality measures, but would\r\nbe interested to track local variants, for example Personalized PageRank or the internally\r\ndeveloped KL-Relative PageRank [W45].\r\n\r\nCan we track any personalized variants of the eigenvector centrality for some (possibly \u25c4\r\nchanging) set of vertices in an expiring graph? There has been internal work on updating\r\neigenvectors and eigenvalues as more edges are observed at the Information Processing SCAMP\r\nin 2009, see [I81], along with a report on its possible implementation [I56].\r\n\r\n6.3 Questions relevant to all properties\r\n\r\n6.3.1\tApproximation\r\n\r\nTypically it is not necessary to know the exact values of the properties listed above, and we can\r\nmake do with an approximation. For an approximation to be useful it should include some form\r\nof error bounds, although the form these take will depend on the specific problem. They could\r\ninclude e-6 bounds, strict upper and lower bounds, errors with a known statistical distribution,\r\netc.\r\n\r\nAre there approximate solutions to any of the problems listed? Where an exact solution \u25c4\r\nexists, how does the computational cost (time and memory) compare?\r\n\r\n6.3.2\tComputational Cost\r\n\r\nFor each of the problems listed in section 6.2 we would like to know the cost of evaluating the\r\nproperties in this way. For our purposes cost is CPU time and memory usage as a function of\r\nthe data size (asymptotics are important but we also care about the constants as derived from\r\nexperiments).\r\n\r\nWe typically work under the semi-streaming graph model where we allow ourselves\r\nO(n log(n)) space. For example, we might imagine storing a component ID for each vertex.\r\n\r\nFor most problems it would be possible to collect a window of data from the stream and re-\r\ncompute the required statistics at the desired query interval. Whether this is practical depends\r\non the window size, the frequency of updates to the graph, and the frequency (and latency)\r\nwith which an answer to the query must be returned. The trade-offs should be considered -\r\nincremental updates might take more compute overall, but in situations where we can take\r\nsome automated action based on the results then we might be willing to accept the cost to gain\r\nthe low latency.\r\n\r\nIn most settings it is unnecessary to know the answer to a question for every edge addition\r\nor deletion, and it is instead sufficient to be able to compute the answer after each batch update,\r\nso long as those updates are sufficiently fast.\r\n\r\nFurthermore, the online process may track and store data to allow efficient updates, but\r\nto get the desired answer may then require us to further process the data we have stored.\r\n\r\nWe might then choose to run this further processing less often, for instance at the request of\r\nan analyst. This is a perfectly valid approach, and could be particularly valuable if the data\r\nstructure lends itself to answering multiple types of query.\r\n\r\nConcrete questions include:\r\n\r\n\u2022 What is the (mean) cost of an update? What is the worst-case cost?\t\u25c4\r\n\r\n47\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n\u2022\tAt what query frequency does the total computational cost of incremental updates become \u25c4\r\nlower than the cost of total re-computation on each query? How does this depend on\r\nbatch size?\r\n\r\n\u2022\tHow does the computational cost vary depending on features of the graph, for example \u25c4\r\ndiameter or average distance.\r\n\r\n\u2022\tHow does the cost vary depending on the window size or the decay rate?\t\u25c4\r\n\r\n6.3.3\tExpiry Policy\r\n\r\nAs well as affecting the speed and computational cost of an algorithm, the choice of expiry\r\nmechanism will affect the accuracy of the results.\r\n\r\nFor windowed data, how should we choose the window size to ensure we get realistic results \u25c4\r\nat a reasonable speed? Is it possible to dynamically change the window size?\t\u25c4\r\n\r\nFor decaying data, how should we chose our decay rate to maintain realistic results? Can \u25c4\r\nwe change the decay rate without restarting the algorithm?\r\n\r\n6.4\tFurther Questions\r\n\r\n6.4.1\tParallel and Distributed processing\r\n\r\nFor high rate data feeds it may be necessary to process the data on multiple nodes of a cluster.\r\n\r\nThe data feed would be split between nodes and these streams cannot be combined until their\r\nrate is sufficiently reduced. Which of the graph properties can be computed in a parallel way? \u25c4\r\nSome SIGINT data sources are split between multiple geographical sites, with limited band-\r\nwidth between them. Is it possible to solve any of these problems for the (virtual) stream of \u25c4\r\njoined data? In this case we would expect to process each feed at the collection site and send\r\na much smaller set of data between sites, either periodically or in order to answer a query.\r\n\r\n6.4.2\tBootstrapping\r\n\r\nFor some properties it may be possible to get an initial approximation to the correct values by\r\nrunning a map-reduce query on an events Hadoop cluster. Can we make use of bootstrapping to \u25c4\r\nimprove the efficiency of our processing? This might be particularly relevant when we process\r\nthe stream in parallel and wish to split the vertices over multiple nodes of a cluster with each\r\nnode being responsible for some proportion of the vertices.\r\n\r\n6.4.3\tAnomaly Detection\r\n\r\nFor many of the properties we wish to compute, we would also like to be able to produce an\r\nalert for anomalies in the data. For example, in the web graph, if a vertex is suddenly connected\r\nto a large number of other vertices this may indicate a denial of service attack. Alerts may\r\nbe used to trigger additional processing, for example capture and storage of relevant data or\r\nadditional processing to categorise the event. Some internal research in this area can be found\r\nin [I20].\r\n\r\nCan we detect significant changes in the properties we are tracking? How soon are we able \u25c4\r\n\r\n48\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nto detect the change after it initially occurs?\r\n\r\n6.4.4\tResilience\r\n\r\nOver time our collection posture changes. Bearers are tasked and de-tasked, and\r\nsystems can fail. This can have a significant effect, especially when monitoring for\r\nHow are the algorithms affected by variations in data volumes?\r\n\r\nIf we identify that a change is due to a processing failure, can we account for\r\ngenerating future alerts once the processing resumes? See for example [I10].\r\n\r\n6.4.5\tQueries on graphs with attributes\r\n\r\nMany SIGINT graphs have some form of attributes associated with vertices and edges, for\r\nexample the location of a phone. It can be useful to answer queries where we restrict ourselves\r\nto vertices with a particular value for some attribute. Is it possible to modify your algorithm \u25c4\r\nto enable queries on vertices with particular attributes?\r\n\r\n6.5\tRelevant Data\r\n\r\nAny streaming graphical data is suitable for these problems, giving a variety of options. Ex-\r\namples include HRMap, telephony, email, SQUEAL alerts and IP flow metadata. All provide a\r\nstream of events with some notion of a source and destination vertex, along with the timestamp\r\nof the event.\r\n\r\nIn addition we have various reference datasets. For example section F.3.1 describes a\r\ndatabase of websites of interest to counter terrorism and BROAD OAK lists known target\r\nphone numbers and email addresses (see section F.3.2). These could be used to identify if an\r\nextracted graph structure has a higher density of targets than would be expected.\r\n\r\nThe idea of wanting to process a stream of edges is not specific to the intelligence community,\r\nand so external collaboration should be possible given a suitable dataset.\r\n\r\n6.6\tCollaboration Points\r\n\r\nThere are the following potential collaboration opportunities both within and outside the in-\r\ntelligence community.\r\n\r\nKACHINA: Sandia National Lab in the USA has a multi-year effort called KACHINA which\r\nincludes the Questa project to look at large graph processing for defence analysis. They\r\nhold security clearances, and would be an obvious group to collaborate with. Points of\r\ncontact are^^^^^^^^| (NSA employee deployed to Sandia) and^^^^^J\r\n\r\nis engaged both in external research at Georgia Tech and as a researcher\r\nin R1 at NSA. His external research in the field includes [E3, E12, E28]. Collaboration\r\nshould be possible on both classified and unclassified problems.\r\n\r\nPod58 \u2014 Cyber Exploration:\tThe Pod runs until the end of January 2012, and aims to use\r\n\r\nanalysis frameworks including DISTILLERY to support analysis of Cyber data.\r\ns the R1 research lead in the Pod.\r\n\r\n49\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nprocessing\r\n\r\nanomalies.\r\n\r\n\u25c4\r\n\r\nthat when \u25c4\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nNSA/R: Various people around the research division at NSA would be good people with\r\nwhom to collaborate. Specific names include\tand\twho normally\r\n\r\nattend the various five-eyes conferences.\tis a GCHQ integree at NSA\r\n\r\nworking on data mining problems including the integration of streaming analysis and\r\nMapReduce based analysis.\r\n\r\nICTR-CISA: This team is responsible for streaming analysis research at GCHQ. Much of\r\ntheir work revolves around the platform (DISTILLERY) however they are also active in\r\ndeveloping algorithms.\tis the team lead.\r\n\r\nIBM Research: As part of the InfoSphere Streams (DISTILLERY) platform, IBM are devel-\r\noping a \u201cGraph Analytics Toolkit\u201d. This is in its early phases and there is potential to\r\ncollaborate on this (at an UNCLASSIFIED level), and potentially have any algorithms\r\ndeveloped incorporated into the toolkit. Initial contact can be made through\r\nin ICTR.\r\n\r\n50\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nA Ways of working\r\n\r\nThis section gives a few thoughts on ways of working. The aim is to build on the positive culture\r\nalready established in the Institute\u2019s crypt work. HIMR researchers are given considerable\r\nfreedom to work in whatever way suits them best, but we hope these ideas will provide a good\r\nstarting-point.\r\n\r\nA.1 Five-eyes collaboration\r\n\r\nAs on the crypt side, we hope that UKUSA collaboration will be a foundation-stone of the data\r\nmining effort at HIMR. This problem book is full of links to related research being carried out\r\nby our five-eyes partners, and researchers are very strongly urged to pursue collaborative angles\r\nwherever possible\u2014above all, to get to know the people working on the same problems and\r\nbuild direct relationships. Researchers are encouraged to attend and present at community-\r\nwide conferences (principally SANAR and ACE), as funding and opportunity allows.\r\n\r\nWe hope that informal short visits to and from HIMR will also be a normal part of data\r\nmining life. HIMR has a tradition of holding short workshops to focus intensively on particular\r\ntopics, where possible with participation from experts across the five eyes community. Fre-\r\nquently these are held during university vacations, to allow our cleared academic consultants\r\nto take part. Each summer, HIMR hosts a SWAMP: a two-month long extended workshop\r\non (traditionally) two topics of high importance, similar to the SCAMPs organized by IDA.\r\nWe hope that HIMR researchers will feel inspired to suggest possible data mining sub-topics\r\nfor future SWAMPs.\r\n\r\nA.2 Knowledge sharing\r\n\r\nInevitably, there is a formal side to reporting results: technical papers, conference talks, code\r\nhanded over to corporate processing, and so on. But informal dissemination of ideas, results,\r\nprogress, set-backs and mistakes is also extremely valuable. This is especially true at HIMR,\r\nfor several reasons.\r\n\r\n\u2022\tThere is a high turnover of people, and it is important that a researcher\u2019s ideas (even the\r\nhalf-baked ones) don\u2019t leave with him or her.\r\n\r\n\u2022\tAcademic consultants form an important part of the research effort: they may only have\r\naccess to classified spaces a few times a year for a few days at a time, so being able to\r\ncatch up quickly with what\u2019s happened since their last visit is crucial to help them make\r\nthe most of their time working with us.\r\n\r\n\u2022\tHIMR is physically detached from the rest of GCHQ, and it\u2019s important to have as many\r\nchannels of communication as possible\u2014preferably bidirectional!\u2014so that this detach-\r\nment doesn\u2019t become isolation. The same goes even more so for second party partners as\r\nwell.\r\n\r\nIn HIMR\u2019s METEOR SHOWER work, knowledge sharing is now primarily accomplished\r\nthrough two compartmented wikis hosted by CCR Princeton. For data mining, there should\r\nbe more flexibility, since almost none of the methods and results produced will be ECI, and\r\n\r\n51\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nin fact they will usually be STRAP1 or lower. Paradoxically, however, the fact that work can\r\nbe more widely shared can mean that there is less of a feeling of a community of interest with\r\nwhom one particularly aims to share it: witness the fact that there is no shining model of data\r\nmining knowledge sharing elsewhere in the community for HIMR to copy!\r\n\r\nWe suggest that as far as possible, data miners at HIMR build up a set of pages on GCWiki\r\n(which can then be read and edited by all five-eyes partners) in a similar way to how crypt\r\nresearch is recorded on the CCR wikis. They can then encourage contacts at GCHQ and\r\nelsewhere to watch, edit and comment on relevant pages. In particular, the practice of holding\r\nregular bull sessions10 and taking live wiki notes during them is highly recommended.\r\n\r\nIf any researchers feel so inclined, GCBlog and the other collaborative tools on GCWeb are\r\navailable, and quite suitable for all STRAP1 work. For informal communications with people\r\nfrom MCR and ICTR, there is a chat-room called himr_dm: anyone involved in the HIMR data\r\nmining effort can keep this open in the background day by day. There is also a distillery\r\nroom that is sadly under-used: in principle, it discusses SPL and the corporate DISTILLERY\r\ninstallations.\r\n\r\nFor any STRAP2 work that comes along, there are currently no good collaborative options:\r\ncreating an email distribution list would be one possibility.\r\n\r\nA.3 Academic engagement\r\n\r\nThe first test for HIMR\u2019s classified work must be its applicability and usefulness for SIGINT,\r\nbut given that constraint, GCHQ is keen to encourage HIMR researchers to build relationships\r\nand collaborate with academic data miners, and publish their results in the open literature.\r\nOf course, security and policy will impose some red lines on what exactly is possible, but the\r\nbasic principle is that when it comes to data mining, SIGINT data is sensitive, but generally-\r\napplicable techniques used to analyse that data often are not. Just about everyone nowadays,\r\nwhether they are in academia, industry or government, has to deal with big data, and by and\r\nlarge they all want to do the same things to it: count it, classify it and cluster it. If researchers\r\ndevelop a new technique that can be published in an open journal once references to SIGINT\r\nare excised, and after doing a small amount of extra work to collect results from applying it to\r\nan open source dataset too, then this should be a win-win situation: the researcher adds to his\r\nor her publication tally, and HIMR builds a reputation for data mining excellence.\r\n\r\nOf course, there may be occasions when publication is not appropriate, for example where\r\na problem comes from a very specific SIGINT situation with no plausible unclassified analogy.\r\nDay-to-day contact with the Deputy Director at HIMR should flag up cases like this early on.\r\nThere are also cases where we feel we have an algorithmic advantage over the outside that is\r\nworth trying to maintain, and this can be further complicated if equity from other partners is\r\ninvolved, or if a technique brings in ideas from areas like crypt where strict secrecy is the norm.\r\nThe Deputy Director should be consulted before discussing anything that might be classified in\r\na non-secure setting: he or she can further refer the question to Ops Policy if necessary. Over\r\n\r\n10Informal meetings at blackboards where people briefly describe work they have been doing and problems\r\nthey have encountered, with accompanying discussion from others in the room. The rules: people who wish to\r\nspeak bid the number of minutes they need (including time for questions). Talks are ordered from low to high\r\nbid, with ties broken arbitrarily. You can ask questions at any time. You can leave at any time. If you manage\r\nto take the chalk from the speaker, you can give the talk.\r\n\r\n52\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\ntime, researchers will build up a good idea of what is sensitive and what is not, but in the first\r\ninstance, erring on the side of caution is a sound starting point where classified information is\r\ninvolved.\r\n\r\nSimilarly, if there are grey areas about when work should count as part of a researcher\u2019s\r\nclassified or unclassified effort, this can be settled by an informal conversation with the HIMR\r\nDirector or Deputy Director.\r\n\r\n53\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nB DISTILLERY\r\n\r\nDISTILLERY is a project to deliver a platform for near-real-time streaming analytics. It\r\nis a research partnership between NSA and IBM Research, with GCHQ also having been\r\ninvolved for a number of years. DISTILLERY was released by IBM as a commercial product\r\nin 2010 as IBM InfoSphere Streams, often shortened to just Streams. We use the three terms\r\nsynonymously. For more on the DISTILLERY platform, and links to plenty of other useful\r\npages see [W11].\r\n\r\nCentral to the DISTILLERY platform is the stream processing paradigm. We use the\r\nterminology of the Streams documentation. A Streams application is made up of one or more\r\ncomposite operators. A composite operator contains one or more operators, each of which\r\nhas zero or more input ports and zero or more output ports. Data takes the form of tuples\r\nconforming to a schema, where the schema defines the names and types of the entries which\r\nmake up a tuple. Streams of tuples flow along the edges of the flow graph between the operator\r\nports and the operators carry out some kind of transformation on these streams. When built\r\nand launched into the Streams platform, operators are placed in a series of processing elements\r\nor PEs connected according to the application flow graph. Each PE contains one or more\r\noperators (by default exactly one, but we can combine multiple operators into a single PE for\r\nefficiency).\r\n\r\nCrucially, we can process data as it arrives. If we know in advance what questions we would\r\nlike to ask of the data then we may never need to store the data. Instead, we build a processing\r\nflow to answer the question on the stream of data. Our output is a stream of answers. As well\r\nas saving storage, processing data provides other advantages. An obvious one is near-real-time\r\ntipping. Given some event of interest, we can alert an analyst as soon as we observe that\r\nevent. We can typically provide a tip-off within a second of the event occurring, although the\r\nlatency of the analyst is somewhat higher. However we do not restrict ourselves to tipping a\r\nhuman. Observing an event might cause us to take some other action, for example collecting\r\nmore detailed data for identifiers that appear in the initial event.\r\n\r\nStreams applications are written in SPL, the Streams Processing Language [W40], and are\r\nrun on InfoSphere Streams version 2. Older applications were written in SPADE and run on\r\nInfoSphere Streams version 1. We are currently converting our applications from SPADE to\r\nSPL, and we plan for most new applications to be written in SPL.\r\n\r\nB.1 When would I use InfoSphere Streams?\r\n\r\nStream based processing is useful any time where you want to produce results as soon as possible\r\nafter the relevant events occur or when we cannot reasonably store all the data required for a\r\nproblem. In these situations we can use Streams to handle the plumbing between our operators.\r\nIt provides parallelism over multiple hosts in a cluster whilst also providing some resiliency\r\nagainst system failures. Through the use of Import and Export operators an application can\r\nbe developed and deployed in stages, and data streams can be shared with other users.\r\n\r\nImport operators will also allow you to take advantage of the data streams already available\r\non the cluster. In this case, someone else will already have arranged for the feed to be delivered\r\nfrom our front-end collection systems, and your application need not be concerned with format\r\nchanges.\r\n\r\n54\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nB.2 Documentation and Training\r\n\r\nDocumentation is linked from\r\n\r\nand\tFurther documentation\r\n\r\ncan be found on a Streams cluster at\r\nThe SPL documentation consists of:\r\n\r\n\u2022\tSPL Introductory Tutorial: start here after following the instructions on Getting Started\r\nbelow.\r\n\r\n\u2022\tSPL Language Specification: describes the language itself.\r\n\r\n\u2022\tSPL Standard Toolkit Reference: describes the operators provided in Streams.\r\n\r\n\u2022\tSPL Standard Toolkit Types and Function: describes the built in functions.\r\n\r\n\u2022\tSPL Config Reference: covers additional configuration options which allow you to alter\r\nthe behaviour of operators or the runtime platform.\r\n\r\n\u2022\tSPL Compiler Usage Reference: describes the many compiler options in detail.\r\n\r\n\u2022\tSPL Operator Model Reference: the information you need to write a new operator.\r\n\r\n\u2022\tSPL Streams Debugger Reference: describes how to use the debugger.\r\n\r\n\u2022\tStudio Installation and User\u2019s Guide: describes the Eclipse development tools available\r\nto help you write SPL.\r\n\r\n\u2022\tInstallation and Administration Guide: covers how to install Streams and to configure a\r\nStreams instance.\r\n\r\nTraining may be available from IBM UK organised through QA - contact\r\n\r\nor details of upcoming courses. IBM, NSA and GCHQ have published a paper on\r\ndesign principles which may be useful [E43].\r\n\r\nB.3 Logging on and Getting Started\r\n\r\nAccess to a DISTILLERY cluster is via ssh, and you will initially use the BHDIST\r\ncluster (see below). Use one of\r\n\r\nOnce you log on for the first time you should go through the\r\nsteps listed on the getting started GCWiki page [W16], although the following steps should be\r\nsufficient to get you started.\r\n\r\nConfigure key based ssh access (accept the defaults presented by ssh-keygen):\r\n\r\nssh-keygen -t dsa\r\ncd ~/.ssh\r\n\r\ncat id_dsa.pub > authorized_keys\r\nchmod 600 *\r\n\r\n55\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nYou should then be able to type \u2018ssh localhost\u2019 and it won\u2019t ask for a password. This is essential\r\nas DISTILLERY uses ssh to launch commands and processes on all nodes (even when running\r\nonly on localhost).\r\n\r\nAdd the following to your .bashrc file:\r\n\r\n# Source global definitions\r\nif [ -f /etc/bashrc ]; then\r\n. /etc/bashrc\r\nfi\r\n\r\numask 0027\r\n\r\nexport JAVA_HOME=/opt/ibm/java-x86_64-60/\r\n\r\nexport ECLIPSE_HOME=/opt/eclipse-spl\r\n\r\nexport PATH=$JAVA_HOME/bin:opt/eclipse-spl:$PATH\r\n\r\nexport STREAMS_SPLPATH=/opt/distillery/toolkits\r\nsource /\r\n\r\nConfigure a streams public/private keypair (to avoid needing a password to stop/start jobs)\r\nwith:\r\n\r\nstreamtool genkey\r\n\r\nSet up a hostfile to tell Streams which hosts to use. The hosts file is in\r\n\r\ne and for now should contain a single line with the host you\u2019re\r\nusing but in the blackhole.net domain as this uses a faster network switch, e.g.\r\n\r\nYou should now be able to follow the SPL Introductory Tutorial linked from\r\n\r\nFor using the Eclipse tools, including the ability to view your jobs in a flow graph, then use\r\neclipse with\tThis should be in your path if you followed\r\n\r\nthe instructions above. Figure 5 shows an example of multiple jobs connected together in a\r\nshared DISTILLERY instance, as seen through the Streams Live Graph view in Eclipse.\r\n\r\nMany people choose to run a VNC session on the cluster to provide a desktop environment.\r\nFor instructions see the DISTILLERY pages on GCWiki.\r\n\r\nThe two main clusters used for research work are listed in table 2. To get an account on\r\neither contact\r\n\r\nB.4 Data\r\n\r\nData typically arrives into a DISTILLERY cluster via either a UDP or TCP socket from our\r\nfront-end processing systems. UDP is used where we need to avoid delays in our processing\r\ncausing delays earlier in the processing chain - instead we just drop the extra data. We are\r\nmoving to using TCP and then using a threaded port on the next operator so we can measure\r\nour data losses (see section B.5.1 on page 58).\r\n\r\nYour home directory is shared over the cluster, as is\t. Applications need\r\n\r\nto be run from a shared location so all nodes can access them. Results should be saved to\r\nrather than your home directory as the filesystem is local to the cluster.\r\n\r\n56\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nFigure 5: Streams Live Graph view: interlinked jobs in the AHS EXPLORE DISTILLERY cluster.\r\n\r\nNode names\tNumber of nodes\tAccount  management\tPurpose\r\n\t10\tICTR\tDevelopment and operational prototypes. Data from ICTR re- search probes.\r\n\t3\tAHS\tDevelopment and \u201cExplore\u201d prototypes. Data from MVR and mailorder.\r\n\r\nTable 2: DISTILLERY clusters available for use.\r\n\r\n57\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nB.5 Conventions\r\n\r\nThe DISTILLERY clusters contain operational prototypes as well as development code, so it\r\nis important to consider the impact on others when running jobs.\r\n\r\nWhen running jobs on the live data feeds, try to do initial processing and data reduction\r\non the same host as the data import to avoid unnecessary network use. Avoid causing back\r\npressure to the live feeds - see section B.5.1. Ideally you should test your code on a small\r\nsample before connecting to the live data feeds, although this may not always be possible.\r\n\r\nB.5.1 Use threaded ports on shared data\r\n\r\nIf the incoming data rate is faster than you can process then by default you will cause the\r\nincoming data to slow down, causing back pressure. If you are reading from a shared data\r\nstream then this affects everyone reading from that stream - all processing will be slowed\r\ndown. This may cause data to be lost further up the chain, for example at the point where it\r\nis received from the front-end probes.\r\n\r\nTo avoid causing this problem, you should normally configure the first operator of a job\r\nto drop tuples if it has too many already waiting to be processed. Typically this would be an\r\nImport() operator, which is configured as follows:\r\n\r\nstream<SomeTupleType> I1 = ImportO {\r\n\r\nparam subscription : DataFeed == \"SomeData\";\r\n\r\n}\r\n\r\nstream<myschema> I2 = Functor(Il) {\r\n\r\nconfig threadedPort : queue(I1, Sys.DropLast);\r\n\r\n}\r\n\r\nThe queue function has an optional third parameter which specifies the buffer size (in tuples),\r\nand the second option can be replaced by Sys.DropFirst.\r\n\r\nWhen reading from a file then you should not set such a buffering configuration, since you\r\nwant to read the data as fast as you can process it but without discarding any tuples.\r\n\r\nB.5.2 Operator Toolkits and Namespaces\r\n\r\nSPL (DISTILLERY) code is stored in toolkits. These split into two broad types - tookits\r\nof operators and toolkits containing applications. The Five Eyes repositories of toolkits are\r\nheld in MadForge and are described at\r\n\r\n. When we wish to share our operators (typically once they are\r\ntried and tested) then we will add them to MadForge. Before that we store the code in a\r\nGit repository on http://github.ar.gchq, with the repository name matching the toolkit\r\nname but prefixed with \u201cspl-\u201d. Instructions for creating a new repository can be found at\r\n\r\nMost of the repositories get built at least once a week and deployed to the cluster. To add\r\na repository to the build list contact\tor\tTo have\r\n\r\nnew versions of your toolkit be automatically deployed you must ensure that you increment the\r\ntoolkit version number. Toolkits are installed to /opt/distillery/toolkits and can then be\r\n\r\n58\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nused in your applications. Rather than hard-code this path we put it into the STREAMS_SPLPATH\r\nenvironment variable.\r\n\r\nToolkits containing operators are placed in the gchq.* namespace, for example\r\ngchq.ingest contains the TcpLineReader operator for multi-threaded reading of SIGINT data.\r\nApplication toolkits are in the gchq.app.* namespace to differentiate them. These are not in-\r\nstalled into /opt/distillery/toolkits but are instead checkout out into /streams/apps if\r\nyou want to run them.\r\n\r\nOne particularly important toolkit is\t. Despite the name, this is in fact\r\n\r\ninstalled into\tand contains the schemas for the data available in\r\n\r\nthe cluster. This is needed when importing data into your application. As an example, HRMap\r\ndata matches the HRMapRecord schema. Details for all the datasets described in section F can be\r\nfound in\r\n\r\nB.6 Further help and resources\r\n\r\nThe DISTILLERY team in ICTR-CISA are the best points of contact for questions.\r\n\r\nis the team lead and can cover most types of issue.\tis the best contact for\r\n\r\ninfrastructure issues. In OPC-MCR the best contact for DISTILLERY questions is\r\n\r\nThere is a distillery room on the instant messaging server (accessed using Pidgin, see\r\nappendix D). This can be used to ask questions on SPADE, SPL, and the infrastructure.\r\nAlthough the ICTR team do not make much use of it at present, there is normally someone\r\nthere who can help.\r\n\r\nAll relevant resources, are linked from\r\n\r\n59\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nC Hadoop\r\n\r\nHadoop is a software framework that supports static data-intensive distributed applications.\r\nIts design is heavily based on that of Google\u2019s infrastructure as disclosed in [E10]. It is designed\r\nto be scalable rather than fast and efficient. This means that for any given task there is likely\r\nto exist a more efficient solution. However the ease of parallelism more than counteracts this\r\nin most cases. In this model of parallelism the computation is shipped to the data, rather than\r\ndata to computation, therefore saving large amounts of network traffic. Typically Hadoop is\r\ninstalled across a cluster of computers, which are often referred to as clouds. Indeed the only\r\nreason to install it on a single computer is for testing purposes.\r\n\r\nHadoop consists of two main components, the Hadoop Distributed File System (HDFS)\r\nand MapReduce. As a user it should not be necessary to worry about how the file system\r\nis implemented. Instead one can consider it to act just like a very large filesystem. However\r\nshould one wish to use Hadoop to process data then knowledge of MapReduce is required.\r\nFortunately the key concepts of MapReduce are simple and easily understood. As the name\r\nsuggests there are two stages to any MapReduce job\u2014a Map and a Reduce. In the map stage\r\none receives successive input records. For each input one produces zero, one or many output\r\nrecords in the form of key-value pairs. These output records then go into a shuffle phase, in\r\nwhich all records are sorted so that the reduce stage receives all records with a common key\r\ntogether. This reduce group is then processed together and again zero, one or many output\r\nrecords may be produced. As the entire output of the Mapper is being sorted it is possible to\r\nperform a secondary sort to provide data to the Reducer in an advantageous order. This is\r\ndone by specifying that grouping should only consider part of the key, whereas ordering should\r\nconsider all of it. A common use of this is to provide time ordered data in a reducer for a\r\nparticular identifier.\r\n\r\nThe Hadoop framework is written in Java. Java is therefore a popular choice for writing\r\nHadoop MapReduce applications. Using Java one has access to the full functionality of Hadoop\r\nand is recommended for sustainable code. However it is not necessary to know any Java to get\r\nMapReduce jobs running on Hadoop using the Streaming package. Streaming is invoked from\r\nthe command line on a Hadoop node. Any script or program that accepts data on STDIN and\r\noutputs it to STDOUT can be specified as a Mapper or Reducer. This significantly lowers the\r\nentry barrier and is ideal for quickly trying out ideas where the full Java treatment seems like\r\noverkill.\r\n\r\nC.1 When would I use Hadoop?\r\n\r\nThe short answer is whenever you want to batch process a large amount of static data. There\r\nis not really any other option for such computations within GCHQ.\r\n\r\nA slightly longer answer is that Hadoop clusters are where GCHQ has chosen to keep its\r\nbulk events data. This is due to the large amount of data processing power Hadoop offers. With\r\nhundreds of hard disks working simultaneously multiple gigabytes can be read per second. This\r\nallows the processing of the multi-terabyte datasets we intercept. By having the data in its raw\r\nstate it is possible to ask a huge number of different questions of it. This can be contrasted\r\nwith the QFDs which also store very large amounts of data, but are databases optimised for\r\na specific type of analyst queries. The QFDs therefore do not offer a sensible data mining\r\n\r\n60\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nplatform.\r\n\r\nHadoop generally excels when your algorithm can be expressed in a small number of MapRe-\r\nduce steps. It is less efficient when implementing iterative algorithms. This is because between\r\niterations all state must be written down to disk and then read back in again. This extra\r\nI/O cost can easily end up swamping the time taken to perform the computations. Sometimes\r\nthere may be no other way of performing an algorithm given the size of the data and the only\r\nsolution is patience11.\r\n\r\nC.2 Documentation and Training\r\n\r\nThe standard Hadoop documentation is available linked from\r\nThis consists of:\r\n\r\n\u2022\tA MapReduce Tutorial that shows you how to write MapReduce applications in Java.\r\n\r\n\u2022\tAn introduction to Hadoop Streaming. Although not a full tutorial all the information\r\nyou need to run Streaming jobs is there.\r\n\r\n\u2022\tAn overview of the Hadoop command line arguments.\r\n\r\n\u2022\tThe Java documentation of the Hadoop API. If writing Hadoop in Java this is extremely\r\nuseful.\r\n\r\nThe Hadoop page on GCWiki [W20] has many resources, including:\r\n\r\n\u2022\t6 lectures and 2 exercises from Cloudera, a Hadoop consultancy company.\r\n\r\n\u2022\tAn overview of Hadoop by IBM\u2019s Jimeng Sun.\r\n\r\nTom White\u2019s book Hadoop: The Definitive Guide is probably the best book currently\r\navailable on Hadoop. It is also available on NSA\u2019s Safari book library [W35].\r\n\r\nClassroom based training should also be available. TDB have organised internal training\r\nled by GCHQ employees. Some people have also attended a multi-day training course offered\r\nby Cloudera.\r\n\r\nC.3 Logging on and Getting Started\r\n\r\nAccess to Hadoop clusters is via ssh. You will ssh to an edge node. These are not part of the\r\ncompute cluster but do allow you to submit jobs and interact with HDFS.\r\n\r\nInstructions for accessing SUN STORM, the largest cluster, are available at\r\n\r\nThe other clusters are detailed in table 3.\r\n\r\nSome useful aliases for your .bashrc are given below. Adding these will save you a huge\r\namount of typing and make interacting with HDFS feel more like using a regular filesystem.\r\n\r\n11ICTR-DMR are currently developing Bagel an implementation of Google\u2019s Pregel distributed graph mining\r\nsolution. While still in its early stages Bagel keeps its state in memory and therefore avoids this extra I/O cost\r\nbetween steps.\r\n\r\n61\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nCluster name\tNum nodes\tPurpose\r\nSUN STORM\t897\tCheltenham events cluster\r\nGOLD MINE\t125\tCyber/content cluster\r\nHAGER AWEL\t800\tBude events cluster\r\nWoody\t133\tICTR research cluster\r\nBuzz\t42\tICTR research cluster\r\n\r\nTable 3: GCHQ\u2019s Hadoop clusters\r\n\r\nexport HADOOP_HOME=/opt/hadoop/current\r\nalias hadoop=${HADOOP_HOME}/bin/hadoop\r\n\r\nalias hstream=\u2019hadoop jar $HADOOP_HOME/contrib/streaming/hadoop-streaming-0.20.10.jar\u2019\r\n\r\nalias hl=\u2019hadoop fs -ls\u2019\r\n\r\nalias hjobl=\u2019hadoop job -list\u2019\r\n\r\nalias hjobk=\u2019hadoop job -kill\u2019\r\n\r\nalias hjob=\u2019hadoop job\u2019\r\n\r\nalias hjar=\u2019hadoop jar\u2019\r\n\r\nalias hc=\u2019hadoop fs -count\u2019\r\n\r\nalias hput=\u2019hadoop fs -put\u2019\r\n\r\nalias hget=\u2019hadoop fs -get\u2019\r\n\r\nalias hf=\u2019hadoop fs\u2019\r\n\r\nalias hcat=\u2019hadoop fs -cat\u2019\r\n\r\nalias hdu=\u2019hadoop fs -du\u2019\r\n\r\nexport TMOUT=36000000\r\n\r\nC.4 Data\r\n\r\nThere are a large number of datasets available on the corporate clusters. These typically each\r\noccupy a subdirectory under data. The datasets on SUNSTORM are listed at\r\n\r\nhas equivalent datasets containing data\r\n\r\nprocessed at Bude rather than Cheltenham.\r\n\r\nC.5 Conventions and restrictions\r\n\r\nThe three corporate clusters are all configured similarly. This subsection refers to their\r\nconfigurations\u2014for the research clusters all bets are off and ICTR-DMR should advise you\r\nof any restrictions should you gain access.\r\n\r\nC.5.1 Scheduler\r\n\r\nThe clusters all have the Fair Scheduler installed [W19]. This replaces the vanilla FIFO that\r\nHadoop has installed by default. Fair scheduling is a method of assigning resources to jobs\r\nsuch that all jobs get, on average, an equal share of resources over time. When there is a single\r\njob running, that job uses the entire cluster. When other jobs are submitted, task slots that\r\nfree up are assigned to the new jobs, so that each job gets roughly the same amount of CPU\r\ntime.\r\n\r\n62\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nEach user (and special processing users) are assigned their own pool. The scheduler tries to\r\ngive each pool an equal amount of time on the cluster. Processing users also have a minimum\r\nnumber of map and reduce slots below which they will not drop if they request them. Further\r\neach user is restricted to having a single concurrent running job.\r\n\r\nC.5.2 HDFS /user/yoursid space\r\n\r\nOn logging into a corporate cluster you will have a HDFS home directory created at\r\n/user/yoursid. This is where the results of your Hadoop jobs will end up by default. That\r\nis, if you don\u2019t specify an absolute path,it will be taken relative to your home directory. Your\r\nhome directory has a size limit on it (believed to be 2TB). If you need more space than this\r\nthen you should contact the cluster administrators to find a solution.\r\n\r\nC.6 Running Hadoop on the LID\r\n\r\nIt is discouraged to use either SUN STORM or HAGER AWEL for developing code as they\r\nare both somewhat production systems. It is therefore a good idea to iron out bugs elsewhere\r\nif possible to ensure your code will not bring the cluster down. The easiest way to do this\r\nis probably on a pseudo-distributed Hadoop installation, following the instructions given in\r\nthe standard Hadoop documentation. If you wish to do this on the LID then you need to do\r\nslightly more to get around issues with localhost not always being the same depending which\r\nbox you are on. Following these instructions should give you working Hadoop instance. If the\r\nstandard ports are already in use then more configuration properties need to be added. At this\r\npoint it\u2019s probably best to either try another machine or ask for some advice.\r\n\r\n1.\tMake sure you can execute a passwordless ssh to your machine. This must be done using\r\nthe machine\u2019s hostname, not localhost. This is because there are multiple different LID\r\nservers, each with a different idea of what localhost is. By adding one machine\u2019s localhost\r\nto the known_hosts file you will cause yourself problems. If passwordless ssh does not\r\nwork execute the following commands.\r\n\r\nssh-keygen -t rsa -P \u2019\u2019 -f ~/.ssh/id_rsa\r\n\r\ncat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys\r\n\r\n2.\tChoose a directory in which to install Hadoop. This should be somewhere visible from\r\nall LID machines. Following shell scripting we will refer to this as $HADOOP_HOME. In fact\r\nyou might want to put the following into your .userprofile along with the other aliases\r\ngiven previously.\r\n\r\nexport HADOOP_HOME=/path/to/Hadoop/dir/\r\n\r\n3.\tUntar the hadoop tarball into $HADOOP_HOME.\r\n\r\n4.\tIn $HADOOP_HOME/conf/hadoop-env.sh add the line\r\n\r\nexport JAVA_HOME=/usr/lib/jvm/java-1.6.0/\r\n\r\n63\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n5.\tMake the directories $HADOOP_HOME/data and $HADOOP_HOME/name\r\n\r\n6.\tIn $HADOOP_HOME/conf/hdfs-site.xml add the entries\r\n\r\n<configuration>\r\n\r\n<property>\r\n\r\n<name>dfs.replication</name>\r\n\r\n<value>1</value>\r\n\r\n</property>\r\n\r\n<property>\r\n\r\n<name>dfs.data.dir</name>\r\n\r\n<value>HADOOP_HOME/data</value>\r\n\r\n</property>\r\n\r\n<property>\r\n\r\n<name>dfs.name.dir</name>\r\n\r\n<value>HADOOP_HOME/name</value>\r\n\r\n</property>\r\n\r\n</configuration>\r\n\r\nWhere HADOOPHOME is replaced with the Hadoop home directory. Using shell vari-\r\nables won\u2019t work here as the configuration files are read verbatim.\r\n\r\n7. In $HADOOP_HOME/conf/mapred-site.xml add the entries\r\n\r\n<configuration>\r\n\r\n<property>\r\n\r\n<name>mapred.job.tracker</name>\r\n\r\n<value>HOSTNAME:9001</value>\r\n\r\n</property>\r\n\r\n</configuration>\r\n\r\nWhere HOSTNAME is replaced with the hostname of the machine you are on.\r\n8. In $HADOOP_HOME/conf/core-site.xml add the entries\r\n\r\n<configuration>\r\n\r\n<property>\r\n\r\n<name>fs.default.name</name>\r\n\r\n<value>HOSTNAME:9000</value>\r\n\r\n</property>\r\n\r\n</configuration>\r\n\r\nWhere HOSTNAME is replaced with the hostname of the machine you are on.\r\n\r\n9. In $HADOOP_HOME/conf/masters and $HADOOP_HOME/conf/slaves replace localhost\r\nwith the hostname of the machine you are on.\r\n\r\n10.\tRun $HADOOP_HOME/bin/hadoop namenode -format to format the namenode.\r\n\r\n11.\tRun $HADOOP_HOME/bin/start-all.sh to start the Hadoop daemons.\r\n\r\n64\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n12.\tTo check this has worked OK go to http://HOSTNAME:50070/ to check on the status of\r\nthe namenode and http://HOSTNAME:50030/ for the jobtracker.\r\n\r\n13.\tNow you can try to run a toy Hadoop job. Copy the input files into the distrib-\r\nuted filesystem: $HADOOP_HOME/bin/hadoop fs -put conf input. Now run some of\r\nthe examples provided: $HADOOP_HOME/bin/hadoop jar hadoop-*-examples.jar grep\r\ninput output \u2019dfs[a-z.] + \u2019.\r\n\r\nWhen you log out of this LID session the Hadoop daemons will be killed by the logoff script.\r\nYou will therefore need to restart them in your next LID session. However each time you log\r\ninto the LID you cannot guarantee which machine you will be allocated. If you are allocated\r\na different machine to that where you installed Hadoop you will not be able to directly restart\r\nit. Instead you will need to do so over ssh:\r\n\r\nssh HOSTNAME \u2019HADOOP_HOME/bin/start-all.sh\u2019\r\n\r\nAgain HOSTNAME is the machine on which you originally installed Hadoop. You can then\r\nsubmit jobs and interact with HDFS from any LID machine, i.e. including the one you currently\r\nhave a session on. Hadoop will then carry on running until the end of the next session you are\r\nassigned on the machine on which you installed it.\r\n\r\nC.7 Further help and resources\r\n\r\nIn OPC-MCR^^^^^^^^^^| is the best contact for Hadoop questions,\tcan also\r\n\r\noffer advice, particularly on Streaming. Outside of MCR there is a large community of Hadoop\r\nusers and administrators. The best way to contact this community is probably through the\r\nrough_diamond chatroom on the Jabber server.\r\n\r\nThere are a large number of resources available on GCWiki. Some highlights, in no partic-\r\nular order:\r\n\r\n\u2022\t_(Work_Package): The main page for\r\nSILVER LINING, the work package within TDB that provides Hadoop clusters. It links\r\nto many places and may stay more up to date than this document.\r\n\r\n\u2022\t_-_User_Guide: An initial user guide for the\r\nSUN STORM cluster. However many of the tips hold in general across all Hadoop\r\nclusters.\r\n\r\n\u2022\t_-_Streaming_interface: A short guide to\r\nuser Hadoop Streaming with code examples to run on data on SUN STORM.\r\n\r\n\u2022\t: SILVER LIBRARY is a library of Ha-\r\ndoop parsers, writables and other utility classes to simplify development of MapReduce\r\nanalytics in Java. This pages describes at least some of it. Links to Utilities and Search\r\nare on the right hand side. The library is strongly recommded for Java MapReduce on\r\nthe corporate clusters as it has built in parsers that save users having to understand how\r\nthe events are structured.\r\n\r\n65\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nD Other computing resources\r\n\r\nThere are various computing options available to HIMR researchers beyond the bulk data\r\nsources of Hadoop and DISTILLERY. There is expertise in these environments at HIMR so we\r\nonly briefly document these options here. Further information can be found at [W22, W21].\r\n\r\nFirstly researchers have access to the Microsoft Windows environment of VALHALLA.\r\nVALHALLA is the standard desktop and provides email, Microsoft Office, web browsing, in-\r\nstant messaging and a gateway to other systems. The /data/himr_dm/ filesystem should be\r\naccessible in Windows with VALHALLA (at the time of writing the Windows mount location\r\nis not known).\r\n\r\nInstant messaging is accessible via the Pidgin application. Many employees of GCHQ can\r\nbe found online both for direct messaging and in chat rooms. The following chat rooms are\r\nof particular note: himr_dm (HIMR data mining research), distillery (DISTILLERY users),\r\nrough_diamond (Hadoop users), hecsupport (compute clusters queries) and lid_support (LID\r\nsupport). Instructions for getting going on Pidgin can be found at [W29].\r\n\r\nFrom VALHALLA researchers can access DISCOVER. This is GCHQ\u2019s document repos-\r\nitory. Literature for this research task has been filed at DISCOVER 10499535. Other sources\r\nof information that are of particular note are the the collaborative GCWiki [W15], which con-\r\ntains information about many GCHQ activities, and the Safari online bookshelf [W35], which\r\nprovides electronic versions of many technical books.\r\n\r\nThe primary interactive data analysis environment will be the Linux Interactive Desktop\r\n(LID). The LID provides a remote desktop onto a RedHat Linux box. Various mathematical\r\ntools such as R, Matlab, Mathematica, Maple, Sage and Magma are available. Scripting\r\nlanguages are available: Perl is the most commonly used scripting language in GCHQ but\r\nPython is starting to gain traction. Compilers are also available for C, C++ and Fortran. It\r\nis worth noting that GCHQ have imported the general repository for R packages, CRAN, at\r\n[W9] and implementations of many machine learning techniques can be found there.\r\n\r\nThere are two Linux compute clusters available. MOUNT MCKINLEY is probably\r\nthe machine of choice and has 652 compute nodes each with 8 cores, giving a total of 5216\r\ncores. The cores are clocked at 2.4GHz. Each node has 32GB of RAM and there is a fast\r\ninterconnect between nodes. MOUNT MCKINLEY can be accessed from VALHALLA. The\r\ncatch with MOUNT MCKINLEY is there are few user tools available and hence it should\r\nprimarily be seen as a place to run compiled code (Perl and Python scripting is also available).\r\nMOUNT MCKINLEY is also used for operational processing so researchers will need to abide\r\nby conventions around HIMR\u2019s use. An older compute cluster called SEPANG is also available\r\nbut is expected to be decommissioned shortly. SEPANG is firewalled from the rest of the GCHQ\r\nnetwork and does not have easy access to any of the data sources described; however it does\r\nhave a wide range of user tools installed and is reserved for HIMR\u2019s sole use.\r\n\r\nBoth the LID and MOUNT MCKINLEY user nodes mount\tIf you want\r\n\r\nto analyse data from Hadoop or DISTILLERY on LID or MOUNT MCKINLEY then you will\r\nneed to transfer the data with scp.\r\n\r\n66\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nE Legalities\r\n\r\nThis appendix is intended as a brief guide to the legal information of most relevance to your\r\nwork at HIMR. However [W25] and your legalities training should be treated as the definitive\r\nreferences.\r\n\r\nE.1 Overview\r\n\r\nGCHQ always complies with UK law12. In particular we are bound by the Regulation of\r\nInvestigatory Powers Act (RIPA) and Intelligence Services Act (ISA). RIPA requires GCHQ to\r\nhave arrangements in place to minimise its retention and dissemination of intercepted material.\r\nRIPA also applies specific protection to the communications of people in the UK. ISA requires\r\nGCHQ to have arrangements in place to ensure that it obtains or discloses information only in\r\nthe proper discharge of its functions or for the purpose of any criminal proceedings.\r\n\r\nThe complete and official compliance guide can be found in [W25]. In general we must be\r\nable to demonstrate that our actions are both necessary and proportionate. We show that our\r\nactions are necessary and proportionate by producing an accountable record for oversight and\r\naudit. This typically takes the form of an HRA (Human Rights Act) justification. The Human\r\nRights Acts defines the basic rights everyone must have respected. In particular there is a right\r\nto privacy which can only be violated \u201cin the interests of national security, public safety or the\r\neconomic well-being of the country, for the prevention of disorder or crime, for the protection of\r\nhealth and morals, or for the protection of the rights and freedoms of others.\u201d For GCHQ this\r\nmeans we must justify our activities as being in the interests of national security, the economic\r\nwell-being of the UK, or in support of the prevention or detection of serious crime.\r\n\r\nYou should bear in mind that you have signed and are bound by the Official Secrets Act\r\n(OSA). In particular you should take care in discussing or releasing potentially classified data\r\nand techniques. If you are unsure on an item\u2019s classification then you should seek guidance from\r\nthe data owner. Our data and information is also exempt from the Freedom of Information\r\nAct (FOIA). All documents should carry the same caveat as this document.\r\n\r\nAs accessing the content of an individual\u2019s communications is regarded as more invasive\r\nthan examining its metadata there are tighter restrictions imposed on such data. Content need\r\nnot necessarily be an email or phone call. For example, the content of a URI beyond the first\r\nslash is considered content, as are the specifics of someone\u2019s online mapping activity.\r\n\r\nE.2 Procedures\r\n\r\nWe now highlight some specific procedures that should be followed when working with bulk\r\nmetadata.\r\n\r\nDetailed policy guidance for corporate Hadoop clusters can be found at [W26]. We give the\r\nmost relevant information here. If you are extracting a dataset or performing analyses in a way\r\nwhich is not expected to target an individual then there is no need to do anything. However if\r\nthe criteria specify individuals, or behaviours which are sufficiently precise that they apply to\r\nonly a few individuals, then you will need to complete a manual HRA log [W23]. You do not\r\nneed to complete this every time that you perform the same extraction, or perform follow-on\r\n\r\n12The bulk of our work is also compliant with the policies and laws of five-eyes partners.\r\n\r\n67\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nanalysis using similar techniques and for a similar purpose, so long as you write your first log in\r\na way that is just general enough to cover your current work. Further if your analyses specify\r\nfive-eyes individuals or organisations, or if the query includes data that is designated as content\r\nthen you will need Sensitive Targeting Approval in addition to completing a manual HRA log.\r\n\r\nWhen completing a manual HRA log the application name should be \u201cSILVER_LINING\u201d\r\nif working on a Hadoop cluster. The reason should be \u201cNS\u201d (national security), a JIC pri-\r\nority of \u201c1\u201d and MIRANDA number of \u201c20135\u201d (\u201cIntelligence in support of GCHQ research\r\nwork intended to maintain and develop general purpose capabilities in the field of target com-\r\nmunications in order to be able to meet such intelligence requirements as may be specified\r\nnow and in the future\u201d). If you are developing new techniques then the query type should\r\nbe \u201cQFD-DEVELOPMENT\u201d, or if selecting data that focuses down to a few individuals then\r\n\u201cBULKEXTRACT\u201d.\r\n\r\nQueries in DISTILLERY should also be logged using the manual HRA logging service and\r\nmost of the guidance above applies. Until \u201cDISTILLERY\u201d is added to the list of applications,\r\nplease use \u201cBLACK_HOLE\u201d. The data source should be the source most closely matching the\r\nfeeds you are using, otherwise use \u201cAD_HOC_EXTERNAL_DATA\u201d. In order to complete the\r\n\u201cNumber of Results Returned\u201d field you will need to submit the log after you have run the\r\nquery - there is currently no way for you to update a manual HRA log.\r\n\r\n68\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nF Data\r\n\r\nIn this appendix we summarise the datasets made available at the outset of this research.\r\nResearchers are encouraged to work with GCHQ staff to find other datasets if required.\r\n\r\nF.1 SIGINT events\r\n\r\nFirstly we describe datasets of raw SIGINT events: typically these are available as live datasets\r\nin Hadoop or DISTILLERY.\r\n\r\nF.1.1 SALAMANCA\r\n\r\nThe contents of this dataset are classified TOP SECRET STRAP2 CHORDAL.\r\n\r\nGCHQ collects telephone call record events from a wide variety of sources, and these are stored\r\nin a database called SALAMANCA [W36]. This data is also fed to the SUN STORM cloud\r\nand the BHDIST DISTILLERY cluster (and other DISTILLERY clusters). This data is a\r\nrelatively low rate feed of user events, around 5000 events per second, and can be viewed as\r\neither a directed or undirected graph. It could be used for the streaming EDA and streaming\r\nexpiring graphs topics as well as feature extraction for payphones for the beyond supervised\r\nlearning topic.\r\n\r\nIn general we have better collection of calls where the two sides are in different countries,\r\nalthough for some countries we also have good collection of in-country calls. This means the\r\ngraph can have some unusual features and it is worth bearing these in mind when examining\r\nfeatures of the graph. Some properties of SIGINT collected telephony graphs are discussed in\r\n[I33, I34]. A comparison between SIGINT collected call records and billing records is given in\r\n\r\n[I73].\t_________________\r\n\r\nOn SUN STORM the data can be found under\tin folders named by\r\n\r\ndate. The full format is as described in the Interface Control Document [I79] but with an\r\nadditional field at the end which uniquely identifies the event within SUN STORM.\r\n\r\nIn DISTILLERY the data is forwarded into the shared SPL instance on the BHDIST cluster\r\nby running a VlTCPSource in client mode. The resulting stream can be subscribed to using\r\nthe subscription DataFeed==\"Salamanca\" && EventType==\"FullCallRecord\".\r\n\r\nThe full data contains many attributes, but the relevant ones are the timestamp and\r\ncallLength along with identifiers. Records will typically have some of dialledNumber, di-\r\nalledNumberNorm, callerID and callerIDNorm, where the \u201cNorm\u201d versions may have been\r\nnormalised, for example by adding the country code. The normalised versions are in E.164\r\nformat and give the fully qualified number as opposed to the digits actually dialled which could\r\ninclude just the local number.\r\n\r\nSome identifiers are specific to mobile telephony, including the IMSI (which is an ID for a\r\nSIM card), the IMEI (which is an ID for a mobile phone handset), and the MSISDN (which\r\nshould match one of dialledNumberNorm and callerIDNorm). To know which side of the call\r\nthese attributes refer to you must also read the CallDirection attribute which is either \u201cMO\u201d\r\nfor mobile originated (i.e. the IMSI and IMEI relate to the callerID) or \u201cMT\u201d for mobile\r\nterminated (i.e. the IMSI and IMEI relate to the dialledNumber).\r\n\r\n69\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nMay 01\tMay 06\tMay 11\tMay 16\tMay 21\r\n\r\nTime\r\n\r\nFigure 6: Plot of events counts per hour in our snapshot of FIVE ALIVE data. The period from\r\nMay 6-11 is clearly the best quality.\r\n\r\nF.1.2 FIVE ALIVE\r\n\r\nFIVE ALIVE is an ICTR prototype Query Focused Dataset (QFD) providing access to bulk\r\nIP-IP connection events, giving a unique unselected view of all activity on SIGINT bearers.\r\nEach record in FIVE ALIVE summarises a flow between two IP addresses. This summary\r\nconsists of:\r\n\r\n\u2022\tThe start of flow time, unfortunately at second granularity in the static dataset, but\r\nmicrosecond granularity in DISTILLERY.\r\n\r\n\u2022\tThe source and destination IPs and ports and the protocol\u2014together these are known as\r\nthe 5-tuple, hence the name FIVE ALIVE.\r\n\r\n\u2022\tOptionally extra information on flow size and direction depending upon the protocol.\r\nThe data format is fully described in [I9].\r\n\r\nWe have a snapshot of FIVE ALIVE data covering, with gaps, approximately 6-19 May\r\n2011. Figure 6 shows the number of events per hour in this snapshot. This snapshot is available:\r\n\r\n\u2022\tOn the GOLD MINE Hadoop cluster at\tin hdfs. The\r\n\r\ndates on the subdirectories indicate when it was loaded into the cluster and should be\r\nignored.\r\n\r\n\u2022\tOn Mount McKinley at\r\n\r\nThere is also a feed of streaming FIVE ALIVE data on the BHDIST DISTILLERY\r\ncluster. It is a high-rate feed (around 1 million events a second) and is published in\r\nmultiple \u201cSplits\u201d. They can be imported in the shared instance using the subscrip-\r\ntion DataFeed == \"FiveAlive\" && EventType == \"FlowRecord\" && Split == \"N\" where\r\nN ranges from 0 to 11 (but this may be increased to accommodate additional bearers). Don\u2019t\r\nleave out the Split condition or you\u2019ll get all the data in one feed. Ideally you should run your\r\ninitial processing on the same host as the data is published to reduce network load. This data\r\ncould also be made available at Bude to provide a multi-site high-rate feed.\r\n\r\n70\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nF.1.3 HRMap\r\n\r\nThe contents of this dataset are classified TOP SECRET STRAP2 CHORDAL.\r\n\r\nWhen a user requests a webpage from the internet, this is observed in SIGINT as an HTTP\r\nGET request. As well as the page requested it often contains the URL of the previously viewed\r\npage. The hostname of the requested page is the \u201cHOST\u201d and the hostname of the previous\r\npage is the \u201cREFERRER\u201d. When we consider just the hostnames rather than the full URI\r\nthen this is considered events data. This can be viewed as a directed graph of hostnames, and\r\nis given the name HRMap at GCHQ. It is a moderately high rate stream (around 20000 events\r\nper second) which should be suitable for the streaming EDA and streaming expiring graphs\r\ntopics.\r\n\r\nSince many web pages point to other web pages on the same server, a large proportion of\r\nHRMap events have the hostname matching the referrer. Many records will have no referrer.\r\nThis happens if the user typed the URL, uses a bookmark, or has configured their browser not\r\nto send the referrer attribute.\r\n\r\nAs well as the host and referrer, an HRMap record also contains a timestamp (in seconds),\r\nthe client IP address, the client port, and the client HTTP header fingerprint (HHFP) which\r\nis a hash of various headers sent by the client and can be used to approximately distinguish\r\nclients behind a gateway [I38].\r\n\r\nHRMap data is available in DISTILLERY on the bhdist cluster.\r\nIt can be imported in the shared instance using the subscription\r\nDataFeed == \"HRMap\" && EventType == \"HostReferrer\". HRMap could also be made\r\navailable at Bude to give a multi-site streaming graph\r\n\r\nStatic HRMap is available on the SUN STORM Hadoop cluster at\r\nand\tNow that the HAGEL AWEL Hadoop cluster at Bude is\r\n\r\noperational, data collected there will no longer be loaded onto SUN STORM. Data collected\r\nat Bude now instead is loaded onto HAGER AWEL at\tThe Bude data\r\n\r\nat Cheltenham will gradually age off and be deleted 6 months after its load date.\r\n\r\nF.1.4 SKB\r\n\r\nThe contents of this dataset are classified TOP SECRET STRAP2 CHORDAL UKEO.\r\n\r\nThe Signature Knowledge Base is a system for tracking file transfers made on the internet. A\r\nrecord is made each time we see certain file types being transferred. Each file is identified by\r\nits format and a hash of some of its content. Whilst this does mean we can store the data,\r\nhash collisions are inevitable. Therefore one cannot guarantee that all records referring to the\r\nsame hash are in fact the same file. Further we only process a small number of different file\r\nformats. The dictionary of which file types are logged is given in [I86].\r\n\r\nEach single line record in the SKB dataset has the format:\r\n\r\ndate time src_IP dst_IP frag_# IP_ID len protocol.# src_port dst_port seq_#\r\nack_# file_offset file_type file_signature src_geo dst_geo\r\n\r\ne.g.\r\n\r\n71\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n22:59:58 03-08-2011 192.168.2.1 10.0.0.1 16384 45872 1398 6 80 53302 4032239316\r\n4106241239 256 SWF-Compressed-V9 Geo-IP-Src 32\r\n55.0436;37.3378;MOSCOW;RU;5MMM Geo-IP-Dst 25 40.4;-3.68;MADRID;ES;7LMH\r\n\r\nFor more details on how the logging is performed and the hashes calculated see [I67, I22].\r\nThe SKB data is stored both in a QFD for analysts to query and in BLACKHOLE. We\r\nhave an extract of 1 week on SKB data\tIf you require more data\r\n\r\nthen it is possible to extract some using the blacktools interface.\r\n\r\nF.1.5 Arrival Processes\r\n\r\nThe contents of this dataset are classified SECRET STRAP 2.\r\n\r\nThere are two standard datasets that have been used to evaluate all approaches to temporal\r\ncorrelation. These are known as the telephony and C2C datasets. They both consist of records\r\nof stochastic processes in the format\r\n\r\n<name>\\t<Number of events>\\t<Space separated event times>\r\n\r\nand files containing pairs of identifiers to be scored in the format\r\n\r\n<name1> <name2>\r\n\r\nThe data is stored in /data/himr_dm/data/arrival_processes.\r\n\r\nTelephony data\r\n\r\nThe original event times were taken from 18 weeks worth of telephony data. These event times\r\nwere then transformed to give the times in the .sps files.\r\n\r\nRandom pairs of event times are generated this way: choose a pair of distinct originating\r\nnumbers, A and B; choose from the set {1,..., 17}; circularly shift the event times of B by 5\r\nweeks (i.e. modify the event times of B by adding 5 x 604800 to them modulo T = 18 x 604800,\r\n604800 being the number of seconds in a week). The purpose of the cyclic shift is to reduce the\r\neffect of any \u201crandom\u201d pairs in which some of A\u2019s calls truly cause B to make calls. Shifting\r\nby one-week multiples is done to retain the time-of-day and day-of-week structure of the data.\r\nIf time interval [0, T) can be partitioned into two subintervals, one containing all of the events\r\nof A and the other containing all of the events of B, then (A, B) is rejected as a random\r\npair for experimental purposes since presumably no one would consider that they might be\r\ncorrelated. The stochastic processes generated in this way are in the file^^^^^^^^s. This\r\nfile contains 151,811 processes. B\u2019s name has 5 appended to show the size of the shift. For\r\nexample if 441242221491 had been shifted 3 weeks it would be called 441242221491.03.\r\n\r\nCausal pairs of event times are generated this way: generate a random pair (A, B); randomly\r\nselect proportion p of A\u2019s call initiation times; to each selected initiation time, add the duration\r\nof the corresponding call plus a delay drawn from an exponential distribution with mean f\r\nseconds; merge the resulting times into B\u2019s call initiation times. A proportion of A\u2019s calls\r\ncause B to make a call, and B makes these calls after the causative call of A ends and after a\r\n\r\n72\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nrandom delay. The causal stochastic processes are in files\ts. The standard\r\n\r\none used in experiments is\ts. This file contains 155,746 processes. B\u2019s\r\n\r\nname has 5 and A\u2019s name appended. For example if 441242221491 had been shifted 3 weeks and\r\nhad a causal dependency on 441242226816 it would be called 441242221491.03.441242226816.\r\nBoth the random and causal pairs for CLASP to score are listed in the file\r\n\r\nC2C data\r\n\r\nThe event times were taken from 93 days of C2C presence activity. Records are logged each time\r\nthe identifier is seen performing an activity. The timestamps in the C2C data are unaltered to\r\nprovide a realistic test dataset. The stochastic processes are in the file ip.all.sps.new.sun2.\r\nThere are 457,305 processes in this file.\r\n\r\nThere are also two pairs files. The file\tcontains 431,689 random pairs.\r\n\r\nThe file\tcontains 45,932 pairs in which the proportion of causal pairs was\r\n\r\nthought by the data experts to be relatively high, compared to the proportion of causal pairs\r\nin the set of all identifier pairs. The exact criteria for making it onto these lists can be found\r\nin section 2.4 of [I49]. The names of identifiers consist of the username, a series of dots and\r\ndashes and then the identifier type. There are no transformations done to the names in the\r\nC2C data.\r\n\r\nF.1.6 SOLID INK and FLUID INK\r\n\r\nThe contents of this dataset are classified SECRET STRAP1.\r\n\r\nThese are quite old telephony datasets, but we feel it is worth highlighting them to HIMR\r\nresearchers because the view they offer is so unusual.\r\n\r\nSOLID INK is three weeks of telephony events from 2007, as seen from billing records.\r\nFLUID INK is an approximate subset of SOLID INK, but as seen via GCHQ\u2019s SIGINT collec-\r\ntion. Our points of access mean that we mostly collect calls between the target country and the\r\nrest of the world; therefore in-country calls are likely to be missing from FLUID INK. Indeed,\r\nSOLID INK has 2.7 billion events involving 74 million numbers, while FLUID INK has only\r\n136 million events involving 15 million numbers.\r\n\r\nThere are also various sources of SIGINT noise which are poorly understood, such as missing\r\ncalls, duplicate calls, node mislabelling and timing errors. We only have anonymized versions\r\nof the datasets available: for legal reasons, we could not retain the unminimized versions this\r\nlong.\r\n\r\nEach INK data set has four fields: timestamp, user-1, user-2 and a number. Unfortunately,\r\nthe timestamp fields seem to have become corrupted somewhere along the line, and in different\r\nways in each of the datasets. However, timestamp deltas within each set are probably still\r\ncorrect (in seconds). In FLUID INK the call direction is user-1 to user-2, and the fourth field\r\n\r\n73\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nis call duration in seconds. In SOLID INK the fourth field is a code in {1, 2, 3, 4}, where:\r\n\r\n1\t= Voice user-1 to user-2\r\n\r\n2\t= SMS user-1 to user-2\r\n\r\n3\t= Voice user-2 to user-1\r\n\r\n4\t= SMS user-2 to user-1\r\n\r\nThe datasets are available at\tand\r\n\r\nThere are also\r\n\r\nversions, where events involving pizza nodes have been removed.\r\n\r\nA very interesting analysis of these datasets came out of the 2008 graph mining SWAMP at\r\nHIMR [I73], which revealed just how great the disparity between SIGINT and \u2018ground truth\u2019\r\ncan be, for example when it comes to contact chaining. CSEC have also done some work that\r\nlargely confirms and replicates those results [W4].\r\n\r\nF.1.7 Squeal hits\r\n\r\nThe contents of this dataset are classified TOP SECRET STRAP2 CHORDAL UKEO.\r\n\r\nSqueal is a signature-based system for detecting electronic attacks, see [W39]. When a poten-\r\ntial attack is detected a hit is forwarded to DISTILLERY. Each hit contains the source and\r\ndestination IPs and ports, the timestamp, the hit details and geolocation for the IP addresses.\r\nBy examining multiple hits we may be able to learn about the attacks. For example, we might\r\nlook for multiple IP addresses that launch attacks in a similar way.\r\n\r\nA stream of Squeal hits is initially created on the AHS Explore DISTILLERY cluster,\r\nhowever this is also forwarded to the shared SPL instance on the BHDIST cluster. It can be\r\nimported using the subscription DataFeed==\"Squeal\" && EventType==\"SquealHit\". This is\r\na low rate stream, around 75 events per second, and contains the hits from all sites.\r\n\r\nSqueal hits are available on the SUN STORM Hadoop cluster at /data/ead. This covers\r\nevents collected from all sites.\r\n\r\nF.2 Open-source graphs and events\r\n\r\nWe also provide some open-source graphical and events based data which may be of specific\r\nrelevance to this research.\r\n\r\nF.2.1 Enron\r\n\r\nThe contents of this dataset are classified UNCLASSIFIED.\r\n\r\nEnron was an American energy company that collapsed in 2001 due to massive financial fraud\r\nand eventual bankruptcy. After criminal proceedings were completed the complete emails of\r\naround 150 Enron employees, mostly senior management, were publicly released. There are\r\napproximately half a million emails covering November 1998 to July 2002. There is a brief\r\nintroduction to this dataset in [E22]. This gives a few summary statistics, such as number\r\nof emails per user and conversation thread length. We have a copy of enron.sql, the SQL\r\n\r\n74\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\ndatabase file which contains this data. The format of this is not particularly nice so we have\r\nalso extracted a simpler data set, which hopefully contains the data needed for this work. If\r\nnot it is not too hard to return to the original file to gather more data. This formatted file is\r\ncalled enron_transactions.txt. Each email has one record for each recipient, however each\r\nline contains all relevant information. Each record is tab separated with the following fields\r\n\r\n<time> <timezone> <message_id> <sender> <recipient> <recipient_type> <subject>\r\n\r\nThese data files can be found at\r\nF.2.2 US flights data\r\n\r\nThe contents of this dataset are classified UNCLASSIFIED.\r\n\r\nThe American Statistical Association\u2019s Data Expo \u201909 asked for analysis of a large dataset\r\nof US flight arrivals and departures. The data was made available to the public by the\r\nUS Department of Transport\u2019s research arm, RITA (Research and Innovative Technology\r\nAdministration), and covers the years 1987 to 2008. The Expo \u201909 website is mirrored at\r\n\r\nIt con-\r\ntains a fuller description of the problem, as well as the winning posters produced by participants\r\nin the competition.\r\n\r\nWhen the Home Office decided to fund UKVAC research (see section 5.8.2), it was decided\r\nto provide the researchers with two unclassified challenge problems in order to focus their\r\nefforts. One was chosen by the HUMINT agencies: to predict the next winners of Nobel prizes.\r\nThe second came from GCHQ, and was to do further analysis on the RITA flights data. In\r\nfact, the second author of this problem book was largely responsible for selecting the problem\r\nand framing its statement, so it mirrors very closely the point of view of this problem book,\r\nparticularly section 5. The flights are meant to be an unclassified proxy for SIGINT events\r\ndata, and although the dataset can just about be handled in core on modern hardware, UKVAC\r\nparticipants were strongly encouraged to process the data in a stream.\r\n\r\nWe hope that researchers will be able to compare their approaches, especially on visual-\r\nization questions, with what the UKVAC comes up with: having a common dataset should\r\nhelp with that. In case any direct collaboration emerges with UKVAC participants, having the\r\ndataset they are working on to hand will obviously also be a significant help.\r\n\r\nThe data consists of 22 bzipped CSV files, one for each year. Each record has 29 fields,\r\ndescribed in table 4. Supplemental CSV files describe the codes used for airports, carriers and\r\nsome individual planes: see the\tpage on the Expo \u201909 mirror.\r\n\r\nF.2.3 Wikipedia graph\r\n\r\nThe contents of this dataset are classified UNCLASSIFIED.\r\n\r\nThis is not directly relevant for SIGINT, but there are several reasons why it might be handy\r\nto have around. Many outside algorithms get tested on this graph, so it might be useful for\r\nbenchmarking, or as test data to apply algorithms intended for external publication to. It is\r\nalso a foil for HR map (appendix F.1.3): although that data set does not contain internal clicks\r\nbetween Wikipedia pages (so there is no direct comparison), nonetheless it might be interesting\r\n\r\n75\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nIndex\tName\tDescription\r\n1\tYear\t1987-2008\r\n2\tMonth\t1-12\r\n3\tDayofMonth\t1-31\r\n4\tDayOfWeek\t1 (Monday) - 7 (Sunday)\r\n5\tDepTime\tactual departure time (local, hhmm)\r\n6\tCRSDepTime\tscheduled departure time (local, hhmm)\r\n7\tArrTime\tactual arrival time (local, hhmm)\r\n8\tCRSArrTime\tscheduled arrival time (local, hhmm)\r\n9\tUniqueCarrier\tunique carrier code\r\n10\tFlightNum\tflight number\r\n11\tTailNum\tplane tail number\r\n12\tActualElapsedTime\tactual time in minutes\r\n13\tCRSElapsedTime\tscheduled time in minutes\r\n14\tAirTime\tair time in minutes\r\n15\tArrDelay\tarrival delay, in minutes\r\n16\tDepDelay\tdeparture delay, in minutes\r\n17\tOrigin\torigin IATA airport code\r\n18\tDest\tdestination IATA airport code\r\n19\tDistance\tin miles\r\n20\tTaxiln\ttaxi in time, in minutes\r\n21\tTaxiOut\ttaxi out time in minutes\r\n22\tCancelled\twas the flight cancelled?\r\n23\tCancellationCode\treason for cancellation (A = carrier, B = weather, C = NAS\u2014air traffic control system failure, D = security)\r\n24\tDiverted\t1 = yes, 0 = no\r\n25\tCarrierDelay\tin minutes\r\n26\tWeatherDelay\tin minutes\r\n27\tNASDelay\tin minutes\r\n28\tSecurityDelay\tin minutes\r\n29\tLateAircraftDelay\tin minutes\r\n\r\nTable 4: Flights data fields.\r\n\r\n76\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nto compare in broad terms how algorithms perform on the dynamic HR map of clicks versus a\r\nstatic graph of links.\r\n\r\nThe data files are in\tThere is a list of vertices,\r\n\r\nwhich are all the articles on the English Wikipedia at a\r\ncertain point in 2008. Whenever an article links to another article, there is a corresponding\r\nline\tgiving the source and target of the link (as indices into\r\n\r\nthe .title file).\r\n\r\nF.3 SIGINT reference data\r\n\r\nTo help researchers enrich their research findings we provide lists of websites of interest and\r\ntarget selectors. We also provide lists of covert infrastructure and known payphones to support\r\nresearch on information flow in graphs and positive-only learning.\r\n\r\nF.3.1 Websites of interest\r\n\r\nThe contents of this dataset are classified TOP SECRET STRAP2 UKEO.\r\n\r\nA list of websites of interest is available in a database on\t. These\r\n\r\nhave been manually classified through open source research and contain radical and extremist\r\nsites along with many others. These may be useful when examining HRMap data to determine\r\ntarget density.\r\n\r\nTo get a list of radical and extremist sites, first get a username and password from Andrew\r\nRoss (ajrossl). Then connect to the database and run the query as follows:\r\n\r\n~db2user/sqllib/bin/db2 connect to DIST1\r\n\r\n~db2user/sqllib/bin/db2 \"select SITENAME, RADICALISM, Type, URL\r\nfrom\r\n\r\nwhere RADICALISM = \u2019Radical\u2019 or RADICALISM = \u2019Extremist\u2019\"\r\n\r\n~db2user/sqllib/bin/db2 connect reset\r\n\r\nIt is also possible to use this data directly in DISTILLERY using the Database toolkit.\r\nF.3.2 Target selectors\r\n\r\nThe contents of this dataset are classified TOP SECRET STRAP2 UKEO.\r\n\r\nOur target knowledge database is BROAD OAK which includes the ability to task various\r\nselector types including phone numbers and email addresses. The resulting list of selectors is\r\nsometimes called the target dictionary and is delivered to our DISTILLERY clusters at least\r\nonce a day, and is also available on our Hadoop clusters. This data could be used to see if some\r\nresult set contains an increased density of targets.\r\n\r\nFor DISTILLERY, the telephony and C2C dictionaries are delivered in separate streams\r\nand can be imported with DataFeed==\"BroadOak\" && EventType==\"TargetSelector\" and\r\nDataFeed==\"BroadOakC2C\" && EventType==\"TargetSelector\" respectively. A re-send of the\r\nlatest dictionary can be requested by sending a UDP packet to\r\n\r\n(port 10450 for telephony, 10460 for C2C) containing the line resend. This could be sent with\r\na UDPSink operator.\r\n\r\n77\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nOn SUN STORM, the BROAD OAK reference data (all target types) is in HDFS at\r\n\r\nWhen using selectors to examine parts of a graph then this is considered targetting and an\r\nHRA log must be completed. See appendix E on page 67 for details.\r\n\r\nF.3.3 Covert Infrastructure\r\n\r\nThe contents of this dataset are classified TOP SECRET STRAP1.\r\n\r\nGCHQ has knowledge of, and collection from, CNE acceses owned by foreign intelligence\r\nagencies. This is done without their permission and is known as fourth party collec-\r\ntion. As data is exfiltrated from target networks we should be able to see information\r\nflows over their infrastructure. Data on foreign covert infrastructure can be found at\r\n\r\nWe also have knowledge of our own covert infrastructure. However this data is understand-\r\nably more sensitive. Work is still ongoing to explore the possibility of making this dataset\r\naccessible to HIMR researchers.\r\n\r\nF.3.4 Conficker botnet\r\n\r\nThe contents of this dataset are classified SECRET STRAP1.\r\n\r\nGCHQ has an interest in being able to detect botnets operating in the wild. This is cur-\r\nrently done using packet content fingerprinting and specific behaviours of certain bot software.\r\nHowever we would like to be able to detect botnets only by their generalisable activity. For\r\nthe Conficker botnet we have a list of IP addresses that hit against either the packet fin-\r\ngerprinting or a Conficker specific activity profile. The fingerprinted IPs can be found at\r\n\r\nThis set should be largely reliable as\r\nthe signature is believed to be highly discriminative. The behaviourally identified IPs are at\r\n\r\nThese are slightly more tentative and\r\nare based on the Conficker software contacting remote IPs on specific ports. Of course this can\r\nhappen randomly so only those IPs which perform a significantly high number, after Bonferoni\r\ncorrection, make the list. As Conficker contains a peer-to-peer (P2P) component we believe\r\nthat there may be information flows involving these potentially infected IPs.\r\n\r\nF.3.5 Payphones\r\n\r\nThe contents of this dataset are classified TOP SECRET STRAP1.\r\n\r\nAnalysts are interested in understanding telephone numbers in their analysis. A particular\r\nfeature of a number they would like to know is whether the number is a payphone. The fact\r\nthat a number is a payphone would suggest that contact chaining through the number is not\r\nrecommended. On the other hand some target discovery work starts with a known modus op-\r\nerandi of payphone usage (which targets follow to make it hard to target their communication)\r\nand so looking for communication between payphones is the starting point.\r\n\r\nHowever GCHQ have lists of payphones for very few countries. The aim is start from partial\r\nlists of payphones in some countries and extend to full lists of payphones in those countries\r\n\r\n78\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nCountry\r\n\r\nSpain\r\n\r\nPakistan\r\n\r\nPakistan\r\n\r\nBarbados\r\n\r\nSurinam\r\n\r\n# known payphones\r\n93,634\r\n3,117\r\n118\r\n761\r\n363\r\n\r\nFilename\r\n\r\nNotes\r\n\r\nBelieved near complete\r\nPartial\r\n\r\nPartial (FATA region only)\r\n\r\nPartial\r\n\r\nPartial\r\n\r\nTable 5: Known payphones\r\n\r\nand in other countries based on call meta-data. This problem is an example of positive-only\r\nlearning.\r\n\r\nhas provided lists of payphones in four countries as described in\r\n\r\ntable 5.\r\n\r\nGCHQ have recently moved their telephony event data to the cloud and we do not have\r\nfeature extraction algorithms for this data. However the basic features in [I3] should be easy to\r\nimplement from scratch as an Hadoop analytic using the data as described in appendix F.1.1.\r\n\r\nWe also provide the source code for the original SPIKY ROCK feature extraction as C code.\r\n\r\nThe use of payphones is an active interest so a complete Hadoop feature extraction and \u25c4\r\nclassification analytic would be likely to be directly taken on by GCHQ and results fed into\r\nthe the LUCKY STRIKE database.\r\n\r\nThe data and the old SPIKY ROCK source code is available in\r\n\r\nF.4 SIGINT truthed data\r\n\r\nTo support the beyond supervised learning research we provide several SIGINT truthed datasets\r\nfrom recent research.\r\n\r\nF.4.1 Logo recognition\r\n\r\nThe contents of this dataset are classified SECRET STRAP1.\r\n\r\nWe are interested in automatically detecting the source of videos on the internet through the\r\nrecognition of logos in the video. We have previously researched logo detection and have recently\r\nlooked at supervised machine learning for logo recognition [I19].\thas\r\n\r\nprovided the data from this research.\r\n\r\nThe feature space is derived as follows:\r\n\r\n1.\tLogo detection algorithms give us the logo and mask (i.e. the logo shape) as 8-bit images.\r\nThe mask is binary in that values are either 0 or 255 (i.e. black or white).\r\n\r\n2.\tBoth the logo and mask are independently downscaled to 8 x 8. During these down-\r\nsampling processes the results are rescaled so that they retain their original pixel depth\r\n(i.e. 8-bit).\r\n\r\n3.\tThese 2 resulting 8-bit images are pointwise multiplied to give a 16-bit image (with a\r\nrange of 0-65535).\r\n\r\n79\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n4.\tThis 8 x 8 16-bit image is our feature vector.\r\n\r\nSam is happy to look at extracting other features if HIMR actively research this dataset.\r\n\r\nWe provide 530 truthed samples. The data has been truthed to 109 classes. 7 classes have\r\nmore than 20 examples, 67 classes have only 1 example.\r\n\r\nfrom ICTR-MCA is happy to work with JTRIG to try and provide larger\r\nuntruthed datasets if the researchers decide to work on this problem.\r\n\r\nThe data is available\tThe first field \u201cClass\u201d is\r\n\r\na numeric representation of the class and the remaining fields are the features.\r\n\r\nF.4.2 Spam detection\r\n\r\nThe contents of this dataset are classified SECRET STRAP1.\r\n\r\nSpam emails are a large proportion of emails seen in SIGINT. GCHQ would like to reduce the\r\nimpact of spam emails on data storage, processing and analysis. Most external spam detectors\r\nwork by analysing the content of an email however policy and processing mean this option is\r\nnot always open to us. We must work on features derived from events alone. We therefore\r\nlower our target and instead aim to classify email addresses by the type of emails they send.\r\n\r\nhas provided datasets from his team\u2019s research into this prob-\r\nlem. They built a classifier called MYOFIBRIL [I44]. The dataset consists of an 1809 example\r\nemail addresses with 143 features each truthed into 11 classes. Note that one class is \u201cmul-\r\ntiple_classes\u201d and one class is \u201cuncertain\u201d.\r\n\r\nThis data set is provided in\tThis directory also contains a\r\n\r\nPDF documenting the dataset in more detail [I43].\r\n\r\nIt would be possible to use the data\ton SUN STORM (reading\r\n\r\nthese files with SILVER LIBRARY is recommended) to generate untruthed feature vectors.\r\nHowever it should be noted that the collection posture of GCHQ has changed considerably\r\nsince the truth data was collected.\r\n\r\nF.4.3 Protocol classification\r\n\r\nThe contents of this dataset are classified SECRET STRAP1.\r\n\r\nGCHQ is interested in understanding C2C traffic on bearers. One approach is to use signa-\r\ntures of known applications but signatures can not cover all traffic. We therefore look at the\r\nalternative approach of classifying traffic based on its behaviour. Such approaches may also\r\nprovide a way to understand traffic in encrypted tunnels.\r\n\r\nWe provide datasets from 7 different bearers provided by\t[I54]\r\n\r\nand used in [I70] (see [W1] for related research). Each bearer\u2019s data consists of a little over\r\n100,000 example TCP flows with 51 features truthed to 15 broad classes (and 39 detailed\r\nclasses). These classifications have been obtained by binary content signatures. Note that one\r\nclass is \u201cNULL\u201d which indicates that no signature hit on that flow.\r\n\r\nThese datasets allow one to check the robustness of a classifier against concept drift both\r\nin time (the data spans a little over a year [I70]) and across bearers.\r\n\r\nThe data is provided at\tNote each bearer\u2019s data is arbit-\r\n\r\nrarily split into training and test sets but this split need not be preserved.\r\n\r\n80\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nF.4.4 Steganography detection\r\n\r\nThe contents of this dataset are classified TOP SECRET STRAP1.\r\n\r\nSome targets try to hide their communications through the use of steganography. One approach\r\nis to slightly alter the coefficients in a JPEG image to encode the hidden data whilst trying to\r\nminimise visual changes in the JPEG. We would like a classifier that can identify such altered\r\nimages (commonly called stegged images).\r\n\r\nhas provided data used to build Random Forest classifiers [I74].\r\nThere are a few interesting features of this dataset:\r\n\r\n\u2022\tThis problem can be viewed either as a classification or a regression problem. One can\r\neither regress on the density of embedded data or classify whether there is any embedded\r\ndata or not.\r\n\r\n\u2022\tThe truthing process simulated embedding data into a large sample of images. Some of\r\nthese images might have started with steganography in them and so the truthing may\r\nnot be accurate.\r\n\r\n\u2022\tThis dataset has the most truthed examples. The original research had 50,000 clean\r\nand 50,000 stegged images (for each of 4 steg types) for training and 500,000 clean and\r\n200,000 stegged images (per steg type) for validation and testing. The reason for such a\r\nlarge test and validation set is that we want to ensure a very low false positive rate.\r\n\r\n\u2022 There are the most features of the truthed datasets. There are 661 features (introduced\r\nin [I74]). Features are computed in classes and so could be used to experiment with\r\ncost-sensitive feature selection.\r\n\r\nData is available at\tas compressed CSV files. The first two\r\n\r\nfields should be ignored and the final field of the stegged files contains the simulated stegging\r\nrate. The rest of the fields are the features (summarised in [I74]).\r\n\r\nF.4.5 Genre classification\r\n\r\nThe contents of this dataset are classified SECRET STRAP1.\r\n\r\nA way to make analysts more efficient and also allow further analytics is to add labels to textual\r\ncontent to describe the genre of the content.\thas provided text\r\n\r\ndata sets classified into genres along with the AURA feature extractor [I83].\r\n\r\nAURA extracts 108 features from text documents as described in [I85, I84]. Some features\r\nare from basic counts, some are based on email headers and some are based on more advanced\r\ntextual analysis. AURA can be run on a text document with:\r\n\r\njava -jar aura.jar <text_file> | head -108\r\n\r\nThe first 108 lines of AURA\u2019s output are the feature values. Other information about the file\r\nis returned in the remaining lines.\r\n\r\n81\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nThree corpuses are provided. PEEC and genre-id are UNCLASSIFIED. News-Personal is\r\nclassified. Each item is a file. The classification of items is encoded by the subdirectory an\r\nitem is stored in. There are some duplicate items in these directories.\r\n\r\nThe corpuses and AURA are a\r\n\r\nIf you are new to text classification then [I25] may be good background reading.\r\n\r\nF.4.6 Website classification\r\n\r\nThe contents of this dataset are classified TOP SECRET STRAP1.\r\n\r\nWe would like to label webpages by the type of information on the page. In this case we want to\r\nidentify pages that contain information on chemical, biological, radiological or nuclear (CBRN)\r\nweapons.\thas previously researched this as a supervised learning\r\n\r\nproblem [I36] and has provided his data from this research.\r\n\r\nWebpages have been labelled by an analyst into four classes: CW (chemical weapons), BW\r\n(biological weapons), RN (radiological/nuclear) and NI (not interesting).\r\n\r\nData is provided at\tin the \u201carff\u201d format used by Weka.\r\n\r\nThis format can be treated as a CSV file after removing the header lines.\r\n\r\nThe most important file is\t. This file is the full dataset\r\n\r\nused to produce the original classifier. It contains vectors for all documents in the CBRN\r\ndataset, where each feature corresponds to a single word, and the value of each feature is the\r\nnumber of instances of the word in the document divided by total number of words in the\r\ndocument.\r\n\r\nalso produced lists of the most prevalent words across each topic (in the folder as\r\nBvector, Cvector, Rvector, Nvector and RNvector), and then developed a dataset where each\r\nfeature was a count of words from each list found in the document (the two\r\n\r\nfiles).\treports that these features did not produce very good results compared to\r\n\r\nindividual words, so the dataset wasn\u2019t refined much further, but you may find it interesting.\r\n\r\nIf required the original HTML pages and classifications may be available but could not be\r\neasily found at the time of writing the problem book.\r\n\r\nF.5 Fusion of scores data\r\n\r\nThe contents of this dataset are classified SECRET STRAP2 CHORDAL UKEO.\r\n\r\nThe fusion of scores problem can occur in several contexts. In the following we describe the\r\ncreation of IP geolocation reference data.\r\n\r\nWe want to know the geolocation of IP addresses for many analytic processes. In the main,\r\nthere are two types of data we use:\r\n\r\nCommercial Various commercial providers provide estimates for IP address locations. ICTR-\r\nNE have provided Akamai\u2019s Edgescape dataset.\r\n\r\nSIGINT We find that commercial providers sometimes give poor locations in areas of the\r\nworld of SIGINT interest. We therefore need to augment the commercial data and choose\r\nto do this through analysis of locations referenced in IP collection (e.g. in user profiles\r\nor web forms). We hope that these locations give evidence towards the location of the\r\n\r\n82\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nusers of that IP address. See [I69] for the scoring approach currently used. ICTR-NE\r\nhave provided data from five different types of IP data (called INJUNCTION, PSYCHIC\r\nSALMON, RAGING BULLFROG, ROBOTIC FISH and TIMID TOAD).\r\n\r\nThe aim is to use these different sources to come up with the best estimate of an IP address\u2019s\r\nlocation. For simplicity we recommend considering geolocation to country-level only.\r\n\r\nThe Edgescape data comes as five gzipped text files; each file covers a different range of\r\nIP address space. Each line describes a subnet (an IP address or IP address range). The first\r\nfield gives the IP address range as a subnet and a subnet mask. The second field contains\r\ninformation about the subnet as key-value pairs. In particular the \u201ccountry_code\u201d field is their\r\nguess of the country and the first letter of the \u201cconfidence\u201d field gives the confidence in their\r\nestimate. Confidences are either high \u201cH\u201d, medium \u201cM\u201d or low \u201cL\u201d.\r\n\r\nEach SIGINT system dataset also comes as a gzipped text file with each line describing a\r\nsubnet. The full format is described in [I66] but we describe the important features here. The\r\nfirst field is the subnet and the second field the subnet mask (typically 24). The last field is\r\na semi-colon separated field where the penultimate field is the country and the last character\r\nof the last field is the confidence. Confidences are either high \u201cH\u201d, medium \u201cM\u201d or low \u201cL\u201d.\r\nThese confidences should not be treated as being on the same scale as Edgescape but should\r\nbe comparable between the five SIGINT systems.\r\n\r\nThe files can be found at\r\n\r\n83\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nTHIS PAGE IS INTENTIONALLY LEFT BLANK\r\n\r\n84\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\nReferences\r\n\r\n\u2014 Internal Literature \u2014\r\n\r\n|\tA maximum-entropy algorithm for generating random graphs, 2008.\r\n\r\nReport to appear: see slides DISCOVER 12747135.\r\n\r\n[12]\tModeling and simulation of streaming dynamic graphs using the Cray\r\nXMT. Technical Report MR/TECH/010/09, R1, NSA, 2009. DISCOVER 11806816.\r\n\r\n[13]\r\n\r\n[14]\r\n\r\n[15]\r\n\r\n[16]\r\n\r\n[17]\r\n\r\n[18]\r\n\r\nSPIKY ROCK: Automatic classification of telephone type via usage statistics. Technical\r\nReport MR/TECH/003/04, NSA R1, March 2004. DISCOVER 12211328.\r\n\r\nCOMET: A recipe for learning and using large ensembles on\r\nmassive data. arXiv, cs.LG/1103.2068, March 2011. DISCOVER 12192977.\r\n\r\nLossy counting and\r\n\r\nhierarchical heavy-hitter algorithms. In ACE, May 2011. DISCOVER 12768692.\r\n\r\nComments on NSASAG 07-04: Correlation\r\nof temporal sequences. Technical report, University of California, Berkeley, October\r\n2007. DISCOVER 12689034.\r\n\r\nDISCOVER 12134962, June 2009.\r\n\r\nRandom Forests in MapReduce. Technical Report\r\nMR/TECH/033/10, NSA R1, August 2010. DISCOVER 10833587.\r\n\r\n[I9]\tTechnical report, GCHQ,\r\n\r\nAugust 2011. DISCOVER 7996430 Please contact\t(ICTR-FSP) for access.\r\n\r\n[I10]\tAdapting SIGINT timeseries data to account for variation in collec-\r\n\r\ntion posture. Technical Report OPC-M/Tech.B/58, GCHQ, February 2011. DISCOVER\r\n7895676.\r\n\r\n[I11]\tBAKER\u2019S DOZEN - a method for batch phone\r\n\r\ndiscovery. Technical Report B/6749BA/5001/4/102, GCHQ, March 2008. DISCOVER\r\n12585962.\r\n\r\n[112]\tThe La Jolla SCAMP 2009 problem\r\nbook - information processing. Technical Report SCAMP Working Paper L3/09, IDA-\r\nCCR, 2009. DISCOVER 12907519.\r\n\r\n[113]\tDensity estimation techniques for detecting DNS tunnels. In SANAR,\r\nOctober 2010. DISCOVER 10833937.\r\n\r\n85\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n[114]\tTrusses and fast graph clustering. Slides from SANAR, 2005. DISCOVER\r\n12750235.\r\n\r\n[115]\tTrusses: cohesive subgraphs for social network analysis. Technical Report\r\nTR-R63-001-05, NSA/R63, 2005. DISCOVER 12892477.\r\n\r\n[116]\tTrapezes: more swinging than trusses. Technical Report TR-R63-004-09,\r\nNSA/R63, 2009. DISCOVER 12892478.\r\n\r\n[117]\tSemitrusses, semitrapezes, efficient computation, and streaming. Technical\r\nReport TR-R63-002-10, NSA/R63, 2010. DISCOVER 12892476.\r\n\r\n[118]\tInterpreting\r\nrandom forest classification. Technical report, NSA R1, September 2009. DISCOVER\r\n12193642.\r\n\r\n[119]\tTechnical Report\r\nTRMCA/Inf/656, ICTR-MCA, June 2010. DISCOVER 12667333.\r\n\r\n[120]\tA simple birth-and-death process for scoring\r\nanomalous behavior in a random steady-state graph. Technical Report SCAMP Working\r\nPaper L38/02, IDA-CCR, 2003. DISCOVER 11775537.\r\n\r\n[121]\tBuilding 2-out+ graphs from streaming data. Technical\r\nReport H-TR-017-06, CSEC, November 2006. DISCOVER 12750234.\r\n\r\n[122]\tUpgrade to tcp-file-signature-log - engineering specification. Technical Re-\r\nport B/6805BA/5001/1, GCHQ, February 2008. DISCOVER 12740356 Please contact\r\n\r\n(ICTR-FSP) for access.\r\n\r\n[123]\tClustering of multiple point process streams. Technical report, University\r\nof Florida, July 2007. DISCOVER 12680283.\r\n\r\n[124]\tA model-based approach\r\nto detecting correlated stochastic processes. Technical report, NSA, September 2011.\r\nDISCOVER 13432581.\r\n\r\n[125]\tText categorisation - a beginners guide. Technical Report B14/INF/569,\r\nGCHQ, February 2008. DISCOVER 7878359.\r\n\r\n[126]\tCreating probabilities and combining evidence in NSA\u2019s evidence store.\r\nTechnical Report TRMCA-INF-690, GCHQ, July 2010. DISCOVER 10835062.\r\n\r\n[127]\tCROUCHING SQUIRREL\r\nv4: Filtering and classifying using behavioural vector analysis. Technical Report\r\nB/7934/5001/3/104, GCHQ, December 2010. STRAP2/ORCON: contact author for\r\naccess or see slides DISCOVER 11925562.\r\n\r\n86\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n[128]\r\n\r\n[129]\r\n\r\n[130]\r\n\r\n[131]\r\n\r\n[132]\r\n\r\n[133]\r\n\r\n[134]\r\n\r\n[135]\r\n\r\nRole assignment in private messaging social networks. Technical Report\r\nB/7167BA/5001/4/102, GCHQ, December 2008. DISCOVER 13042933 Please ask\r\nfor access.\r\n\r\nBayesian block modelling. Technical Report B/7635BA/5001/4/101,\r\nGCHQ, November 2009. DISCOVER 13036032.\r\n\r\nWeighted bayesian block modelling sanitised. Technical Report\r\nB/7713BA/5001/4/102, GCHQ, February 2010. DISCOVER 13036033.\r\n\r\nTechniques for measur-\r\ning the strength of communications in email event graphs. Technical Report\r\nB/6845BA/5001/4/102, ICTR-DMR, February 2008. DISCOVER 12656488.\r\n\r\nThe case for target discovery using closed loops against the Islamist terrorist\r\nthreat in the UK - a technical perspective. Technical Report B/7618BA/5001/4/102,\r\nICTR, GCHQ, 2009. DISCOVER 12861894.\r\n\r\nProperties of SIGINT-collected communication graphs, 2003. Technical\r\nReport SCAMP Working Paper L39/03, IDA-CCR, 2004. DISCOVER 11770806.\r\n\r\nProperties of SIGINT-collected communication graphs. Technical\r\nReport SCAMP Working Paper L32/02, IDA-CCR, 2003. DISCOVER 12502484.\r\n\r\nThe NetInf algorithm as a MapReduce job. Technical report, NSA, May\r\n2011. DISCOVER 13202916.\r\n\r\n[136]\tAutomated categorisation of CBRN related webpages. Technical Report\r\nB/7470BA/5001/5/105, ICTR-CISA, July 2009. DISCOVER 12669793.\r\n\r\n[137]\tHistogramming in the streaming environment.\r\nIn ACE, 2007. DISCOVER 12632758.\r\n\r\n[138]\tICTR-FSP. GCHQ TR-FSP HTTP header fingerprint format. B/7535BA/5001/1, 2009.\r\nDISCOVER 2450313.\r\n\r\n[139]\tDetecting dependence among multiple point processes. Technical report,\r\nUniversity of Pittsburgh, August 2007. DISCOVER 12681522.\r\n\r\n[140]\tEstimating set cardinality under streaming conditions. In ACE, 2011.\r\nDISCOVER 12754015.\r\n\r\n[141]\tTiming patterns in call records data with i2 Pattern Tracer and Remit.\r\nTechnical Report B/4351BA/1700/16, GCHQ, July 2003. DISCOVER 12207962.\r\n\r\n[142]\tTiming analysis 2004 - using significant temporal chains\r\nfor call records target development. Technical Report B/5372BA/1700/16, GCHQ,\r\nOctober 2004. DISCOVER 12200466.\r\n\r\n87\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n[143]\t. Pizza node classification - sharable data\r\nset for Random Forests classification. Technical Report B/6316BA/5001/4/102, GCHQ,\r\nDecember 2006. DISCOVER 12189035.\r\n\r\n[144]\tClassifying email addresses by their be-\r\nhaviour in bulk events data. Technical Report OPH-M/TECH.A/458, GCHQ, December\r\n2006. DISCOVER 12183192.\r\n\r\n[145]\tCreating, retaining and combining confidence estimates in a cloud-like\r\nworld, July 2010. DISCOVER 10833599.\r\n\r\n[146]\tTopological measures of evolving graphs: Dynamic betweenness cent-\r\nrality. Technical Report CCR Working Paper 1690, IDA-CCR, 2008. DISCOVER\r\n11770815.\r\n\r\n[147]\tDetecting correlated sequences of events. Slides from SANAR 2010, October\r\n2010. DISCOVER 12595305.\r\n\r\n[148]\tExtending pairwise element similarity to set similarity efficiently (sanitized\r\nversion). Technical Report MR/TECH/032/10, NSA, December 2010. DISCOVER\r\n12497649.\r\n\r\n[149]\tDetecting correlated sequences of events: sanitized\r\nversion. Technical Report OPH-M/Tech.A/456, GCHQ, August 2006. DISCOVER\r\n3730313.\r\n\r\n[150]\tand\tElkan and Noto\u2019s \u201cLearning classifi-\r\n\r\ners from only positive and unlabeled data\u201d is fatally flawed. Technical Report\r\nMR/TECH/009/10, NSA R1, February 2010. DISCOVER 10833916.\r\n\r\n[151]\tStreaming temporal relation additive probability. Technical report, NSA,\r\nApril 2009. DISCOVER 12594200.\r\n\r\n[152]\tCLASPing at straws: Bootstrapping and clustering to\r\nimprove product performance. Technical report, NSA, In Preparation 2011. DISCOVER\r\n12588233.\r\n\r\n[153]\tImprovements to GeoFusion scoring. Technical Report B/7854/5001/3/104,\r\nGCHQ, August 2010. DISCOVER 12839607.\r\n\r\n[154]\tApplication characterisation: Data set specification. Tech-\r\nnical Report B/6728BA/5001/1, GCHQ, December 2007. DISCOVER 12189832.\r\n\r\n[155]\tEmbedding R within InfoSphere Streams for online time series ana-\r\nlysis and predictions. Technical report, GCHQ ICTR-CISA, June 2011. DISCOVER\r\n12267642.\r\n\r\n[156]\tTowards implementation of an algorithm for updating eigenvalues and\r\neigenvectors of streaming graphs. Technical report, ICTR, GCHQ, 2011. DISCOVER\r\n12663078.\r\n\r\n88\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n[157]\r\n\r\n[158]\r\n\r\n[159]\r\n\r\n[160]\r\n\r\n[161]\r\n\r\n[162]\r\n\r\n[163]\r\n\r\n[164]\r\n\r\n[165]\r\n\r\n[166]\r\n\r\n[167]\r\n\r\n[168]\r\n\r\n[169]\r\n\r\n[170]\r\n\r\n[171]\r\n\r\n[172]\r\n\r\nI. Generating realistic random graphs. Technical report,\r\nHIMR, September 2008. DISCOVER 12747134.\r\n\r\nUnsupervised learning on network data. DISCOVER 12589745.\r\n\r\nRADONSHARPEN-B. DISCOVER 12838456, October 2010.\r\n\r\n2008 Bristol SWAMP: Prob-\r\nlems in graph mining. Technical Report OPC-M/TECH.A/6, GCHQ, 2008. DISCOVER\r\n12768417.\r\n\r\nStreaming decision trees. http://wiki.gchq/images/3/37/\r\nRDTrees.tar.gz, June 2007. DISCOVER 12134963.\r\n\r\nHIDDEN OTTER: Detection of multi-hop tem-\r\n\r\nporal chains in IP traffic. Technical Report B/7937BA/5001/3/104, GCHQ, December\r\n2010. DISCOVER 7810599 Ask\t(ICTR-NE) for access.\r\n\r\nStreaming PRIME TIME ap-\r\n\r\nplication design report. Technical Report INCA1323D003-1.1, Detica, December 2010.\r\nDISCOVER 12211763.\r\n\r\nnew technique for correlating stochastic processes. Technical Report\r\nB/7523BA/5001/4/102, GCHQ, September 2009. DISCOVER 12214368.\r\n\r\nNSASAG problem 07-04: Correlation of temporal sequences.\r\nTechnical report, University of Washington, 2007. DISCOVER 12687220.\r\n\r\nGeoFusion VOLSUNGA interface specification. Technical Report\r\nB/6745BA/5001/1, ICTR-FSP, January 2008. DISCOVER 13550106.\r\n\r\nFile signature bulk-logging technique - engineering specification.\r\nTechnical Report B/6173BA/B13/106, GCHQ, July 2006. DISCOVER 12742157.\r\n\r\nInternet flow classification: Random forests and importance-sampled\r\nlearning ensembles. In ACE, October 2007. DISCOVER 12187796.\r\n\r\nA probabilistic score for IP geolocation from INJUNCTION-style\r\ndata. Technical Report OPC-MCR/TECH.B/4, OPC-MCR, November 2007. DIS-\r\nCOVER 13548375.\r\n\r\nApplication characterisation: Generalisation to the unknown. Tech-\r\nnical Report OPC-m/tECH.B/7, GCHQ, April 2008. DISCOVER 12187131.\r\n\r\nEnhanced behavioural detection of botnet command-and-control\r\nservers. Technical Report OPC-M/TECH.B/53, GCHQ, July 2010. DISCOVER\r\n12209112.\r\n\r\nTraffic sketches for measuring bearer similarity and pairing. Tech-\r\nnical Report OPC-M/TECH.B/55, GCHQ, October 2011. DISCOVER 12750231.\r\n\r\n89\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n[173]\tA comparison between billing records and the\r\nview in SIGINT: SOLID INK vs FLUID INK. Technical Report OPC-M/TECH.B/17,\r\nGCHQ, 2009. DISCOVER 12676097.\r\n\r\n[174]\tImproved generic detection of steganography in JPEG coefficients. Tech-\r\nnical Report OPC-M/TECH.A/452, GCHQ, April 2011. DISCOVER 12191941.\r\n\r\n[175]\tGCHQ research & innovation strategy 2011 - 2015. DISCOVER 12013908.\r\n\r\n[176]\tBlocks, bridges and cutvertices in large commu-\r\nnications graphs. Technical Report OPC-M/TECH.B/19, HIMR, October 2008. DIS-\r\nCOVER 12750236.\r\n\r\n[177]\tUsing predictive modelling to identify cocaine drug smugglers. Technical\r\nReport B/4029BA/B1700/13, GCHQ, November 2002. DISCOVER 12815822.\r\n\r\n[178]\tResults document for call\r\nrecord timing analysis. Technical Report CAA146D005-1.0, Detica, November 2001.\r\nDISCOVER 12204886.\r\n\r\n[179]\tTDB. Interface control document (ICD) for the SALAMANCA input handler - external\r\ngeneric feed interface. Technical Report PC/00117CPO/4542/PC0093/000/50, GCHQ,\r\n2010. DISCOVER 12680902.\r\n\r\n[180]\tKnowledge discovery at the new CRI. In SANAR, October 2010.\r\nDISCOVER 12208587.\r\n\r\n[181]\tUpdating eigenvalues and eigenvectors of streaming graphs. Technical\r\nReport SCAMP Working Paper L22/09, IDA-CCR, 2010. DISCOVER 11806837.\r\n\r\n[182]\tSAWUNEH 2010 \u2014 cyber defence\r\nevent mining. In ACE, May 2011. DISCOVER 12754021.\r\n\r\n[183]\t^^DISCOVER 12369711.\r\n\r\n[184]\tAura features: Algorithmic description. DISCOVER 12380899.\r\n\r\n[185]\tAura features: Brief description. DISCOVER 12380897.\r\n\r\n[186]\tSKB definitions.\r\n\r\nPlease ask\t(ICTR-FSP) for access.\r\n\r\n90\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n\u2014 External Literature \u2014\r\n\r\n[E1]\r\n\r\n[E2]\r\n\r\n[E3]\r\n\r\n[E4]\r\n\r\n[E5]\r\n\r\n[E6]\r\n\r\n[E7]\r\n\r\n[E8]\r\n\r\n[E9]\r\n\r\nThe canonical tensor decomposition\r\n\r\nand its application to data analysis, June 2009. DISCOVER 12740014.\r\n\r\nAn empirical study of\r\n\r\ndynamic graph algorithms. ACM Journal on Experimental Algorithmics, pages 192-201,\r\n1996. DISCOVER 11402183.\r\n\r\nSTINGER: Spatio-temporal interaction networks and graphs (STING) extensible rep-\r\nresentation, May 2009. DISCOVER 11821050.\r\n\r\nNetwork science applications to global communications. In\r\nNetSci, 2008. DISCOVER 12804967.\r\n\r\nand\tThe phase transition in inhomogen-\r\n\r\neous random graphs. arXiv:math/0504589v3, June 2006. DISCOVER 12763412.\r\n\r\nForests. Machine Learning, 45, 2001. DISCOVER 13286408.\r\n\r\neditors. Semi-supervised\r\n\r\nlearning. MIT Press, 2010.\r\n\r\nData stream algorithms intro, sampling, entropy. Slides from Bristol\r\nMaths workshop, 2008. DISCOVER 12805861.\r\n\r\nHow does the data sampling strategy impact the discovery of\r\ninformation diffusion in social media? Association for the Advancement of Artificial\r\nIntelligence, 2010. DISCOVER 10763381.\r\n\r\n[E10\r\n\r\n[E11]\r\n\r\n[E12]\r\n\r\n[E13]\r\n\r\n[E14]\r\n\r\nMapReduce: Simplied data processing on large\r\n\r\nclusters. In OSDI, 2004. DISCOVER 12192986.\r\n\r\nBayesian approaches to modeling the con-\r\n\r\nditional dependence between multiple diagnostic tests. Biometrics, 57:158-167, 2001.\r\nDISCOVER 12192608.\r\n\r\nI. Massive streaming data\r\n\r\nanalytics: A case study with clustering coefficients, 2010. DISCOVER 11821048.\r\n\r\n. Learning classifiers from only positive and unlabeled\r\ndata. In KDD, Las Vegas, August 2008. ACM. DISCOVER 12195326.\r\n\r\nDynamic graph algorithms, 1999.\r\n\r\nDISCOVER 11402184.\r\n\r\n91\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n[E15]\r\n\r\nGraph distances in the data-stream model. SIAM Journal on Computing,\r\n38(5):1709-1727, 2008.\r\n\r\n[E16]\tHyperLogLog: the analysis of a near-optimal\r\n\r\ncardinality estimation algorithm. AofA, 2007. DISCOVER 12747198.\r\n\r\n[E17]\tSemi-supervised ranking on\r\n\r\nvery large graphs with rich metadata. In KDD, August 2011. Available from Microsoft\r\nResearch\u2019s website.\r\n\r\n[E18]\tInferring networks\r\n\r\nof diffusion and influence. In KDD\u201910, Washington D.C., 2010. ACM. DISCOVER\r\n12762008.\r\n\r\n[E19]\tEstimating the error rates of diagnostic tests. Biometrics,\r\n\r\n36:167-171, 1980.\r\n\r\n[E20] INSTINCT. Have I got \u201cviews\u201d for you?: gathering and analysing publicly available data\r\nto gain an understanding of current events. Technical report, October 2011. DISCOVER\r\n12626622.\r\n\r\n[E21]\tBayesian estimation of dis-\r\n\r\nease prevalence and the parameters of diagnostic tests in the absence of a gold standard.\r\nAmerican Journal of Epidemiology, 141(3):263-272, 1995. DISCOVER 12195321.\r\n\r\n[E22]\tIntroducing the Enron corpus. Technical report, Carne-\r\n\r\ngie Mellon University, 2004. DISCOVER 12763413.\r\n\r\n[E23]\tMIForests: Multiple-instance learn-\r\n\r\ning with randomized trees, 2010. DISCOVER 12192687.\r\n\r\n[E24]\tSemi-supervised\r\n\r\nrandom forests, 2011. DISCOVER 12192698.\r\n\r\n[E25]\tSocial media analytics: Part 1: Information flow. Slides, Stanford\r\n\r\nUniversity, August 2011. Presented at KDD 2011 DISCOVER 13561614.\r\n\r\n[E26]\tand\tGraph evolution: Densification\r\n\r\nand shrinking diameters. ACM Transactions on Knowledge Discovery from Data, 1(1),\r\n2007. DISCOVER 12761498.\r\n\r\n[E27]\tLearning with an unreliable teacher. Pattern Recognition, 25(1):79-87,\r\n\r\n1992.\r\n\r\n[E28]\tCompact graph representations and parallel\r\n\r\nconnectivity algorithms for massive dynamic network analysis. In 23rd IEEE Interna-\r\ntional Parallel and Distributed Processing Symposium (IPDPS), May 2009. DISCOVER\r\n11816428.\r\n\r\n92\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n[E29]\r\n\r\nSparsification of influence networks. In KDD\u201911, pages 529-537, San Diego,\r\nCA, August 2011. ACM. /discover13560696.\r\n\r\n[E30]\tThe PageRank citation ranking:\r\n\r\nBringing order to the web, 1998.\r\n\r\n[E31]\tSupervised learning from multiple experts: Whom to trust when\r\n\r\neveryone lies a bit. In Proceedings of the 26th International Conference on Machine\r\nLearning, 2009. DISCOVER 12197907.\r\n\r\n[E32]\t\u201cTAGS\u201d, a program for the eval-\r\n\r\nuation of a test accuracy in the absence of a gold standard. Preventative Vetinary\r\nMedicine, 53:67-81, 2002.\r\n\r\n[E33]\tA method for inferring label\r\n\r\nsampling mechanism in semi-supervised learning. In Advances in Neural Information\r\nProcessing Systems, volume 17, 2005. DISCOVER 13287597.\r\n\r\n[E34]\tCorrect-\r\n\r\ning for missing data in information cascades. Technical report, Stanford University,\r\nDecember 2010. DISCOVER 10763155.\r\n\r\n[E35]\tCombined regression and ranking. In KDD. ACM, July 2010. DISCOVER\r\n\r\n12815522.\r\n\r\n[E36]\tLearning with labeled and unlabeled data. Technical report, University\r\n\r\nof Edinburgh, December 2002. DISCOVER 13287596.\r\n\r\n[E37]\tActive learning literature survey. Technical report, University of\r\n\r\nWisconsin-Madison, 2010. DISCOVER 12195329.\r\n\r\n[E38]\tWhen do latent class models overstate accuracy for binary classifiers?:\r\n\r\nWith applications to jury accuracy, survey response error, and diagnostic error. Tech-\r\nnical Report WP-08-10, Northwestern University, May 2009. DISCOVER 12192699.\r\n\r\n[E39]\tStreaming data. WIREs Computational Statistics, January 2011.\r\n\r\nDISCOVER 12197914.\r\n\r\n[E40]\tFast counting of triangles in large real networks: al-\r\n\r\ngorithms and laws. In ICDM, 2008. DISCOVER 12805858.\r\n\r\n[E41]\tThe future of data analysis. Ann. Math. Stat., 1962. DISCOVER\r\n\r\n12804965.\r\n\r\n[E42]\r\n\r\n[E43]\r\n\r\nExploratory data analysis. Addison-Wesley, 1977.\r\n\r\nDesign principles for\r\n\r\ndeveloping stream processing applications. Software - Practice and Experience, 2010.\r\n\r\n93\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n[E44]\tModeling information diffusion in implicit networks.\r\n\r\nTechnical report, Stanford University, 2010. DISCOVER 12763414.\r\n\r\n[E45]\tBoosting the scalability of botnet detection using adaptive traffic\r\n\r\nsampling. In ASIACCS, March 2011. DISCOVER 12804966.\r\n\r\n[E46]\tSemi-supervised learning literature survey. Technical Report TR 1530,\r\n\r\nUniversity of Wisconsin-Madison, July 2008. DISCOVER 13288447.\r\n\r\n\u2014 Websites \u2014\r\n\r\n[W1] Application characterisation.\r\n\r\n[W2] AUTO ASSOC.\r\n\r\n[W3] BIRCH (data clustering).\r\n\r\n[W4] CARBON COPY.\r\n\r\n[W5] CASK: situational awareness for the 2012 Olympics\r\n\r\n[W6] CHART BREAKER.\r\n\r\n[W7] CNE OpSec pages.\r\n\r\n[W8] CNO glossary.\r\n\r\n[W9] CRAN.\r\n\r\n[W10] Decision tree learning on Wikipedia.\r\n\r\n[W11] DISTILLERY.\r\n\r\n[W12] Dynamic Graph.\r\n\r\n[W13] Ensemble learning on Wikipedia.\r\n\r\n[W14] Fused analysis and visualisation research.\r\n\r\n[W15] GCWiki.\r\n\r\n[W16] Getting started on BHDIST.\r\n[W17] GRINNING ROACH.\r\n\r\n94\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n[W18] Ground breaking intelligence capabilities used during recent G20\r\nsummit.\r\n\r\n[W19] Hadoop Fair Scheduler guide.\r\n\r\n[W20] Hadoop on GCWiki.\r\n\r\n[W21] HIMR IT upgrade.\t.\r\n\r\n[W22] HIMR self help.\r\n\r\n[W23] HRA logging.\r\n\r\n[W24] Information flow in graphs GCWiki page.\r\n\r\n[W25] Legal compliance.\r\n\r\n[W26] Legalities SUN STORM/BLACK HOLE.\r\n\r\n[W27] MAMBA.\r\n\r\n[W28] NSASAG.\r\n\r\n[W29] Pidgin setup.\r\n\r\n[W30] PIRATE CAREBEAR.\r\n\r\n[W31] Random Forests.\r\n\r\n[W32] Relationship analysis.\r\n\r\n[W33] Renoir.\r\n\r\n[W34] ROC curves.\r\n\r\n[W35] Safari books online.\t.\r\n\r\n[W36] SALAMANCA.\r\n\r\n[W37] SALTY OTTER.\r\n\r\n[W38] Semi-supervised learning on Wikipedia. http://wikipedia.gchq/index.php\r\n[W39] Squeal eAD and cipher detection PPF app.\r\n\r\n95\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY\r\n\r\nOPC-M/TECH.A/455 (v1.0, r206)\r\n\r\n[W40] Streams Processing Language.\r\n\r\n[W41] Supervised learning on Wikipedia.\r\n\r\n[W42] SWAMP 2008.\r\n\r\n[W43] What\u2019s the relationship between CNO and DNI?\r\n\r\n[W44] WHITERAVEN.\r\n\r\n[W45]\tKL-Relative PageRank.\r\n\r\n96\r\n\r\nThis information is exempt under the Freedom of Information Act 2000 (FOIA) and may be exempt under other UK\r\ninformation legislation. Refer any FOIA queries to GCHQ on\tor|\r\n\r\nUK TOP SECRET STRAP1 COMINT\r\n\r\nAUS/CAN/NZ/UK/US EYES ONLY", 
    "pdf": [
      "https://edwardsnowden.com/wp-content/uploads/2016/02/Problem-Book-Redacted.pdf"
    ]
  }, 
  {
    "released_date": "20160202", 
    "overall_handling_caveats": [], 
    "id": "20160202|whatstheworstthatcouldhappen?", 
    "document_date": "2010-03-01 00:00:00", 
    "codewords": [
      "CONFLICT"
    ], 
    "agency": [
      "GCHQ"
    ], 
    "sub_paragraphs_classifications": [
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap 1 whats the worst that could happen? this document contains examples of specific risk which may affect operations and which may need to be considered when writing submissions. this is not an exhaustive list: any operation could involve new risks. it is also not a pick and mix list. it is here to help you think about the sorts of risk that might need to be included ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "in a submission to ensure that the secretary of state has all the relevant information available when deciding whether or not to approve the submission. are you the most appropriate person to assess the risk of your operation? are you capable of looking at all the areas of risk (eg, reputational, technical, legal)? if not, ask someone who is (eg, an ipt expert, ptd, opp-leg respectively). risks to personnel discovery/compromise of personnel involved in installation risks to personnel associated with housing operation if operation is compromised risk to collaborators / enabling agents adequacy of plausible cover leading to compromise of individuals risk of false attribution and dire consequences (if there were a risk of reprisals against sis agents or embassy staff, then an assessment from the relevant sis controller or ambassador might be appropriate) technical risk appropriate technical colleagues are best placed to provide this information, eg ptd, ndist, gte, jtrig. compromise of technique leading to loss of capability definite technical attribution leading to loss of capability compromise of equity leads to loss of capability and discovery of other operations (eg by fis) novel capabilities have unknown effects outside of lab testing conditions political or reputational risk if you think that any of the following risks are significant in your operation, you should consider whether or not you have adequate operational planning and mitigation in place. attribution to hmg attribution to uk attribution to gchq presumed attribution to uk (the target knows it's been the subject of an attack and assumes the uk is responsible) mistaken attribution (the target mistakenly blames a uk ally, who in turn attributes an effect to the uk) 1\tof 3 this information is exempt from disclosure under the freedom of information act 2000 and may be subject to exemption under other uk information legislation. refer disclosure requests to gchq on ll|hhhh|||||||m|||||||gh|hh|||||||h ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap 1 ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [
          "systemisupgradedorreplaced"
        ], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap 1 political fallout with foreign governments or intelligence partners media exposure compromise of commercial partners humint talk to humint partners if you think you have a significant humint risk. risk of false attribution and dire consequences (if there were a risk of reprisals against sis agents or embassy staff, then an assessment from the relevant sis controller or ambassador might be appropriate) vulnerability of collaborators and enabling agents risks to relationships discovery or attribution could adversely impact on working relationships and/or sharing arrangements with sister agencies and/or second parties discovery or attribution could adversely impact on working relationships with commercial suppliers and ultimately restrict gchq's sigint cability potential to compromise a partner's operation see also political or reputational risk section operational phase see also discovery compromise of operation during installation, the course of the operation itself or egress of traffic inadequate personnel security controls operation does not succeed because the installed hardware/software does not function as planned operation does not success because the installed hardware/software works, but is neutralized (eg because the target network/system is upgraded or replaced) operation does not succeed because the target system is not used in the expected way (eg expected commercial usage does not occur) operation does not succeed because of reliance on an uncertain supply chain or other risky dependence. proportionality - the operation is not specific in its targeting who will have direct access to the data resulting from the operation and do we have any control over this? could anyone take action on it without our agreement, eg could we be enabling the us to conduct a detention op which we would not consider permissible? discovery discovery is a risk itself, which can lead to almost all of the other risks featured here. what follows is a list of circumstances which can lead to discovery. compromise of operation during installation 2\tof 3 this information is exempt from disclosure under the freedom of information act 2000 and may be subject to exemption under other uk information legislation. refer disclosure requests to gchq on ll||h|||m||||||h||l||||j||@||||||||||||||| ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap 1 ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap 1 inadequate personnel security controls and subsequent information leak discover of installed hardware (including post-operation) forensic discovery of installed software discovery of a suspicious audit trail/logs/registry discovery of suspicious rf energy suspicious profile caused by hardware/software malfunction discovery of egressed traffic discovery through other it leakage vulnerability to his or other monitoring inadequate monitoring of profile generated by operation inadequate review of risks during the lifetime of the operation reliance on an uncertain supply chain or other risky dependencies failure by operators to cover tracks, including clearing logs/changing read status of emails novel capabilities and techniques having unknown effects outside of lab testing conditions unforeseen changes to hardware or software leading to compromise of techniques or installation hardware/software malfunctions leading change in target behaviour, potentially including forensic investigation (and potential discovery) and/or loss of target access legality any risks relating to legality of operation or of subsequent actions enabled by the operation will usually be addressed by lawyers in legal section of submission, but may include the following issues: liability of enabling commercial partners the principle of non-intervention in a sovereign country's affairs could the law of armed conflict apply? who will have direct access to the data resulting from the operation and do we have any control over this? could anyone take action on it without our agreement, eg could we be enabling the us to conduct a detention op which we would not consider permissible? 3\tof 3 this information is exempt from disclosure under the freedom of information act 2000 and may be subject to exemption under other uk information legislation. refer disclosure requests to gchq on ll|hhhh|||||||m|||||||gh|hh|||||||h ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap 1 ", 
        "paragraph_relto": []
      }
    ], 
    "pdf_paths": [
      "What-Is-the-Worst-That-Can-Happen-March-2010.pdf"
    ], 
    "overall_classification": "Top Secret", 
    "description": "This GCHQ document from March 2010 presents a checklist of factors analysts should consider before going ahead with an operation to infiltrate a communications network, by physical or other means. Among the concerns raised is the risk that British actions may enable US authorities to conduct operations \u201cwhich we would not consider permissible\u201d: see the [\u2026]", 
    "plain_text": "\ufeffTOP SECRET STRAP 1\r\n\r\nWhat\u2019s the worst that could happen?\r\n\r\nThis document contains examples of specific risk which may affect operations and\r\nwhich may need to be considered when writing submissions. This is not an\r\nexhaustive list: any operation could involve new risks. It is also not a pick and mix\r\nlist. It is here to help you think about the sorts of risk that might need to be included\r\nin a submission to ensure that the Secretary of State has all the relevant information\r\navailable when deciding whether or not to approve the submission.\r\n\r\nAre you the most appropriate person to assess the risk of your operation? Are you\r\ncapable of looking at all the areas of risk (eg, reputational, technical, legal)? If not,\r\nask someone who is (eg, an IPT expert, PTD, OPP-LEG respectively).\r\n\r\nRisks to Personnel\r\n\r\n\u25a0\tdiscovery/compromise of personnel involved in installation\r\n\r\n\u25a0\trisks to personnel associated with housing operation if operation is compromised\r\n\r\n\u25a0\trisk to collaborators / enabling agents\r\n\r\n\u25a0\tadequacy of plausible cover leading to compromise of individuals\r\n\r\n\u25a0\tRisk of false attribution and dire consequences (if there were a risk of reprisals\r\nagainst SIS agents or Embassy staff, then an assessment from the relevant SIS\r\nController or Ambassador might be appropriate)\r\n\r\nTechnical Risk\r\n\r\nAppropriate technical colleagues are best placed to provide this information, eg PTD,\r\nNDIST, GTE, JTRIG.\r\n\r\n\u25a0\tCompromise of technique leading to loss of capability\r\n\r\n\u25a0\tDefinite technical attribution leading to loss of capability\r\n\r\n\u25a0\tCompromise of equity leads to loss of capability and discovery of other operations\r\n(eg by FIS)\r\n\r\n\u25a0\tNovel capabilities have unknown effects outside of lab testing conditions\r\nPolitical or Reputational Risk\r\n\r\nIf you think that any of the following risks are significant in your operation, you should\r\nconsider whether or not you have adequate operational planning and mitigation in\r\nplace.\r\n\r\n\u25a0\tattribution to HMG\r\n\r\n\u25a0\tattribution to UK\r\n\r\n\u25a0\tattribution to GCHQ\r\n\r\n\u25a0\tpresumed attribution to UK (the target knows it's been the subject of an attack\r\nand assumes the UK is responsible)\r\n\r\n\u25a0\tmistaken attribution (the target mistakenly blames a UK ally, who in turn attributes\r\nan effect to the UK)\r\n\r\n1\tof 3\r\n\r\nThis information is exempt from disclosure under the Freedom of Information Act 2000 and may be subject to exemption under\r\n\r\nother UK information legislation. Refer disclosure requests to GCHQ on ll|HHHH|||||||m|||||||gH|hH|||||||H\r\n\r\nTOP SECRET STRAP 1\r\n\r\nTOP SECRET STRAP 1\r\n\r\n\u25a0\tPolitical fallout with foreign governments or intelligence partners\r\n\r\n\u25a0\tMedia exposure\r\n\r\n\u25a0\tCompromise of commercial partners\r\n\r\nHumint\r\n\r\n\u25a0\tTalk to Humint partners if you think you have a significant Humint risk.\r\n\r\n\u25a0\tRisk of false attribution and dire consequences (if there were a risk of reprisals\r\nagainst SIS agents or Embassy staff, then an assessment from the relevant SIS\r\nController or Ambassador might be appropriate)\r\n\r\n\u25a0\tVulnerability of collaborators and enabling agents\r\n\r\nRisks to Relationships\r\n\r\n\u25a0\tDiscovery or attribution could adversely impact on working relationships and/or\r\nsharing arrangements with sister agencies and/or second parties\r\n\r\n\u25a0\tDiscovery or attribution could adversely impact on working relationships with\r\ncommercial suppliers and ultimately restrict GCHQ's sigint cability\r\n\r\n\u25a0\tPotential to compromise a partner's operation\r\n\r\n\u25a0\tSee also Political or Reputational Risk section\r\n\r\nOperational Phase\r\n\r\n\u25a0\tSee also Discovery\r\n\r\n\u25a0\tCompromise of operation during installation, the course of the operation itself or\r\negress of traffic\r\n\r\n\u25a0\tInadequate personnel security controls\r\n\r\n\u25a0\tOperation does not succeed because the installed hardware/software does not\r\nfunction as planned\r\n\r\n\u25a0\tOperation does not success because the installed hardware/software works, but\r\nis neutralized (eg because the target network/system is upgraded or replaced)\r\n\r\n\u25a0\tOperation does not succeed because the target system is not used in the\r\nexpected way (eg expected commercial usage does not occur)\r\n\r\n\u25a0\tOperation does not succeed because of reliance on an uncertain supply chain or\r\nother risky dependence.\r\n\r\n\u25a0\tProportionality - the operation is not specific in its targeting\r\n\r\n\u25a0\tWho will have direct access to the data resulting from the operation and do we\r\nhave any control over this? Could anyone take action on it without our\r\nagreement, eg could we be enabling the US to conduct a detention op which we\r\nwould not consider permissible?\r\n\r\nDiscovery\r\n\r\nDiscovery is a risk itself, which can lead to almost all of the other risks featured here.\r\n\r\nWhat follows is a list of circumstances which can lead to discovery.\r\n\r\n\u25a0\tCompromise of operation during installation\r\n\r\n2\tof 3\r\n\r\nThis information is exempt from disclosure under the Freedom of Information Act 2000 and may be subject to exemption under\r\n\r\nother UK information legislation. Refer disclosure requests to GCHQ on ll||H|||m||||||H||l||||j||@|||||||||||||||\r\n\r\nTOP SECRET STRAP 1\r\n\r\nTOP SECRET STRAP 1\r\n\r\n\u25a0\tInadequate personnel security controls and subsequent information leak\r\n\r\n\u25a0\tDiscover of installed hardware (including post-operation)\r\n\r\n\u25a0\tForensic discovery of installed software\r\n\r\n\u25a0\tDiscovery of a suspicious audit trail/logs/registry\r\n\r\n\u25a0\tDiscovery of suspicious RF energy\r\n\r\n\u25a0\tSuspicious profile caused by hardware/software malfunction\r\n\r\n\u25a0\tDiscovery of egressed traffic\r\n\r\n\u25a0\tDiscovery through other IT leakage\r\n\r\n\u25a0\tVulnerability to HIS or other monitoring\r\n\r\n\u25a0\tInadequate monitoring of profile generated by operation\r\n\r\n\u25a0\tInadequate review of risks during the lifetime of the operation\r\n\r\n\u25a0\tReliance on an uncertain supply chain or other risky dependencies\r\n\r\n\u25a0\tFailure by operators to cover tracks, including clearing logs/changing read status\r\nof emails\r\n\r\n\u25a0\tNovel capabilities and techniques having unknown effects outside of lab testing\r\nconditions\r\n\r\n\u25a0\tUnforeseen changes to hardware or software leading to compromise of\r\ntechniques or installation\r\n\r\n\u25a0\tHardware/software malfunctions leading change in target behaviour, potentially\r\nincluding forensic investigation (and potential discovery) and/or loss of target\r\naccess\r\n\r\nLegality\r\n\r\nAny risks relating to legality of operation or of subsequent actions enabled by the\r\n\r\noperation will usually be addressed by lawyers in legal section of submission, but\r\n\r\nmay include the following issues:\r\n\r\n\u25a0\tliability of enabling commercial partners\r\n\r\n\u25a0\tthe principle of non-intervention in a sovereign country's affairs\r\n\r\n\u25a0\tCould the Law of Armed Conflict apply?\r\n\r\n\u25a0\tWho will have direct access to the data resulting from the operation and do we\r\nhave any control over this? Could anyone take action on it without our\r\nagreement, eg could we be enabling the US to conduct a detention op which we\r\nwould not consider permissible?\r\n\r\n3\tof 3\r\n\r\nThis information is exempt from disclosure under the Freedom of Information Act 2000 and may be subject to exemption under\r\n\r\nother UK information legislation. Refer disclosure requests to GCHQ on ll|HHHH|||||||m|||||||gH|hH|||||||H\r\n\r\nTOP SECRET STRAP 1", 
    "sigads": [], 
    "overall_relto": [], 
    "countries_mentioned": [
      "United Kingdom (GBR/GB)"
    ], 
    "link": "https://edwardsnowden.com/2016/02/02/whats-the-worst-that-could-happen/", 
    "document_topic": [
      "Computer Network Operations"
    ], 
    "pub_date": "Tue, 02 Feb 2016 18:10:01 +0000", 
    "article_links": [
      "https://boingboing.net/2016/02/02/doxxing-sherlock-3.html"
    ], 
    "categories": [
      "Revealed documents", 
      "computer_network_operations", 
      "detention", 
      "detention op", 
      "embassy", 
      "gchq_orig", 
      "gte", 
      "hmg", 
      "humint", 
      "ipt", 
      "jtrig", 
      "law of armed conflict", 
      "ndist", 
      "opp-leg", 
      "ptd", 
      "sigint", 
      "sis"
    ], 
    "title": "What\u2019s the worst that could happen?", 
    "doc_text": "\ufeffTOP SECRET STRAP 1\r\n\r\nWhat\u2019s the worst that could happen?\r\n\r\nThis document contains examples of specific risk which may affect operations and\r\nwhich may need to be considered when writing submissions. This is not an\r\nexhaustive list: any operation could involve new risks. It is also not a pick and mix\r\nlist. It is here to help you think about the sorts of risk that might need to be included\r\nin a submission to ensure that the Secretary of State has all the relevant information\r\navailable when deciding whether or not to approve the submission.\r\n\r\nAre you the most appropriate person to assess the risk of your operation? Are you\r\ncapable of looking at all the areas of risk (eg, reputational, technical, legal)? If not,\r\nask someone who is (eg, an IPT expert, PTD, OPP-LEG respectively).\r\n\r\nRisks to Personnel\r\n\r\n\u25a0\tdiscovery/compromise of personnel involved in installation\r\n\r\n\u25a0\trisks to personnel associated with housing operation if operation is compromised\r\n\r\n\u25a0\trisk to collaborators / enabling agents\r\n\r\n\u25a0\tadequacy of plausible cover leading to compromise of individuals\r\n\r\n\u25a0\tRisk of false attribution and dire consequences (if there were a risk of reprisals\r\nagainst SIS agents or Embassy staff, then an assessment from the relevant SIS\r\nController or Ambassador might be appropriate)\r\n\r\nTechnical Risk\r\n\r\nAppropriate technical colleagues are best placed to provide this information, eg PTD,\r\nNDIST, GTE, JTRIG.\r\n\r\n\u25a0\tCompromise of technique leading to loss of capability\r\n\r\n\u25a0\tDefinite technical attribution leading to loss of capability\r\n\r\n\u25a0\tCompromise of equity leads to loss of capability and discovery of other operations\r\n(eg by FIS)\r\n\r\n\u25a0\tNovel capabilities have unknown effects outside of lab testing conditions\r\nPolitical or Reputational Risk\r\n\r\nIf you think that any of the following risks are significant in your operation, you should\r\nconsider whether or not you have adequate operational planning and mitigation in\r\nplace.\r\n\r\n\u25a0\tattribution to HMG\r\n\r\n\u25a0\tattribution to UK\r\n\r\n\u25a0\tattribution to GCHQ\r\n\r\n\u25a0\tpresumed attribution to UK (the target knows it's been the subject of an attack\r\nand assumes the UK is responsible)\r\n\r\n\u25a0\tmistaken attribution (the target mistakenly blames a UK ally, who in turn attributes\r\nan effect to the UK)\r\n\r\n1\tof 3\r\n\r\nThis information is exempt from disclosure under the Freedom of Information Act 2000 and may be subject to exemption under\r\n\r\nother UK information legislation. Refer disclosure requests to GCHQ on ll|HHHH|||||||m|||||||gH|hH|||||||H\r\n\r\nTOP SECRET STRAP 1\r\n\r\nTOP SECRET STRAP 1\r\n\r\n\u25a0\tPolitical fallout with foreign governments or intelligence partners\r\n\r\n\u25a0\tMedia exposure\r\n\r\n\u25a0\tCompromise of commercial partners\r\n\r\nHumint\r\n\r\n\u25a0\tTalk to Humint partners if you think you have a significant Humint risk.\r\n\r\n\u25a0\tRisk of false attribution and dire consequences (if there were a risk of reprisals\r\nagainst SIS agents or Embassy staff, then an assessment from the relevant SIS\r\nController or Ambassador might be appropriate)\r\n\r\n\u25a0\tVulnerability of collaborators and enabling agents\r\n\r\nRisks to Relationships\r\n\r\n\u25a0\tDiscovery or attribution could adversely impact on working relationships and/or\r\nsharing arrangements with sister agencies and/or second parties\r\n\r\n\u25a0\tDiscovery or attribution could adversely impact on working relationships with\r\ncommercial suppliers and ultimately restrict GCHQ's sigint cability\r\n\r\n\u25a0\tPotential to compromise a partner's operation\r\n\r\n\u25a0\tSee also Political or Reputational Risk section\r\n\r\nOperational Phase\r\n\r\n\u25a0\tSee also Discovery\r\n\r\n\u25a0\tCompromise of operation during installation, the course of the operation itself or\r\negress of traffic\r\n\r\n\u25a0\tInadequate personnel security controls\r\n\r\n\u25a0\tOperation does not succeed because the installed hardware/software does not\r\nfunction as planned\r\n\r\n\u25a0\tOperation does not success because the installed hardware/software works, but\r\nis neutralized (eg because the target network/system is upgraded or replaced)\r\n\r\n\u25a0\tOperation does not succeed because the target system is not used in the\r\nexpected way (eg expected commercial usage does not occur)\r\n\r\n\u25a0\tOperation does not succeed because of reliance on an uncertain supply chain or\r\nother risky dependence.\r\n\r\n\u25a0\tProportionality - the operation is not specific in its targeting\r\n\r\n\u25a0\tWho will have direct access to the data resulting from the operation and do we\r\nhave any control over this? Could anyone take action on it without our\r\nagreement, eg could we be enabling the US to conduct a detention op which we\r\nwould not consider permissible?\r\n\r\nDiscovery\r\n\r\nDiscovery is a risk itself, which can lead to almost all of the other risks featured here.\r\n\r\nWhat follows is a list of circumstances which can lead to discovery.\r\n\r\n\u25a0\tCompromise of operation during installation\r\n\r\n2\tof 3\r\n\r\nThis information is exempt from disclosure under the Freedom of Information Act 2000 and may be subject to exemption under\r\n\r\nother UK information legislation. Refer disclosure requests to GCHQ on ll||H|||m||||||H||l||||j||@|||||||||||||||\r\n\r\nTOP SECRET STRAP 1\r\n\r\nTOP SECRET STRAP 1\r\n\r\n\u25a0\tInadequate personnel security controls and subsequent information leak\r\n\r\n\u25a0\tDiscover of installed hardware (including post-operation)\r\n\r\n\u25a0\tForensic discovery of installed software\r\n\r\n\u25a0\tDiscovery of a suspicious audit trail/logs/registry\r\n\r\n\u25a0\tDiscovery of suspicious RF energy\r\n\r\n\u25a0\tSuspicious profile caused by hardware/software malfunction\r\n\r\n\u25a0\tDiscovery of egressed traffic\r\n\r\n\u25a0\tDiscovery through other IT leakage\r\n\r\n\u25a0\tVulnerability to HIS or other monitoring\r\n\r\n\u25a0\tInadequate monitoring of profile generated by operation\r\n\r\n\u25a0\tInadequate review of risks during the lifetime of the operation\r\n\r\n\u25a0\tReliance on an uncertain supply chain or other risky dependencies\r\n\r\n\u25a0\tFailure by operators to cover tracks, including clearing logs/changing read status\r\nof emails\r\n\r\n\u25a0\tNovel capabilities and techniques having unknown effects outside of lab testing\r\nconditions\r\n\r\n\u25a0\tUnforeseen changes to hardware or software leading to compromise of\r\ntechniques or installation\r\n\r\n\u25a0\tHardware/software malfunctions leading change in target behaviour, potentially\r\nincluding forensic investigation (and potential discovery) and/or loss of target\r\naccess\r\n\r\nLegality\r\n\r\nAny risks relating to legality of operation or of subsequent actions enabled by the\r\n\r\noperation will usually be addressed by lawyers in legal section of submission, but\r\n\r\nmay include the following issues:\r\n\r\n\u25a0\tliability of enabling commercial partners\r\n\r\n\u25a0\tthe principle of non-intervention in a sovereign country's affairs\r\n\r\n\u25a0\tCould the Law of Armed Conflict apply?\r\n\r\n\u25a0\tWho will have direct access to the data resulting from the operation and do we\r\nhave any control over this? Could anyone take action on it without our\r\nagreement, eg could we be enabling the US to conduct a detention op which we\r\nwould not consider permissible?\r\n\r\n3\tof 3\r\n\r\nThis information is exempt from disclosure under the Freedom of Information Act 2000 and may be subject to exemption under\r\n\r\nother UK information legislation. Refer disclosure requests to GCHQ on ll|HHHH|||||||m|||||||gH|hH|||||||H\r\n\r\nTOP SECRET STRAP 1", 
    "pdf": [
      "https://edwardsnowden.com/wp-content/uploads/2016/02/What-Is-the-Worst-That-Can-Happen-March-2010.pdf"
    ]
  }, 
  {
    "released_date": "20160129", 
    "overall_handling_caveats": [], 
    "id": "20160129|isuavvideodescrambling", 
    "document_date": "2008-01-01 00:00:00", 
    "codewords": [], 
    "agency": [
      "GCHQ"
    ], 
    "sub_paragraphs_classifications": [
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "secret isuav video descrambling author: vereon^ra introduction analogue video from israeli uavs has been intercepted in both clear (i.e. unencrypted) and scrambled (i.e. encrypted) formats. processing clear video using m2extra is relatively straightforward, the method being described in anarchist training module 4. for scrambled video the capability exists to exploit the content using a combination of image processing tools and scrypts on mutiny jaguar. background interception of scrambled analogue video signals at anarchist has a long history, with the earliest examples dating back to 1998. the signal the appearance of the encrypted signal in the frequency domain is virtually indistinguishable from the clear video signal. a comparison of the post-d data for an example of clear video, and an encrypted example from a few seconds later (figs 1a & 1b) show that, apart from a subtle modification to the envelope, the signals appear very similar. the most noticable effect is an increase in energy at lower frequencies, consistent with the detail in the image being smoothed out by the scrambling process. scrambled imagery as can be seen by examining an example of a frame of scrambled video (fig.2) the video frame is unchanged by the scrambling method. in addition to the image seen in clear video there is also two lines of digital information encoded in the teletext area at the top of the screen. this is presumed to be information relating to the scrambling, e.g. a cryptographic key to enable the original image to be reconstructed. investigation of the data has determined the method by which the video is scrambled. the method used is a cut & slide technique whereby each line is cut at a location and the two halves are transmitted in the opposite order. this technique was originally used by sky tv to protect their analogue transmissions before they switched to digital, the system being known as videocrypt. 1 of 3 this information is exempt from disclosure under the freedom of information act 2000 and may be subject to exemption under other uk information legislation. refer disclosure requests to gchq\t(non-sec) or email^^^^^^h ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "secret ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "secret fig. 2: an single frame of scrambled video imagery exploiting scrambled video images having determined the technique used to scramble the video imagery a number of known attacks are available from open source material. one technique in particular offers a brute force way of reconstructing the image, without requiring any knowledge of the generating algorithm. this technique, and the source code needed to employ it is freely available on the internet. the computing power needed to descramble the images in near real time is considerable without the use of dedicated hardware such as a video capture card that can record uncompressed images. it is still possible to descramble individual frames to determine the image content without too much effort. method the method involves capturing a video frame in bitmap (.bmp) format using m2extra. the video data should be processed as described in the m2extra video processing guide. when the quality of the video image is good a snapshot can be made of the data in the event processing window. pause the processing and use the left mouse button to zoom in to the scrambled image to exclude the frame. from the file menu in the top left hand corner of the event processing window select snap . .. (ctrl- s), and choose .bmp as the format. start martes in a terminal window with the command martes, and launch the image magick tool from a terminal window with the command magick_display directory: |/daui/midas/m2cxtra/vidco/hin/* beforc.bmp coord'j ooo.i mp coord 5000.tmp coords--.txt coords-acq02-acqt2.txt coords.tmp output.ppm parainsproc_,l bl preds0057v_th.tmp pred 5005 7v_ l h _ bi tsoo.l m p pred5o057v_lh_bits03.imp pred50057v_lh_video.dala pred50057v_th_videoq0.hdr pred s0q57v_lh_video01 key pred50057v_lh_video01.mpg fig. 3: image magick and the file browsing menu 2\tof 3 this information is exempt from disclosure under the freedom of information act 2000 and may be subject to exemption under other uk information legislation. refer disclosure requests to gchq on (non-sec) or emaill ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "secret ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "secret select the bitmap image from the file menu, right click on the image and select save ... the image format can be set by pressing the format button at the bottom of the window. there are a huge number of different formats to select from. the format required is ppm format (portable pixmap). in a terminal window at a command line prompt type antisky -be input.ppm output, ppm this will now have descrambled the image using the program antisky. the descrambled image can be viewed using the image magick tool and converted to a more convenient format if desired. the initial results from running antisky with the default settings as above may not produce particularly good results depending on the image being descrambled. this is because there may be part of the non-scrambled frame of the image included in the descrambling which corrupts the results. to improve the descrambling there are two more option which force the program to ignore the left and right hand sides of the image. using the -i and -r (for left and right) flags and experimenting with different values may produce better results. the descrambled image first obtained with the default settings is shown in fig. 4, whilst the image obtained with the command antisky -be -115 -r3 input.ppm output.ppm is shown in fig. 5 and is considerably clearer. there is no quick way of discovering the optimum settings for antisky other than stepping through the parameter space of values and selecting the one that gives the best results. fig. 5: running antisky with optimised settings fig.4: running antisky with the default settings ' as can be seen from figs 4 & 5, for a good quality signal and optimal settings near perfect image construction can be achieved. 3\tof 3 this information is exempt from disclosure under the freedom of information act 2000 and may be subject to exemption under other uk information legislation. refer disclosure requests to gchq on (non-sec) or emaill ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "secret ", 
        "paragraph_relto": []
      }
    ], 
    "pdf_paths": [
      "Anarchist-Training-mod5-Redacted-Compat.pdf"
    ], 
    "overall_classification": "Secret", 
    "description": "This GCHQ manual from 2008 explains how analysts would unscramble the video signals from Israeli drones: see the Intercept article Spies in the Sky: Israeli Drone Feeds Hacked by British and American Intellience, 29 January 2016.", 
    "plain_text": "\ufeffSECRET\r\n\r\nISUAV Video Descrambling\r\n\r\nAuthor:\r\n\r\nvere\u00eeon^ra\r\n\r\nIntroduction\r\n\r\nAnalogue video from Israeli UAVs has been intercepted in both clear (i.e. unencrypted) and scrambled\r\n(i.e. encrypted) formats. Processing clear video using M2Extra is relatively straightforward, the method\r\nbeing described in Anarchist training Module 4. For scrambled video the capability exists to exploit the\r\ncontent using a combination of image processing tools and scrypts on Mutiny Jaguar.\r\n\r\nBackground\r\n\r\nInterception of scrambled analogue video signals at Anarchist has a long history, with the earliest\r\nexamples dating back to 1998.\r\n\r\nThe Signal\r\n\r\nThe appearance of the encrypted signal in the frequency domain is virtually indistinguishable from the\r\nclear video signal. A comparison of the Post-D data for an example of clear video, and an encrypted\r\nexample from a few seconds later (figs 1a & 1b) show that, apart from a subtle modification to the\r\nenvelope, the signals appear very similar. The most noticable effect is an increase in energy at lower\r\nfrequencies, consistent with the detail in the image being smoothed out by the scrambling process.\r\n\r\nScrambled Imagery\r\n\r\nAs can be seen by examining an example of a frame of scrambled video (Fig.2) the video frame is\r\nunchanged by the scrambling method. In addition to the image seen in clear video there is also two\r\nlines of digital information encoded in the teletext area at the top of the screen. This is presumed to be\r\ninformation relating to the scrambling, e.g. a cryptographic \u2018key\u2019 to enable the original image to be\r\nreconstructed.\r\n\r\nInvestigation of the data has determined the method by which the video is scrambled. The method\r\nused is a \u2018cut & slide\u2019 technique whereby each line is cut at a location and the two halves are\r\ntransmitted in the opposite order. This technique was originally used by Sky TV to protect their\r\nanalogue transmissions before they switched to digital, the system being known as VideoCrypt.\r\n\r\n1 Of 3\r\n\r\nThis information is exempt from disclosure under the Freedom of Information Act 2000 and may be subject to exemption under\r\n\r\nother UK information legislation. Refer disclosure requests to GCHQ\t(non-sec) or email^^^^^^H\r\n\r\nSECRET\r\n\r\nSECRET\r\n\r\nFig. 2: An single frame of scrambled video imagery\r\n\r\nExploiting Scrambled Video Images\r\n\r\nHaving determined the technique used to scramble the video imagery a number of known attacks are\r\navailable from open source material. One technique in particular offers a brute force way of\r\nreconstructing the image, without requiring any knowledge of the generating algorithm. This\r\ntechnique, and the source code needed to employ it is freely available on the internet.\r\n\r\nThe computing power needed to descramble the images in near real time is considerable without the\r\nuse of dedicated hardware such as a video capture card that can record uncompressed images. It is\r\nstill possible to descramble individual frames to determine the image content without too much effort.\r\n\r\nMethod\r\n\r\nThe method involves capturing a video frame in bitmap (.BMP) format using M2Extra. The video data\r\nshould be processed as described in the M2Extra video processing guide. When the quality of the\r\nvideo image is good a snapshot can be made of the data in the Event Processing window. Pause the\r\nprocessing and use the left mouse button to zoom in to the scrambled image to exclude the frame.\r\n\r\nFrom the file menu in the top left hand corner of the Event Processing window select Snap . .. (CTRL-\r\nS), and choose .BMP as the format.\r\n\r\nStart Martes in a terminal window with the command martes, and launch the Image Magick tool from a\r\nterminal window with the command magick_display\r\n\r\nDirectory: |/daui/midas/m2cxtra/vidco/\u00bbhin/*\r\n\r\nbeforc.bmp\r\ncoord'J OOO.i mp\r\ncoord 5000.tmp\r\ncoords--.txt\r\n\r\ncoords-ACQ02-ACQT2.txt\r\n\r\ncoords.tmp\r\n\r\noutput.ppm\r\n\r\nparainsproc_,l bl\r\n\r\npredS0057v_th.tmp\r\n\r\npred 5005 7v_ l h _ bi tsOO.l m p\r\n\r\npred5O057v_lh_bits03.imp\r\n\r\npred50057v_lh_video\u00fc\u00fb.dala\r\n\r\npred50057v_th_videoQ0.hdr\r\n\r\npred S0Q57v_lh_video01 key\r\n\r\npred50057v_lh_video01.mpg\r\n\r\n\r\n\r\nFig. 3: Image Magick and the file browsing menu\r\n\r\n2\tof 3\r\n\r\nThis information is exempt from disclosure under the Freedom of information Act 2000 and may be subject to exemption under\r\n\r\nother UK information legislation. Refer disclosure requests to GCHQ on\r\n\r\n(non-sec) or emaill\r\n\r\nSECRET\r\n\r\nSECRET\r\n\r\nSelect the bitmap image from the file menu, right click on the image and select Save ... The image\r\nformat can be set by pressing the Format button at the bottom of the window. There are a huge\r\nnumber of different formats to select from. The format required is PPM format (portable pixmap).\r\n\r\nIn a terminal window at a command line prompt type\r\n\r\nantisky -be input.ppm output, ppm\r\n\r\nThis will now have descrambled the image using the program antisky. The descrambled image can be\r\nviewed using the Image Magick tool and converted to a more convenient format if desired.\r\n\r\nThe initial results from running antisky with the default settings as above may not produce particularly\r\ngood results depending on the image being descrambled. This is because there may be part of the\r\nnon-scrambled frame of the image included in the descrambling which corrupts the results. To\r\nimprove the descrambling there are two more option which force the program to ignore the left and\r\nright hand sides of the image. Using the -I and -r (for left and right) flags and experimenting with\r\ndifferent values may produce better results. The descrambled image first obtained with the default\r\nsettings is shown in Fig. 4, whilst the image obtained with the command\r\n\r\nantisky -be -115 -r3 input.ppm output.ppm\r\n\r\nis shown in Fig. 5 and is considerably clearer.\r\n\r\nThere is no quick way of discovering the optimum settings for Antisky other than stepping through the\r\nparameter space of values and selecting the one that gives the best results.\r\n\r\nFig. 5: Running antisky with optimised\r\nsettings\r\n\r\nFig.4: Running antisky with the default\r\nsettings\r\n\r\n\u00ab '\r\n\r\nAs can be seen from Figs 4 & 5, for a good quality signal and optimal settings near perfect image\r\nconstruction can be achieved.\r\n\r\n3\tof 3\r\n\r\nThis information is exempt from disclosure under the Freedom of information Act 2000 and may be subject to exemption under\r\n\r\nother UK information legislation. Refer disclosure requests to GCHQ on\r\n\r\n(non-sec) or emaill\r\n\r\nSECRET", 
    "sigads": [], 
    "overall_relto": [], 
    "countries_mentioned": [
      "United Kingdom (GBR/GB)"
    ], 
    "link": "https://edwardsnowden.com/2016/01/31/isuav-video-descrambling/", 
    "document_topic": [
      "Internet Content"
    ], 
    "pub_date": "Sun, 31 Jan 2016 23:46:30 +0000", 
    "article_links": [
      "https://theintercept.com/2016/01/28/israeli-drone-feeds-hacked-by-british-and-american-intelligence/"
    ], 
    "categories": [
      "Revealed documents", 
      "anarchist", 
      "antisky", 
      "gchq_orig", 
      "internet_content", 
      "isuav", 
      "m2extra", 
      "mutiny jaguar", 
      "s455e", 
      "sky tv", 
      "videocrypt"
    ], 
    "title": "ISUAV Video Descrambling", 
    "doc_text": "\ufeffSECRET\r\n\r\nISUAV Video Descrambling\r\n\r\nAuthor:\r\n\r\nvere\u00eeon^ra\r\n\r\nIntroduction\r\n\r\nAnalogue video from Israeli UAVs has been intercepted in both clear (i.e. unencrypted) and scrambled\r\n(i.e. encrypted) formats. Processing clear video using M2Extra is relatively straightforward, the method\r\nbeing described in Anarchist training Module 4. For scrambled video the capability exists to exploit the\r\ncontent using a combination of image processing tools and scrypts on Mutiny Jaguar.\r\n\r\nBackground\r\n\r\nInterception of scrambled analogue video signals at Anarchist has a long history, with the earliest\r\nexamples dating back to 1998.\r\n\r\nThe Signal\r\n\r\nThe appearance of the encrypted signal in the frequency domain is virtually indistinguishable from the\r\nclear video signal. A comparison of the Post-D data for an example of clear video, and an encrypted\r\nexample from a few seconds later (figs 1a & 1b) show that, apart from a subtle modification to the\r\nenvelope, the signals appear very similar. The most noticable effect is an increase in energy at lower\r\nfrequencies, consistent with the detail in the image being smoothed out by the scrambling process.\r\n\r\nScrambled Imagery\r\n\r\nAs can be seen by examining an example of a frame of scrambled video (Fig.2) the video frame is\r\nunchanged by the scrambling method. In addition to the image seen in clear video there is also two\r\nlines of digital information encoded in the teletext area at the top of the screen. This is presumed to be\r\ninformation relating to the scrambling, e.g. a cryptographic \u2018key\u2019 to enable the original image to be\r\nreconstructed.\r\n\r\nInvestigation of the data has determined the method by which the video is scrambled. The method\r\nused is a \u2018cut & slide\u2019 technique whereby each line is cut at a location and the two halves are\r\ntransmitted in the opposite order. This technique was originally used by Sky TV to protect their\r\nanalogue transmissions before they switched to digital, the system being known as VideoCrypt.\r\n\r\n1 Of 3\r\n\r\nThis information is exempt from disclosure under the Freedom of Information Act 2000 and may be subject to exemption under\r\n\r\nother UK information legislation. Refer disclosure requests to GCHQ\t(non-sec) or email^^^^^^H\r\n\r\nSECRET\r\n\r\nSECRET\r\n\r\nFig. 2: An single frame of scrambled video imagery\r\n\r\nExploiting Scrambled Video Images\r\n\r\nHaving determined the technique used to scramble the video imagery a number of known attacks are\r\navailable from open source material. One technique in particular offers a brute force way of\r\nreconstructing the image, without requiring any knowledge of the generating algorithm. This\r\ntechnique, and the source code needed to employ it is freely available on the internet.\r\n\r\nThe computing power needed to descramble the images in near real time is considerable without the\r\nuse of dedicated hardware such as a video capture card that can record uncompressed images. It is\r\nstill possible to descramble individual frames to determine the image content without too much effort.\r\n\r\nMethod\r\n\r\nThe method involves capturing a video frame in bitmap (.BMP) format using M2Extra. The video data\r\nshould be processed as described in the M2Extra video processing guide. When the quality of the\r\nvideo image is good a snapshot can be made of the data in the Event Processing window. Pause the\r\nprocessing and use the left mouse button to zoom in to the scrambled image to exclude the frame.\r\n\r\nFrom the file menu in the top left hand corner of the Event Processing window select Snap . .. (CTRL-\r\nS), and choose .BMP as the format.\r\n\r\nStart Martes in a terminal window with the command martes, and launch the Image Magick tool from a\r\nterminal window with the command magick_display\r\n\r\nDirectory: |/daui/midas/m2cxtra/vidco/\u00bbhin/*\r\n\r\nbeforc.bmp\r\ncoord'J OOO.i mp\r\ncoord 5000.tmp\r\ncoords--.txt\r\n\r\ncoords-ACQ02-ACQT2.txt\r\n\r\ncoords.tmp\r\n\r\noutput.ppm\r\n\r\nparainsproc_,l bl\r\n\r\npredS0057v_th.tmp\r\n\r\npred 5005 7v_ l h _ bi tsOO.l m p\r\n\r\npred5O057v_lh_bits03.imp\r\n\r\npred50057v_lh_video\u00fc\u00fb.dala\r\n\r\npred50057v_th_videoQ0.hdr\r\n\r\npred S0Q57v_lh_video01 key\r\n\r\npred50057v_lh_video01.mpg\r\n\r\n\r\n\r\nFig. 3: Image Magick and the file browsing menu\r\n\r\n2\tof 3\r\n\r\nThis information is exempt from disclosure under the Freedom of information Act 2000 and may be subject to exemption under\r\n\r\nother UK information legislation. Refer disclosure requests to GCHQ on\r\n\r\n(non-sec) or emaill\r\n\r\nSECRET\r\n\r\nSECRET\r\n\r\nSelect the bitmap image from the file menu, right click on the image and select Save ... The image\r\nformat can be set by pressing the Format button at the bottom of the window. There are a huge\r\nnumber of different formats to select from. The format required is PPM format (portable pixmap).\r\n\r\nIn a terminal window at a command line prompt type\r\n\r\nantisky -be input.ppm output, ppm\r\n\r\nThis will now have descrambled the image using the program antisky. The descrambled image can be\r\nviewed using the Image Magick tool and converted to a more convenient format if desired.\r\n\r\nThe initial results from running antisky with the default settings as above may not produce particularly\r\ngood results depending on the image being descrambled. This is because there may be part of the\r\nnon-scrambled frame of the image included in the descrambling which corrupts the results. To\r\nimprove the descrambling there are two more option which force the program to ignore the left and\r\nright hand sides of the image. Using the -I and -r (for left and right) flags and experimenting with\r\ndifferent values may produce better results. The descrambled image first obtained with the default\r\nsettings is shown in Fig. 4, whilst the image obtained with the command\r\n\r\nantisky -be -115 -r3 input.ppm output.ppm\r\n\r\nis shown in Fig. 5 and is considerably clearer.\r\n\r\nThere is no quick way of discovering the optimum settings for Antisky other than stepping through the\r\nparameter space of values and selecting the one that gives the best results.\r\n\r\nFig. 5: Running antisky with optimised\r\nsettings\r\n\r\nFig.4: Running antisky with the default\r\nsettings\r\n\r\n\u00ab '\r\n\r\nAs can be seen from Figs 4 & 5, for a good quality signal and optimal settings near perfect image\r\nconstruction can be achieved.\r\n\r\n3\tof 3\r\n\r\nThis information is exempt from disclosure under the Freedom of information Act 2000 and may be subject to exemption under\r\n\r\nother UK information legislation. Refer disclosure requests to GCHQ on\r\n\r\n(non-sec) or emaill\r\n\r\nSECRET", 
    "pdf": [
      "https://edwardsnowden.com/wp-content/uploads/2016/01/Anarchist-Training-mod5-Redacted-Compat.pdf"
    ]
  }, 
  {
    "released_date": "20160129", 
    "overall_handling_caveats": [], 
    "id": "20160129|s455nisraeliuavdigitalvideo", 
    "document_date": "0000-00-00 00:00:00", 
    "codewords": [
      "MAGIC"
    ], 
    "agency": [
      "GCHQ"
    ], 
    "sub_paragraphs_classifications": [
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 spoke sigint.development s455n - israeli uav digital video ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Confidential", 
        "paragraph_text": "golf section, jssu(cyp) analyst: 1 of 7 this information is exempt from disclosure under the freedom of information act 2000 and may be subject to exemption under other uk information legislation. refer disclosure requests to gchq on\t(non-sec) or email ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 spoke ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 spoke contents 1.introduction........................................3 2.\tmodulation.........................................3 3.\tforward error correction (fec) and error detection.3 4.\trandomiser.........................................4 5.\tpayload............................................5 6.\tvideo & s455e......................................6 7.\tconclusion.........................................7 2\tof 7 this information is exempt from disclosure under the freedom of information act 2000 and may be subject to exemption under other uk information legislation. refer disclosure requests to gchq on\t(non-sec) or email ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 spoke ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 spoke 1.\tintroduction 1.1\tthis report covers analysis of s455n a high data rate (hdr) signal emanating from ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "an israeli uav. the signal of interest (soi) was first intercepted in april 2009 however, the original recording was too weak for full analysis. this report is based on the analysis of a recording made in april 2010. 1.2\ts455n is a complex signal utilising a number of error correction and detection techniques to successfully convey internet protocol (ip) data carrying streaming digital video. 2.\tmodulation 2.1\tthe soi employs fsk modulation and is keyed at 9.11mbauds occupying approximately 10mhz bandwidth. demodulation of the soi was attempted using various demodulators including m2extra however, the resultant bits were poor quality. the soi was successfully demodulated using an fm demod in black magic. 2.2\tdata is nrzl and frames consist of 4140 bits with a 44 bit synchronisation pattern - 11101011010101001101001101110011011111110000. fig 1: dvt sync'd data frames 3.\tforward error correction (fec) and error detection 3.1\tfec and edac are achieved utilising a block interleaver and a two dimensional turbo product code (tpc). the interleaver is a 64x64 bit block interleaver used to spread the data to improve the performance of the tpc. the tpc is a (64, 57)*(64,57) 2 dimensional code employing parity with a generating polynomial of:- g(x) = x6 + x1 +1 3.2\tthe fec can be utilised to correct the data using magyk or removed by applying a t3648s448 to remove the vertical dimension and a t57s7 to remove the horizontal dimension. 3\tof 7 this information is exempt from disclosure under the freedom of information act 2000 and may be subject to exemption under other uk information legislation. refer disclosure requests to gchq on\t(non-sec) or email ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 spoke ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 spoke fig 2: depview showing horizontal dimension fig 3: depview showing vertical dimension 4.\trandomiser 4.1\tafter deinterleaving the data and removing the fec the frame width should be 3249 (57*57). the frame begins with a 10 bit sync except on every third frame where 10 bits of data are sent. these 10 bits of data raster on a width of 512 and conform to s455e. removal of the 10 bits of sync/s455e from each frame will result in a frame width of 3239. the remaining data is randomised using a feed through randomiser f15(0,1,15). 4\tof 7 this information is exempt from disclosure under the freedom of information act 2000 and may be subject to exemption under other uk information legislation. refer disclosure requests to gchq on\t(non-sec) or email ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 spoke ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 spoke fig 4: dvt showing s455e frames 5.\tpayload 5.1\tfollowing removal of the randomiser the data was found to be hdlc. the packets ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "contained ip data carrying universal datagram protocol (udp) conveying a number of different protocols. the main protocol in use was real time protocol (rtp) and this was being used to carry mpeg 4 streaming video. analysis of the video revealed multiple video streams from different cameras. the exact video encoding parameters have not been fully resolved and this should be taken in to consideration when viewing any outputted files. fig 5: pktswing showing ip packets carrying rtp conveying mpeg 4 5\tof 7 this information is exempt from disclosure under the freedom of information act 2000 and may be subject to exemption under other uk information legislation. refer disclosure requests to gchq on\t(non-sec) or email ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 spoke ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 spoke 6. video & s455e 6.1 the video is mpeg 4 and appears to contain multiple streams; each stream appears to be capable of scanning through different camera views ' snapshots from video 6.2\ttelemetry is transmitted using normal s455e fig 6: geo plot extracted from s455e 6\tof 7 this information is exempt from disclosure under the freedom of information act 2000 and may be subject to exemption under other uk information legislation. refer disclosure requests to gchq on\t(non-sec) or email ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 spoke ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 spoke 7. conclusion 7.1\ta number of elements of this soi need further analysis video - being analysed by opc-spf, gchq remaining ip data - they are a number of protocols in use that need resolving 7.2\tthis is potentially a significant upgrade to the normal analogue video we see, this new system adds the capability to see a number of video feeds simultaneously. we currently have no collection system capable of processing this signal due to the high data rate and complexity of the underlying data. there are a number of sigint collection solutions that would be more than capable of dealing with this signal should there be a requirement to do so. further information: intercept information and screen shots of associated s455a/e can be found on this wiki page:- this report was issued as: ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 spoke strap handling notice ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(see annexe h of the strap security manual for detailed guidance) secret strap reports may be seen by strap-inducted sc cleared readers who have a valid need-to-know. strap-inducted ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "readers who hold a dv clearance may only see top secret reports at any strap level. contact: acknowledgements: 7\tof 7 this information is exempt from disclosure under the freedom of information act 2000 and may be subject to exemption under other uk information legislation. refer disclosure requests to gchq on\t(non-sec) or email ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 spoke ", 
        "paragraph_relto": []
      }
    ], 
    "pdf_paths": [
      "S455N-Redacted.pdf"
    ], 
    "overall_classification": "Top Secret", 
    "description": "This undated GCHQ report from the agency\u2019s Cyprus (GOLF) division, describes, in technical data, the S455N signals sent out by Israeli drones: see the Intercept article Spies in the Sky: Israeli Drone Feeds Hacked by British and American Intellience, 29 January 2016.", 
    "plain_text": "\ufeffTOP SECRET STRAP1 SPOKE\r\n\r\nsigint.development\r\n\r\nS455N - Israeli UAV Digital Video\r\n\r\nGolf Section, JSSU(CYP)\r\n\r\nAnalyst:\r\n\r\n1 of 7\r\n\r\nThis information is exempt from disclosure under the Freedom of Information Act 2000 and may be subject to exemption under\r\nother UK information legislation. Refer disclosure requests to GCHQ on\t(non-sec) or email\r\n\r\nTOP SECRET STRAP1 SPOKE\r\n\r\nTOP SECRET STRAP1 SPOKE\r\n\r\nCONTENTS\r\n\r\n1.INTRODUCTION........................................3\r\n\r\n2.\tMODULATION.........................................3\r\n\r\n3.\tFORWARD ERROR CORRECTION (FEC) AND ERROR DETECTION.3\r\n\r\n4.\tRANDOMISER.........................................4\r\n\r\n5.\tPAYLOAD............................................5\r\n\r\n6.\tVIDEO & S455E......................................6\r\n\r\n7.\tCONCLUSION.........................................7\r\n\r\n2\tof 7\r\n\r\nThis information is exempt from disclosure under the Freedom of Information Act 2000 and may be subject to exemption under\r\nother UK information legislation. Refer disclosure requests to GCHQ on\t(non-sec) or email\r\n\r\nTOP SECRET STRAP1 SPOKE\r\n\r\nTOP SECRET STRAP1 SPOKE\r\n\r\n1.\tINTRODUCTION\r\n\r\n1.1\tThis report covers analysis of S455N a High Data Rate (HDR) signal emanating from\r\nan Israeli UAV. The Signal of Interest (SOI) was first intercepted in April 2009\r\nhowever, the original recording was too weak for full analysis. This report is based on\r\nthe analysis of a recording made in April 2010.\r\n\r\n1.2\tS455N is a complex signal utilising a number of error correction and detection\r\ntechniques to successfully convey Internet Protocol (IP) data carrying streaming digital\r\nvideo.\r\n\r\n2.\tMODULATION\r\n\r\n2.1\tThe SOI employs FSK modulation and is keyed at 9.11MBauds occupying\r\napproximately 10MHz bandwidth. Demodulation of the SOI was attempted using\r\nvarious demodulators including m2Extra however, the resultant bits were poor quality.\r\nThe SOI was successfully demodulated using an FM demod in Black Magic.\r\n\r\n2.2\tData is NRZL and frames consist of 4140 bits with a 44 bit synchronisation pattern -\r\n11101011010101001101001101110011011111110000.\r\n\r\nFig 1: DVT Sync'd Data Frames\r\n\r\n3.\tFORWARD ERROR CORRECTION (FEC) AND ERROR DETECTION\r\n\r\n3.1\tFEC and EDAC are achieved utilising a block interleaver and a two dimensional Turbo\r\nProduct Code (TPC). The interleaver is a 64x64 bit block interleaver used to spread\r\nthe data to improve the performance of the TPC. The TPC is a (64, 57)*(64,57) 2\r\ndimensional code employing parity with a generating polynomial of:-\r\n\r\ng(x) = x6 + x1 +1\r\n\r\n3.2\tThe FEC can be utilised to correct the data using magyk or removed by applying a\r\nt3648s448 to remove the vertical dimension and a t57s7 to remove the horizontal\r\ndimension.\r\n\r\n3\tof 7\r\n\r\nThis information is exempt from disclosure under the Freedom of Information Act 2000 and may be subject to exemption under\r\nother UK information legislation. Refer disclosure requests to GCHQ on\t(non-sec) or email\r\n\r\nTOP SECRET STRAP1 SPOKE\r\n\r\nTOP SECRET STRAP1 SPOKE\r\n\r\nFig 2: Depview showing horizontal dimension\r\n\r\nFig 3: Depview showing vertical dimension\r\n\r\n4.\tRANDOMISER\r\n\r\n4.1\tAfter deinterleaving the data and removing the FEC the frame width should be 3249\r\n(57*57). The frame begins with a 10 bit sync except on every third frame where 10 bits\r\nof data are sent. These 10 bits of data raster on a width of 512 and conform to S455E.\r\nRemoval of the 10 bits of sync/S455E from each frame will result in a frame width of\r\n3239. The remaining data is randomised using a feed through randomiser F15(0,1,15).\r\n\r\n4\tof 7\r\n\r\nThis information is exempt from disclosure under the Freedom of Information Act 2000 and may be subject to exemption under\r\nother UK information legislation. Refer disclosure requests to GCHQ on\t(non-sec) or email\r\n\r\nTOP SECRET STRAP1 SPOKE\r\n\r\nTOP SECRET STRAP1 SPOKE\r\n\r\nFig 4: DVT Showing S455E Frames\r\n\r\n5.\tPAYLOAD\r\n\r\n5.1\tFollowing removal of the randomiser the data was found to be HDLC. The packets\r\ncontained IP data carrying Universal Datagram Protocol (UDP) conveying a number of\r\ndifferent protocols. The main protocol in use was Real Time Protocol (RTP) and this\r\nwas being used to carry MPEG 4 streaming video. Analysis of the video revealed\r\nmultiple video streams from different cameras. The exact video encoding parameters\r\nhave not been fully resolved and this should be taken in to consideration when viewing\r\nany outputted files.\r\n\r\nFig 5: PktSwing showing IP packets carrying RTP conveying MPEG 4\r\n\r\n5\tof 7\r\n\r\nThis information is exempt from disclosure under the Freedom of Information Act 2000 and may be subject to exemption under\r\nother UK information legislation. Refer disclosure requests to GCHQ on\t(non-sec) or email\r\n\r\nTOP SECRET STRAP1 SPOKE\r\n\r\nTOP SECRET STRAP1 SPOKE\r\n\r\n6. VIDEO & S455E\r\n\r\n6.1 The Video is MPEG 4 and appears to contain multiple streams; each stream appears to\r\nbe capable of scanning through different camera views\r\n\r\n\t' \u25a0\t\t\t\r\n\t\t\t\t\r\n\r\nSnapshots from Video\r\n\r\n6.2\tTelemetry is transmitted using normal S455E\r\n\r\nFig 6: GEO Plot extracted from S455E\r\n\r\n6\tof 7\r\n\r\nThis information is exempt from disclosure under the Freedom of Information Act 2000 and may be subject to exemption under\r\nother UK information legislation. Refer disclosure requests to GCHQ on\t(non-sec) or email\r\n\r\nTOP SECRET STRAP1 SPOKE\r\n\r\nTOP SECRET STRAP1 SPOKE\r\n\r\n7. CONCLUSION\r\n\r\n7.1\tA number of elements of this SOI need further analysis\r\n\r\n\u25a0\tVideo - Being analysed by OPC-SPF, GCHQ\r\n\r\n\u25a0\tRemaining IP Data - They are a number of protocols In use that need resolving\r\n\r\n7.2\tThis Is potentially a significant upgrade to the normal analogue video we see, this new\r\nsystem adds the capability to see a number of video feeds simultaneously. We\r\ncurrently have no collection system capable of processing this signal due to the high\r\ndata rate and complexity of the underlying data. There are a number of SIGINT\r\ncollection solutions that would be more than capable of dealing with this signal should\r\nthere be a requirement to do so.\r\n\r\nFurther information:\r\n\r\nIntercept information and screen shots of associated S455A/E can be found on this wiki page:-\r\n\r\nThis report was issued as:\r\n\r\nTOP SECRET STRAP1 SPOKE\r\n\r\nSTRAP HANDLING NOTICE\r\n\r\n(See Annexe H of the STRAP Security Manual for detailed guidance) SECRET STRAP reports may\r\nbe seen by STRAP-inducted SC cleared readers who have a valid need-to-know. STRAP-inducted\r\nreaders who hold a DV clearance may only see TOP SECRET reports at any STRAP level.\r\n\r\nCONTACT:\r\n\r\nACKNOWLEDGEMENTS:\r\n\r\n7\tof 7\r\n\r\nThis information is exempt from disclosure under the Freedom of Information Act 2000 and may be subject to exemption under\r\nother UK information legislation. Refer disclosure requests to GCHQ on\t(non-sec) or email\r\n\r\nTOP SECRET STRAP1 SPOKE", 
    "sigads": [], 
    "overall_relto": [], 
    "countries_mentioned": [
      "Cyprus (CYP/CY)", 
      "Israel (ISR/IL)", 
      "United Kingdom (GBR/GB)"
    ], 
    "link": "https://edwardsnowden.com/2016/01/31/s455n-israeli-uav-digital-video/", 
    "document_topic": [], 
    "pub_date": "Sun, 31 Jan 2016 23:28:23 +0000", 
    "article_links": [
      "https://theintercept.com/2016/01/28/israeli-drone-feeds-hacked-by-british-and-american-intelligence/"
    ], 
    "categories": [
      "Revealed documents", 
      "black magic", 
      "cyprus", 
      "fsk", 
      "gchq_orig", 
      "golf", 
      "ip", 
      "israel", 
      "jssu", 
      "nrzl", 
      "s455n", 
      "signal of interest", 
      "soi"
    ], 
    "title": "S455N \u2013 Israeli UAV Digital Video", 
    "doc_text": "\ufeffTOP SECRET STRAP1 SPOKE\r\n\r\nsigint.development\r\n\r\nS455N - Israeli UAV Digital Video\r\n\r\nGolf Section, JSSU(CYP)\r\n\r\nAnalyst:\r\n\r\n1 of 7\r\n\r\nThis information is exempt from disclosure under the Freedom of Information Act 2000 and may be subject to exemption under\r\nother UK information legislation. Refer disclosure requests to GCHQ on\t(non-sec) or email\r\n\r\nTOP SECRET STRAP1 SPOKE\r\n\r\nTOP SECRET STRAP1 SPOKE\r\n\r\nCONTENTS\r\n\r\n1.INTRODUCTION........................................3\r\n\r\n2.\tMODULATION.........................................3\r\n\r\n3.\tFORWARD ERROR CORRECTION (FEC) AND ERROR DETECTION.3\r\n\r\n4.\tRANDOMISER.........................................4\r\n\r\n5.\tPAYLOAD............................................5\r\n\r\n6.\tVIDEO & S455E......................................6\r\n\r\n7.\tCONCLUSION.........................................7\r\n\r\n2\tof 7\r\n\r\nThis information is exempt from disclosure under the Freedom of Information Act 2000 and may be subject to exemption under\r\nother UK information legislation. Refer disclosure requests to GCHQ on\t(non-sec) or email\r\n\r\nTOP SECRET STRAP1 SPOKE\r\n\r\nTOP SECRET STRAP1 SPOKE\r\n\r\n1.\tINTRODUCTION\r\n\r\n1.1\tThis report covers analysis of S455N a High Data Rate (HDR) signal emanating from\r\nan Israeli UAV. The Signal of Interest (SOI) was first intercepted in April 2009\r\nhowever, the original recording was too weak for full analysis. This report is based on\r\nthe analysis of a recording made in April 2010.\r\n\r\n1.2\tS455N is a complex signal utilising a number of error correction and detection\r\ntechniques to successfully convey Internet Protocol (IP) data carrying streaming digital\r\nvideo.\r\n\r\n2.\tMODULATION\r\n\r\n2.1\tThe SOI employs FSK modulation and is keyed at 9.11MBauds occupying\r\napproximately 10MHz bandwidth. Demodulation of the SOI was attempted using\r\nvarious demodulators including m2Extra however, the resultant bits were poor quality.\r\nThe SOI was successfully demodulated using an FM demod in Black Magic.\r\n\r\n2.2\tData is NRZL and frames consist of 4140 bits with a 44 bit synchronisation pattern -\r\n11101011010101001101001101110011011111110000.\r\n\r\nFig 1: DVT Sync'd Data Frames\r\n\r\n3.\tFORWARD ERROR CORRECTION (FEC) AND ERROR DETECTION\r\n\r\n3.1\tFEC and EDAC are achieved utilising a block interleaver and a two dimensional Turbo\r\nProduct Code (TPC). The interleaver is a 64x64 bit block interleaver used to spread\r\nthe data to improve the performance of the TPC. The TPC is a (64, 57)*(64,57) 2\r\ndimensional code employing parity with a generating polynomial of:-\r\n\r\ng(x) = x6 + x1 +1\r\n\r\n3.2\tThe FEC can be utilised to correct the data using magyk or removed by applying a\r\nt3648s448 to remove the vertical dimension and a t57s7 to remove the horizontal\r\ndimension.\r\n\r\n3\tof 7\r\n\r\nThis information is exempt from disclosure under the Freedom of Information Act 2000 and may be subject to exemption under\r\nother UK information legislation. Refer disclosure requests to GCHQ on\t(non-sec) or email\r\n\r\nTOP SECRET STRAP1 SPOKE\r\n\r\nTOP SECRET STRAP1 SPOKE\r\n\r\nFig 2: Depview showing horizontal dimension\r\n\r\nFig 3: Depview showing vertical dimension\r\n\r\n4.\tRANDOMISER\r\n\r\n4.1\tAfter deinterleaving the data and removing the FEC the frame width should be 3249\r\n(57*57). The frame begins with a 10 bit sync except on every third frame where 10 bits\r\nof data are sent. These 10 bits of data raster on a width of 512 and conform to S455E.\r\nRemoval of the 10 bits of sync/S455E from each frame will result in a frame width of\r\n3239. The remaining data is randomised using a feed through randomiser F15(0,1,15).\r\n\r\n4\tof 7\r\n\r\nThis information is exempt from disclosure under the Freedom of Information Act 2000 and may be subject to exemption under\r\nother UK information legislation. Refer disclosure requests to GCHQ on\t(non-sec) or email\r\n\r\nTOP SECRET STRAP1 SPOKE\r\n\r\nTOP SECRET STRAP1 SPOKE\r\n\r\nFig 4: DVT Showing S455E Frames\r\n\r\n5.\tPAYLOAD\r\n\r\n5.1\tFollowing removal of the randomiser the data was found to be HDLC. The packets\r\ncontained IP data carrying Universal Datagram Protocol (UDP) conveying a number of\r\ndifferent protocols. The main protocol in use was Real Time Protocol (RTP) and this\r\nwas being used to carry MPEG 4 streaming video. Analysis of the video revealed\r\nmultiple video streams from different cameras. The exact video encoding parameters\r\nhave not been fully resolved and this should be taken in to consideration when viewing\r\nany outputted files.\r\n\r\nFig 5: PktSwing showing IP packets carrying RTP conveying MPEG 4\r\n\r\n5\tof 7\r\n\r\nThis information is exempt from disclosure under the Freedom of Information Act 2000 and may be subject to exemption under\r\nother UK information legislation. Refer disclosure requests to GCHQ on\t(non-sec) or email\r\n\r\nTOP SECRET STRAP1 SPOKE\r\n\r\nTOP SECRET STRAP1 SPOKE\r\n\r\n6. VIDEO & S455E\r\n\r\n6.1 The Video is MPEG 4 and appears to contain multiple streams; each stream appears to\r\nbe capable of scanning through different camera views\r\n\r\n\t' \u25a0\t\t\t\r\n\t\t\t\t\r\n\r\nSnapshots from Video\r\n\r\n6.2\tTelemetry is transmitted using normal S455E\r\n\r\nFig 6: GEO Plot extracted from S455E\r\n\r\n6\tof 7\r\n\r\nThis information is exempt from disclosure under the Freedom of Information Act 2000 and may be subject to exemption under\r\nother UK information legislation. Refer disclosure requests to GCHQ on\t(non-sec) or email\r\n\r\nTOP SECRET STRAP1 SPOKE\r\n\r\nTOP SECRET STRAP1 SPOKE\r\n\r\n7. CONCLUSION\r\n\r\n7.1\tA number of elements of this SOI need further analysis\r\n\r\n\u25a0\tVideo - Being analysed by OPC-SPF, GCHQ\r\n\r\n\u25a0\tRemaining IP Data - They are a number of protocols In use that need resolving\r\n\r\n7.2\tThis Is potentially a significant upgrade to the normal analogue video we see, this new\r\nsystem adds the capability to see a number of video feeds simultaneously. We\r\ncurrently have no collection system capable of processing this signal due to the high\r\ndata rate and complexity of the underlying data. There are a number of SIGINT\r\ncollection solutions that would be more than capable of dealing with this signal should\r\nthere be a requirement to do so.\r\n\r\nFurther information:\r\n\r\nIntercept information and screen shots of associated S455A/E can be found on this wiki page:-\r\n\r\nThis report was issued as:\r\n\r\nTOP SECRET STRAP1 SPOKE\r\n\r\nSTRAP HANDLING NOTICE\r\n\r\n(See Annexe H of the STRAP Security Manual for detailed guidance) SECRET STRAP reports may\r\nbe seen by STRAP-inducted SC cleared readers who have a valid need-to-know. STRAP-inducted\r\nreaders who hold a DV clearance may only see TOP SECRET reports at any STRAP level.\r\n\r\nCONTACT:\r\n\r\nACKNOWLEDGEMENTS:\r\n\r\n7\tof 7\r\n\r\nThis information is exempt from disclosure under the Freedom of Information Act 2000 and may be subject to exemption under\r\nother UK information legislation. Refer disclosure requests to GCHQ on\t(non-sec) or email\r\n\r\nTOP SECRET STRAP1 SPOKE", 
    "pdf": [
      "https://edwardsnowden.com/wp-content/uploads/2016/01/S455N-Redacted.pdf"
    ]
  }, 
  {
    "released_date": "20160129", 
    "overall_handling_caveats": [], 
    "id": "20160129|mhsfisintsuccessfullycollectsisraelif-16headsupdisplay", 
    "document_date": "2008-02-01 00:00:00", 
    "codewords": [], 
    "agency": [
      "GCHQ", 
      "NSA"
    ], 
    "sub_paragraphs_classifications": [
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//comint/talent keyhole// rel to usa, fvey published march 2008 mhs fisint successfully collects israeli f-16 heads-up display ", 
        "paragraph_relto": [
          "Canada", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "United Kingdom"
        ]
      }, 
      {
        "paragraph_handling_caveats": [
          "si", 
          "rel"
        ], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s//si//rel) , menwith hill station (f77) ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [
          "si", 
          "tk", 
          "rel"
        ], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s//si/tk//rel) during the recent unrest in the gaza strip in january, menwith hill station fisint operators collected video for the first time from the cockpit of an israeli air force f-16 fighter jet. the day before, mhs fisint operators collected video from ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "an unmanned aerial vehicle (uav). the uav appeared to still be on the ground, which prompted the site to go back to the area again the next day. as a result, mhs collected the f-16 heads-up display that showed a target on the ground being tracked. mhs worked closely with a gchq site in cyprus for tip-offs. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [
          "si", 
          "rel"
        ], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s//si//rel) reacting to the unrest in the gaza strip, mhs conducted ad hoc range surveillance. on 3 january, the site collected the aircraft video from an israeli f-16 fighter. the 14-second long video showed an unbroken line running through the targeting display, indicating that the target being tracked was on the ground.1 ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(siisiiirel) heads-up display from an israeli f-16 fighter over the gaza strip. the target being tracked is located inside the circle. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//comint/talent keyhole// rel to usa, fvey ", 
        "paragraph_relto": [
          "Canada", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "United Kingdom"
        ]
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//comint/talent keyhole// rel to usa, fvey ", 
        "paragraph_relto": [
          "Canada", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "United Kingdom"
        ]
      }, 
      {
        "paragraph_handling_caveats": [
          "fouo"
        ], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "(u//fouo) poc: ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "(u) notes: ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [
          "fouo"
        ], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "1\t(u//fouo) open-source reporting indicated that the israeli air force was involved in at least five airstrikes over the gaza strip killing two militants. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [
          "fouo"
        ], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "(u//fouo) this article is reprinted from mhss horizon newsletter, february edition. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//comint/talent keyhole// rel to usa, fvey ", 
        "paragraph_relto": [
          "Canada", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "United Kingdom"
        ]
      }
    ], 
    "pdf_paths": [
      "F-16-FISINT2-Redacted.pdf"
    ], 
    "overall_classification": "Top Secret", 
    "description": "This March 2008 post from the internal NSA newsletter SIDToday, describes the Menwith Hill station\u2019s success in intercepting the video feeds from Israeli F-16 fighter jets and drones: see the Intercept article Spies in the Sky: Israeli Drone Feeds Hacked by British and American Intellience, 29 January 2016.", 
    "plain_text": "\ufeffTOP SECRET//COMINT/TALENT KEYHOLE// REL TO USA, FVEY\r\n\r\npublished March 2008\r\n\r\nMHS FISINT Successfully Collects Israeli F-16 Heads-Up Display\r\n\r\n(S//SI//REL)\r\n\r\n, Menwith Hill Station (F77)\r\n\r\n(S//SI/TK//REL) During the recent unrest in the Gaza Strip in January, Menwith Hill\r\nStation FISINT operators collected video for the first time from the cockpit of an Israeli\r\nAir Force F-16 fighter jet. The day before, MHS FISINT operators collected video from\r\nan Unmanned Aerial Vehicle (UAV). The UAV appeared to still be on the ground, which\r\nprompted the site to go back to the area again the next day. As a result, MHS collected\r\nthe F-16 heads-up display that showed a target on the ground being tracked. MHS\r\nworked closely with a GCHQ site in Cyprus for tip-offs.\r\n\r\n(S//SI//REL) Reacting to the unrest in the Gaza Strip, MHS conducted ad hoc range\r\nsurveillance. On 3 January, the site collected the aircraft video from an Israeli F-16\r\nfighter. The 14-second long video showed an \u201cunbroken line\u201d running through the\r\ntargeting display, indicating that the target being tracked was on the ground.1\r\n\r\n(SIISIIIREL) Heads-up display from an Israeli F-16 fighter over the Gaza Strip. The\r\ntarget being tracked is located inside the circle.\r\n\r\nTOP SECRET//COMINT/TALENT KEYHOLE// REL TO USA, FVEY\r\n\r\nTOP SECRET//COMINT/TALENT KEYHOLE// REL TO USA, FVEY\r\n\r\n(U//FOUO) POC:\r\n\r\n(U) Notes:\r\n\r\n1\t(U//FOUO) Open-source reporting indicated that the Israeli Air Force was involved in\r\nat least five airstrikes over the Gaza Strip killing two militants.\r\n\r\n(U//FOUO) This article is reprinted from MHS\u2019s Horizon newsletter, February edition.\r\n\r\nTOP SECRET//COMINT/TALENT KEYHOLE// REL TO USA, FVEY", 
    "sigads": [], 
    "overall_relto": [
      "Canada", 
      "United States", 
      "New Zealand", 
      "Australia", 
      "United Kingdom"
    ], 
    "countries_mentioned": [
      "Cyprus (CYP/CY)", 
      "Israel (ISR/IL)", 
      "United States (USA/US)"
    ], 
    "link": "https://edwardsnowden.com/2016/01/31/mhs-fisint-successfully-collects-israeli-f-16-heads-up-display/", 
    "document_topic": [
      "SIDtoday"
    ], 
    "pub_date": "Sun, 31 Jan 2016 23:11:21 +0000", 
    "article_links": [
      "https://theintercept.com/2016/01/28/israeli-drone-feeds-hacked-by-british-and-american-intelligence/"
    ], 
    "categories": [
      "Revealed documents", 
      "cyprus", 
      "drones", 
      "f-16", 
      "fisint", 
      "gaza", 
      "gchq_orig", 
      "horizon", 
      "israel", 
      "jet", 
      "menwith hill", 
      "msh", 
      "nsa_orig", 
      "sidtoday", 
      "uav"
    ], 
    "title": "MHS FISINT Successfully Collects Israeli F-16 Heads Up Display", 
    "doc_text": "\ufeffTOP SECRET//COMINT/TALENT KEYHOLE// REL TO USA, FVEY\r\n\r\npublished March 2008\r\n\r\nMHS FISINT Successfully Collects Israeli F-16 Heads-Up Display\r\n\r\n(S//SI//REL)\r\n\r\n, Menwith Hill Station (F77)\r\n\r\n(S//SI/TK//REL) During the recent unrest in the Gaza Strip in January, Menwith Hill\r\nStation FISINT operators collected video for the first time from the cockpit of an Israeli\r\nAir Force F-16 fighter jet. The day before, MHS FISINT operators collected video from\r\nan Unmanned Aerial Vehicle (UAV). The UAV appeared to still be on the ground, which\r\nprompted the site to go back to the area again the next day. As a result, MHS collected\r\nthe F-16 heads-up display that showed a target on the ground being tracked. MHS\r\nworked closely with a GCHQ site in Cyprus for tip-offs.\r\n\r\n(S//SI//REL) Reacting to the unrest in the Gaza Strip, MHS conducted ad hoc range\r\nsurveillance. On 3 January, the site collected the aircraft video from an Israeli F-16\r\nfighter. The 14-second long video showed an \u201cunbroken line\u201d running through the\r\ntargeting display, indicating that the target being tracked was on the ground.1\r\n\r\n(SIISIIIREL) Heads-up display from an Israeli F-16 fighter over the Gaza Strip. The\r\ntarget being tracked is located inside the circle.\r\n\r\nTOP SECRET//COMINT/TALENT KEYHOLE// REL TO USA, FVEY\r\n\r\nTOP SECRET//COMINT/TALENT KEYHOLE// REL TO USA, FVEY\r\n\r\n(U//FOUO) POC:\r\n\r\n(U) Notes:\r\n\r\n1\t(U//FOUO) Open-source reporting indicated that the Israeli Air Force was involved in\r\nat least five airstrikes over the Gaza Strip killing two militants.\r\n\r\n(U//FOUO) This article is reprinted from MHS\u2019s Horizon newsletter, February edition.\r\n\r\nTOP SECRET//COMINT/TALENT KEYHOLE// REL TO USA, FVEY", 
    "pdf": [
      "https://edwardsnowden.com/wp-content/uploads/2016/01/F-16-FISINT2-Redacted.pdf"
    ]
  }, 
  {
    "released_date": "20160129", 
    "overall_handling_caveats": [], 
    "id": "20160129|significanttrftroodosstoriesoverpast6months", 
    "document_date": "2012-01-01 00:00:00", 
    "codewords": [
      "HERON"
    ], 
    "agency": [
      "GCHQ"
    ], 
    "sub_paragraphs_classifications": [
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 significant trf troodos stories over past 6 months i ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 success against syria 17th feb 2012 collection on an undocumented frequency of 1208mhz. ababil iii (iranian manufactured) uav from shayrat airfield. tip-off procedures facilitated co-incident collect from golf, e section and mhs on 9th march. site made a further recording on 11th march. presidential level interest in further video samples. ", 
        "paragraph_relto": []
      }
    ], 
    "pdf_paths": [
      "6-Months-Overview-Redacted.pdf"
    ], 
    "overall_classification": "Top Secret", 
    "description": "This GCHQ presentation from 2012 describes the Troodos (Cyprus) station\u2019s successes in intercepting signals from drones, including Israeli-made drones \u201ccarrying weapons\u201d and Iranian-made drones being used in Syria, which were the subject of \u201cpresidential\u201d interest: see the Intercept article Spies in the Sky: Israeli Drone Feeds Hacked by British and American Intellience, 29 January 2016. [\u2026]", 
    "plain_text": "\ufeffTOP SECRET STRAP1\r\n\r\nSignificant TRF TROODOS stories over past 6\r\n\r\nmonths\r\n\r\n\r\n\r\nI\r\n\r\nTOP SECRET STRAP1\r\n\r\nSuccess against Syria\r\n\r\n\u2022\t17th Feb 2012 collection on an undocumented frequency of\r\n1208MHz.\r\n\r\n\u2022\tAbabil III (Iranian manufactured) UAV from Shayrat\r\nAirfield.\r\n\r\n\u2022\tTip-off procedures facilitated co-incident collect from Golf, E\r\nSection and MHS on 9th March.\r\n\r\n\u2022\tSite made a further\r\nrecording on 11th March.\r\n\r\n\u2022\tPresidential level\r\ninterest in further video\r\nsamples.", 
    "sigads": [], 
    "overall_relto": [], 
    "countries_mentioned": [
      "Cyprus (CYP/CY)", 
      "Iran (IRN/IR)", 
      "Israel (ISR/IL)"
    ], 
    "link": "https://edwardsnowden.com/2016/01/31/significant-trf-troodos-stories-over-past-6-months/", 
    "document_topic": [
      "Internet Content"
    ], 
    "pub_date": "Sun, 31 Jan 2016 22:29:41 +0000", 
    "article_links": [
      "https://theintercept.com/2016/01/28/israeli-drone-feeds-hacked-by-british-and-american-intelligence/"
    ], 
    "categories": [
      "Revealed documents", 
      "abibil", 
      "gchq_orig", 
      "golf", 
      "heron", 
      "internet_content", 
      "iran", 
      "israel", 
      "mhs", 
      "shayrat", 
      "syria", 
      "troodos"
    ], 
    "title": "Significant TRF TROODOS stories over past 6 months", 
    "doc_text": "\ufeffTOP SECRET STRAP1\r\n\r\nSignificant TRF TROODOS stories over past 6\r\n\r\nmonths\r\n\r\n\r\n\r\nI\r\n\r\nTOP SECRET STRAP1\r\n\r\nSuccess against Syria\r\n\r\n\u2022\t17th Feb 2012 collection on an undocumented frequency of\r\n1208MHz.\r\n\r\n\u2022\tAbabil III (Iranian manufactured) UAV from Shayrat\r\nAirfield.\r\n\r\n\u2022\tTip-off procedures facilitated co-incident collect from Golf, E\r\nSection and MHS on 9th March.\r\n\r\n\u2022\tSite made a further\r\nrecording on 11th March.\r\n\r\n\u2022\tPresidential level\r\ninterest in further video\r\nsamples.", 
    "pdf": [
      "https://edwardsnowden.com/wp-content/uploads/2016/01/6-Months-Overview-Redacted.pdf"
    ]
  }, 
  {
    "released_date": "20151118", 
    "overall_handling_caveats": [], 
    "id": "20151118|sigdev:isittimeforatargetreboot?", 
    "document_date": "2011-03-23 00:00:00", 
    "codewords": [
      "CADENCE", 
      "OCTAVE", 
      "PINWALE", 
      "SURREY", 
      "XKEYSCORE (XKS)"
    ], 
    "agency": [
      "NSA"
    ], 
    "sub_paragraphs_classifications": [
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": null, 
        "paragraph_text": "sigdev-is-it-time-for-a-target-reboot-p1-normal.gif: dynamic page - highest possible classification is ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret // si / tk // rel to usa aus can gbr nzl welcome! saturday, 10 nov 2012 web search agencv-all emails sid-all emails nsa rolodex . scoawk: the sid mailbag sidtodav blog sidtodav series sigint worldwide vtc sidtodav article letter to the editor sigint-v social mediasigdev-is-it-time-for-a-target-reboot-p2-normal-232x300.gif: sigdev-is-it-time-for-a-target-reboot-p3-normal-232x300.gif: sigdev-is-it-time-for-a-target-reboot-p4-normal-232x300.gif: i wtaom sigdev-is-it-time-for-a-target-reboot-p5-normal-232x300.gif: kt* <*)mil jotw rout nrti it*\"* ml i i,*-,  . nwmln *** *' tros mc r.i - h4nr mmmi avmrin wftklit.'m biiu l%\\ *ia cam cm hfl mimimim vvmum i i: iuno mt *nn tri tt amw ", 
        "paragraph_relto": [
          "United Kingdom", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "Canada"
        ]
      }
    ], 
    "pdf_paths": [
      "sigdev-is-it-time-for-a-target-reboot-p1-normal.gif", 
      "sigdev-is-it-time-for-a-target-reboot-p2-normal-232x300.gif", 
      "sigdev-is-it-time-for-a-target-reboot-p3-normal-232x300.gif", 
      "sigdev-is-it-time-for-a-target-reboot-p4-normal-232x300.gif", 
      "sigdev-is-it-time-for-a-target-reboot-p5-normal-232x300.gif"
    ], 
    "overall_classification": null, 
    "description": "This 23 March 2011 article from the internal NSA newsletter SIDToday describes an analyst\u2019s surprise at discovering that the agency was collecting internal communications from Venezuelan energy company Petr\u00f3leos de Venezuela (PDVSA): see the Intercept article Overwhelmed NSA Surprised To Discover Its Own Surveillance \u201cGoldmine\u201d on Venezuela\u2019s Oil Executives, 18 November 2015.", 
    "plain_text": "sigdev-is-it-time-for-a-target-reboot-p1-normal.gif: \n\ufeffDYNAMIC PAGE - HIGHEST POSSIBLE CLASSIFICATION\r\n\r\nIS\r\n\r\nTOP SECRET // SI / TK // REL TO USA AUS CAN GBR NZL\r\n\r\nWelcome! Saturday, 10 Nov 2012\r\n\r\n\u2022\tWeb search\r\n\r\n\u2022\tAgencv-all Emails\r\n\r\n\u2022\tSID-all Emails\r\n\r\n\u2022\tNSA Rolodex\r\n\r\n. SCOAWK: The SID\r\nMailbag\r\n\r\n\u2022\tSIDtodav Blog\r\n\r\n\u2022\tSIDtodav Series\r\n\r\n\u2022\tSIGINT Worldwide VTC\r\n\r\n\u2022\tSIDtodav Article\r\n\r\n\u2022\tLetter to the Editor\r\n\r\n\u2022\tSIGINT-v Social Mediasigdev-is-it-time-for-a-target-reboot-p2-normal-232x300.gif: \n\ufeffsigdev-is-it-time-for-a-target-reboot-p3-normal-232x300.gif: \n\ufeffsigdev-is-it-time-for-a-target-reboot-p4-normal-232x300.gif: \n\ufeffI WtAOM\r\n\r\nsigdev-is-it-time-for-a-target-reboot-p5-normal-232x300.gif: \n\ufeff\u2022 kt* <*\u2022\u00bb\u2022)\u00abMil\r\n\u2022JO\u00ebTW\r\n\r\nrout nrti\r\n\r\nIt*\"* Ml i\u00bb\r\n\r\n\u00abI,*-, \u2014 \u2014.\r\n\r\n\u00bb\u00abnwMlN ***\u2022 \u2022*'\r\n\r\n\r\n\r\n\r\n\r\ntros \u00abMc r\u00ab.i - H4nr mmmi a\u00abvM\u00bb\u00abrin \u00bb\r\n\r\nWftKlIT.'M \u00ab\u00bbBIIU l%\\ *ia CAM CM Hfl\r\nMiMimiM vvmum i i: iuno mt *n\u00bbn \u00abtri t\u00bbt amw", 
    "sigads": [], 
    "overall_relto": [], 
    "countries_mentioned": [
      "Iran (IRN/IR)", 
      "United States (USA/US)", 
      "Venezuela (VEN/VE)"
    ], 
    "link": "https://edwardsnowden.com/2015/11/18/sigdev-is-it-time-for-a-target-reboot/", 
    "document_topic": [
      "Internet Content", 
      "Computer Network Operations", 
      "SIDtoday"
    ], 
    "pub_date": "Wed, 18 Nov 2015 16:52:30 +0000", 
    "article_links": [
      "https://theintercept.com/2015/11/18/overwhelmed-nsa-surprised-to-discover-its-own-surveillance-goldmine-on-venezuelas-oil-executives/"
    ], 
    "categories": [
      "Revealed documents", 
      "ahmadinejad", 
      "analyst's notebook", 
      "cadence", 
      "caracas", 
      "computer_network_operations", 
      "dni", 
      "energy", 
      "internet_content", 
      "iran", 
      "nsa_orig", 
      "octave", 
      "oil", 
      "pdvsa", 
      "pequiven", 
      "pinwale", 
      "ramirez", 
      "s2c13", 
      "searchlight", 
      "sidtoday", 
      "surrey", 
      "TAO", 
      "target reboot", 
      "topi", 
      "utt", 
      "Venezuela", 
      "vierma", 
      "xkeyscore"
    ], 
    "title": "SIGDEV: Is It Time for a \u2018Target Reboot\u2019?", 
    "doc_text": "sigdev-is-it-time-for-a-target-reboot-p1-normal.gif: \n\ufeffDYNAMIC PAGE - HIGHEST POSSIBLE CLASSIFICATION\r\n\r\nIS\r\n\r\nTOP SECRET // SI / TK // REL TO USA AUS CAN GBR NZL\r\n\r\nWelcome! Saturday, 10 Nov 2012\r\n\r\n\u2022\tWeb search\r\n\r\n\u2022\tAgencv-all Emails\r\n\r\n\u2022\tSID-all Emails\r\n\r\n\u2022\tNSA Rolodex\r\n\r\n. SCOAWK: The SID\r\nMailbag\r\n\r\n\u2022\tSIDtodav Blog\r\n\r\n\u2022\tSIDtodav Series\r\n\r\n\u2022\tSIGINT Worldwide VTC\r\n\r\n\u2022\tSIDtodav Article\r\n\r\n\u2022\tLetter to the Editor\r\n\r\n\u2022\tSIGINT-v Social Mediasigdev-is-it-time-for-a-target-reboot-p2-normal-232x300.gif: \n\ufeffsigdev-is-it-time-for-a-target-reboot-p3-normal-232x300.gif: \n\ufeffsigdev-is-it-time-for-a-target-reboot-p4-normal-232x300.gif: \n\ufeffI WtAOM\r\n\r\nsigdev-is-it-time-for-a-target-reboot-p5-normal-232x300.gif: \n\ufeff\u2022 kt* <*\u2022\u00bb\u2022)\u00abMil\r\n\u2022JO\u00ebTW\r\n\r\nrout nrti\r\n\r\nIt*\"* Ml i\u00bb\r\n\r\n\u00abI,*-, \u2014 \u2014.\r\n\r\n\u00bb\u00abnwMlN ***\u2022 \u2022*'\r\n\r\n\r\n\r\n\r\n\r\ntros \u00abMc r\u00ab.i - H4nr mmmi a\u00abvM\u00bb\u00abrin \u00bb\r\n\r\nWftKlIT.'M \u00ab\u00bbBIIU l%\\ *ia CAM CM Hfl\r\nMiMimiM vvmum i i: iuno mt *n\u00bbn \u00abtri t\u00bbt amw", 
    "pdf": [
      "https://edwardsnowden.com/wp-content/uploads/2015/11/sigdev-is-it-time-for-a-target-reboot-p1-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/11/sigdev-is-it-time-for-a-target-reboot-p2-normal-232x300.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/11/sigdev-is-it-time-for-a-target-reboot-p3-normal-232x300.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/11/sigdev-is-it-time-for-a-target-reboot-p4-normal-232x300.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/11/sigdev-is-it-time-for-a-target-reboot-p5-normal-232x300.gif"
    ]
  }, 
  {
    "released_date": "20150929", 
    "overall_handling_caveats": [], 
    "id": "20150929|sidtrainsforathensolympics", 
    "document_date": "2003-08-15 00:00:00", 
    "codewords": [], 
    "agency": [
      "NSA"
    ], 
    "sub_paragraphs_classifications": [
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": null, 
        "paragraph_text": "id-195-redacted-formatted-p1-normal.gif: dynamic page - highest possible classification is ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret // si / tk // rel to usa aus can gbr nzl ", 
        "paragraph_relto": [
          "United Kingdom", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "Canada"
        ]
      }, 
      {
        "paragraph_handling_caveats": [
          "fouo"
        ], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "(u//fouo) sid trains for athens olympics usaf sigint communications run date: 08/15/2003 ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [
          "fouo"
        ], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "(u//fouo) in just over a year the torch will be lit, and thus will kick off the 2004 summer olympic games in athens, greece, home to the first olympic games. although the first race, dive, and somersault are still a year away, the intelligence community is already in full \"training mode\" for the event. in truth, nsa has been gearing up for the 2004 olympics for quite some time, in anticipation of playing a larger role than ever before at the international games. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "(u) prior games ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s) the first phase of preparation actually began years ago through the involvement of nsa with the olympic games in other cities. nsa has had an active role in the olympics since the 1984 los angeles games, and has seen its involvement increase with the recent games in atlanta, sydney, and salt lake city. during the 2002 winter olympics in salt lake city, the focus was on counterterrorism, and nsa acted largely in support of the fbi in a fusion cell known as the olympics intelligence center (oic). the mission of the oic was to fuse foreign intelligence and law enforcement information to provide threat warning and situation awareness before and during the games. nsa's support to the 2004 olympics in athens will be much more complicated. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "(u) the athens outlook ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [
          "si"
        ], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s//si) several factors will make the athens olympics vastly different, not the least of which is the fact these olympics will not be held at a domestic location. also different is that the security organization that nsa will support is the eyp, or greek national intelligence service. nsa will gather information and tip off the eyp of possible terrorist or criminal actions. without a doubt, the communication between nsa and eyp will take some coordination, and for that reason preparations are already underway. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [
          "si"
        ], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s//si) nsa, and sid in particular, will be sending the largest contingent of personnel in support of the games in our history. a team of 10 nsa analysts will arrive in greece anywhere from 30-45 days before the olympics and stay until the flame is extinguished to provide the best support possible to the safety and security of the games. it is also important to note that preparations are being made for our in-house support to the games. nsoc again will serve as the single point of contact for the olympics for our customers. work is being done across sid to work with customers to receive and understand their specific information needs. data acquisition, working with sigint development, the target offices of primary interest, and the extended sigint enterprise, is preparing a comprehensive olympics collection strategy. moreover, sid is partnering with the foreign affairs directorate to develop a strategy to share threat information with our sigint partners.id-195-redacted-formatted-p2-normal.gif: ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [
          "fouo"
        ], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "(u//fouo) the olympic games are perhaps the greatest platform for global unity, even if it is for just a short time; but they are also an enormous target for would-be evildoers. thousands will participate and billions will be watching as the games unfold. the scope of the olympics is tremendous, and so will be the support of sid and nsa. the world will be watching, and so will nsa! ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [
          "fouo"
        ], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "\"(u//fouo) sidtoday articles may not be republished or reposted outside nsanet without the consent of s0121(dl sid comms).\" information owner: i page publisher: somj last modified: 11/09/2012 / last reviewed: 11/09/2012 dynamic page - highest possible classification is ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//si /tk//relto usa aus can gbr nzl derived from: nsa/cssm 1-52, dated 08 jan 2007 declassify on: 20320108 ", 
        "paragraph_relto": []
      }
    ], 
    "pdf_paths": [
      "id-195-redacted-formatted-p1-normal.gif", 
      "id-195-redacted-formatted-p2-normal.gif"
    ], 
    "overall_classification": null, 
    "description": "This 15 August 2003 post from the NSA\u2019s internal SIDToday newsletter discusses the agency\u2019s plans for the Athens Olympics the following year, which were of a much larger scale than for previous events: see the Intercept article A Death in Athens: Did a Rogue NSA Operation Cause the Death of a Greek Telecom Employee?, 29 [\u2026]", 
    "plain_text": "id-195-redacted-formatted-p1-normal.gif: \n\ufeffDYNAMIC PAGE - HIGHEST POSSIBLE CLASSIFICATION IS\r\n\r\nTOP SECRET // SI / TK // REL TO USA AUS CAN GBR NZL\r\n\r\n(U//FOUO) SID Trains for Athens Olympics\r\n\r\nUSAF\r\n\r\nSIGINT Communications\r\nRun Date: 08/15/2003\r\n\r\n(U//FOUO) In just over a year the torch will be lit, and thus will kick off the 2004\r\nSummer Olympic Games in Athens, Greece, home to the first Olympic Games.\r\nAlthough the first race, dive, and somersault are still a year away, the Intelligence\r\nCommunity is already in full \"training mode\" for the event. In truth, NSA has been\r\ngearing up for the 2004 Olympics for quite some time, in anticipation of playing a\r\nlarger role than ever before at the international games.\r\n\r\n(U) Prior Games\r\n\r\n(S) The first phase of preparation actually began years ago through the\r\ninvolvement of NSA with the Olympic Games in other cities. NSA has had an active\r\nrole in the Olympics since the 1984 Los Angeles games, and has seen its\r\ninvolvement increase with the recent games in Atlanta, Sydney, and Salt Lake City.\r\nDuring the 2002 Winter Olympics in Salt Lake City, the focus was on\r\ncounterterrorism, and NSA acted largely in support of the FBI in a fusion cell\r\nknown as the Olympics Intelligence Center (OIC). The mission of the OIC was to\r\nfuse foreign intelligence and law enforcement information to provide threat\r\nwarning and situation awareness before and during the games. NSA's support to\r\nthe 2004 Olympics in Athens will be much more complicated.\r\n\r\n(U) The Athens Outlook\r\n\r\n(S//SI) Several factors will make the Athens Olympics vastly different, not the least\r\nof which is the fact these Olympics will not be held at a domestic location. Also\r\ndifferent is that the security organization that NSA will support is the EYP, or Greek\r\nNational Intelligence Service. NSA will gather information and tip off the EYP of\r\npossible terrorist or criminal actions. Without a doubt, the communication between\r\nNSA and EYP will take some coordination, and for that reason preparations are\r\nalready underway.\r\n\r\n(S//SI) NSA, and SID in particular, will be sending the largest contingent of\r\npersonnel in support of the games in our history. A team of 10 NSA analysts will\r\narrive in Greece anywhere from 30-45 days before the Olympics and stay until the\r\nflame is extinguished to provide the best support possible to the safety and security\r\nof the games. It is also important to note that preparations are being made for our\r\nin-house support to the games. NSOC again will serve as the single point of contact\r\nfor the Olympics for our customers. Work is being done across SID to work with\r\ncustomers to receive and understand their specific Information Needs. Data\r\nAcquisition, working with SIGINT Development, the Target Offices of Primary\r\nInterest, and the extended SIGINT Enterprise, is preparing a comprehensive\r\nOlympics Collection Strategy. Moreover, SID is partnering with the Foreign Affairs\r\nDirectorate to develop a strategy to share threat information with our SIGINT\r\nPartners.id-195-redacted-formatted-p2-normal.gif: \n\ufeff(U//FOUO) The Olympic Games are perhaps the greatest platform for global unity,\r\neven if it is for just a short time; but they are also an enormous target for would-be\r\nevildoers. Thousands will participate and billions will be watching as the games\r\nunfold. The scope of the Olympics is tremendous, and so will be the support of SID\r\nand NSA. The world will be watching, and so will NSA!\r\n\r\n\"(U//FOUO)\r\nSIDtoday\r\narticles may not\r\nbe republished\r\nor reposted\r\noutside NSANet\r\nwithout the\r\nconsent of\r\n\r\nS0121(DL\r\n\r\nsid comms).\"\r\n\r\nInformation\r\nOwner: I\r\n\r\nPage Publisher:\r\n\r\nsomj\r\n\r\nLast Modified:\r\n11/09/2012 / Last\r\nReviewed:\r\n11/09/2012\r\n\r\nDYNAMIC PAGE -\r\nHIGHEST\r\nPOSSIBLE\r\nCLASSIFICATION\r\nIS\r\n\r\nTOP SECRET//SI\r\n/TK//RELTO\r\nUSA AUS CAN\r\nGBR NZL\r\nDERIVED FROM:\r\nNSA/CSSM 1-52,\r\nDATED 08 JAN\r\n2007\r\n\r\nDECLASSIFY ON:\r\n20320108", 
    "sigads": [], 
    "overall_relto": [], 
    "countries_mentioned": [
      "Greece (GRC/GR)", 
      "United States (USA/US)"
    ], 
    "link": "https://edwardsnowden.com/2015/10/03/sid-trains-for-athens-olympics/", 
    "document_topic": [
      "Internal Procedures", 
      "SIDtoday"
    ], 
    "pub_date": "Sat, 03 Oct 2015 17:22:24 +0000", 
    "article_links": [
      "https://theintercept.com/2015/09/28/death-athens-rogue-nsa-operation/"
    ], 
    "categories": [
      "Revealed documents", 
      "athens", 
      "greece", 
      "internal_procedures", 
      "nsa_orig", 
      "olympics", 
      "sidtoday"
    ], 
    "title": "SID Trains for Athens Olympics", 
    "doc_text": "id-195-redacted-formatted-p1-normal.gif: \n\ufeffDYNAMIC PAGE - HIGHEST POSSIBLE CLASSIFICATION IS\r\n\r\nTOP SECRET // SI / TK // REL TO USA AUS CAN GBR NZL\r\n\r\n(U//FOUO) SID Trains for Athens Olympics\r\n\r\nUSAF\r\n\r\nSIGINT Communications\r\nRun Date: 08/15/2003\r\n\r\n(U//FOUO) In just over a year the torch will be lit, and thus will kick off the 2004\r\nSummer Olympic Games in Athens, Greece, home to the first Olympic Games.\r\nAlthough the first race, dive, and somersault are still a year away, the Intelligence\r\nCommunity is already in full \"training mode\" for the event. In truth, NSA has been\r\ngearing up for the 2004 Olympics for quite some time, in anticipation of playing a\r\nlarger role than ever before at the international games.\r\n\r\n(U) Prior Games\r\n\r\n(S) The first phase of preparation actually began years ago through the\r\ninvolvement of NSA with the Olympic Games in other cities. NSA has had an active\r\nrole in the Olympics since the 1984 Los Angeles games, and has seen its\r\ninvolvement increase with the recent games in Atlanta, Sydney, and Salt Lake City.\r\nDuring the 2002 Winter Olympics in Salt Lake City, the focus was on\r\ncounterterrorism, and NSA acted largely in support of the FBI in a fusion cell\r\nknown as the Olympics Intelligence Center (OIC). The mission of the OIC was to\r\nfuse foreign intelligence and law enforcement information to provide threat\r\nwarning and situation awareness before and during the games. NSA's support to\r\nthe 2004 Olympics in Athens will be much more complicated.\r\n\r\n(U) The Athens Outlook\r\n\r\n(S//SI) Several factors will make the Athens Olympics vastly different, not the least\r\nof which is the fact these Olympics will not be held at a domestic location. Also\r\ndifferent is that the security organization that NSA will support is the EYP, or Greek\r\nNational Intelligence Service. NSA will gather information and tip off the EYP of\r\npossible terrorist or criminal actions. Without a doubt, the communication between\r\nNSA and EYP will take some coordination, and for that reason preparations are\r\nalready underway.\r\n\r\n(S//SI) NSA, and SID in particular, will be sending the largest contingent of\r\npersonnel in support of the games in our history. A team of 10 NSA analysts will\r\narrive in Greece anywhere from 30-45 days before the Olympics and stay until the\r\nflame is extinguished to provide the best support possible to the safety and security\r\nof the games. It is also important to note that preparations are being made for our\r\nin-house support to the games. NSOC again will serve as the single point of contact\r\nfor the Olympics for our customers. Work is being done across SID to work with\r\ncustomers to receive and understand their specific Information Needs. Data\r\nAcquisition, working with SIGINT Development, the Target Offices of Primary\r\nInterest, and the extended SIGINT Enterprise, is preparing a comprehensive\r\nOlympics Collection Strategy. Moreover, SID is partnering with the Foreign Affairs\r\nDirectorate to develop a strategy to share threat information with our SIGINT\r\nPartners.id-195-redacted-formatted-p2-normal.gif: \n\ufeff(U//FOUO) The Olympic Games are perhaps the greatest platform for global unity,\r\neven if it is for just a short time; but they are also an enormous target for would-be\r\nevildoers. Thousands will participate and billions will be watching as the games\r\nunfold. The scope of the Olympics is tremendous, and so will be the support of SID\r\nand NSA. The world will be watching, and so will NSA!\r\n\r\n\"(U//FOUO)\r\nSIDtoday\r\narticles may not\r\nbe republished\r\nor reposted\r\noutside NSANet\r\nwithout the\r\nconsent of\r\n\r\nS0121(DL\r\n\r\nsid comms).\"\r\n\r\nInformation\r\nOwner: I\r\n\r\nPage Publisher:\r\n\r\nsomj\r\n\r\nLast Modified:\r\n11/09/2012 / Last\r\nReviewed:\r\n11/09/2012\r\n\r\nDYNAMIC PAGE -\r\nHIGHEST\r\nPOSSIBLE\r\nCLASSIFICATION\r\nIS\r\n\r\nTOP SECRET//SI\r\n/TK//RELTO\r\nUSA AUS CAN\r\nGBR NZL\r\nDERIVED FROM:\r\nNSA/CSSM 1-52,\r\nDATED 08 JAN\r\n2007\r\n\r\nDECLASSIFY ON:\r\n20320108", 
    "pdf": [
      "https://edwardsnowden.com/wp-content/uploads/2015/10/id-195-redacted-formatted-p1-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/id-195-redacted-formatted-p2-normal.gif"
    ]
  }, 
  {
    "released_date": "20150929", 
    "overall_handling_caveats": [], 
    "id": "20150929|nsateamselectedforolympicssupport", 
    "document_date": "2003-12-15 00:00:00", 
    "codewords": [], 
    "agency": [
      "NSA"
    ], 
    "sub_paragraphs_classifications": [
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": null, 
        "paragraph_text": "id-488-redacted-formatted-p1-normal.gif: dynamic page - highest possible classification is ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret // si / tk // rel to usa aus can gbr nzl ", 
        "paragraph_relto": [
          "United Kingdom", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "Canada"
        ]
      }, 
      {
        "paragraph_handling_caveats": [
          "fouo"
        ], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "(u//fouo) nsa team selected for olympics support from: nsa olympics support team unknown run date: 12/15/2003 ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [
          "fouo"
        ], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "(u//fouo) the response to the sid vacancy announcement for analytical support for u.s. olympics fusion center was overwhelming. there were over 300 applicants for the eight available positions and the qualifications of each one of them was impressive. the selection team wants to thank all those who expressed an interest in serving at the olympics fusion center next summer. with so many talented individuals to choose from, it was a herculean task to review resumes and make a final selection. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [
          "fouo"
        ], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "(u//fouo) the final team members come from varied backgrounds with strong analytical and reporting skills, tdy or pcs exposure working with other intelligence community and military representatives, and experience in the counterterrorism production effort. the selectees include: (s17), (ia intern), (ia intern), (ia intern), t4soc), (s2i), i), and (nceur). ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [
          "si"
        ], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s//si) preparations and training for the olympics continue across the extended nsa enterprise as we bring together u.s. resources and those of our foreign sigint partners. scenarios are being drafted to support eucom and socom exercises in march, as well as exercises with the sigint seniors nations. these foreign partners (i.e. belgium, canada, denmark, france, germany, italy, netherlands, norway, spain, sweden, the uk and the u.s.) will use the sigdasys communications network to send scripted information to athens in a communications exercise during the above exercises. nsa will round out the exercise phase with another communications exercise utilizing the resources of all 36 foreign partners. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s) the entire u.s. intelligence community (ic) has come together in one team environment to provide information to both u.s. government and the government of greece (gog) customers. the co-location of ic analysts both at the u.s. embassy athens as well as at the greek national intelligence service greatly enhances information sharing across the ic and provides timely and useful information to the front end. nsa will continue to be a major contributor to that joint ic effort as we head for the finish line.id-488-redacted-formatted-p2-normal.gif: ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [
          "fouo"
        ], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "\" (u//fouo) sidtoday articles may not be republished or reposted outside nsanet without the consent of s0121 (dl sid comms).\" information owner: i (email) page publisher: s0121, last modified: 11/09/2012 / last reviewed: 11/09/2012 dynamic page ~ highest possible classification is ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//si /tk//relto usa aus can gbr nzl derived from: nsa/cssm 1-52, dated 08 jan 2007 declassify on: 20320108 ", 
        "paragraph_relto": []
      }
    ], 
    "pdf_paths": [
      "id-488-redacted-formatted-p1-normal.gif", 
      "id-488-redacted-formatted-p2-normal.gif"
    ], 
    "overall_classification": null, 
    "description": "This 15 December 2003 post from the internal NSA newsletter SIDToday discusses plans for the agency\u2019s operations at the Athens Olympics the following year: see the Intercept article A Death in Athens: Did a Rogue NSA Operation Cause the Death of a Greek Telecom Employee?, 29 September 2015.", 
    "plain_text": "id-488-redacted-formatted-p1-normal.gif: \n\ufeffDYNAMIC PAGE - HIGHEST POSSIBLE CLASSIFICATION IS\r\n\r\nTOP SECRET // SI / TK // REL TO USA AUS CAN GBR NZL\r\n\r\n(U//FOUO) NSA Team Selected for Olympics Support\r\n\r\nFROM: NSA Olympics Support Team\r\nUnknown\r\n\r\nRun Date: 12/15/2003\r\n\r\n(U//FOUO) The response to the SID vacancy announcement for analytical support\r\nfor U.S. Olympics Fusion Center was overwhelming. There were over 300\r\napplicants for the eight available positions and the qualifications of each one of\r\nthem was impressive. The selection team wants to thank all those who expressed\r\nan interest in serving at the Olympics Fusion Center next summer. With so many\r\ntalented individuals to choose from, it was a Herculean task to review resumes and\r\nmake a final selection.\r\n\r\n(U//FOUO) The final team members come from varied backgrounds with strong\r\nanalytical and reporting skills, TDY or PCS exposure working with other\r\nIntelligence Community and military representatives, and experience in the\r\ncounterterrorism production effort. The selectees include:\r\n\r\n(S17),\r\n\r\n(IA Intern),\r\n(IA Intern),\r\n(IA Intern),\r\nT4SOC),\r\n(S2I),\r\n\r\nI), and\r\n(NCEUR).\r\n\r\n(S//SI) Preparations and training for the Olympics continue across the extended\r\nNSA enterprise as we bring together U.S. resources and those of our foreign\r\nSIGINT partners. Scenarios are being drafted to support EUCOM and SOCOM\r\nexercises in March, as well as exercises with the SIGINT Seniors nations. These\r\nforeign partners (i.e. Belgium, Canada, Denmark, France, Germany, Italy,\r\nNetherlands, Norway, Spain, Sweden, the UK and the U.S.) will use the SIGDASYS\r\ncommunications network to send scripted information to Athens in a\r\ncommunications exercise during the above exercises. NSA will round out the\r\nexercise phase with another communications exercise utilizing the resources of all\r\n36 foreign partners.\r\n\r\n(S) The entire U.S. Intelligence Community (IC) has come together in one team\r\nenvironment to provide information to both U.S. Government and the Government\r\nof Greece (GOG) customers. The co-location of IC analysts both at the U.S. Embassy\r\nAthens as well as at the Greek National Intelligence Service greatly enhances\r\ninformation sharing across the IC and provides timely and useful information to the\r\nfront end. NSA will continue to be a major contributor to that joint IC effort as we\r\nhead for the finish line.id-488-redacted-formatted-p2-normal.gif: \n\ufeff\" (U//FOUO)\r\nSIDtoday\r\narticles may not\r\nbe republished\r\nor reposted\r\noutside NSANet\r\nwithout the\r\nconsent of\r\nS0121 (DL\r\nsid comms).\"\r\n\r\nInformation\r\nOwner: I\r\n\r\n(email)\r\nPage Publisher:\r\n\r\nS0121,\r\n\r\nLast Modified:\r\n11/09/2012 / Last\r\nReviewed:\r\n\r\n11/09/2012\r\n\r\nDYNAMIC PAGE ~\r\nHIGHEST\r\nPOSSIBLE\r\nCLASSIFICATION\r\nIS\r\n\r\nTOP SECRET//SI\r\n/TK//RELTO\r\nUSA AUS CAN\r\nGBR NZL\r\nDERIVED FROM:\r\nNSA/CSSM 1-52,\r\nDATED 08 JAN\r\n2007\r\n\r\nDECLASSIFY ON:\r\n20320108", 
    "sigads": [], 
    "overall_relto": [], 
    "countries_mentioned": [
      "Belgium (BEL/BE)", 
      "Canada (CAN/CA)", 
      "Denmark (DNK/DK)", 
      "France (FRA/FR)", 
      "Germany (DEU/DE)", 
      "Greece (GRC/GR)", 
      "Italy (ITA/IT)", 
      "Netherlands (NLD/NL)", 
      "Norway (NOR/NO)", 
      "Spain (ESP/ES)", 
      "Sweden (SWE/SE)", 
      "United Kingdom (GBR/GB)", 
      "United States (USA/US)"
    ], 
    "link": "https://edwardsnowden.com/2015/10/03/nsa-team-selected-for-olympics-support/", 
    "document_topic": [
      "Internal Procedures"
    ], 
    "pub_date": "Sat, 03 Oct 2015 17:18:35 +0000", 
    "article_links": [
      "https://theintercept.com/2015/09/28/death-athens-rogue-nsa-operation/"
    ], 
    "categories": [
      "Revealed documents", 
      "athens", 
      "greece", 
      "internal_procedures", 
      "nceur", 
      "nsa_orig", 
      "nsoc", 
      "olympics", 
      "s17", 
      "s21", 
      "s2e", 
      "sigdagsys"
    ], 
    "title": "NSA Team Selected for Olympics Support", 
    "doc_text": "id-488-redacted-formatted-p1-normal.gif: \n\ufeffDYNAMIC PAGE - HIGHEST POSSIBLE CLASSIFICATION IS\r\n\r\nTOP SECRET // SI / TK // REL TO USA AUS CAN GBR NZL\r\n\r\n(U//FOUO) NSA Team Selected for Olympics Support\r\n\r\nFROM: NSA Olympics Support Team\r\nUnknown\r\n\r\nRun Date: 12/15/2003\r\n\r\n(U//FOUO) The response to the SID vacancy announcement for analytical support\r\nfor U.S. Olympics Fusion Center was overwhelming. There were over 300\r\napplicants for the eight available positions and the qualifications of each one of\r\nthem was impressive. The selection team wants to thank all those who expressed\r\nan interest in serving at the Olympics Fusion Center next summer. With so many\r\ntalented individuals to choose from, it was a Herculean task to review resumes and\r\nmake a final selection.\r\n\r\n(U//FOUO) The final team members come from varied backgrounds with strong\r\nanalytical and reporting skills, TDY or PCS exposure working with other\r\nIntelligence Community and military representatives, and experience in the\r\ncounterterrorism production effort. The selectees include:\r\n\r\n(S17),\r\n\r\n(IA Intern),\r\n(IA Intern),\r\n(IA Intern),\r\nT4SOC),\r\n(S2I),\r\n\r\nI), and\r\n(NCEUR).\r\n\r\n(S//SI) Preparations and training for the Olympics continue across the extended\r\nNSA enterprise as we bring together U.S. resources and those of our foreign\r\nSIGINT partners. Scenarios are being drafted to support EUCOM and SOCOM\r\nexercises in March, as well as exercises with the SIGINT Seniors nations. These\r\nforeign partners (i.e. Belgium, Canada, Denmark, France, Germany, Italy,\r\nNetherlands, Norway, Spain, Sweden, the UK and the U.S.) will use the SIGDASYS\r\ncommunications network to send scripted information to Athens in a\r\ncommunications exercise during the above exercises. NSA will round out the\r\nexercise phase with another communications exercise utilizing the resources of all\r\n36 foreign partners.\r\n\r\n(S) The entire U.S. Intelligence Community (IC) has come together in one team\r\nenvironment to provide information to both U.S. Government and the Government\r\nof Greece (GOG) customers. The co-location of IC analysts both at the U.S. Embassy\r\nAthens as well as at the Greek National Intelligence Service greatly enhances\r\ninformation sharing across the IC and provides timely and useful information to the\r\nfront end. NSA will continue to be a major contributor to that joint IC effort as we\r\nhead for the finish line.id-488-redacted-formatted-p2-normal.gif: \n\ufeff\" (U//FOUO)\r\nSIDtoday\r\narticles may not\r\nbe republished\r\nor reposted\r\noutside NSANet\r\nwithout the\r\nconsent of\r\nS0121 (DL\r\nsid comms).\"\r\n\r\nInformation\r\nOwner: I\r\n\r\n(email)\r\nPage Publisher:\r\n\r\nS0121,\r\n\r\nLast Modified:\r\n11/09/2012 / Last\r\nReviewed:\r\n\r\n11/09/2012\r\n\r\nDYNAMIC PAGE ~\r\nHIGHEST\r\nPOSSIBLE\r\nCLASSIFICATION\r\nIS\r\n\r\nTOP SECRET//SI\r\n/TK//RELTO\r\nUSA AUS CAN\r\nGBR NZL\r\nDERIVED FROM:\r\nNSA/CSSM 1-52,\r\nDATED 08 JAN\r\n2007\r\n\r\nDECLASSIFY ON:\r\n20320108", 
    "pdf": [
      "https://edwardsnowden.com/wp-content/uploads/2015/10/id-488-redacted-formatted-p1-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/id-488-redacted-formatted-p2-normal.gif"
    ]
  }, 
  {
    "released_date": "20150929", 
    "overall_handling_caveats": [], 
    "id": "20150929|goldmedalsupporttothesummergames", 
    "document_date": "2004-09-14 00:00:00", 
    "codewords": [
      "BLUE"
    ], 
    "agency": [
      "NSA"
    ], 
    "sub_paragraphs_classifications": [
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": null, 
        "paragraph_text": "id-827-redacted-formatted-p1-normal.gif: dynamic page - highest possible classification is ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret // si / tk // rel to usa aus can gbr nzl ", 
        "paragraph_relto": [
          "United Kingdom", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "Canada"
        ]
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "(u) gold medal support to the summer games from: link access programs (s33) run date: 09/14/2004 ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [
          "fouo"
        ], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "(u//fouo) the 2004 summer olympic games were held 13-29 august 2004 in athens, greece. athletes from over 200 countries participated in the games themselves; over 150 heads of state or heads of government attended at least one olympic event; and over 5 billion people watched the olympics on television or followed it on the internet. the olympic venues were located throughout greece, including athens, crete, volos, patra, olympia, and thessaloniki. such an important international event with a worldwide audience wrapped to their television and pcs for two weeks presented a very tempting target for terrorists. athens as seen from the acropolis ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [
          "si"
        ], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s//si) well before the start of the summer games, nsa began supporting intelligence community efforts to: provide force protection/indication and warning of imminent, indigenous and transnational threats to u.s. interests in the olympic area of responsibility (aor); develop an awareness of the greek government's knowledge of threats to the games and or u.s. interests; understand how countries bordering greece were prepared to respond to a potential attack; and, support the u.s. military in any operation to provide assistance to the greek government and/or evacuate u.s. entities from the area. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [
          "si"
        ], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s//si) to accomplish this herculean task, nsa personnel, at the heart of the action in athens, were working very closely with the state department, which was responsible for providing security for u.s. olympic officials, judges and athletes -- at the sporting events, the olympic village and aboard cruise ships in piraeus harbor serving as floating hotels. from the olympic aor, around the world and back to the fort, nsa personnel were manning 24-hour watches and operations while working with home land security, the fbi, nga, cia and dia, as well as eucom and socom in support of nato. nsa support to the 2004 summer games encompassed a wide range of offices to include: the information assurance directorate (iad), installations and logistics (i&l), information technology infrastructure services (itis), ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Confidential", 
        "paragraph_text": "counterterrorism (ct), international security issues (isi), ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "customer relationships (si), the national security operations center (nsoc), tailored access, link access, ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Confidential", 
        "paragraph_text": "cryptanalysis and exploitation (ces),id-827-redacted-formatted-p2-normal.gif: geocell, our second party partners, and many more. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [
          "si"
        ], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s//si) a shining example of focused mission support to the games was that being provided by the link access support to the olympics (laso) team. comprised of subject matter experts from the office of overhead (oh), radio frequency ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "operations (rfo), special collection service (scs) and special source operations ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(sso), the laso team was the focal point for everything olympics -- from planning to resource allocation through collection management and crisis response -- for all olympics security operations. la team members supported the sid olympics team for more than 10 months, and were in place well before the opening ceremonies. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [
          "si"
        ], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s//si) nsa/css olympic operations included several major initiatives within la spanning its accesses: blue force tracking, scs and sso. scs support included the activities of us-966g and two survey sites (us-969x183 and us-969x202). sso support included deployment of access capabilities (april flowers) to directly support the olympics. la olympic operations and the laso team concept were just a small part of the larger corporate effort to the xxviii summer olympiad made possible with the hard work and dedication of many nsa organizations working together to achieve a common goal -- a safe olympics! olympic stadium parthenon ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [
          "fouo"
        ], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "\"(u//fouo) sidtoday articles may not be republished or reposted outside nsanet without the consent of s0121 (dl sidcomms).\" information last modified: 11/09/2012 / last reviewed: 11/09/2012id-827-redacted-formatted-p3-normal.gif: dynamic page ~ highest possible classification is ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//si /tk//relto usa aus can gbr nzl derived from: nsa/cssm 1-52, dated 08 jan 2007 declassify on: 20320108 ", 
        "paragraph_relto": []
      }
    ], 
    "pdf_paths": [
      "id-827-redacted-formatted-p1-normal.gif", 
      "id-827-redacted-formatted-p2-normal.gif", 
      "id-827-redacted-formatted-p3-normal.gif"
    ], 
    "overall_classification": null, 
    "description": "This 14 September 2004 post from the internal NSA newsletter SIDToday reviews the agency\u2019s operations at the Athens Olympics, which had just concluded: see the Intercept article A Death in Athens: Did a Rogue NSA Operation Cause the Death of a Greek Telecom Employee?, 29 September 2015.", 
    "plain_text": "id-827-redacted-formatted-p1-normal.gif: \n\ufeffDYNAMIC PAGE - HIGHEST POSSIBLE CLASSIFICATION IS\r\n\r\nTOP SECRET // SI / TK // REL TO USA AUS CAN GBR NZL\r\n\r\n(U) Gold Medal Support to the Summer Games\r\n\r\nFROM:\r\n\r\nLink Access Programs (S33)\r\n\r\nRun Date: 09/14/2004\r\n\r\n(U//FOUO) The 2004 Summer Olympic Games were held 13-29 August 2004 in\r\nAthens, Greece. Athletes from over 200 countries participated in the Games\r\nthemselves; over 150 heads of State or heads of government attended at least one\r\nOlympic event; and over 5 billion people watched the Olympics on television or\r\nfollowed it on the Internet. The Olympic venues were located throughout Greece,\r\nincluding Athens, Crete, Volos, Patra, Olympia, and Thessaloniki. Such an\r\nimportant international event with a worldwide audience wrapped to their\r\ntelevision and PCs for two weeks presented a very tempting target for terrorists.\r\n\r\nAthens as seen from the Acropolis\r\n\r\n(S//SI) Well before the start of the Summer Games, NSA began supporting\r\nIntelligence Community efforts to:\r\n\r\n\u2022\tprovide Force Protection/Indication and Warning of imminent, indigenous and\r\ntransnational threats to U.S. interests in the Olympic area of responsibility\r\n(AOR);\r\n\r\n\u2022\tdevelop an awareness of the Greek Government's knowledge of threats to the\r\nGames and or U.S. interests;\r\n\r\n\u2022\tunderstand how countries bordering Greece were prepared to respond to a\r\npotential attack; and,\r\n\r\n\u2022\tsupport the U.S. Military in any operation to provide assistance to the Greek\r\nGovernment and/or evacuate U.S. entities from the area.\r\n\r\n(S//SI) To accomplish this herculean task, NSA personnel, at the heart of the action\r\nin Athens, were working very closely with the State Department, which was\r\nresponsible for providing security for U.S. Olympic officials, judges and athletes --\r\nat the sporting events, the Olympic Village and aboard cruise ships in Piraeus\r\nHarbor serving as floating hotels. From the Olympic AOR, around the world and\r\nback to the Fort, NSA personnel were manning 24-hour watches and operations\r\nwhile working with Home Land Security, the FBI, NGA, CIA and DIA, as well as\r\nEUCOM and SOCOM in support of NATO. NSA support to the 2004 Summer Games\r\nencompassed a wide range of offices to include:\r\n\r\n\u2022\tthe Information Assurance Directorate (IAD),\r\n\r\n\u2022\tInstallations and Logistics (I&L),\r\n\r\n\u2022\tInformation Technology Infrastructure Services (ITIS),\r\n\r\n\u2022\tCounterterrorism (CT),\r\n\r\n\u2022\tInternational Security Issues (ISI),\r\n\r\n\u2022\tCustomer Relationships (SI),\r\n\r\n\u2022\tthe National Security Operations Center (NSOC),\r\n\r\n\u2022\tTailored Access,\r\n\r\n\u2022\tLink Access,\r\n\r\n\u2022\tCryptanalysis and Exploitation (CES),id-827-redacted-formatted-p2-normal.gif: \n\ufeff\u2022\tGeocell,\r\n\r\n\u2022\tour Second Party partners, and many more.\r\n\r\n(S//SI) A shining example of focused mission support to the Games was that being\r\nprovided by the Link Access Support to the Olympics (LASO) team. Comprised of\r\nsubject matter experts from the Office of Overhead (OH), Radio Frequency\r\nOperations (RFO), Special Collection Service (SCS) and Special Source Operations\r\n(SSO), the LASO team was the focal point for everything Olympics -- from planning\r\nto resource allocation through collection management and crisis response -- for all\r\nOlympics security operations. LA team members supported the SID Olympics team\r\nfor more than 10 months, and were in place well before the opening ceremonies.\r\n\r\n(S//SI) NSA/CSS Olympic operations included several major initiatives within LA\r\nspanning its accesses: BLUE FORCE TRACKING, SCS and SSO. SCS support\r\nincluded the activities of US-966G and two survey sites (US-969X183 and\r\nUS-969X202). SSO support included deployment of access capabilities (APRIL\r\nFLOWERS) to directly support the Olympics. LA Olympic Operations and the LASO\r\nTeam concept were just a small part of the larger corporate effort to the XXVIII\r\nSummer Olympiad made possible with the hard work and dedication of many NSA\r\norganizations working together to achieve a common goal -- a safe Olympics!\r\n\r\nOlympic stadium\r\n\r\nParthenon\r\n\r\n\"(U//FOUO)\r\nSIDtoday\r\narticles may not\r\nbe republished\r\nor reposted\r\noutside NSANet\r\nwithout the\r\nconsent of\r\nS0121 (DL\r\nsid\u201ecomms).\"\r\nInformation\r\n\r\nLast Modified:\r\n11/09/2012 / Last\r\nReviewed:\r\n11/09/2012id-827-redacted-formatted-p3-normal.gif: \n\ufeffDYNAMIC PAGE ~\r\nHIGHEST\r\nPOSSIBLE\r\nCLASSIFICATION\r\nIS\r\n\r\nTOP SECRET//SI\r\n/TK//RELTO\r\nUSA AUS CAN\r\nGBR NZL\r\nDERIVED FROM:\r\nNSA/CSSM 1-52,\r\nDATED 08 JAN\r\n2007\r\n\r\nDECLASSIFY ON:\r\n20320108", 
    "sigads": [
      "US-966G", 
      "US-969X183", 
      "US-969X202"
    ], 
    "overall_relto": [], 
    "countries_mentioned": [
      "Greece (GRC/GR)", 
      "United States (USA/US)"
    ], 
    "link": "https://edwardsnowden.com/2015/10/03/gold-medal-support-to-the-summer-games/", 
    "document_topic": [], 
    "pub_date": "Sat, 03 Oct 2015 17:13:58 +0000", 
    "article_links": [
      "https://theintercept.com/2015/09/28/death-athens-rogue-nsa-operation/"
    ], 
    "categories": [
      "Revealed documents", 
      "athens", 
      "blue force tracking", 
      "nsa_orig", 
      "olympics", 
      "s33", 
      "scs", 
      "sso", 
      "us-966g", 
      "us-969x183", 
      "us-969x202"
    ], 
    "title": "Gold Medal Support to the Summer Games", 
    "doc_text": "id-827-redacted-formatted-p1-normal.gif: \n\ufeffDYNAMIC PAGE - HIGHEST POSSIBLE CLASSIFICATION IS\r\n\r\nTOP SECRET // SI / TK // REL TO USA AUS CAN GBR NZL\r\n\r\n(U) Gold Medal Support to the Summer Games\r\n\r\nFROM:\r\n\r\nLink Access Programs (S33)\r\n\r\nRun Date: 09/14/2004\r\n\r\n(U//FOUO) The 2004 Summer Olympic Games were held 13-29 August 2004 in\r\nAthens, Greece. Athletes from over 200 countries participated in the Games\r\nthemselves; over 150 heads of State or heads of government attended at least one\r\nOlympic event; and over 5 billion people watched the Olympics on television or\r\nfollowed it on the Internet. The Olympic venues were located throughout Greece,\r\nincluding Athens, Crete, Volos, Patra, Olympia, and Thessaloniki. Such an\r\nimportant international event with a worldwide audience wrapped to their\r\ntelevision and PCs for two weeks presented a very tempting target for terrorists.\r\n\r\nAthens as seen from the Acropolis\r\n\r\n(S//SI) Well before the start of the Summer Games, NSA began supporting\r\nIntelligence Community efforts to:\r\n\r\n\u2022\tprovide Force Protection/Indication and Warning of imminent, indigenous and\r\ntransnational threats to U.S. interests in the Olympic area of responsibility\r\n(AOR);\r\n\r\n\u2022\tdevelop an awareness of the Greek Government's knowledge of threats to the\r\nGames and or U.S. interests;\r\n\r\n\u2022\tunderstand how countries bordering Greece were prepared to respond to a\r\npotential attack; and,\r\n\r\n\u2022\tsupport the U.S. Military in any operation to provide assistance to the Greek\r\nGovernment and/or evacuate U.S. entities from the area.\r\n\r\n(S//SI) To accomplish this herculean task, NSA personnel, at the heart of the action\r\nin Athens, were working very closely with the State Department, which was\r\nresponsible for providing security for U.S. Olympic officials, judges and athletes --\r\nat the sporting events, the Olympic Village and aboard cruise ships in Piraeus\r\nHarbor serving as floating hotels. From the Olympic AOR, around the world and\r\nback to the Fort, NSA personnel were manning 24-hour watches and operations\r\nwhile working with Home Land Security, the FBI, NGA, CIA and DIA, as well as\r\nEUCOM and SOCOM in support of NATO. NSA support to the 2004 Summer Games\r\nencompassed a wide range of offices to include:\r\n\r\n\u2022\tthe Information Assurance Directorate (IAD),\r\n\r\n\u2022\tInstallations and Logistics (I&L),\r\n\r\n\u2022\tInformation Technology Infrastructure Services (ITIS),\r\n\r\n\u2022\tCounterterrorism (CT),\r\n\r\n\u2022\tInternational Security Issues (ISI),\r\n\r\n\u2022\tCustomer Relationships (SI),\r\n\r\n\u2022\tthe National Security Operations Center (NSOC),\r\n\r\n\u2022\tTailored Access,\r\n\r\n\u2022\tLink Access,\r\n\r\n\u2022\tCryptanalysis and Exploitation (CES),id-827-redacted-formatted-p2-normal.gif: \n\ufeff\u2022\tGeocell,\r\n\r\n\u2022\tour Second Party partners, and many more.\r\n\r\n(S//SI) A shining example of focused mission support to the Games was that being\r\nprovided by the Link Access Support to the Olympics (LASO) team. Comprised of\r\nsubject matter experts from the Office of Overhead (OH), Radio Frequency\r\nOperations (RFO), Special Collection Service (SCS) and Special Source Operations\r\n(SSO), the LASO team was the focal point for everything Olympics -- from planning\r\nto resource allocation through collection management and crisis response -- for all\r\nOlympics security operations. LA team members supported the SID Olympics team\r\nfor more than 10 months, and were in place well before the opening ceremonies.\r\n\r\n(S//SI) NSA/CSS Olympic operations included several major initiatives within LA\r\nspanning its accesses: BLUE FORCE TRACKING, SCS and SSO. SCS support\r\nincluded the activities of US-966G and two survey sites (US-969X183 and\r\nUS-969X202). SSO support included deployment of access capabilities (APRIL\r\nFLOWERS) to directly support the Olympics. LA Olympic Operations and the LASO\r\nTeam concept were just a small part of the larger corporate effort to the XXVIII\r\nSummer Olympiad made possible with the hard work and dedication of many NSA\r\norganizations working together to achieve a common goal -- a safe Olympics!\r\n\r\nOlympic stadium\r\n\r\nParthenon\r\n\r\n\"(U//FOUO)\r\nSIDtoday\r\narticles may not\r\nbe republished\r\nor reposted\r\noutside NSANet\r\nwithout the\r\nconsent of\r\nS0121 (DL\r\nsid\u201ecomms).\"\r\nInformation\r\n\r\nLast Modified:\r\n11/09/2012 / Last\r\nReviewed:\r\n11/09/2012id-827-redacted-formatted-p3-normal.gif: \n\ufeffDYNAMIC PAGE ~\r\nHIGHEST\r\nPOSSIBLE\r\nCLASSIFICATION\r\nIS\r\n\r\nTOP SECRET//SI\r\n/TK//RELTO\r\nUSA AUS CAN\r\nGBR NZL\r\nDERIVED FROM:\r\nNSA/CSSM 1-52,\r\nDATED 08 JAN\r\n2007\r\n\r\nDECLASSIFY ON:\r\n20320108", 
    "pdf": [
      "https://edwardsnowden.com/wp-content/uploads/2015/10/id-827-redacted-formatted-p1-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/id-827-redacted-formatted-p2-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/id-827-redacted-formatted-p3-normal.gif"
    ]
  }, 
  {
    "released_date": "20150929", 
    "overall_handling_caveats": [], 
    "id": "20150929|exploitingforeignlawfulintercept(li)roundtable", 
    "document_date": "2012-01-01 00:00:00", 
    "codewords": [
      "STARPROC", 
      "XKEYSCORE (XKS)"
    ], 
    "agency": [
      "NSA"
    ], 
    "sub_paragraphs_classifications": [
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": null, 
        "paragraph_text": "2012-lawful-intercept-redacted2-p1-normal.gif: ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//si//rel to usa, fvey ", 
        "paragraph_relto": [
          "Canada", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "United Kingdom"
        ]
      }, 
      {
        "paragraph_handling_caveats": [
          "si", 
          "rel"
        ], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s//si//rel) exploiting foreign lawful intercept (li) roundtable s31122 ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//si//rel to usa, fvey2012-lawful-intercept-redacted2-p2-normal.gif: ", 
        "paragraph_relto": [
          "Canada", 
          "United Kingdom", 
          "Australia", 
          "United States", 
          "New Zealand", 
          "Norway"
        ]
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//si//rel to usa, fvey ", 
        "paragraph_relto": [
          "Canada", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "United Kingdom"
        ]
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "(u) definition lawful intercept (li) - obtaining communications network data by legal authority for analysis or evidence nwo/ap/svpst domain lea domain ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//si//rel to usa, fvey 2012-lawful-intercept-redacted2-p3-normal.gif: ", 
        "paragraph_relto": [
          "Canada", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "United Kingdom"
        ]
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//si//rel to usa, fvey ", 
        "paragraph_relto": [
          "Canada", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "United Kingdom"
        ]
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "(u) li standards ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "-\tcalea (us) -\tetsi (european) -\tsorm (russian) j other ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//si//rel to usa, fvey \\2012-lawful-intercept-redacted2-p4-normal.gif: ", 
        "paragraph_relto": [
          "Canada", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "United Kingdom"
        ]
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//si//rel to usa, fvey ", 
        "paragraph_relto": [
          "Canada", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "United Kingdom"
        ]
      }, 
      {
        "paragraph_handling_caveats": [
          "si", 
          "rel"
        ], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "(ts//si//rel) countries of interest pakistan\t* egypt afghanistan\t- algeria iran\tj mexico iraq\t* indonesia yemen\t- uae syria\tj saudi arabia china\t* russia ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//si//rel to usa, fvey \\2012-lawful-intercept-redacted2-p5-normal.gif: ", 
        "paragraph_relto": [
          "Canada", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "United Kingdom"
        ]
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//si//rel to usa, fvey ", 
        "paragraph_relto": [
          "Canada", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "United Kingdom"
        ]
      }, 
      {
        "paragraph_handling_caveats": [
          "si", 
          "rel"
        ], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s//si//rel) xks fingerprints (~60) aqsacom\tj nokia atis\t* siemens ericsson\t* trovicor etsi\t* utimaco huawei\t- zte motorola\t- generic ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//si//rel to usa, fvey \\_____________________________________2012-lawful-intercept-redacted2-p6-normal.gif: ", 
        "paragraph_relto": [
          "Canada", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "United Kingdom"
        ]
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//si//rel to usa, fvey ", 
        "paragraph_relto": [
          "Canada", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "United Kingdom"
        ]
      }, 
      {
        "paragraph_handling_caveats": [
          "fouo"
        ], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "(u//fouo) access methods j fornsat j microwave (f6) ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "j special source operations (sso) j tailored access operations (tao) ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//si//rel to usa, fvey \\______________________________________________2012-lawful-intercept-redacted2-p7-normal.gif: ", 
        "paragraph_relto": [
          "Canada", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "United Kingdom"
        ]
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//si//rel to usa, fvey ", 
        "paragraph_relto": [
          "Canada", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "United Kingdom"
        ]
      }, 
      {
        "paragraph_handling_caveats": [
          "si", 
          "rel"
        ], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s//si//rel) taplists * developing advanced analytics to determine patterns in numbers being tasked j creating database to store ll-related information j discovering informal tasking ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//si//rel to usa, fvey \\______________________________________________2012-lawful-intercept-redacted2-p8-normal.gif: ", 
        "paragraph_relto": [
          "Canada", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "United Kingdom"
        ]
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//si//rel to usa, fvey ", 
        "paragraph_relto": [
          "Canada", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "United Kingdom"
        ]
      }, 
      {
        "paragraph_handling_caveats": [
          "si", 
          "rel"
        ], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s//si//rel) mapping networks j telecommunication and internet service providers in a region - li vendors/service providers j ip addresses/ports of usage j likely transmission medium ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//si//rel to usa, fvey \\______________________________________________2012-lawful-intercept-redacted2-p9-normal.gif: ", 
        "paragraph_relto": [
          "Canada", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "United Kingdom"
        ]
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//si//rel to usa, fvey ", 
        "paragraph_relto": [
          "Canada", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "United Kingdom"
        ]
      }, 
      {
        "paragraph_handling_caveats": [
          "si", 
          "rel"
        ], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s//si//rel) processing solution -\tkittybinge j tao custom solutions -\tstarproc ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//si//rel to usa, fvey 2012-lawful-intercept-redacted2-p10-normal.gif: ", 
        "paragraph_relto": [
          "Canada", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "United Kingdom"
        ]
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//si//rel to usa, fvey ", 
        "paragraph_relto": [
          "Canada", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "United Kingdom"
        ]
      }, 
      {
        "paragraph_handling_caveats": [
          "si", 
          "rel"
        ], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s//si//rel) types of li j telecommunication j internet - differentiating between regular voice/lnternet traffic from tasked traffic. protocol indications? ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//si//rel to usa, fvey \\2012-lawful-intercept-redacted2-p11-normal.gif: ", 
        "paragraph_relto": [
          "Canada", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "United Kingdom"
        ]
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//si//rel to usa, fvey ", 
        "paragraph_relto": [
          "Canada", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "United Kingdom"
        ]
      }, 
      {
        "paragraph_handling_caveats": [
          "si", 
          "rel"
        ], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s//si//rel) li pod ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//si//rel to usa, fvey 2012-lawful-intercept-redacted2-p12-normal.gif: ", 
        "paragraph_relto": [
          "Canada", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "United Kingdom"
        ]
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//si//rel to usa, fvey ", 
        "paragraph_relto": [
          "Canada", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "United Kingdom"
        ]
      }, 
      {
        "paragraph_handling_caveats": [
          "si", 
          "rel"
        ], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s//si//rel) li discussion topics j discovery j access methods j taplist analytics j corporate database j corporate processing solution j other issues/roadblocks ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret//si//rel to usa, fvey \\ - - ", 
        "paragraph_relto": [
          "Canada", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "United Kingdom"
        ]
      }
    ], 
    "pdf_paths": [
      "2012-lawful-intercept-redacted2-p1-normal.gif", 
      "2012-lawful-intercept-redacted2-p2-normal.gif", 
      "2012-lawful-intercept-redacted2-p3-normal.gif", 
      "2012-lawful-intercept-redacted2-p4-normal.gif", 
      "2012-lawful-intercept-redacted2-p5-normal.gif", 
      "2012-lawful-intercept-redacted2-p6-normal.gif", 
      "2012-lawful-intercept-redacted2-p7-normal.gif", 
      "2012-lawful-intercept-redacted2-p8-normal.gif", 
      "2012-lawful-intercept-redacted2-p9-normal.gif", 
      "2012-lawful-intercept-redacted2-p10-normal.gif", 
      "2012-lawful-intercept-redacted2-p11-normal.gif", 
      "2012-lawful-intercept-redacted2-p12-normal.gif"
    ], 
    "overall_classification": null, 
    "description": "This NSA presentation from 2012 discusses techniques for subverting \u201clawful intercept\u201d systems used abroad: see the Intercept article A Death in Athens: Did a Rogue NSA Operation Cause the Death of a Greek Telecom Employee?, 29 September 2015.", 
    "plain_text": "2012-lawful-intercept-redacted2-p1-normal.gif: \n\ufeffTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n(S//SI//REL) Exploiting Foreign\r\nLawful Intercept (LI)\r\nRoundtable\r\n\r\nS31122\r\n\r\nTOP SECRET//SI//REL TO USA, FVEY2012-lawful-intercept-redacted2-p2-normal.gif: \n\ufeffTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n(U) Definition\r\n\r\nLawful Intercept (LI) - obtaining communications\r\nnetwork data by legal authority for analysis or\r\nevidence\r\n\r\nNWO/AP/SvP\u2019st domain\r\n\r\nLEA\r\n\r\ndomain\r\n\r\nTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n2012-lawful-intercept-redacted2-p3-normal.gif: \n\ufeffTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n(U) LI Standards\r\n\r\n-\tCALEA (US)\r\n\r\n-\tETSI (European)\r\n\r\n-\tSORM (Russian)\r\nJ Other\r\n\r\nTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n\\2012-lawful-intercept-redacted2-p4-normal.gif: \n\ufeffTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n(TS//SI//REL) Countries of Interest\r\n\r\nPakistan\t* Egypt\r\nAfghanistan\t- Algeria\r\nIran\tj Mexico\r\nIraq\t\u25a0* Indonesia\r\nYemen\t- UAE\r\nSyria\tj Saudi Arabia\r\nChina\t* Russia\r\n\r\nTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n\\2012-lawful-intercept-redacted2-p5-normal.gif: \n\ufeffTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n(S//SI//REL) XKS Fingerprints (~60)\r\n\r\nAqsacom\tj Nokia\r\nATIS\t* Siemens\r\nEricsson\t* Trovicor\r\nETSI\t* Utimaco\r\nHuawei\t- ZTE\r\nMotorola\t- GENERIC\r\n\r\nTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n\\_____________________________________2012-lawful-intercept-redacted2-p6-normal.gif: \n\ufeffTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n(U//FOUO) Access Methods\r\n\r\nJ FORNSAT\r\nJ Microwave (F6)\r\n\r\nj Special Source Operations (SSO)\r\nj Tailored Access Operations (TAO)\r\n\r\nTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n\\______________________________________________2012-lawful-intercept-redacted2-p7-normal.gif: \n\ufeffTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n(S//SI//REL) Taplists\r\n\r\n\u25a0* Developing advanced analytics to determine\r\npatterns in numbers being tasked\r\n\r\nj Creating database to store Ll-related\r\ninformation\r\n\r\nJ Discovering informal tasking\r\n\r\nTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n\\______________________________________________2012-lawful-intercept-redacted2-p8-normal.gif: \n\ufeffTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n(S//SI//REL) Mapping Networks\r\n\r\nj Telecommunication and Internet Service\r\nProviders in a region\r\n\r\n- LI vendors/service providers\r\nJ IP addresses/ports of usage\r\nj Likely transmission medium\r\n\r\nTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n\\______________________________________________2012-lawful-intercept-redacted2-p9-normal.gif: \n\ufeffTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n(S//SI//REL) Processing Solution\r\n\r\n-\tKITTYBINGE\r\n\r\nJ TAO custom solutions\r\n\r\n-\tSTARPROC\r\n\r\nTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n2012-lawful-intercept-redacted2-p10-normal.gif: \n\ufeffTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n(S//SI//REL) Types of LI\r\n\r\nj Telecommunication\r\nj Internet\r\n\r\n- Differentiating between regular voice/lnternet\r\ntraffic from tasked traffic. Protocol indications?\r\n\r\nTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n\\2012-lawful-intercept-redacted2-p11-normal.gif: \n\ufeffTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n(S//SI//REL) LI Pod\r\n\r\nTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n2012-lawful-intercept-redacted2-p12-normal.gif: \n\ufeffTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n(S//SI//REL) LI Discussion Topics\r\n\r\nj Discovery\r\nJ Access Methods\r\nj Taplist Analytics\r\nJ Corporate Database\r\nj Corporate Processing Solution\r\nj Other Issues/Roadblocks\r\n\r\nTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n\\ - -", 
    "sigads": [], 
    "overall_relto": [], 
    "countries_mentioned": [
      "Afghanistan (AFG/AF)", 
      "Algeria (DZA/DZ)", 
      "China (CHN/CN)", 
      "Egypt (EGY/EG)", 
      "Indonesia (IDN/ID)", 
      "Iran (IRN/IR)", 
      "Iraq (IRQ/IQ)", 
      "Mexico (MEX/MX)", 
      "Pakistan (PAK/PK)", 
      "Russia (RUS/RU)", 
      "Saudi Arabia (SAU/SA)", 
      "United States (USA/US)", 
      "Yemen (YEM/YE)"
    ], 
    "link": "https://edwardsnowden.com/2015/10/03/exploiting-foreign-lawful-intercept-li-roundtable/", 
    "document_topic": [
      "Computer Network Operations"
    ], 
    "pub_date": "Sat, 03 Oct 2015 17:05:02 +0000", 
    "article_links": [
      "https://theintercept.com/2015/09/28/death-athens-rogue-nsa-operation/"
    ], 
    "categories": [
      "Revealed documents", 
      "calea", 
      "computer_network_operations", 
      "etsi", 
      "f6", 
      "fornsat", 
      "kittybinge", 
      "nsa_orig", 
      "sorm", 
      "sso", 
      "starproc", 
      "TAO", 
      "xks"
    ], 
    "title": "Exploiting Foreign Lawful Intercept (LI) Roundtable", 
    "doc_text": "2012-lawful-intercept-redacted2-p1-normal.gif: \n\ufeffTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n(S//SI//REL) Exploiting Foreign\r\nLawful Intercept (LI)\r\nRoundtable\r\n\r\nS31122\r\n\r\nTOP SECRET//SI//REL TO USA, FVEY2012-lawful-intercept-redacted2-p2-normal.gif: \n\ufeffTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n(U) Definition\r\n\r\nLawful Intercept (LI) - obtaining communications\r\nnetwork data by legal authority for analysis or\r\nevidence\r\n\r\nNWO/AP/SvP\u2019st domain\r\n\r\nLEA\r\n\r\ndomain\r\n\r\nTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n2012-lawful-intercept-redacted2-p3-normal.gif: \n\ufeffTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n(U) LI Standards\r\n\r\n-\tCALEA (US)\r\n\r\n-\tETSI (European)\r\n\r\n-\tSORM (Russian)\r\nJ Other\r\n\r\nTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n\\2012-lawful-intercept-redacted2-p4-normal.gif: \n\ufeffTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n(TS//SI//REL) Countries of Interest\r\n\r\nPakistan\t* Egypt\r\nAfghanistan\t- Algeria\r\nIran\tj Mexico\r\nIraq\t\u25a0* Indonesia\r\nYemen\t- UAE\r\nSyria\tj Saudi Arabia\r\nChina\t* Russia\r\n\r\nTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n\\2012-lawful-intercept-redacted2-p5-normal.gif: \n\ufeffTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n(S//SI//REL) XKS Fingerprints (~60)\r\n\r\nAqsacom\tj Nokia\r\nATIS\t* Siemens\r\nEricsson\t* Trovicor\r\nETSI\t* Utimaco\r\nHuawei\t- ZTE\r\nMotorola\t- GENERIC\r\n\r\nTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n\\_____________________________________2012-lawful-intercept-redacted2-p6-normal.gif: \n\ufeffTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n(U//FOUO) Access Methods\r\n\r\nJ FORNSAT\r\nJ Microwave (F6)\r\n\r\nj Special Source Operations (SSO)\r\nj Tailored Access Operations (TAO)\r\n\r\nTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n\\______________________________________________2012-lawful-intercept-redacted2-p7-normal.gif: \n\ufeffTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n(S//SI//REL) Taplists\r\n\r\n\u25a0* Developing advanced analytics to determine\r\npatterns in numbers being tasked\r\n\r\nj Creating database to store Ll-related\r\ninformation\r\n\r\nJ Discovering informal tasking\r\n\r\nTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n\\______________________________________________2012-lawful-intercept-redacted2-p8-normal.gif: \n\ufeffTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n(S//SI//REL) Mapping Networks\r\n\r\nj Telecommunication and Internet Service\r\nProviders in a region\r\n\r\n- LI vendors/service providers\r\nJ IP addresses/ports of usage\r\nj Likely transmission medium\r\n\r\nTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n\\______________________________________________2012-lawful-intercept-redacted2-p9-normal.gif: \n\ufeffTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n(S//SI//REL) Processing Solution\r\n\r\n-\tKITTYBINGE\r\n\r\nJ TAO custom solutions\r\n\r\n-\tSTARPROC\r\n\r\nTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n2012-lawful-intercept-redacted2-p10-normal.gif: \n\ufeffTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n(S//SI//REL) Types of LI\r\n\r\nj Telecommunication\r\nj Internet\r\n\r\n- Differentiating between regular voice/lnternet\r\ntraffic from tasked traffic. Protocol indications?\r\n\r\nTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n\\2012-lawful-intercept-redacted2-p11-normal.gif: \n\ufeffTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n(S//SI//REL) LI Pod\r\n\r\nTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n2012-lawful-intercept-redacted2-p12-normal.gif: \n\ufeffTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n(S//SI//REL) LI Discussion Topics\r\n\r\nj Discovery\r\nJ Access Methods\r\nj Taplist Analytics\r\nJ Corporate Database\r\nj Corporate Processing Solution\r\nj Other Issues/Roadblocks\r\n\r\nTOP SECRET//SI//REL TO USA, FVEY\r\n\r\n\\ - -", 
    "pdf": [
      "https://edwardsnowden.com/wp-content/uploads/2015/10/2012-lawful-intercept-redacted2-p1-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/2012-lawful-intercept-redacted2-p2-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/2012-lawful-intercept-redacted2-p3-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/2012-lawful-intercept-redacted2-p4-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/2012-lawful-intercept-redacted2-p5-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/2012-lawful-intercept-redacted2-p6-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/2012-lawful-intercept-redacted2-p7-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/2012-lawful-intercept-redacted2-p8-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/2012-lawful-intercept-redacted2-p9-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/2012-lawful-intercept-redacted2-p10-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/2012-lawful-intercept-redacted2-p11-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/2012-lawful-intercept-redacted2-p12-normal.gif"
    ]
  }, 
  {
    "released_date": "20150929", 
    "overall_handling_caveats": [], 
    "id": "20150929|anothersuccessfulolympicsstory", 
    "document_date": "2004-10-06 00:00:00", 
    "codewords": [], 
    "agency": [
      "NSA"
    ], 
    "sub_paragraphs_classifications": [
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": null, 
        "paragraph_text": "id-863-redacted-formatted-p1-normal.gif: dynamic page - highest possible classification is ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret // si / tk // rel to usa aus can gbr nzl ", 
        "paragraph_relto": [
          "United Kingdom", 
          "United States", 
          "New Zealand", 
          "Australia", 
          "Canada"
        ]
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "(u) another successful olympics story from: collection strategies and requirements center (s3c) run date: 10/06/2004 ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [
          "si"
        ], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s//si) like the athletes themselves, data acquisition (da) expended countless hours in preparation for the 2004 athens olympics. the collection strategies and ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Confidential", 
        "paragraph_text": "requirements center (csrc) olympics strategists worked with people and organizations from across the extended enterprise to create a sigint campaign strategy focusing on support to the games. unlike the athletes, when the olympics are over, the nsa team is hoping you won't even know they were there. instead of olympic gold, their goal was making sure the olympics proceeded without terrorist incident and that the approximately 10,500 athletes from over 200 countries, millions of fans, and the international press could focus on the sporting events in the olympic spirit of peaceful competition. (s//si^taruncn^002^csrc strategists, ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Confidential", 
        "paragraph_text": "and hhhihhhi worked with customer relations division (crd) and external customers to document previously unstated information needs. teaming with sigdev and analysis and production (a&p) to ensure that an analytic attack was in place and that targets' social networks were defined, these strategists examined the evolving communications network being built for the games, determined gaps in sigint access, and directed fielding of collection and forwarding systems. and all this was before the torch was lit signifying the opening of the games of the xxviii olympiad. in short, the team followed the sid operating principles to systematically analyze what our customers needed and planned how the sigint system would meet those needs. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [
          "si"
        ], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "(s//si) when the plan went into the implementation phase, the csrc monitored the effort. this was simplified through the use of an info work space (iws) virtual room dedicated to the games, which allowed intelligence community professionals from across the extended enterprise, including denver, the national geospatial- intelligence agency's (nga) 24/7 multi-int olympic watch, nsaw, and those deployed in athens itself, to coordinate operations smoothly. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [
          "si"
        ], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "(ts//si) given the broad scope of the games, all da groups played a part in improving access, collection, and forwarding of traffic. for example, prior to the start of the olympics: commercial technologies group worked with vendors to learn about communications being installed to support the olympics; csrc gathered data from cia documenting the gsm networks active in athens; special source operations improved mid-point cable access to dni and voice targets in greece; scs athens fielded additional capabilities to bring traffic back to nsaw; tailored access operations performed cne operations against greek communications providers.id-863-redacted-formatted-p2-normal.gif: additional support during the games included fielding three remote collection teams (one each from link access, cryptanalysis and exploitation services, and the scs) active in the athens area to fill collection gaps. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [
          "fouo"
        ], 
        "paragraph_classification": "Unclassified", 
        "paragraph_text": "\"(u//fouo) sidtoday articles may not be republished or reposted outside nsanet without the consent of s0121 (dl sid commsl.\" information last modified: 11/09/2012 / last reviewed: 11/09/2012 dynamic page - highest possible classification is ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret // si /tk//relto usa aus can gbr nzl derived from: nsa/cssm 1-52, dated 08 jan 2007 declassify on: 20320108 ", 
        "paragraph_relto": []
      }
    ], 
    "pdf_paths": [
      "id-863-redacted-formatted-p1-normal.gif", 
      "id-863-redacted-formatted-p2-normal.gif"
    ], 
    "overall_classification": null, 
    "description": "This post from the NSA\u2019s internal SIDToday newsletter, dated 6 October 2004, reviews the agency\u2019s operations for the recently-concluded Athens Olympics: see the Intercept article A Death in Athens: Did a Rogue NSA Operation Cause the Death of a Greek Telecom Employee?, 29 September 2015.", 
    "plain_text": "id-863-redacted-formatted-p1-normal.gif: \n\ufeffDYNAMIC PAGE - HIGHEST POSSIBLE CLASSIFICATION IS\r\n\r\nTOP SECRET // SI / TK // REL TO USA AUS CAN GBR NZL\r\n\r\n(U) Another Successful Olympics Story\r\n\r\nFROM:\r\n\r\nCollection Strategies and Requirements Center (S3C)\r\nRun Date: 10/06/2004\r\n\r\n(S//SI) Like the athletes themselves, Data Acquisition (DA) expended countless\r\nhours in preparation for the 2004 Athens Olympics. The Collection Strategies and\r\nRequirements Center (CSRC) Olympics Strategists worked with people and\r\norganizations from across the Extended Enterprise to create a SIGINT Campaign\r\nStrategy focusing on support to the Games. Unlike the athletes, when the Olympics\r\nare over, the NSA team is hoping you won't even know they were there. Instead of\r\nOlympic gold, their goal was making sure the Olympics proceeded without terrorist\r\nincident and that the approximately 10,500 athletes from over 200 countries,\r\nmillions of fans, and the international press could focus on the sporting events in\r\nthe Olympic spirit of peaceful competition.\r\n\r\n(S//SI^tarUncn^002^CSRC Strategists,\r\n\r\nand HHHIHHHi worked with Customer Relations Division (CRD) and\r\nexternal customers to document previously unstated Information Needs. Teaming\r\nwith SIGDEV and Analysis and Production (A&P) to ensure that an analytic attack\r\nwas in place and that targets' social networks were defined, these strategists\r\nexamined the evolving communications network being built for the Games,\r\ndetermined gaps in SIGINT access, and directed fielding of collection and\r\nforwarding systems. And all this was before the torch was lit signifying the Opening\r\nof the Games of the XXVIII Olympiad. In short, the team followed the SID\r\nOperating Principles to systematically analyze what our customers needed and\r\nplanned how the SIGINT system would meet those needs.\r\n\r\n(S//SI) When the plan went into the implementation phase, the CSRC monitored the\r\neffort. This was simplified through the use of an Info Work Space (IWS) virtual\r\nroom dedicated to the Games, which allowed Intelligence Community professionals\r\nfrom across the Extended Enterprise, including Denver, the National Geospatial-\r\nIntelligence Agency's (NGA) 24/7 multi-INT Olympic watch, NSAW, and those\r\ndeployed in Athens itself, to coordinate operations smoothly.\r\n\r\n(TS//SI) Given the broad scope of the Games, all DA Groups played a part in\r\nimproving access, collection, and forwarding of traffic. For example, prior to the\r\nstart of the Olympics:\r\n\r\n\u2022\tCommercial Technologies Group worked with vendors to learn about\r\ncommunications being installed to support the Olympics;\r\n\r\n\u2022\tCSRC gathered data from CIA documenting the GSM networks active in\r\nAthens;\r\n\r\n\u2022\tSpecial Source Operations improved mid-point cable access to DNI and voice\r\ntargets in Greece;\r\n\r\n\u2022\tSCS Athens fielded additional capabilities to bring traffic back to NSAW;\r\n\r\n\u2022\tTailored Access Operations performed CNE operations against Greek\r\ncommunications providers.id-863-redacted-formatted-p2-normal.gif: \n\ufeffAdditional support during the Games included fielding three remote collection\r\nteams (one each from Link Access, Cryptanalysis and Exploitation Services, and the\r\nSCS) active in the Athens area to fill collection gaps.\r\n\r\n\"(U//FOUO)\r\nSIDtoday\r\narticles may not\r\nbe republished\r\nor reposted\r\noutside NSANet\r\nwithout the\r\nconsent of\r\nS0121 (DL\r\nsid commsl.\"\r\nInformation\r\n\r\nLast Modified:\r\n11/09/2012 / Last\r\nReviewed:\r\n11/09/2012\r\n\r\nDYNAMIC PAGE -\r\nHIGHEST\r\nPOSSIBLE\r\nCLASSIFICATION\r\nIS\r\n\r\nTOP SECRET // SI\r\n/TK//RELTO\r\nUSA AUS CAN\r\nGBR NZL\r\nDERIVED FROM:\r\nNSA/CSSM 1-52,\r\nDATED 08 JAN\r\n2007\r\n\r\nDECLASSIFY ON:\r\n20320108", 
    "sigads": [], 
    "overall_relto": [], 
    "countries_mentioned": [
      "Greece (GRC/GR)", 
      "United States (USA/US)"
    ], 
    "link": "https://edwardsnowden.com/2015/10/03/another-successful-olympics-story/", 
    "document_topic": [
      "Phone Content", 
      "Internet Content", 
      "Computer Network Operations"
    ], 
    "pub_date": "Sat, 03 Oct 2015 16:55:47 +0000", 
    "article_links": [
      "https://theintercept.com/2015/09/28/death-athens-rogue-nsa-operation/"
    ], 
    "categories": [
      "Revealed documents", 
      "athens", 
      "cne", 
      "computer_network_operations", 
      "crsc", 
      "greece", 
      "internet_content", 
      "nsa_orig", 
      "nsaw", 
      "olympics", 
      "phone_content", 
      "special source", 
      "tailored access"
    ], 
    "title": "Another Successful Olympics Story", 
    "doc_text": "id-863-redacted-formatted-p1-normal.gif: \n\ufeffDYNAMIC PAGE - HIGHEST POSSIBLE CLASSIFICATION IS\r\n\r\nTOP SECRET // SI / TK // REL TO USA AUS CAN GBR NZL\r\n\r\n(U) Another Successful Olympics Story\r\n\r\nFROM:\r\n\r\nCollection Strategies and Requirements Center (S3C)\r\nRun Date: 10/06/2004\r\n\r\n(S//SI) Like the athletes themselves, Data Acquisition (DA) expended countless\r\nhours in preparation for the 2004 Athens Olympics. The Collection Strategies and\r\nRequirements Center (CSRC) Olympics Strategists worked with people and\r\norganizations from across the Extended Enterprise to create a SIGINT Campaign\r\nStrategy focusing on support to the Games. Unlike the athletes, when the Olympics\r\nare over, the NSA team is hoping you won't even know they were there. Instead of\r\nOlympic gold, their goal was making sure the Olympics proceeded without terrorist\r\nincident and that the approximately 10,500 athletes from over 200 countries,\r\nmillions of fans, and the international press could focus on the sporting events in\r\nthe Olympic spirit of peaceful competition.\r\n\r\n(S//SI^tarUncn^002^CSRC Strategists,\r\n\r\nand HHHIHHHi worked with Customer Relations Division (CRD) and\r\nexternal customers to document previously unstated Information Needs. Teaming\r\nwith SIGDEV and Analysis and Production (A&P) to ensure that an analytic attack\r\nwas in place and that targets' social networks were defined, these strategists\r\nexamined the evolving communications network being built for the Games,\r\ndetermined gaps in SIGINT access, and directed fielding of collection and\r\nforwarding systems. And all this was before the torch was lit signifying the Opening\r\nof the Games of the XXVIII Olympiad. In short, the team followed the SID\r\nOperating Principles to systematically analyze what our customers needed and\r\nplanned how the SIGINT system would meet those needs.\r\n\r\n(S//SI) When the plan went into the implementation phase, the CSRC monitored the\r\neffort. This was simplified through the use of an Info Work Space (IWS) virtual\r\nroom dedicated to the Games, which allowed Intelligence Community professionals\r\nfrom across the Extended Enterprise, including Denver, the National Geospatial-\r\nIntelligence Agency's (NGA) 24/7 multi-INT Olympic watch, NSAW, and those\r\ndeployed in Athens itself, to coordinate operations smoothly.\r\n\r\n(TS//SI) Given the broad scope of the Games, all DA Groups played a part in\r\nimproving access, collection, and forwarding of traffic. For example, prior to the\r\nstart of the Olympics:\r\n\r\n\u2022\tCommercial Technologies Group worked with vendors to learn about\r\ncommunications being installed to support the Olympics;\r\n\r\n\u2022\tCSRC gathered data from CIA documenting the GSM networks active in\r\nAthens;\r\n\r\n\u2022\tSpecial Source Operations improved mid-point cable access to DNI and voice\r\ntargets in Greece;\r\n\r\n\u2022\tSCS Athens fielded additional capabilities to bring traffic back to NSAW;\r\n\r\n\u2022\tTailored Access Operations performed CNE operations against Greek\r\ncommunications providers.id-863-redacted-formatted-p2-normal.gif: \n\ufeffAdditional support during the Games included fielding three remote collection\r\nteams (one each from Link Access, Cryptanalysis and Exploitation Services, and the\r\nSCS) active in the Athens area to fill collection gaps.\r\n\r\n\"(U//FOUO)\r\nSIDtoday\r\narticles may not\r\nbe republished\r\nor reposted\r\noutside NSANet\r\nwithout the\r\nconsent of\r\nS0121 (DL\r\nsid commsl.\"\r\nInformation\r\n\r\nLast Modified:\r\n11/09/2012 / Last\r\nReviewed:\r\n11/09/2012\r\n\r\nDYNAMIC PAGE -\r\nHIGHEST\r\nPOSSIBLE\r\nCLASSIFICATION\r\nIS\r\n\r\nTOP SECRET // SI\r\n/TK//RELTO\r\nUSA AUS CAN\r\nGBR NZL\r\nDERIVED FROM:\r\nNSA/CSSM 1-52,\r\nDATED 08 JAN\r\n2007\r\n\r\nDECLASSIFY ON:\r\n20320108", 
    "pdf": [
      "https://edwardsnowden.com/wp-content/uploads/2015/10/id-863-redacted-formatted-p1-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/id-863-redacted-formatted-p2-normal.gif"
    ]
  }, 
  {
    "released_date": "20150925", 
    "overall_handling_caveats": [], 
    "id": "20150925|supportinginternetoperations", 
    "document_date": "2009-01-01 00:00:00", 
    "codewords": [
      "ARCANO", 
      "CIRCUIT", 
      "GERONTIC", 
      "GRASP", 
      "HIASCO", 
      "PINNAGE"
    ], 
    "agency": [
      "GCHQ"
    ], 
    "sub_paragraphs_classifications": [
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": null, 
        "paragraph_text": "200g-iris-access-p1-normal.gif: supporting internet operations supporting internet operations special source access200g-iris-access-p2-normal.gif: stepmo mamiopihm> 15 mins to cover: -\twhat does the environment look like -\twhat does the sse roadmap tell us: current posture ..and where do we want to be -\twhere are we now -\taccess plans for fy 10/11200g-iris-access-p3-normal.gif: old cable map more bandwidth being lit on existing cable systems moving target: several new cable systems being introduced (just in 2010). as per sse roadmap, we need to maintain our investment in the access footprint in order to keep up. )200g-iris-access-p4-normal.gif: 1.\tthis is a view of the commercial cable systems transiting the uk. there are around 1600 available 10gs within these cables. 2.\tthis is 25% of all internet traffic 3.\talthough the total percentage processed may seem in the lower percentile range we can actually survey the majority of the 1600. 4.\tthis allows us to select the most valuable to switch into our processing systems. 5.\tadvancing techniques wil allow a greater rate of processing by using targeted techniques (bulk presence events and t1pc). 3200g-iris-access-p5-normal.gif: current capability supporting internet operations following the efforts made for the july deliverable, and the progress being made towards the 100 march 2010 target, gchqs current 10g sse capability is: ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "-\twe can intercept/touch: -800x 10gs (see note ri) -\twe can cyclic survey: 188 -\twe can egress to gchq processing: 87 (see note #2) in addition we are working with gerontic to agree an iru which will enable a significant reduction in annual running costs (~2m saving p.a), along with a further 10x 10g egress. note #1. does not include circuit/waygood note #2. hiasco access/egress to bude complete - awaiting extra arcano egress ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1200g-iris-access-p6-normal.gif: sse roadmap / future capability supporting internet operations the sse roadmap is still valid though needs re-visiting to update/valldate the recommended intercept and egress expansion. along with tea and srt (and ecb) we are developing new relationships to expand our access footprint, to bring the number of 10g bearers: -\tintercepted by mar 2011 to: 1513 (or there abouts...) (+70 if we include circuit/wg) -\tegressed to gchq processing systems by mar 2011 to: 415 eagle eyed will have noticed that this doesn't align with the projected processing and storage profile. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1200g-iris-access-p7-normal.gif: stpportng internet operations sino access plans for 2010 hi asco , pinnage site other existing accesses / 0 d f vote!* 2x 10g egress bude extra 1 ox 10( egress a arcano another \\ site / investigation cheltenham |oqjf . / grasp sostrum visage little site kennington - 224x 10gs ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1200g-iris-access-p8-normal.gif: supporting internet operations sino access: where are we fr 10 x 10g from hiasco now available at bude: awaiting debit card commissioning to process 8 out of 10 additional arcano bearers for bude - on track for march 2010 kennington agreement complete to enable increased sostrum, grasp and visage access and egress plane & prove sites available: -\tegress comms from prove to cheltenham will be in place by march 2010 (plane to follow) -\tinitial capability planned for march includes kea, sd and fkb osds: -\tbude osds ioc's today (capability now - 150*) -\tcheltenham osds upgraded december (capability now - 78) new relationships and access - pinnage and little progressing but no dates yet. assessment of potential rpc-2 (and 3/4) sites underway :pandable to 300 ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1200g-iris-access-p9-normal.gif: supporting intwnw operations questions.. ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 ", 
        "paragraph_relto": []
      }
    ], 
    "pdf_paths": [
      "200g-iris-access-p1-normal.gif", 
      "200g-iris-access-p2-normal.gif", 
      "200g-iris-access-p3-normal.gif", 
      "200g-iris-access-p4-normal.gif", 
      "200g-iris-access-p5-normal.gif", 
      "200g-iris-access-p6-normal.gif", 
      "200g-iris-access-p7-normal.gif", 
      "200g-iris-access-p8-normal.gif", 
      "200g-iris-access-p9-normal.gif"
    ], 
    "overall_classification": null, 
    "description": "This GCHQ presentation from 2010 describes the extent of the agency\u2019s cable-tapping and plans for the future: see the Intercept article Profiled: From Radio to Porn, British Spies Track Web Users\u2019 Online Identities, 25 September 2015.", 
    "plain_text": "200g-iris-access-p1-normal.gif: \n\ufeffSupporting Internet Operations\r\n\r\nSupporting Internet Operations\r\n\r\nSpecial Source Access200g-iris-access-p2-normal.gif: \n\ufeffStEPM\u2014O MamiOpi\u00abHM>\r\n\r\n15 mins to cover:\r\n\r\n-\tWhat does the environment look like\r\n\r\n-\tWhat does the SSE Roadmap tell us:\r\n\r\n\u2022\tCurrent posture\r\n\r\n\u2022\t..and where do we want to be\r\n\r\n-\tWhere are we now\r\n\r\n-\tAccess plans for FY 10/11200g-iris-access-p3-normal.gif: \n\ufeffOld Cable Map\r\n\r\n\u2022 More bandwidth being lit on existing cable\r\nsystems\r\n\r\nMoving target:\r\n\r\n\u2022\tSeveral new cable systems being\r\nintroduced (just in 2010).\r\n\r\n\u2022\tAs per SSE Roadmap, we need to\r\nmaintain our investment in the access\r\nfootprint in order to keep up.\r\n\r\n)200g-iris-access-p4-normal.gif: \n\ufeff1.\tThis is a view of the commercial cable systems transiting the UK. There are around 1600 available\r\n10Gs within these cables.\r\n\r\n2.\tThis is 25% of all internet traffic\r\n\r\n3.\tAlthough the total percentage processed may seem in the lower percentile range we can actually\r\nsurvey the majority of the 1600.\r\n\r\n4.\tThis allows us to select the most valuable to switch into our processing systems.\r\n\r\n5.\tAdvancing techniques wil allow a greater rate of processing by using targeted techniques (bulk\r\npresence events and T1PC).\r\n\r\n3200g-iris-access-p5-normal.gif: \n\ufeffCurrent Capability\r\n\r\nSupporting Internet Operations\r\n\r\n\u2022\tFollowing the efforts made for the July deliverable, and\r\nthe progress being made towards the 100 March 2010\r\ntarget, GCHQs current 10G SSE capability is:\r\n\r\n-\tWe can intercept/touch: -800x 10Gs (See note ri)\r\n\r\n-\tWe can cyclic survey: 188\r\n\r\n-\tWe can egress to GCHQ processing: 87 (See note #2)\r\n\r\n\u2022\tIn addition we are working with GERONTIC to agree an\r\nIRU which will enable a significant reduction in annual\r\nrunning costs (~\u00a32M saving p.a), along with a further 10x\r\n10G egress.\r\n\r\nNote #1. Does not include CIRCUIT/WAYGOOD\r\n\r\nNote #2. HIASCO access/egress to Bude complete - awaiting extra ARCANO egress\r\n\r\nTOP SECRET STRAP1200g-iris-access-p6-normal.gif: \n\ufeffSSE Roadmap / Future Capability\r\n\r\nSupporting Internet Operations\r\n\r\n\u2022\tThe SSE Roadmap is still valid though needs re-visiting to\r\nupdate/valldate the recommended intercept and egress\r\nexpansion.\r\n\r\n\u2022\tAlong with TEA and SRT (and ECB) we are developing\r\nnew relationships to expand our access footprint, to bring\r\nthe number of 10G bearers:\r\n\r\n-\tIntercepted by Mar 2011 to: 1513 (or there abouts...)\r\n\r\n(+70 if we include CIRCUIT/WG)\r\n\r\n-\tEgressed to GCHQ processing systems by Mar 2011 to: 415\r\n\r\nEagle eyed will have noticed that this doesn't align with the\r\nprojected processing and storage profile.\r\n\r\nTOP SECRET STRAP1200g-iris-access-p7-normal.gif: \n\ufeffStpportng Internet Operations\r\n\r\nSINO Access Plans for 2010\r\n\r\nHI ASCO\r\n\r\n, PINNAGE\r\n\r\nSite\r\n\r\nOther\r\n\r\nExisting\r\n\r\nAccesses\r\n\r\n\u2022 \u2022 \u25a0 / \u00a10 D F\r\n\r\nVote!*\r\n\r\n2x 10G egress\r\n\r\nBUDE\r\n\r\nExtra 1 Ox 10(\r\negress A\r\n\r\nARCANO\r\n\r\nAnother \\\r\nSite /\r\n\r\nInvestigation\r\n\r\nCHELTENHAM |OQjF . /\r\n\r\nGRASP SOSTRUM VISAGE\r\n\r\nLITTLE\r\n\r\nSite\r\n\r\nKENNINGTON - 224x 10Gs\r\n\r\nTOP SECRET STRAP1200g-iris-access-p8-normal.gif: \n\ufeffSupporting Internet Operations\r\n\r\nSINO Access: Where are we\r\n\r\nfr\r\n\r\n\u2022\t10 x 10G from HIASCO now available at Bude: awaiting DEBIT CARD\r\ncommissioning to process\r\n\r\n\u2022\t8 out of 10 additional ARCANO bearers for Bude - on track for March\r\n2010\r\n\r\n\u2022\tKENNINGTON agreement complete to enable increased SOSTRUM,\r\nGRASP and VISAGE access and egress\r\n\r\n\u2022\tPLANE & PROVE sites available:\r\n\r\n-\tEgress comms from PROVE to Cheltenham will be in place by March 2010\r\n(PLANE to follow)\r\n\r\n-\tInitial capability planned for March includes KEA, SD and FKB\r\n\r\n\u2022\tOSDS:\r\n\r\n-\tBude OSDS IOC's today (capability now - 150*)\r\n\r\n-\tCheltenham OSDS upgraded December (capability now - 78)\r\n\r\n\u2022\tNew relationships and access - PINNAGE and LITTLE progressing but\r\nno dates yet.\r\n\r\n\u2022\tAssessment of potential RPC-2 (and 3/4) sites underway\r\n\r\n:pandable to 300\r\n\r\nTOP SECRET STRAP1200g-iris-access-p9-normal.gif: \n\ufeffSupporting Intwnw Operations\r\n\r\nQuestions..\r\n\r\nTOP SECRET STRAP1", 
    "sigads": [], 
    "overall_relto": [], 
    "countries_mentioned": [
      "United Kingdom (GBR/GB)"
    ], 
    "link": "https://edwardsnowden.com/2015/10/03/supporting-internet-operations/", 
    "document_topic": [
      "Internet Content"
    ], 
    "pub_date": "Sat, 03 Oct 2015 14:29:51 +0000", 
    "article_links": [
      "https://theintercept.com/2015/09/25/gchq-radio-porn-spies-track-web-users-online-identities/"
    ], 
    "categories": [
      "Revealed documents", 
      "arcano", 
      "bude", 
      "cheltenham", 
      "circuit", 
      "gchq_orig", 
      "gerontic", 
      "grasp", 
      "hiasco", 
      "internet_content", 
      "kennington", 
      "pinnage", 
      "sostrum", 
      "special source", 
      "waygood"
    ], 
    "title": "Supporting Internet Operations", 
    "doc_text": "200g-iris-access-p1-normal.gif: \n\ufeffSupporting Internet Operations\r\n\r\nSupporting Internet Operations\r\n\r\nSpecial Source Access200g-iris-access-p2-normal.gif: \n\ufeffStEPM\u2014O MamiOpi\u00abHM>\r\n\r\n15 mins to cover:\r\n\r\n-\tWhat does the environment look like\r\n\r\n-\tWhat does the SSE Roadmap tell us:\r\n\r\n\u2022\tCurrent posture\r\n\r\n\u2022\t..and where do we want to be\r\n\r\n-\tWhere are we now\r\n\r\n-\tAccess plans for FY 10/11200g-iris-access-p3-normal.gif: \n\ufeffOld Cable Map\r\n\r\n\u2022 More bandwidth being lit on existing cable\r\nsystems\r\n\r\nMoving target:\r\n\r\n\u2022\tSeveral new cable systems being\r\nintroduced (just in 2010).\r\n\r\n\u2022\tAs per SSE Roadmap, we need to\r\nmaintain our investment in the access\r\nfootprint in order to keep up.\r\n\r\n)200g-iris-access-p4-normal.gif: \n\ufeff1.\tThis is a view of the commercial cable systems transiting the UK. There are around 1600 available\r\n10Gs within these cables.\r\n\r\n2.\tThis is 25% of all internet traffic\r\n\r\n3.\tAlthough the total percentage processed may seem in the lower percentile range we can actually\r\nsurvey the majority of the 1600.\r\n\r\n4.\tThis allows us to select the most valuable to switch into our processing systems.\r\n\r\n5.\tAdvancing techniques wil allow a greater rate of processing by using targeted techniques (bulk\r\npresence events and T1PC).\r\n\r\n3200g-iris-access-p5-normal.gif: \n\ufeffCurrent Capability\r\n\r\nSupporting Internet Operations\r\n\r\n\u2022\tFollowing the efforts made for the July deliverable, and\r\nthe progress being made towards the 100 March 2010\r\ntarget, GCHQs current 10G SSE capability is:\r\n\r\n-\tWe can intercept/touch: -800x 10Gs (See note ri)\r\n\r\n-\tWe can cyclic survey: 188\r\n\r\n-\tWe can egress to GCHQ processing: 87 (See note #2)\r\n\r\n\u2022\tIn addition we are working with GERONTIC to agree an\r\nIRU which will enable a significant reduction in annual\r\nrunning costs (~\u00a32M saving p.a), along with a further 10x\r\n10G egress.\r\n\r\nNote #1. Does not include CIRCUIT/WAYGOOD\r\n\r\nNote #2. HIASCO access/egress to Bude complete - awaiting extra ARCANO egress\r\n\r\nTOP SECRET STRAP1200g-iris-access-p6-normal.gif: \n\ufeffSSE Roadmap / Future Capability\r\n\r\nSupporting Internet Operations\r\n\r\n\u2022\tThe SSE Roadmap is still valid though needs re-visiting to\r\nupdate/valldate the recommended intercept and egress\r\nexpansion.\r\n\r\n\u2022\tAlong with TEA and SRT (and ECB) we are developing\r\nnew relationships to expand our access footprint, to bring\r\nthe number of 10G bearers:\r\n\r\n-\tIntercepted by Mar 2011 to: 1513 (or there abouts...)\r\n\r\n(+70 if we include CIRCUIT/WG)\r\n\r\n-\tEgressed to GCHQ processing systems by Mar 2011 to: 415\r\n\r\nEagle eyed will have noticed that this doesn't align with the\r\nprojected processing and storage profile.\r\n\r\nTOP SECRET STRAP1200g-iris-access-p7-normal.gif: \n\ufeffStpportng Internet Operations\r\n\r\nSINO Access Plans for 2010\r\n\r\nHI ASCO\r\n\r\n, PINNAGE\r\n\r\nSite\r\n\r\nOther\r\n\r\nExisting\r\n\r\nAccesses\r\n\r\n\u2022 \u2022 \u25a0 / \u00a10 D F\r\n\r\nVote!*\r\n\r\n2x 10G egress\r\n\r\nBUDE\r\n\r\nExtra 1 Ox 10(\r\negress A\r\n\r\nARCANO\r\n\r\nAnother \\\r\nSite /\r\n\r\nInvestigation\r\n\r\nCHELTENHAM |OQjF . /\r\n\r\nGRASP SOSTRUM VISAGE\r\n\r\nLITTLE\r\n\r\nSite\r\n\r\nKENNINGTON - 224x 10Gs\r\n\r\nTOP SECRET STRAP1200g-iris-access-p8-normal.gif: \n\ufeffSupporting Internet Operations\r\n\r\nSINO Access: Where are we\r\n\r\nfr\r\n\r\n\u2022\t10 x 10G from HIASCO now available at Bude: awaiting DEBIT CARD\r\ncommissioning to process\r\n\r\n\u2022\t8 out of 10 additional ARCANO bearers for Bude - on track for March\r\n2010\r\n\r\n\u2022\tKENNINGTON agreement complete to enable increased SOSTRUM,\r\nGRASP and VISAGE access and egress\r\n\r\n\u2022\tPLANE & PROVE sites available:\r\n\r\n-\tEgress comms from PROVE to Cheltenham will be in place by March 2010\r\n(PLANE to follow)\r\n\r\n-\tInitial capability planned for March includes KEA, SD and FKB\r\n\r\n\u2022\tOSDS:\r\n\r\n-\tBude OSDS IOC's today (capability now - 150*)\r\n\r\n-\tCheltenham OSDS upgraded December (capability now - 78)\r\n\r\n\u2022\tNew relationships and access - PINNAGE and LITTLE progressing but\r\nno dates yet.\r\n\r\n\u2022\tAssessment of potential RPC-2 (and 3/4) sites underway\r\n\r\n:pandable to 300\r\n\r\nTOP SECRET STRAP1200g-iris-access-p9-normal.gif: \n\ufeffSupporting Intwnw Operations\r\n\r\nQuestions..\r\n\r\nTOP SECRET STRAP1", 
    "pdf": [
      "https://edwardsnowden.com/wp-content/uploads/2015/10/200g-iris-access-p1-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/200g-iris-access-p2-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/200g-iris-access-p3-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/200g-iris-access-p4-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/200g-iris-access-p5-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/200g-iris-access-p6-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/200g-iris-access-p7-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/200g-iris-access-p8-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/200g-iris-access-p9-normal.gif"
    ]
  }, 
  {
    "released_date": "20150925", 
    "overall_handling_caveats": [], 
    "id": "20150925|blackholeanalytics", 
    "document_date": "2009-09-01 00:00:00", 
    "codewords": [
      "BLAZING SADDLES", 
      "EVOLVED MUTANT BROTH", 
      "KARMA POLICE", 
      "BLACKHOLE", 
      "MUTANT BROTH"
    ], 
    "agency": [
      "GCHQ"
    ], 
    "sub_paragraphs_classifications": [
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": null, 
        "paragraph_text": "add-sd-blackhole-p1-normal.gif: black hole analytics add/sd briefing, september 2009 ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap 1add-sd-blackhole-p2-normal.gif: ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 contents describe the new breed of c2c tools developed in applied research (tr) scaling them up through the next generation events (nge) projectadd-sd-blackhole-p3-normal.gif: ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 next generation events roadmap gtac f convergence 1 cloud upscale i ntcmcl profiling 2 i ntcmcl profiling 1 -*0 * log -2g0 experts capability development (including ca) large-scale contact chaining data mining and profilingadd-sd-blackhole-p4-normal.gif: ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 nge analytical capabilitiesadd-sd-blackhole-p5-normal.gif: ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 **0 some useful definitions presence event describes that an identifier was online, on an ip address, at a point in time. simple, atomic element. can be very easily developed so are very diverse very useful! tdi = target description identifier has a type, eg yahoo-y-cookie and a value, eg tom123@yahoo gtdi = generic target detection identifier expands the tdi concept to telephony e.g. a gsm location update messageadd-sd-blackhole-p6-normal.gif: ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 some more definitions black hole: the large flat file storage where all the data sits after initial processing, and before being manipulated and correlated and loaded into the qfd database tables qfd: question focused dataset (database) - one for each tool: mutant broth, auto assoc etcadd-sd-blackhole-p7-normal.gif: ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 goicjadd-sd-blackhole-p8-normal.gif: ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 ^0 qfd desktop...so far... enables analysts to: create a profile of a target's online activities (mutant broth) find other identifiers for a target (auto assoc) ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "create a social network (social animal) investigate websites or web forums of interest (karma police, infinite monkeys, hrmap) find out who has been searching the web and for what (memory hole) find out who has been looking at what on google earth (marbled gecko)add-sd-blackhole-p9-normal.gif: converged qfd desktop...by dec... enables analysts to: create a profile of a target's online activities alongside telephony ( evolved mutant broth) find alternative identifiers across telephony and the internet (hard assoc) create a social network including telephony (evolved social animal) ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Secret", 
        "paragraph_text": "find out what has been happening in real time (samuel pepys) all available on the desktop via looking glass plug-ins and web guisadd-sd-blackhole-p10-normal.gif: ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 f success story -tss2 nocon slides removed - contact\tfor full versionadd-sd-blackhole-p11-normal.gif: ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1add-sd-blackhole-p12-normal.gif: ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 capability dev workspace oh. this looks interesting - what does an analyst think? easy access to data, however it is collected use live data to w-ork on real problems put the latest results processing power ready to use improvement hmm. new data... i wonder what happens if i mine it like this... i ve just developed collection of will this nsa algorithm help? is that better? i'll put that processing on a few more bearers... collection engineer/ research team analytics'^ developer or this? ok. but could you just... good, but how about... could you tweak it to... analyst with an operational problem oh heck. i've caught bin laden this data might be best viewed like this: take a look is that better? l_ m just add in some of those results... user-interface specialistadd-sd-blackhole-p13-normal.gif: ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 data mining at scale experiments with cloud ongoing to enable analysts to request and run moags (large tnn graphs) from the desktop distillery will enable analysts to spot real time changes to the data at scale (e.g. detection of impossible travel) joint collaboration environment (lnnov8) - trialling running of large scale analytics using both gchq and nsa data add-sd-blackhole-p14-normal.gif: ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 future implications we shall be able to: easily monitor changes in our targets' profiles and networks develop and trial new capabilities using real life analytical experiments respond quickly in a crisisadd-sd-blackhole-p15-normal.gif: questions? ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 |/blazing_saddles /nge black hole ", 
        "paragraph_relto": []
      }
    ], 
    "pdf_paths": [
      "add-sd-blackhole-p1-normal.gif", 
      "add-sd-blackhole-p2-normal.gif", 
      "add-sd-blackhole-p3-normal.gif", 
      "add-sd-blackhole-p4-normal.gif", 
      "add-sd-blackhole-p5-normal.gif", 
      "add-sd-blackhole-p6-normal.gif", 
      "add-sd-blackhole-p7-normal.gif", 
      "add-sd-blackhole-p8-normal.gif", 
      "add-sd-blackhole-p9-normal.gif", 
      "add-sd-blackhole-p10-normal.gif", 
      "add-sd-blackhole-p11-normal.gif", 
      "add-sd-blackhole-p12-normal.gif", 
      "add-sd-blackhole-p13-normal.gif", 
      "add-sd-blackhole-p14-normal.gif", 
      "add-sd-blackhole-p15-normal.gif"
    ], 
    "overall_classification": null, 
    "description": "This GCHQ briefing from September 2009 describes the tools then available to analyse metadata collected on a massive scale: see the Intercept article Profiled: From Radio to Porn, British Spies Track Web Users\u2019 Online Identities, 25 September 2015.", 
    "plain_text": "add-sd-blackhole-p1-normal.gif: \n\ufeffBLACK HOLE ANALYTICS\r\n\r\nADD/SD briefing, September 2009\r\n\r\nTOP SECRET STRAP 1add-sd-blackhole-p2-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\nContents\r\n\r\n\u25a0\tDescribe the new breed of C2C tools\r\ndeveloped in Applied Research (TR)\r\n\r\n\u25a0\tScaling them up through the Next\r\nGeneration Events (NGE) projectadd-sd-blackhole-p3-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\nNext Generation Events Roadmap\r\n\r\nGTAC f\r\n\r\nConvergence 1\r\n\r\nCloud upscale\r\n\r\nI ntcmcl Profiling 2\r\n\r\nI ntcmcl\r\nProfiling 1\r\n\r\n-*0 * lOg\r\n\r\n-2G0 experts\r\n\r\nCapability development\r\n(including cA)\r\n\r\nLarge-scale contact\r\nchaining\r\n\r\nData mining and\r\nprofilingadd-sd-blackhole-p4-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\nNGE Analytical Capabilitiesadd-sd-blackhole-p5-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\n**0\r\n\r\nSome useful definitions\r\n\r\n\u2022\tPresence Event\r\n\r\n\u2022\tDescribes that an identifier was online, on an IP address, at a point in\r\ntime.\r\n\r\n\u2022\tSimple, atomic element.\r\n\r\n\u2022\tCan be very easily developed so are very diverse\r\n\r\n\u2022\tVery useful!\r\n\r\n\u2022\tTDI = Target Description Identifier\r\n\r\n\u2022\tHas a type, eg Yahoo-Y-Cookie\r\n\r\n\u2022\tAnd a value, eg tom123@yahoo\r\n\r\n\u2022\tGTDI = Generic Target Detection Identifier\r\n\r\n\u2022\tExpands the TDI concept to telephony e.g. A GSM location update\r\nmessageadd-sd-blackhole-p6-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\nSome more definitions\r\n\r\n\u2022\tBLACK HOLE: The large flat file storage where all the data sits\r\n\r\n\u2022\tAfter initial processing, and before being manipulated and correlated\r\nand loaded into the QFD database tables\r\n\r\n\u2022\tQFD: Question Focused Dataset (Database)\r\n\r\n- One for each tool: MUTANT BROTH, AUTO ASSOC etcadd-sd-blackhole-p7-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\nGOICjadd-sd-blackhole-p8-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\n^0\r\n\r\nQFD desktop...so far...\r\n\r\nEnables analysts to:\r\n\r\nCreate a profile of a target's online activities (Mutant Broth)\r\nFind other identifiers for a target (Auto Assoc)\r\n\r\nCreate a social network (Social Animal)\r\n\r\nInvestigate websites or web forums of interest (Karma Police,\r\nInfinite Monkeys, HRMAP)\r\n\r\nFind out who has been searching the web and for what\r\n(Memory Hole)\r\n\r\nFind out who has been looking at what on Google Earth\r\n(Marbled Gecko)add-sd-blackhole-p9-normal.gif: \n\ufeffConverged QFD desktop...by Dec...\r\n\r\n\u25a0\tEnables analysts to:\r\n\r\n\u25a0\tCreate a profile of a target's online activities alongside\r\ntelephony ( Evolved Mutant Broth)\r\n\r\n\u25a0\tFind alternative identifiers across telephony and the internet\r\n(Hard Assoc)\r\n\r\n\u25a0\tCreate a social network including telephony (Evolved Social\r\nAnimal)\r\n\r\n\u25a0\tFind out what has been happening in real time (Samuel Pepys)\r\n\r\nAll available on the desktop via Looking Glass plug-ins and Web\r\nGUIsadd-sd-blackhole-p10-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\n\u00abf\r\n\r\nSuccess story -TSS2 Nocon\r\n\r\n\u25a0 Slides removed - contact\tfor full\r\n\r\nversionadd-sd-blackhole-p11-normal.gif: \n\ufeffTOP SECRET STRAP1add-sd-blackhole-p12-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\nCapability Dev Workspace\r\n\r\nOh. this looks interesting -\r\nwhat does an analyst think?\r\n\r\nEasy access to data,\r\nhowever it is collected\r\n\r\nUse live data to\r\nw-ork on real problems\r\n\r\nPut the latest results\r\n\r\nProcessing power\r\nready to use\r\n\r\nimprovement\r\n\r\nHmm. new data... I wonder what\r\nhappens if I mine it like this...\r\n\r\nI ve just developed collection of\r\n\r\nWill this NSA algorithm help?\r\n\r\nIs that better?\r\n\r\nI'll put that\r\nprocessing on a\r\nfew more\r\nbearers...\r\n\r\nCollection\r\n\r\nengineer/\r\n\r\nresearch\r\n\r\nteam\r\n\r\nAnalytics'^\r\n\r\ndeveloper\r\n\r\nOr this?\r\n\r\nOK. but could you just...\r\n\r\nGood, but how about...\r\n\r\nCould you tweak it to...\r\n\r\nAnalyst with an\r\noperational problem\r\n\r\nOh heck. I've caught\r\nBin Laden\r\n\r\nThis data might be best viewed like this: take a look\t\r\nIs that better? L_\t\r\nm just add in some of those results...\t\r\n\r\nUser-interface\r\n\r\nspecialistadd-sd-blackhole-p13-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\nData Mining at scale\r\n\r\nExperiments with Cloud ongoing to enable\r\nanalysts to request and run MOAGs (large TNN\r\ngraphs) from the desktop\r\n\r\nDistillery will enable analysts to spot real time\r\nchanges to the data at scale (e.g. detection of\r\nimpossible travel)\r\n\r\nJoint Collaboration Environment (lnnov8) -\r\ntrialling running of large scale analytics using\r\nboth GCHQ and NSA data\r\n\r\nadd-sd-blackhole-p14-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\nFuture Implications\r\n\r\n\u25a0\tWe shall be able to:\r\n\r\n\u2022 easily monitor changes in our targets' profiles and networks\r\n\r\n\u25a0\tdevelop and trial new capabilities using real life analytical\r\nexperiments\r\n\r\n\u25a0\trespond quickly in a crisisadd-sd-blackhole-p15-normal.gif: \n\ufeffQuestions?\r\n\r\nTOP SECRET STRAP1\r\n\r\n|/BLAZING_SADDLES\r\n/NGE BLACK HOLE", 
    "sigads": [], 
    "overall_relto": [], 
    "countries_mentioned": [], 
    "link": "https://edwardsnowden.com/2015/10/03/black-hole-analytics/", 
    "document_topic": [
      "Internet Metadata"
    ], 
    "pub_date": "Sat, 03 Oct 2015 14:22:35 +0000", 
    "article_links": [
      "https://theintercept.com/2015/09/25/gchq-radio-porn-spies-track-web-users-online-identities/"
    ], 
    "categories": [
      "Revealed documents", 
      "auto assoc", 
      "black hole", 
      "blazing saddles", 
      "evolved mutant broth", 
      "evolved social animal", 
      "gchq_orig", 
      "gtac", 
      "hrmap", 
      "infinite monkeys", 
      "internet_metadata", 
      "karma police", 
      "looking glass", 
      "marbled gecko", 
      "memory hole", 
      "mutant broth", 
      "qfd", 
      "samuel pepys"
    ], 
    "title": "Black Hole Analytics", 
    "doc_text": "add-sd-blackhole-p1-normal.gif: \n\ufeffBLACK HOLE ANALYTICS\r\n\r\nADD/SD briefing, September 2009\r\n\r\nTOP SECRET STRAP 1add-sd-blackhole-p2-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\nContents\r\n\r\n\u25a0\tDescribe the new breed of C2C tools\r\ndeveloped in Applied Research (TR)\r\n\r\n\u25a0\tScaling them up through the Next\r\nGeneration Events (NGE) projectadd-sd-blackhole-p3-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\nNext Generation Events Roadmap\r\n\r\nGTAC f\r\n\r\nConvergence 1\r\n\r\nCloud upscale\r\n\r\nI ntcmcl Profiling 2\r\n\r\nI ntcmcl\r\nProfiling 1\r\n\r\n-*0 * lOg\r\n\r\n-2G0 experts\r\n\r\nCapability development\r\n(including cA)\r\n\r\nLarge-scale contact\r\nchaining\r\n\r\nData mining and\r\nprofilingadd-sd-blackhole-p4-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\nNGE Analytical Capabilitiesadd-sd-blackhole-p5-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\n**0\r\n\r\nSome useful definitions\r\n\r\n\u2022\tPresence Event\r\n\r\n\u2022\tDescribes that an identifier was online, on an IP address, at a point in\r\ntime.\r\n\r\n\u2022\tSimple, atomic element.\r\n\r\n\u2022\tCan be very easily developed so are very diverse\r\n\r\n\u2022\tVery useful!\r\n\r\n\u2022\tTDI = Target Description Identifier\r\n\r\n\u2022\tHas a type, eg Yahoo-Y-Cookie\r\n\r\n\u2022\tAnd a value, eg tom123@yahoo\r\n\r\n\u2022\tGTDI = Generic Target Detection Identifier\r\n\r\n\u2022\tExpands the TDI concept to telephony e.g. A GSM location update\r\nmessageadd-sd-blackhole-p6-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\nSome more definitions\r\n\r\n\u2022\tBLACK HOLE: The large flat file storage where all the data sits\r\n\r\n\u2022\tAfter initial processing, and before being manipulated and correlated\r\nand loaded into the QFD database tables\r\n\r\n\u2022\tQFD: Question Focused Dataset (Database)\r\n\r\n- One for each tool: MUTANT BROTH, AUTO ASSOC etcadd-sd-blackhole-p7-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\nGOICjadd-sd-blackhole-p8-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\n^0\r\n\r\nQFD desktop...so far...\r\n\r\nEnables analysts to:\r\n\r\nCreate a profile of a target's online activities (Mutant Broth)\r\nFind other identifiers for a target (Auto Assoc)\r\n\r\nCreate a social network (Social Animal)\r\n\r\nInvestigate websites or web forums of interest (Karma Police,\r\nInfinite Monkeys, HRMAP)\r\n\r\nFind out who has been searching the web and for what\r\n(Memory Hole)\r\n\r\nFind out who has been looking at what on Google Earth\r\n(Marbled Gecko)add-sd-blackhole-p9-normal.gif: \n\ufeffConverged QFD desktop...by Dec...\r\n\r\n\u25a0\tEnables analysts to:\r\n\r\n\u25a0\tCreate a profile of a target's online activities alongside\r\ntelephony ( Evolved Mutant Broth)\r\n\r\n\u25a0\tFind alternative identifiers across telephony and the internet\r\n(Hard Assoc)\r\n\r\n\u25a0\tCreate a social network including telephony (Evolved Social\r\nAnimal)\r\n\r\n\u25a0\tFind out what has been happening in real time (Samuel Pepys)\r\n\r\nAll available on the desktop via Looking Glass plug-ins and Web\r\nGUIsadd-sd-blackhole-p10-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\n\u00abf\r\n\r\nSuccess story -TSS2 Nocon\r\n\r\n\u25a0 Slides removed - contact\tfor full\r\n\r\nversionadd-sd-blackhole-p11-normal.gif: \n\ufeffTOP SECRET STRAP1add-sd-blackhole-p12-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\nCapability Dev Workspace\r\n\r\nOh. this looks interesting -\r\nwhat does an analyst think?\r\n\r\nEasy access to data,\r\nhowever it is collected\r\n\r\nUse live data to\r\nw-ork on real problems\r\n\r\nPut the latest results\r\n\r\nProcessing power\r\nready to use\r\n\r\nimprovement\r\n\r\nHmm. new data... I wonder what\r\nhappens if I mine it like this...\r\n\r\nI ve just developed collection of\r\n\r\nWill this NSA algorithm help?\r\n\r\nIs that better?\r\n\r\nI'll put that\r\nprocessing on a\r\nfew more\r\nbearers...\r\n\r\nCollection\r\n\r\nengineer/\r\n\r\nresearch\r\n\r\nteam\r\n\r\nAnalytics'^\r\n\r\ndeveloper\r\n\r\nOr this?\r\n\r\nOK. but could you just...\r\n\r\nGood, but how about...\r\n\r\nCould you tweak it to...\r\n\r\nAnalyst with an\r\noperational problem\r\n\r\nOh heck. I've caught\r\nBin Laden\r\n\r\nThis data might be best viewed like this: take a look\t\r\nIs that better? L_\t\r\nm just add in some of those results...\t\r\n\r\nUser-interface\r\n\r\nspecialistadd-sd-blackhole-p13-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\nData Mining at scale\r\n\r\nExperiments with Cloud ongoing to enable\r\nanalysts to request and run MOAGs (large TNN\r\ngraphs) from the desktop\r\n\r\nDistillery will enable analysts to spot real time\r\nchanges to the data at scale (e.g. detection of\r\nimpossible travel)\r\n\r\nJoint Collaboration Environment (lnnov8) -\r\ntrialling running of large scale analytics using\r\nboth GCHQ and NSA data\r\n\r\nadd-sd-blackhole-p14-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\nFuture Implications\r\n\r\n\u25a0\tWe shall be able to:\r\n\r\n\u2022 easily monitor changes in our targets' profiles and networks\r\n\r\n\u25a0\tdevelop and trial new capabilities using real life analytical\r\nexperiments\r\n\r\n\u25a0\trespond quickly in a crisisadd-sd-blackhole-p15-normal.gif: \n\ufeffQuestions?\r\n\r\nTOP SECRET STRAP1\r\n\r\n|/BLAZING_SADDLES\r\n/NGE BLACK HOLE", 
    "pdf": [
      "https://edwardsnowden.com/wp-content/uploads/2015/10/add-sd-blackhole-p1-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/add-sd-blackhole-p2-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/add-sd-blackhole-p3-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/add-sd-blackhole-p4-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/add-sd-blackhole-p5-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/add-sd-blackhole-p6-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/add-sd-blackhole-p7-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/add-sd-blackhole-p8-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/add-sd-blackhole-p9-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/add-sd-blackhole-p10-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/add-sd-blackhole-p11-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/add-sd-blackhole-p12-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/add-sd-blackhole-p13-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/add-sd-blackhole-p14-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/add-sd-blackhole-p15-normal.gif"
    ]
  }, 
  {
    "released_date": "20150925", 
    "overall_handling_caveats": [], 
    "id": "20150925|reportonarchitecturalrisk2012summary", 
    "document_date": "2012-03-12 00:00:00", 
    "codewords": [
      "BLACKHOLE"
    ], 
    "agency": [
      "GCHQ"
    ], 
    "sub_paragraphs_classifications": [
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": null, 
        "paragraph_text": "architecture-risk-2012-p1-normal.gif: ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap 1 report on architectural risk 2012 - summary ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap 1architecture-risk-2012-p2-normal.gif: ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 introduction 1.\tthe 2011 corporate technology risk identified our solution architecture as being one of the contributors to the high risk rating. in recent years a strong focus on delivery has resulted in an under investment in architecture. this will eventually have an impact on our ability to deliver. 2.\tthe december board meeting were concerned that investment decisions being made in the 2012/13 portfolio build could be non-optimal if architecture considerations were not taken into account and asked the following question: given our changes in mission and changes in the external environment (cyber defence, offensive cyber, increased partnering, increased data volumes, etc) which parts of our architecture are under most strain and so carry the most risk to this years investment 3.\tpart of the new dcto role is to define a technology vision and then champion improvements to the solution architecture at portfolio build time. however, it will take time to construct that vision. therefore in the interim a broad brush approach has been taken in order to allow some immediate advice to be given to the portfolio. 4.\twe have a defined a number of high level change drivers on the architecture (annex 1). these are changes in either our mission, ways of doing business or external technology which are relatively recent and were not taken into account when our current solution architecture was built. we have also represented our current solution architecture as a number of high level elements. we then assessed each change driver against the current solution architecture and identified those architectural elements most stressed by the drivers (annex 3 and annex 4). 5.\tthis has been done in a short period of time with only limited amounts of effort. there are therefore a number of caveats that need to be made: this is a broad brush, high level analysis. whilst we have consulted as widely as possible, we have inevitably not managed to consult everyone we would have liked to have involved we have restricted ourselves to the infrastructure and application layers (and so not explicitly considered the business layer) we are not attempting to define the to-be solution architecture. instead we have concentrated on identifying risks with the current architecture 2\tof 6 thts information is exempt from disclosure under the freedom of informatior^c^ool^jnc^navjx^ubjecuoexemplionijidot other uk information legislation. refer disclosure requests to gchq ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1architecture-risk-2012-p3-normal.gif: ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 recommendations 6.\tthis high-level architectural analysis has highlighted parts of the solution architecture which needs immediate attention. there are currently line items in the unconstrained portfolio build which will help address the three main concerns. it is recommended that these line items are prioritised in the filter and twist phase. big data. we need to develop an end-end big data strategy which covers expected data growth, tradecraft, qfd architecture, cloud architecture, black hole, the role of streaming analytics and the proposed new data centre. a series of experiments should be carried out between ta, tdb innovation, ictr and sd to de-risk some of the possible solutions. integrated analytics framework. we need to converge to a small number of analytics frameworks for use across our multiple missions which support the rapid deployment of experimental analytics tools and provide the apis required for fused analytics. security services. we need to provide an end to end and cohesive uplift to the capabilities used to support assured information sharing within and across our enterprise boundaries, with support to the information assurance agenda, ensuring the appropriate accessibility, releasibility and traceability. vision and strategy. the coherence we need in order to deliver against the drivers needs investment into the development of end to end technical vision and supporting technology strategies, supporting the business needs. the current \"redness\" in annex 3 demonstrates that there are some fundamental changes required to the architecture. whilst the first three recommendations will address some of the more urgent symptoms we need to also invest in addressing the underlying causes. 7.\tnsa are already some way down the path of instantiating their new architecture. their \"2017 vision: the future of nsa it\" has a small number of principles: smart data; virtualization and mobility. as we construct our equivalent vision we need, as a minimum, to be interoperable with nsa's new architecture. we should also look to take as much advantage as makes sense of nsas specific implementations. 8.\tfinally, please note this report was created over a short period of time with only limited amounts of effort. there is a need to establish an appropriate framework that allows a more considered view to be presented as input to future portfolio builds. 3\tof 6 this information is exempt from disclosure under the freedom of lnformatior^c^oo^n^na>^^ubcuoexemplioni*idot other uk information legislation. refer disclosure requests to gchq ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1architecture-risk-2012-p4-normal.gif: ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [
          "shrinkingresources"
        ], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 annex 1: change drivers 1.\tsize of access => vastly increased data volumes 2.\tincrease in number and type of customers (wider government, industry, third parties) i.e. our consumers -\tand more points where are customers interact with us (not just ep) 3.\tincrease in number and type of partners (sia, mod, industry, 3rd parties) i.e. our providers 4.\tnsa/us it efficiencies -\trationalisation of systems -\tmore integrated us intelligence community 5.\tincreased size of internet connectivity -\tone way, two way, covert -\tmore reliance on open source obtained from internet 6.\tincreased presence/activity on internet -\tscaling up of one (more implants, more supporting infrastructure etc) 7.\tspeed of change of internet services leading to: -\tlots of capability in experiment space -\tanalyst task becomes harder -\tanalyst - developer model -\tmore types of data -\tneed for more innovation (which needs open interfaces) 8.\tour wider integrated mission (sigint, domestic, ia, cyber defence, effects) 9.\tincreased need to take action in near real time 10.\tincreased emphasis on gchq's reputation (ia exemplar. legal, business continuity) 11.\tmajor technology trends: -\tmobile broadband and devices -\tspread of ssla/pns/ubiquitous encryption 12.\tmobility of our users 13.\tless money (finite/shrinking resources) -\tto build systems -\tsupport systems (power, space, cooling) 14.\tmore use of industry to build our capability 15.\tincreased amount of difficult work (in scale & complexity) placing more demand on our limited numbers of highly skilled people 16.\tvolatility of target networks 4\tof 6 this information is exempt from disclosure under the freedom of informatior^c^oo^n^na^^ubscuoexemplionijjder other uk information legislation. refer disclosure requests to gchq on ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1architecture-risk-2012-p5-normal.gif: ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 annex 3: mapping of drivers to architecture elements 5 of 6 this information is exempt from disclosure under the freedom of informationact^oooandmaybesu^ec^ other uk information legislation. refer disclosure requests to gchq ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1architecture-risk-2012-p6-normal.gif: ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 annex 4: summary of rag status of each architectural element business applications --------- i processing access launch platform target env lab mission management ------------' mission knowledge reporting/ response infrastructure audit/ accounting information transfer service active\t\t\t' content\t\tdesktop\t\tfacilities handling . sharing/ collaborati 6 of 6 this information is exempt from disclosure under the freedom of information act 2000 and may be s olher uk information legislaton. re'er disclosure requests to gchq on^ on under ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap1 ", 
        "paragraph_relto": []
      }
    ], 
    "pdf_paths": [
      "architecture-risk-2012-p1-normal.gif", 
      "architecture-risk-2012-p2-normal.gif", 
      "architecture-risk-2012-p3-normal.gif", 
      "architecture-risk-2012-p4-normal.gif", 
      "architecture-risk-2012-p5-normal.gif", 
      "architecture-risk-2012-p6-normal.gif"
    ], 
    "overall_classification": null, 
    "description": "This GCHQ report summary from 12 March 2012 discusses the impact of the move to a \u201cend-end big data strategy\u201d on the agency\u2019s infrastructure: see the Intercept article Profiled: From Radio to Porn, British Spies Track Web Users\u2019 Online Identities, 25 September 2015.", 
    "plain_text": "architecture-risk-2012-p1-normal.gif: \n\ufeffTOP SECRET STRAP 1\r\n\r\nReport on Architectural\r\nRisk 2012 - Summary\r\n\r\nTOP SECRET STRAP 1architecture-risk-2012-p2-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\nIntroduction\r\n\r\n1.\tThe 2011 Corporate Technology Risk identified our solution architecture as\r\nbeing one of the contributors to the High risk rating. In recent years a strong\r\nfocus on delivery has resulted in an under investment in architecture. This will\r\neventually have an impact on our ability to deliver.\r\n\r\n2.\tThe December board meeting were concerned that investment decisions\r\nbeing made in the 2012/13 portfolio build could be non-optimal if architecture\r\nconsiderations were not taken into account and asked the following question:\r\n\r\n\u201cGiven our changes in mission and changes in the external environment\r\n(Cyber defence, offensive cyber, increased partnering, increased data\r\nvolumes, etc) which parts of our architecture are under most strain and\r\nso carry the most risk to this year\u2019s investment \u201c\r\n\r\n3.\tPart of the new DCTO role is to define a technology vision and then champion\r\nimprovements to the solution architecture at portfolio build time. However, it\r\nwill take time to construct that vision. Therefore in the interim a broad brush\r\napproach has been taken in order to allow some immediate advice to be given\r\nto the portfolio.\r\n\r\n4.\tWe have a defined a number of high level change drivers on the architecture\r\n(Annex 1). These are changes in either our mission, ways of doing business or\r\nexternal technology which are relatively recent and were not taken into\r\naccount when our current solution architecture was built. We have also\r\nrepresented our current solution architecture as a number of high level\r\nelements. We then assessed each change driver against the current solution\r\narchitecture and identified those architectural elements most stressed by the\r\ndrivers (Annex 3 and Annex 4).\r\n\r\n5.\tThis has been done in a short period of time with only limited amounts of\r\neffort. There are therefore a number of caveats that need to be made:\r\n\r\n\u2022\tThis is a broad brush, high level analysis.\r\n\r\n\u2022\tWhilst we have consulted as widely as possible, we have inevitably not\r\nmanaged to consult everyone we would have liked to have involved\r\n\r\n\u2022\tWe have restricted ourselves to the infrastructure and application layers\r\n(and so not explicitly considered the business layer)\r\n\r\n\u2022\tWe are not attempting to define the \u201cto-be\u201d solution architecture. Instead\r\nwe have concentrated on identifying risks with the current architecture\r\n\r\n2\tof 6\r\n\r\nThts information is exempt from disclosure under the Freedom of Informatior^c^OOl^jnc^navJx^ubjecUoexemplionijidOT\r\nother UK information legislation. Refer disclosure requests to GCHQ\r\n\r\nTOP SECRET STRAP1architecture-risk-2012-p3-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\nRecommendations\r\n\r\n6.\tThis high-level architectural analysis has highlighted parts of the solution\r\narchitecture which needs immediate attention. There are currently line items in\r\nthe unconstrained portfolio build which will help address the three main\r\nconcerns. It is recommended that these line items are prioritised in the filter\r\nand twist phase.\r\n\r\n\u2022\tBig Data. We need to develop an end-end big data strategy which\r\n\r\ncovers expected data growth, tradecraft, QFD architecture, cloud\r\narchitecture, Black Hole, the role of streaming analytics and the\r\nproposed new data centre. A series of experiments should be carried\r\nout between TA, TDB innovation, ICTR and SD to de-risk some of the\r\npossible solutions.\r\n\r\n\u2022\tIntegrated Analytics Framework. We need to converge to a small\r\n\r\nnumber of analytics frameworks for use across our multiple missions\r\nwhich support the rapid deployment of experimental analytics tools\r\nand provide the APIs required for fused analytics.\r\n\r\n\u2022\tSecurity Services. We need to provide an end to end and cohesive\r\n\r\nuplift to the capabilities used to support assured information sharing\r\nwithin and across our enterprise boundaries, with support to the\r\nInformation Assurance agenda, ensuring the appropriate accessibility,\r\nreleasibility and traceability.\r\n\r\n\u2022\tVision and Strategy. The coherence we need in order to deliver against\r\n\r\nthe drivers needs investment into the development of end to end\r\ntechnical vision and supporting technology strategies, supporting the\r\nbusiness needs. The current \"redness\" in Annex 3 demonstrates that\r\nthere are some fundamental changes required to the architecture.\r\nWhilst the first three recommendations will address some of the more\r\nurgent symptoms we need to also invest in addressing the underlying\r\ncauses.\r\n\r\n7.\tNSA are already some way down the path of instantiating their new\r\narchitecture. Their \"2017 Vision: the Future of NSA IT\" has a small number of\r\nprinciples: smart data; virtualization and mobility. As we construct our\r\nequivalent vision we need, as a minimum, to be interoperable with NSA's new\r\narchitecture. We should also look to take as much advantage as makes sense\r\nof NSA\u2019s specific implementations.\r\n\r\n8.\tFinally, please note this report was created over a short period of time with\r\nonly limited amounts of effort. There is a need to establish an appropriate\r\nframework that allows a more considered view to be presented as input to\r\nfuture portfolio builds.\r\n\r\n3\tof 6\r\n\r\nThis information is exempt from disclosure under the Freedom of lnformatior^c^OO^n^na>^^ub\u00abcUoexemplioni*idOT\r\nother UK information legislation. Refer disclosure requests to GCHQ\r\n\r\nTOP SECRET STRAP1architecture-risk-2012-p4-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\nAnnex 1: Change Drivers\r\n\r\n1.\tSize of access => vastly increased data volumes\r\n\r\n2.\tIncrease in number and type of customers (wider government, industry,\r\nthird parties) i.e. our consumers\r\n\r\n-\tAnd more points where are customers interact with us (not just EP)\r\n\r\n3.\tIncrease in number and type of partners (SIA, MOD, industry, 3rd parties)\r\ni.e. our providers\r\n\r\n4.\tNSA/US IT efficiencies\r\n\r\n-\tRationalisation of systems\r\n\r\n-\tMore integrated US intelligence community\r\n\r\n5.\tIncreased size of internet connectivity\r\n\r\n-\tOne way, two way, covert\r\n\r\n-\tMore reliance on open source obtained from internet\r\n\r\n6.\tIncreased presence/activity on internet\r\n\r\n-\tScaling up of ONE (more implants, more supporting infrastructure etc)\r\n\r\n7.\tSpeed of change of internet services leading to:\r\n\r\n-\tLots of capability in experiment space\r\n\r\n-\tAnalyst task becomes harder\r\n\r\n-\tAnalyst - developer model\r\n\r\n-\tMore types of data\r\n\r\n-\tNeed for more innovation (which needs open interfaces)\r\n\r\n8.\tOur wider integrated mission (Sigint, Domestic, IA, Cyber Defence, Effects)\r\n\r\n9.\tIncreased need to take action in near real time\r\n\r\n10.\tIncreased emphasis on GCHQ's Reputation (IA exemplar. Legal, Business\r\nContinuity)\r\n\r\n11.\tMajor Technology trends:\r\n\r\n-\tMobile broadband and devices\r\n\r\n-\tSpread of SSLA/PNs/ubiquitous encryption\r\n\r\n12.\tMobility of our users\r\n\r\n13.\tLess money (Finite/shrinking resources)\r\n\r\n-\tTo build systems\r\n\r\n-\tSupport systems (power, space, cooling)\r\n\r\n14.\tMore use of industry to build our capability\r\n\r\n15.\tIncreased amount of difficult work (in scale & complexity) placing more\r\ndemand on our limited numbers of highly skilled people\r\n\r\n16.\tVolatility of target networks\r\n\r\n4\tof 6\r\n\r\nThis information is exempt from disclosure under the Freedom of Informatior^c^OO^n^na^^ubscUoexemplionijjder\r\nother UK information legislation. Refer disclosure requests to GCHQ on\r\n\r\nTOP SECRET STRAP1architecture-risk-2012-p5-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\nAnnex 3: Mapping of Drivers to Architecture Elements\r\n\r\n5 of 6\r\n\r\nThis information is exempt from disclosure under the Freedom of InformationAct^OOOandmaybesu^ec^\r\nother UK information legislation. Refer disclosure requests to GCHQ\r\n\r\nTOP SECRET STRAP1architecture-risk-2012-p6-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\nAnnex 4: Summary of RAG Status of each Architectural Element\r\n\r\nBusiness\r\n\r\nApplications\r\n\r\n--------- I\r\n\r\n\u25a0 Processing\r\nAccess \u25a0\r\n\r\nLaunch\r\n\r\nPlatform\r\n\r\nTarget Env\r\nLab\r\n\r\nMission\r\n\r\nManagement\r\n\r\n------------'\r\n\r\nMission\r\n\r\nKnowledge\r\n\r\nReporting/\r\n\r\nResponse\r\n\r\nInfrastructure\r\n\r\nAudit/\r\n\r\nAccounting\r\n\r\nInformation\r\n\r\nTransfer\r\n\r\nService\r\n\r\nActive\t\t\u2019\t'\t\t\r\nContent\t\tDesktop\t\tFacilities\r\nHandling .\t\t\t\t\r\n\r\nsharing/\r\n\r\ncollaborati\r\n\r\n6 Of 6\r\n\r\nThis information is exempt from disclosure under the Freedom of Information Act 2000 and may be s\r\nolher UK information legislaton. Re'er disclosure requests to GCHQ on^\r\n\r\n\r\n\r\non under\r\n\r\nTOP SECRET STRAP1", 
    "sigads": [], 
    "overall_relto": [], 
    "countries_mentioned": [
      "United Kingdom (GBR/GB)"
    ], 
    "link": "https://edwardsnowden.com/2015/10/03/report-on-architectural-risk-2012-summary/", 
    "document_topic": [
      "Internal Procedures"
    ], 
    "pub_date": "Sat, 03 Oct 2015 14:08:32 +0000", 
    "article_links": [
      "https://theintercept.com/2015/09/25/gchq-radio-porn-spies-track-web-users-online-identities/"
    ], 
    "categories": [
      "Revealed documents", 
      "black hole", 
      "cne", 
      "gchq_orig", 
      "ictr", 
      "internal_procedures", 
      "NSA", 
      "qfd"
    ], 
    "title": "Report on Architectural Risk 2012 \u2013 Summary", 
    "doc_text": "architecture-risk-2012-p1-normal.gif: \n\ufeffTOP SECRET STRAP 1\r\n\r\nReport on Architectural\r\nRisk 2012 - Summary\r\n\r\nTOP SECRET STRAP 1architecture-risk-2012-p2-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\nIntroduction\r\n\r\n1.\tThe 2011 Corporate Technology Risk identified our solution architecture as\r\nbeing one of the contributors to the High risk rating. In recent years a strong\r\nfocus on delivery has resulted in an under investment in architecture. This will\r\neventually have an impact on our ability to deliver.\r\n\r\n2.\tThe December board meeting were concerned that investment decisions\r\nbeing made in the 2012/13 portfolio build could be non-optimal if architecture\r\nconsiderations were not taken into account and asked the following question:\r\n\r\n\u201cGiven our changes in mission and changes in the external environment\r\n(Cyber defence, offensive cyber, increased partnering, increased data\r\nvolumes, etc) which parts of our architecture are under most strain and\r\nso carry the most risk to this year\u2019s investment \u201c\r\n\r\n3.\tPart of the new DCTO role is to define a technology vision and then champion\r\nimprovements to the solution architecture at portfolio build time. However, it\r\nwill take time to construct that vision. Therefore in the interim a broad brush\r\napproach has been taken in order to allow some immediate advice to be given\r\nto the portfolio.\r\n\r\n4.\tWe have a defined a number of high level change drivers on the architecture\r\n(Annex 1). These are changes in either our mission, ways of doing business or\r\nexternal technology which are relatively recent and were not taken into\r\naccount when our current solution architecture was built. We have also\r\nrepresented our current solution architecture as a number of high level\r\nelements. We then assessed each change driver against the current solution\r\narchitecture and identified those architectural elements most stressed by the\r\ndrivers (Annex 3 and Annex 4).\r\n\r\n5.\tThis has been done in a short period of time with only limited amounts of\r\neffort. There are therefore a number of caveats that need to be made:\r\n\r\n\u2022\tThis is a broad brush, high level analysis.\r\n\r\n\u2022\tWhilst we have consulted as widely as possible, we have inevitably not\r\nmanaged to consult everyone we would have liked to have involved\r\n\r\n\u2022\tWe have restricted ourselves to the infrastructure and application layers\r\n(and so not explicitly considered the business layer)\r\n\r\n\u2022\tWe are not attempting to define the \u201cto-be\u201d solution architecture. Instead\r\nwe have concentrated on identifying risks with the current architecture\r\n\r\n2\tof 6\r\n\r\nThts information is exempt from disclosure under the Freedom of Informatior^c^OOl^jnc^navJx^ubjecUoexemplionijidOT\r\nother UK information legislation. Refer disclosure requests to GCHQ\r\n\r\nTOP SECRET STRAP1architecture-risk-2012-p3-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\nRecommendations\r\n\r\n6.\tThis high-level architectural analysis has highlighted parts of the solution\r\narchitecture which needs immediate attention. There are currently line items in\r\nthe unconstrained portfolio build which will help address the three main\r\nconcerns. It is recommended that these line items are prioritised in the filter\r\nand twist phase.\r\n\r\n\u2022\tBig Data. We need to develop an end-end big data strategy which\r\n\r\ncovers expected data growth, tradecraft, QFD architecture, cloud\r\narchitecture, Black Hole, the role of streaming analytics and the\r\nproposed new data centre. A series of experiments should be carried\r\nout between TA, TDB innovation, ICTR and SD to de-risk some of the\r\npossible solutions.\r\n\r\n\u2022\tIntegrated Analytics Framework. We need to converge to a small\r\n\r\nnumber of analytics frameworks for use across our multiple missions\r\nwhich support the rapid deployment of experimental analytics tools\r\nand provide the APIs required for fused analytics.\r\n\r\n\u2022\tSecurity Services. We need to provide an end to end and cohesive\r\n\r\nuplift to the capabilities used to support assured information sharing\r\nwithin and across our enterprise boundaries, with support to the\r\nInformation Assurance agenda, ensuring the appropriate accessibility,\r\nreleasibility and traceability.\r\n\r\n\u2022\tVision and Strategy. The coherence we need in order to deliver against\r\n\r\nthe drivers needs investment into the development of end to end\r\ntechnical vision and supporting technology strategies, supporting the\r\nbusiness needs. The current \"redness\" in Annex 3 demonstrates that\r\nthere are some fundamental changes required to the architecture.\r\nWhilst the first three recommendations will address some of the more\r\nurgent symptoms we need to also invest in addressing the underlying\r\ncauses.\r\n\r\n7.\tNSA are already some way down the path of instantiating their new\r\narchitecture. Their \"2017 Vision: the Future of NSA IT\" has a small number of\r\nprinciples: smart data; virtualization and mobility. As we construct our\r\nequivalent vision we need, as a minimum, to be interoperable with NSA's new\r\narchitecture. We should also look to take as much advantage as makes sense\r\nof NSA\u2019s specific implementations.\r\n\r\n8.\tFinally, please note this report was created over a short period of time with\r\nonly limited amounts of effort. There is a need to establish an appropriate\r\nframework that allows a more considered view to be presented as input to\r\nfuture portfolio builds.\r\n\r\n3\tof 6\r\n\r\nThis information is exempt from disclosure under the Freedom of lnformatior^c^OO^n^na>^^ub\u00abcUoexemplioni*idOT\r\nother UK information legislation. Refer disclosure requests to GCHQ\r\n\r\nTOP SECRET STRAP1architecture-risk-2012-p4-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\nAnnex 1: Change Drivers\r\n\r\n1.\tSize of access => vastly increased data volumes\r\n\r\n2.\tIncrease in number and type of customers (wider government, industry,\r\nthird parties) i.e. our consumers\r\n\r\n-\tAnd more points where are customers interact with us (not just EP)\r\n\r\n3.\tIncrease in number and type of partners (SIA, MOD, industry, 3rd parties)\r\ni.e. our providers\r\n\r\n4.\tNSA/US IT efficiencies\r\n\r\n-\tRationalisation of systems\r\n\r\n-\tMore integrated US intelligence community\r\n\r\n5.\tIncreased size of internet connectivity\r\n\r\n-\tOne way, two way, covert\r\n\r\n-\tMore reliance on open source obtained from internet\r\n\r\n6.\tIncreased presence/activity on internet\r\n\r\n-\tScaling up of ONE (more implants, more supporting infrastructure etc)\r\n\r\n7.\tSpeed of change of internet services leading to:\r\n\r\n-\tLots of capability in experiment space\r\n\r\n-\tAnalyst task becomes harder\r\n\r\n-\tAnalyst - developer model\r\n\r\n-\tMore types of data\r\n\r\n-\tNeed for more innovation (which needs open interfaces)\r\n\r\n8.\tOur wider integrated mission (Sigint, Domestic, IA, Cyber Defence, Effects)\r\n\r\n9.\tIncreased need to take action in near real time\r\n\r\n10.\tIncreased emphasis on GCHQ's Reputation (IA exemplar. Legal, Business\r\nContinuity)\r\n\r\n11.\tMajor Technology trends:\r\n\r\n-\tMobile broadband and devices\r\n\r\n-\tSpread of SSLA/PNs/ubiquitous encryption\r\n\r\n12.\tMobility of our users\r\n\r\n13.\tLess money (Finite/shrinking resources)\r\n\r\n-\tTo build systems\r\n\r\n-\tSupport systems (power, space, cooling)\r\n\r\n14.\tMore use of industry to build our capability\r\n\r\n15.\tIncreased amount of difficult work (in scale & complexity) placing more\r\ndemand on our limited numbers of highly skilled people\r\n\r\n16.\tVolatility of target networks\r\n\r\n4\tof 6\r\n\r\nThis information is exempt from disclosure under the Freedom of Informatior^c^OO^n^na^^ubscUoexemplionijjder\r\nother UK information legislation. Refer disclosure requests to GCHQ on\r\n\r\nTOP SECRET STRAP1architecture-risk-2012-p5-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\nAnnex 3: Mapping of Drivers to Architecture Elements\r\n\r\n5 of 6\r\n\r\nThis information is exempt from disclosure under the Freedom of InformationAct^OOOandmaybesu^ec^\r\nother UK information legislation. Refer disclosure requests to GCHQ\r\n\r\nTOP SECRET STRAP1architecture-risk-2012-p6-normal.gif: \n\ufeffTOP SECRET STRAP1\r\n\r\nAnnex 4: Summary of RAG Status of each Architectural Element\r\n\r\nBusiness\r\n\r\nApplications\r\n\r\n--------- I\r\n\r\n\u25a0 Processing\r\nAccess \u25a0\r\n\r\nLaunch\r\n\r\nPlatform\r\n\r\nTarget Env\r\nLab\r\n\r\nMission\r\n\r\nManagement\r\n\r\n------------'\r\n\r\nMission\r\n\r\nKnowledge\r\n\r\nReporting/\r\n\r\nResponse\r\n\r\nInfrastructure\r\n\r\nAudit/\r\n\r\nAccounting\r\n\r\nInformation\r\n\r\nTransfer\r\n\r\nService\r\n\r\nActive\t\t\u2019\t'\t\t\r\nContent\t\tDesktop\t\tFacilities\r\nHandling .\t\t\t\t\r\n\r\nsharing/\r\n\r\ncollaborati\r\n\r\n6 Of 6\r\n\r\nThis information is exempt from disclosure under the Freedom of Information Act 2000 and may be s\r\nolher UK information legislaton. Re'er disclosure requests to GCHQ on^\r\n\r\n\r\n\r\non under\r\n\r\nTOP SECRET STRAP1", 
    "pdf": [
      "https://edwardsnowden.com/wp-content/uploads/2015/10/architecture-risk-2012-p1-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/architecture-risk-2012-p2-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/architecture-risk-2012-p3-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/architecture-risk-2012-p4-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/architecture-risk-2012-p5-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/architecture-risk-2012-p6-normal.gif"
    ]
  }, 
  {
    "released_date": "20150925", 
    "overall_handling_caveats": [], 
    "id": "20150925|blazingsaddles", 
    "document_date": "0000-00-00 00:00:00", 
    "codewords": [
      "BLAZING SADDLES", 
      "KARMA POLICE", 
      "AUTOASSOC", 
      "BLACKHOLE", 
      "MUTANT BROTH", 
      "SOCIAL ANTHROPOID"
    ], 
    "agency": [
      "GCHQ"
    ], 
    "sub_paragraphs_classifications": [
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": null, 
        "paragraph_text": "blazing-saddles-tools-p1-normal.gif: ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "top secret strap 1 comint ", 
        "paragraph_relto": []
      }, 
      {
        "paragraph_handling_caveats": [], 
        "paragraph_classification": "Top Secret", 
        "paragraph_text": "the maximum classification allowed on gcwiki is top secret strap1 comint. click to report inappropriate content. for gcwiki help contact: webteam\tsupport page blazing saddles from gcwiki jump to: navigation, search overview getting an account user requirements training/support overview blazing saddles icon.png brought to you by logo large.jpg [edit! overview blazing saddles is the tdb portion of the second pilot of the next generation events project under the better analysis programme. the primary objective of blazing saddles is to increase the supportability and scale of presence events stored for a number of key internet profiling tools. this will be achieved by the deployment of a range of applied research ofds and an instance of black hole to a tdb maintained experiment environment at cheltenham and also at bude. for more background to this work sec the (j: internet profiling se context provided by ba [edit] operational qfds bzs - useful info o events product centre qfds o loading status related products o social anthropoid o tdi database o tdis useful links o blazing saddles blog o spvspace group o black hole o nge input buffer o ng_e_g_ateway o supporting internet operations o nge gcforum o training tech o dev server info o (j:)technical documentation/sourceiz:) o technical documentation o infrastructure o qfd jeeqe deployments o operational deployment o reference system activities qfd type what it holds questions it answersblazing-saddles-tools-p2-normal.gif: autoassoc hrmp infinite monkeys karma police marbled gecko bulk unsclccted tdi-td1 system information correlations with confidence scores - information events\tabout which tdis have been seen at the same times and from the same ip addresses as other tdis. host-referrer relationships - information about events\thow p^p*0 8et to websites, including links followed and direct accesses. bulk unsclectcd v-bulletin identities - information about events\tmembership of webforums powered by v-bulletin software. bulk unsclectcd tdi-wcbsite correlations - information about which tdis have events\tbeen seen at approximately the same time, and from the same computer, as visits to websites. what other tdis belong to your target what technologies your target is using (so long as those technologies generate tdis) how do people get to my website of interest and where do they go to next? what websites have been visited from a given if? what v-bullctin accounts docs my target have? who uses this v-bulletin forum? where are the members of this v-bulletin forum based? which websites your target visits, and when/where those visits occurred who visits suspicious websites, and whcn/whcrc those visits occurred which other websites arc visited by people who visit a suspicious website which ip address and web browser were being used by your target when they visited a website content information about the use of google earth and google maps. when, where and from which ip address, particular areas of the earth have been looked at what areas of the earth were looked at from a particular ip address or computerblazing-saddles-tools-p3-normal.gif: (combined with mutant broth) who was looking at those areas of the earth memory hole mutant broth samuel pepys social animal information about _\tthe use of google content\t. . .. and similar services queries. information about _\ttdis which were events seen on the internet. samuel pepys is a near real time internet diarisation tool. it enables powerful ip stream events and analysis/profiling content\tby fusing all available traffic types in one place. it contains both unsclccted events and content. information about how users interact events\twith other users, and with filcs/picturcs when, where and from which ip address, particular searches were made what searches were made from a particular ip address or computer (combined with mutant broth) who made those searches whether your target is being seen by the collection system where and when your target was active what ip address your target was using what other tdis were seen on that ip address at a similar time what kinds of computers does you target use who shares a computer with your target are there any cne opportunities for your target? sp can answer a wide range of analytic questions based on all available traffic types it contains. who your target interacts with. interactions include chats, file-transfers and buddy-listsblazing-saddles-tools-p4-normal.gif: what filcs/picturcs/videos /video on the internet.\tyour target interacts with converged comms events database, allowing you to see who your targets have communicated with via phone, over the internet.\t what communications your or using\ttarget is engaged in converged\t who has your target been social\tevents\tchannels (c.g.\tcommunicating with anthropoid\t\tsending emails\t what communications have from a phone or\toccurred using a particular making voice\tlocator (ip address, cell tower, calls over the internet). will subsume social  animal and has replaced haustorium (now  decommissioned).\tetc) primarily imei defeats, including a severity score and associated correlations for\t is this handset cloned? golden axe\tevents\teach imei. other\t docs this selector uniquely selectors such as imsi. msc_gt,\tidentify my target? vlr_gt will be supported in future. r categories: blazing saddles | systems with accreditation information infoboxes | systems with expired accreditation ", 
        "paragraph_relto": []
      }
    ], 
    "pdf_paths": [
      "blazing-saddles-tools-p1-normal.gif", 
      "blazing-saddles-tools-p2-normal.gif", 
      "blazing-saddles-tools-p3-normal.gif", 
      "blazing-saddles-tools-p4-normal.gif"
    ], 
    "overall_classification": null, 
    "description": "This page from GCHQ\u2019s internal GCWiki describes the BLAZING SADDLES tool for handling huge amounts of metadata and the specialised analysis it supports: see the Intercept article Profiled: From Radio to Porn, British Spies Track Web Users\u2019 Online Identities, 25 September 2015.", 
    "plain_text": "blazing-saddles-tools-p1-normal.gif: \n\ufeffTOP SECRET STRAP 1 COMINT\r\n\r\nThe maximum classification allowed on GCWiki is TOP SECRET STRAP1 COMINT. Click to report\r\ninappropriate content.\r\n\r\nFor GCWiki help contact: webteam\tSupport page\r\n\r\nBlazing Saddles\r\n\r\nFrom GCWiki\r\n\r\nJump to: navigation, search\r\n\r\nOverview\r\n\r\nGetting an account\r\n\r\nUser requirements\r\n\r\nTraining/Support\r\n\r\nOverview\r\n\r\nBlazing saddles\r\nicon.png\r\n\r\nBrought to you\r\nby\r\n\r\nLogo large.jpg\r\n\r\n\t\t\t\t\r\n\t\t\t\t\r\n\r\n[edit! Overview\r\n\r\nBLAZING SADDLES is the TDB\r\nportion of the second pilot of the Next\r\nGeneration Events project under the Better\r\nAnalysis Programme. The primary\r\nobjective of BLAZING SADDLES is to\r\nincrease the supportability and scale of\r\npresence events stored for a number of\r\nkey internet profiling tools. This will be\r\nachieved by the deployment of a range of\r\nApplied Research OFDs and an instance\r\nof Black Hole to a TDB maintained\r\nexperiment environment at Cheltenham\r\nand also at Bude. For more background to\r\nthis work sec the (J: internet Profiling SE\r\nContext provided by BA\r\n\r\n[edit] Operational QFDs\r\n\r\n\u2022\tBzS - useful info\r\n\r\no Events Product Centre QFDs\r\no Loading Status\r\n\r\n\u2022\tRelated products\r\n\r\no Social Anthropoid\r\no TDI Database\r\no TDIs\r\n\r\n\u2022\tUseful Links\r\n\r\no Blazing Saddles Blog\r\no SpvSpace Group\r\no BLACK HOLE\r\no NGE Input Buffer\r\no NG_E_G_ateway\r\no Supporting Internet Operations\r\no NGE GCForum\r\no Training\r\n\r\n\u2022\tTech\r\n\r\no Dev Server Info\r\n\r\no (J:)Technical Documentation/SourceiZ:)\r\no Technical Documentation\r\no Infrastructure\r\no QFD JEEQE deployments\r\no Operational Deployment\r\no Reference system activities\r\n\r\nQFD\r\n\r\nTYpe What it holds\r\n\r\nQuestions it answersblazing-saddles-tools-p2-normal.gif: \n\ufeffAUTOASSOC\r\n\r\nHRM\u00fcp\r\n\r\nINFINITE MONKEYS\r\n\r\nKARMA POLICE\r\n\r\nMARBLED GECKO\r\n\r\nBulk unsclccted\r\n\r\nTDI-TD1 System information\r\n\r\ncorrelations with\r\nconfidence scores\r\n- information\r\n\r\nEvents\tabout which TDIs\r\n\r\nhave been seen at\r\nthe same times\r\nand from the\r\nsame IP addresses\r\nas other TDIs.\r\n\r\nHost-referrer\r\nrelationships -\r\ninformation about\r\n\r\nEvents\thow P^P*0 8et to\r\n\r\nwebsites,\r\n\r\nincluding links\r\nfollowed and\r\ndirect accesses.\r\n\r\nBulk unsclectcd\r\nv-bulletin\r\nidentities -\r\ninformation about\r\n\r\nEvents\tmembership of\r\n\r\nwebforums\r\npowered by\r\nv-bulletin\r\nsoftware.\r\n\r\nBulk unsclectcd\r\nTDI-wcbsite\r\ncorrelations -\r\ninformation about\r\nwhich TDIs have\r\n\r\nEvents\tbeen seen at\r\n\r\napproximately the\r\nsame time, and\r\nfrom the same\r\ncomputer, as\r\nvisits to websites.\r\n\r\n\u2022\tWhat other TDIs belong to\r\nyour target\r\n\r\n\u2022\tWhat technologies your target\r\nis using (so long as those\r\ntechnologies generate TDIs)\r\n\r\n\u2022\tHow do people get to my\r\nwebsite of interest and where\r\ndo they go to next?\r\n\r\n\u2022\tWhat websites have been\r\nvisited from a given IF?\r\n\r\n\u2022\tWhat v-bullctin accounts docs\r\nmy target have?\r\n\r\n\u2022\tWho uses this v-bulletin\r\nforum?\r\n\r\n\u2022\tWhere are the members of this\r\nv-bulletin forum based?\r\n\r\n\u2022\tWhich websites your target\r\nvisits, and when/where those\r\nvisits occurred\r\n\r\n\u2022\tWho visits suspicious\r\nwebsites, and whcn/whcrc\r\nthose visits occurred\r\n\r\n\u2022\tWhich other websites arc\r\nvisited by people who visit a\r\nsuspicious website\r\n\r\n\u2022\tWhich IP address and web\r\nbrowser were being used by\r\nyour target when they visited a\r\nwebsite\r\n\r\nContent\r\n\r\nInformation about\r\nthe use of Google\r\nEarth and Google\r\nMaps.\r\n\r\n\u2022\tWhen, where and from which\r\nIP address, particular areas of\r\nthe earth have been looked at\r\n\r\n\u2022\tWhat areas of the earth were\r\nlooked at from a particular IP\r\naddress or computerblazing-saddles-tools-p3-normal.gif: \n\ufeff(Combined with MUTANT\r\nBROTH) Who was looking at\r\nthose areas of the earth\r\n\r\nMEMORY HOLE\r\n\r\nMUTANT BROTH\r\n\r\nSAMUEL PEPYS\r\n\r\nSOCIAL ANIMAL\r\n\r\nInformation about\r\n\r\n_\tthe use of Google\r\n\r\nContent\t. . ..\r\n\r\nand similar\r\n\r\nservices queries.\r\n\r\nInformation about\r\n\r\n_\tTDIs which were\r\n\r\nEvents\r\n\r\nseen on the\r\nInternet.\r\n\r\nSAMUEL\r\nPEPYS is a near\r\nreal time Internet\r\ndiarisation tool. It\r\nenables powerful\r\nIP stream\r\n\r\nEvents and analysis/profiling\r\n\r\nContent\tby fusing all\r\n\r\navailable traffic\r\ntypes in one\r\nplace. It contains\r\nboth unsclccted\r\nevents and\r\ncontent.\r\n\r\nInformation about\r\nhow users interact\r\n\r\nEvents\twith other users,\r\n\r\nand with\r\nfilcs/picturcs\r\n\r\n\u2022\tWhen, where and from which\r\nIP address, particular searches\r\nwere made\r\n\r\n\u2022\tWhat searches were made\r\nfrom a particular IP address or\r\ncomputer\r\n\r\n\u2022\t(Combined with MUTANT\r\nBROTH) Who made those\r\nsearches\r\n\r\n\u2022\tWhether your target is being\r\nseen by the collection system\r\n\r\n\u2022\tWhere and when your target\r\nwas active\r\n\r\n\u2022\tWhat IP address your target\r\nwas using\r\n\r\n\u2022\tWhat other TDIs were seen on\r\nthat IP address at a similar\r\ntime\r\n\r\n\u2022\tWhat kinds of computers does\r\nyou target use\r\n\r\n\u2022\tWho shares a computer with\r\nyour target\r\n\r\n\u2022\tAre there any CNE\r\nopportunities for your target?\r\n\r\n\u2022 SP can answer a wide range of\r\nanalytic questions based on all\r\navailable traffic types it\r\ncontains.\r\n\r\n\u2022 Who your target interacts\r\nwith. Interactions include\r\nchats, file-transfers and\r\nbuddy-listsblazing-saddles-tools-p4-normal.gif: \n\ufeff\t\t\t\u2022 What filcs/picturcs/videos\r\n\t\t/video on the Internet.\tyour target interacts with\r\n\t\tConverged\t\r\n\t\tcomms events\t\r\n\t\tdatabase, allowing you to see who your targets have communicated with via phone, over the internet.\t\u2022 What communications your\r\n\t\tor using\ttarget is engaged in\r\n\t\tconverged\t\u2022 Who has your target been\r\nSOCIAL\tEvents\tchannels (c.g.\tcommunicating with\r\nANTHROPOID\t\tsending emails\t\u2022 What communications have\r\n\t\tfrom a phone or\toccurred using a particular\r\n\t\tmaking voice\tlocator (IP address, cell tower,\r\n\t\tcalls over the internet). Will subsume SOCIAL  ANIMAL and has replaced HAUSTORIUM (now  decommissioned).\tetc)\r\n\t\tPrimarily IMEI defeats, including a severity score and associated correlations for\t\u2022 Is this handset cloned?\r\nGOLDEN AXE\tEvents\teach IMEI. Other\t\u2022 Docs this selector uniquely\r\n\t\tselectors such as IMSI. MSC_GT,\tidentify my target?\r\n\t\tVLR_GT will be\t\r\n\t\tsupported in future.\t\r\nr\t\t\t\r\n\t\t\t\r\n\r\nCategories: BLAZING SADDLES | Systems with accreditation information infoboxes | Systems with\r\nexpired accreditation", 
    "sigads": [], 
    "overall_relto": [], 
    "countries_mentioned": [], 
    "link": "https://edwardsnowden.com/2015/10/03/blazing-saddles/", 
    "document_topic": [
      "Internet Metadata"
    ], 
    "pub_date": "Sat, 03 Oct 2015 14:02:19 +0000", 
    "article_links": [
      "https://theintercept.com/2015/09/25/gchq-radio-porn-spies-track-web-users-online-identities/"
    ], 
    "categories": [
      "Revealed documents", 
      "autoassoc", 
      "black hole", 
      "blazing saddles", 
      "bude", 
      "cheltenham", 
      "cne", 
      "gchq_orig", 
      "gcwiki", 
      "golden axe", 
      "google", 
      "hrmap", 
      "infinite monkeys", 
      "internet_metadata", 
      "karma police", 
      "marbled gecko", 
      "memory hole", 
      "mutant broth", 
      "samuel pepys", 
      "social animal", 
      "social anthropoid"
    ], 
    "title": "Blazing Saddles", 
    "doc_text": "blazing-saddles-tools-p1-normal.gif: \n\ufeffTOP SECRET STRAP 1 COMINT\r\n\r\nThe maximum classification allowed on GCWiki is TOP SECRET STRAP1 COMINT. Click to report\r\ninappropriate content.\r\n\r\nFor GCWiki help contact: webteam\tSupport page\r\n\r\nBlazing Saddles\r\n\r\nFrom GCWiki\r\n\r\nJump to: navigation, search\r\n\r\nOverview\r\n\r\nGetting an account\r\n\r\nUser requirements\r\n\r\nTraining/Support\r\n\r\nOverview\r\n\r\nBlazing saddles\r\nicon.png\r\n\r\nBrought to you\r\nby\r\n\r\nLogo large.jpg\r\n\r\n\t\t\t\t\r\n\t\t\t\t\r\n\r\n[edit! Overview\r\n\r\nBLAZING SADDLES is the TDB\r\nportion of the second pilot of the Next\r\nGeneration Events project under the Better\r\nAnalysis Programme. The primary\r\nobjective of BLAZING SADDLES is to\r\nincrease the supportability and scale of\r\npresence events stored for a number of\r\nkey internet profiling tools. This will be\r\nachieved by the deployment of a range of\r\nApplied Research OFDs and an instance\r\nof Black Hole to a TDB maintained\r\nexperiment environment at Cheltenham\r\nand also at Bude. For more background to\r\nthis work sec the (J: internet Profiling SE\r\nContext provided by BA\r\n\r\n[edit] Operational QFDs\r\n\r\n\u2022\tBzS - useful info\r\n\r\no Events Product Centre QFDs\r\no Loading Status\r\n\r\n\u2022\tRelated products\r\n\r\no Social Anthropoid\r\no TDI Database\r\no TDIs\r\n\r\n\u2022\tUseful Links\r\n\r\no Blazing Saddles Blog\r\no SpvSpace Group\r\no BLACK HOLE\r\no NGE Input Buffer\r\no NG_E_G_ateway\r\no Supporting Internet Operations\r\no NGE GCForum\r\no Training\r\n\r\n\u2022\tTech\r\n\r\no Dev Server Info\r\n\r\no (J:)Technical Documentation/SourceiZ:)\r\no Technical Documentation\r\no Infrastructure\r\no QFD JEEQE deployments\r\no Operational Deployment\r\no Reference system activities\r\n\r\nQFD\r\n\r\nTYpe What it holds\r\n\r\nQuestions it answersblazing-saddles-tools-p2-normal.gif: \n\ufeffAUTOASSOC\r\n\r\nHRM\u00fcp\r\n\r\nINFINITE MONKEYS\r\n\r\nKARMA POLICE\r\n\r\nMARBLED GECKO\r\n\r\nBulk unsclccted\r\n\r\nTDI-TD1 System information\r\n\r\ncorrelations with\r\nconfidence scores\r\n- information\r\n\r\nEvents\tabout which TDIs\r\n\r\nhave been seen at\r\nthe same times\r\nand from the\r\nsame IP addresses\r\nas other TDIs.\r\n\r\nHost-referrer\r\nrelationships -\r\ninformation about\r\n\r\nEvents\thow P^P*0 8et to\r\n\r\nwebsites,\r\n\r\nincluding links\r\nfollowed and\r\ndirect accesses.\r\n\r\nBulk unsclectcd\r\nv-bulletin\r\nidentities -\r\ninformation about\r\n\r\nEvents\tmembership of\r\n\r\nwebforums\r\npowered by\r\nv-bulletin\r\nsoftware.\r\n\r\nBulk unsclectcd\r\nTDI-wcbsite\r\ncorrelations -\r\ninformation about\r\nwhich TDIs have\r\n\r\nEvents\tbeen seen at\r\n\r\napproximately the\r\nsame time, and\r\nfrom the same\r\ncomputer, as\r\nvisits to websites.\r\n\r\n\u2022\tWhat other TDIs belong to\r\nyour target\r\n\r\n\u2022\tWhat technologies your target\r\nis using (so long as those\r\ntechnologies generate TDIs)\r\n\r\n\u2022\tHow do people get to my\r\nwebsite of interest and where\r\ndo they go to next?\r\n\r\n\u2022\tWhat websites have been\r\nvisited from a given IF?\r\n\r\n\u2022\tWhat v-bullctin accounts docs\r\nmy target have?\r\n\r\n\u2022\tWho uses this v-bulletin\r\nforum?\r\n\r\n\u2022\tWhere are the members of this\r\nv-bulletin forum based?\r\n\r\n\u2022\tWhich websites your target\r\nvisits, and when/where those\r\nvisits occurred\r\n\r\n\u2022\tWho visits suspicious\r\nwebsites, and whcn/whcrc\r\nthose visits occurred\r\n\r\n\u2022\tWhich other websites arc\r\nvisited by people who visit a\r\nsuspicious website\r\n\r\n\u2022\tWhich IP address and web\r\nbrowser were being used by\r\nyour target when they visited a\r\nwebsite\r\n\r\nContent\r\n\r\nInformation about\r\nthe use of Google\r\nEarth and Google\r\nMaps.\r\n\r\n\u2022\tWhen, where and from which\r\nIP address, particular areas of\r\nthe earth have been looked at\r\n\r\n\u2022\tWhat areas of the earth were\r\nlooked at from a particular IP\r\naddress or computerblazing-saddles-tools-p3-normal.gif: \n\ufeff(Combined with MUTANT\r\nBROTH) Who was looking at\r\nthose areas of the earth\r\n\r\nMEMORY HOLE\r\n\r\nMUTANT BROTH\r\n\r\nSAMUEL PEPYS\r\n\r\nSOCIAL ANIMAL\r\n\r\nInformation about\r\n\r\n_\tthe use of Google\r\n\r\nContent\t. . ..\r\n\r\nand similar\r\n\r\nservices queries.\r\n\r\nInformation about\r\n\r\n_\tTDIs which were\r\n\r\nEvents\r\n\r\nseen on the\r\nInternet.\r\n\r\nSAMUEL\r\nPEPYS is a near\r\nreal time Internet\r\ndiarisation tool. It\r\nenables powerful\r\nIP stream\r\n\r\nEvents and analysis/profiling\r\n\r\nContent\tby fusing all\r\n\r\navailable traffic\r\ntypes in one\r\nplace. It contains\r\nboth unsclccted\r\nevents and\r\ncontent.\r\n\r\nInformation about\r\nhow users interact\r\n\r\nEvents\twith other users,\r\n\r\nand with\r\nfilcs/picturcs\r\n\r\n\u2022\tWhen, where and from which\r\nIP address, particular searches\r\nwere made\r\n\r\n\u2022\tWhat searches were made\r\nfrom a particular IP address or\r\ncomputer\r\n\r\n\u2022\t(Combined with MUTANT\r\nBROTH) Who made those\r\nsearches\r\n\r\n\u2022\tWhether your target is being\r\nseen by the collection system\r\n\r\n\u2022\tWhere and when your target\r\nwas active\r\n\r\n\u2022\tWhat IP address your target\r\nwas using\r\n\r\n\u2022\tWhat other TDIs were seen on\r\nthat IP address at a similar\r\ntime\r\n\r\n\u2022\tWhat kinds of computers does\r\nyou target use\r\n\r\n\u2022\tWho shares a computer with\r\nyour target\r\n\r\n\u2022\tAre there any CNE\r\nopportunities for your target?\r\n\r\n\u2022 SP can answer a wide range of\r\nanalytic questions based on all\r\navailable traffic types it\r\ncontains.\r\n\r\n\u2022 Who your target interacts\r\nwith. Interactions include\r\nchats, file-transfers and\r\nbuddy-listsblazing-saddles-tools-p4-normal.gif: \n\ufeff\t\t\t\u2022 What filcs/picturcs/videos\r\n\t\t/video on the Internet.\tyour target interacts with\r\n\t\tConverged\t\r\n\t\tcomms events\t\r\n\t\tdatabase, allowing you to see who your targets have communicated with via phone, over the internet.\t\u2022 What communications your\r\n\t\tor using\ttarget is engaged in\r\n\t\tconverged\t\u2022 Who has your target been\r\nSOCIAL\tEvents\tchannels (c.g.\tcommunicating with\r\nANTHROPOID\t\tsending emails\t\u2022 What communications have\r\n\t\tfrom a phone or\toccurred using a particular\r\n\t\tmaking voice\tlocator (IP address, cell tower,\r\n\t\tcalls over the internet). Will subsume SOCIAL  ANIMAL and has replaced HAUSTORIUM (now  decommissioned).\tetc)\r\n\t\tPrimarily IMEI defeats, including a severity score and associated correlations for\t\u2022 Is this handset cloned?\r\nGOLDEN AXE\tEvents\teach IMEI. Other\t\u2022 Docs this selector uniquely\r\n\t\tselectors such as IMSI. MSC_GT,\tidentify my target?\r\n\t\tVLR_GT will be\t\r\n\t\tsupported in future.\t\r\nr\t\t\t\r\n\t\t\t\r\n\r\nCategories: BLAZING SADDLES | Systems with accreditation information infoboxes | Systems with\r\nexpired accreditation", 
    "pdf": [
      "https://edwardsnowden.com/wp-content/uploads/2015/10/blazing-saddles-tools-p1-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/blazing-saddles-tools-p2-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/blazing-saddles-tools-p3-normal.gif", 
      "https://edwardsnowden.com/wp-content/uploads/2015/10/blazing-saddles-tools-p4-normal.gif"
    ]
  }
]